{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from alibi.explainers import AnchorText\n",
    "from alibi.datasets import fetch_movie_sentiment\n",
    "from alibi.utils.download import spacy_model\n",
    "from alibi.utils.lang_model import DistilbertBaseUncased, BertBaseUncased, RobertaBase\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load movie review dataset\n",
    "\n",
    "The `fetch_movie_sentiment` function returns a `Bunch` object containing the features, the targets and the target names for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = fetch_movie_sentiment()\n",
    "movies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies.data\n",
    "labels = movies.target\n",
    "target_names = movies.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(data, labels, test_size=.2, random_state=42)\n",
    "train, val, train_labels, val_labels = train_test_split(train, train_labels, test_size=.1, random_state=42)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply CountVectorizer to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(vectorizer.transform(train), train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: clf.predict(vectorizer.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9801624284382905\n",
      "Validation accuracy 0.7544910179640718\n",
      "Test accuracy 0.7589841878294202\n"
     ]
    }
   ],
   "source": [
    "preds_train = predict_fn(train)\n",
    "preds_val = predict_fn(val)\n",
    "preds_test = predict_fn(test)\n",
    "print('Train accuracy', accuracy_score(train_labels, preds_train))\n",
    "print('Validation accuracy', accuracy_score(val_labels, preds_val))\n",
    "print('Test accuracy', accuracy_score(test_labels, preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spaCy model\n",
    "\n",
    "English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'en_core_web_md'\n",
    "spacy_model(model=model)\n",
    "nlp = spacy.load(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "lang_model = DistilbertBaseUncased()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 299  379  997 1601  264  229 1774 1968  458  252]\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.choice(len(test), size=10, replace=False)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following keys are incorrect: punctuation, prec_mask_templates, filling_method\n",
      "The following keys are incorrect: prec_mask_templates\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"top_n\": 50,\n",
    "    \"sample_proba\": 0.5,\n",
    "    \"filling_method\": 'parallel',\n",
    "    \"prec_mask_templates\": 0.1,\n",
    "    \"punctuation\": string.punctuation\n",
    "}\n",
    "\n",
    "explainer_sim = AnchorText(nlp=nlp, sampling_method=\"similarity\", predictor=predict_fn, **config)\n",
    "explainer_lm = AnchorText(language_model=lang_model, sampling_method=\"language_model\", predictor=predict_fn, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_explanation(explanation) -> str:\n",
    "    s = ''\n",
    "    s += 'Anchor: %s\\n' % (' AND '.join(explanation.anchor))\n",
    "    s += 'Precision: %.2f\\n' % explanation.precision\n",
    "    \n",
    "    # print examples covered as True\n",
    "    s += '\\n\\nExamples where anchor applies and model predicts %s:\\n' % pred\n",
    "    if len(explanation.raw['examples']):\n",
    "        s += '\\n'.join([x for x in explanation.raw['examples'][-1]['covered_true']])\n",
    "    \n",
    "    # print examples covered as False\n",
    "    s += '\\n\\nExamples where anchor applies and model predicts %s:\\n' % alternative\n",
    "    if len(explanation.raw['examples']):\n",
    "        s += '\\n'.join([x for x in explanation.raw['examples'][-1]['covered_false']])\n",
    "    \n",
    "    s += '\\n\\n\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = movies.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f34e82d0ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f34e82d0ee0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[0]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text, threshold=0.95)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: a fantastically vital movie that manages to invest real humor , sensuality , and sympathy into a story about two adolescent boys .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: manages AND about\n",
      "Precision: 0.95\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "no fantastically vital episode whatever manages to aquire financial humor , sensuality , and animosity into another story about two adolescent boys .\n",
      "a fantastically considerable porno that manages to grow real humor , depravity , and fondness into any narrative about two adolescent boys .\n",
      "an fantastically vital scene that manages to invest real humor , sensuality , and sympathy across some story about two adolescent boys .\n",
      "the depressingly vital movie that manages to invest real humor , fleshy , and sympathy within any story about two asian youths .\n",
      "any fantastically vital movie that manages to invest real absurdity , altruism , and ire into the writer about two adolescent ladies .\n",
      "this enormously responsible cinema that manages to continue real humour , cowardice , and fondness into each fable about two adolescent chaps .\n",
      "a fantastically vital movie which manages to lend ultimate comedy , ambition , and affectionate past any protagonist about two adolescent ages .\n",
      "a exceptionally vital movie that manages to invest real snark , fondness , and uproar until both plot about two adolescent boys .\n",
      "both fantastically significant movie that manages to invest willing humor , sensuality , and sympathy into any prologue about two adolescent boys .\n",
      "a fantastically necessary porn whatever manages to benefit real humor , sensuality , and sympathy into a story about two adolescent boys .\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "the fantastically vital flick whatever manages to invest real humor , sensuality , and affectionate because some story about two gay men .\n",
      "any fantastically vital movie that manages to invest same humor , depravity , and sympathy after a story about two suicidal boys .\n",
      "a extremly satisfactory movie whatever manages to invest immovable humor , sensuality , and sympathy behind a tome about two rowdy tots .\n",
      "some fantastically newsworthy cinematography that manages to invest fake humor , curiosity , and sympathy into a saga about two erotic boys .\n",
      "an fantastically vital movie whatever manages to sustain financial comedian , gluttony , and sympathy until some story about two adolescent boys .\n",
      "a unbelievably imperative tv that manages to invest ultimate humor , sensuality , and compassion onto a story about two adolescent mothers .\n",
      "a fantastically vital horror that manages to invest little humour , sensuality , and outcry onto any writer about two chested boys .\n",
      "a unnaturally vital movie that manages to benefit little humor , envy , and sympathy upon a foreshadowing about two naughty olds .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: manages AND two\n",
      "Precision: 0.97\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "a fantastically vital movie serial manages to invest real humor, morality, imp comical adventure of fantasies involving two adolescent boys.\n",
      "a fantastically vital movie show manages to invest within humor, heroism, im humor sentimental hero scenes towards two adolescent boys.\n",
      "a fantastically vital movie character manages to invest amidst humor, imagination, im qui and con stories portraying two adolescent boys.\n",
      "a fantastically vital movie character manages to invest her humor, fantasy, and nu qui emotional while and two adolescent boys.\n",
      "a fantastically vital movie poster manages to invest its humor, ambition, und em of romance stunts entertaining two adolescent boys.\n",
      "a fantastically vital movie maker manages to invest out humor, funny, daring funny the con jokes featuring two adolescent boys.\n",
      "a fantastically vital movie company manages to invest beyond humor, magic, drama moral et or while involves two adolescent boys.\n",
      "a fantastically vital movie noir manages to invest into humor, satire, une so with love sequences amongst two adolescent boys.\n",
      "a fantastically vital movie poster manages to invest his humor, realistic, often or social to while throughout two adolescent boys.\n",
      "a fantastically vital movie romance manages to invest within humor, fun, comic adventure imp imp fun alongside two adolescent boys.\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "while teen comedy movie script manages to invest more dignity, sensuality, and sympathy tell a story uniting two adolescent kids.\n",
      "a sexy acclaimed movie that manages to invest his purity, sensuality, and sympathy into a story about two local boys.\n",
      "• fantastically vital movie series manages by invest the humor, sensuality, and sympathy through comedic narratives about two adolescent boys.\n",
      "any fantastically vital movie title manages in invest to humor, sensuality, and sympathy – supernatural stories about two adolescent boys.\n",
      "that fantastically staged movie star manages to add real humor, fantasy, and sympathy – a story about two little boys.\n",
      "vincent exhibits vital fact that manages to recapture real drama, sensuality, feminine sympathy tell a story spanning two teen boys.\n",
      "a fantastically vital prose that manages to generate real humor, sensuality, passionate sympathy between a story offering two contrasting layers.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/workspace/alibi/alibi/explainers/anchor_text.py:116: UserWarning: [W008] Evaluating Lexeme.similarity based on empty vectors.\n",
      "  by_similarity = sorted(queries, key=lambda w: word_vocab.similarity(w), reverse=True)[:self.n_similar]\n",
      "/home/robert/workspace/alibi/alibi/explainers/anchor_text.py:127: UserWarning: [W008] Evaluating Lexeme.similarity based on empty vectors.\n",
      "  similarities.append(word_vocab.similarity(lexeme))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[1]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: there is a refreshing absence of cynicism in stuart little 2--quite a rarity , even in the family film market . eventually , it wins you over .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: refreshing AND family AND even AND film AND market AND absence AND in\n",
      "Precision: 0.95\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "there is an refreshing absence of cynicism on stuart shy 2 - level a occurance , even in each family film market . eventually , it sees you out .\n",
      "there is a refreshing absence because cynicism in australian own 2 - -quite each greatness , even in these family film market . eventually , it selects you out .\n",
      "there is a refreshing absence with hostility in stuart good 2 - -quite any craftsmanship , even in the family film market . even , it wins you over .\n",
      "there is each refreshing absence throughout cynicism although irish little 2 - anything both jewel , even in the family film market . eventually , it wins you out .\n",
      "there is every refreshing absence during cynicism midst irish tiny 2 - side the popularity , even in the family film market . mysteriously , it bids you over .\n",
      "there is any refreshing absence whether helplessness over scottish rough 2 - thing a craftsmanship , even in both family film market . eventually , it receives you over .\n",
      "there is every refreshing absence of cynicism in swift little 2 - thing a rarity , even in a family film market . eventually , it wins you over .\n",
      "there is a refreshing absence about mistrust to british little 2 - -quite a imaginable , even in the family film market . back , it selects you over .\n",
      "there is any refreshing absence toward cynicism although stuart old 2 - -quite every allure , even in any family film market . eventually , it sweeps you up .\n",
      "there is a refreshing absence that cynicism with stuart short 2 - someone a allure , even in the family film market . thus , it knows you over .\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "there is some refreshing absence before cynicism in stuart little 2 - -quite some irregardless , even in this family film market . thus , it wins you up .\n",
      "there is another refreshing absence that tedium in christian bad 2 - -quite a rarity , even in all family film market . then , it wins you over .\n",
      "there is a refreshing absence of ignorance amid stuart little 2 - anyone a uniqueness , even in another family film market . eventually , it hopes you over .\n",
      "there is a refreshing absence for cynicism in stuart little 2 - person a infatuation , even in the family film market . shortly , it wins you over .\n",
      "there is a refreshing absence upon cynicism in stuart little 2 - -quite any rarity , even in all family film market . eventually , it wins you over .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: refreshing AND film AND family AND market AND you AND rarity AND absence AND it\n",
      "Precision: 0.95\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "there is his refreshing absence of cynicism aboard stuart little appears - - quite into rarity, even from the family film market. yes, it wants you funny.\n",
      "there is always refreshing absence of cynicism or stuart little faces - - quite below rarity, even entering the family film market. yet, it pulls you forget.\n",
      "there is fairly refreshing absence of cynicism behind stuart little works - - quite of rarity, even through the family film market. so, it reminds you understand.\n",
      "there is the refreshing absence of cynicism under stuart little guy - - quite their rarity, even concerning the family film market. moreover, it seems you both.\n",
      "there is the refreshing absence of cynicism within stuart little eyes - - quite much rarity, even upon the family film market. oh, it draws you laugh.\n",
      "there is such refreshing absence of cynicism with stuart little follows - - quite the rarity, even inside the family film market. now, it got you absolutely.\n",
      "there is that refreshing absence of cynicism throughout stuart little success - - quite little rarity, even though the family film market. furthermore, it wins you everywhere.\n",
      "there is also refreshing absence of cynicism among stuart little writes - - quite at rarity, even outside the family film market. yet, it suits you easily.\n",
      "there is that refreshing absence of cynicism as stuart little starred - - quite exceeding rarity, even entering the family film market. basically, it kills you well.\n",
      "there goes a refreshing absence that cynicism in disney cinematic audiences - - relatively finds rarity, ubiquitous in the family film market. eventually, it switches you over.\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "there is so refreshing absence of cynicism aboard stuart little said - - quite like rarity, even at the family film market. no, it scares you yourself.\n",
      "it is some refreshing absence of many imp than about material - - quite sheer rarity, albeit in the family film market. eventually, it wins you over.\n",
      "tv is such refreshing absence of even in nor color ” - - quite little rarity, much in the family film market. eventually, it wins you over.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find an result satisfying the 0.95 precision constraint. Now returning the best non-eligible result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[2]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: it doesn't offer audiences any way of gripping what its point is , or even its attitude toward its subject .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: offer AND point AND audiences AND toward\n",
      "Precision: 0.63\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "it does n't offer audiences some trouble with gripping what its point is , or even its ethic toward its individual .\n",
      "it does n't offer audiences any way after touching what its point is , or however its politeness toward its anyone .\n",
      "it does n't offer audiences any way of motivating what its point is , or even its stance toward its subject .\n",
      "it does n't offer audiences those thing of gripping what its point is , or possibly its attitude toward its interpretation .\n",
      "it does n't offer audiences both situation into gripping what its point is , or then its attitude toward its explaination .\n",
      "it does n't offer audiences any guy within motivating what its point is , or unfortunately its attitude toward its subject .\n",
      "it does n't offer audiences any whole into empowering what its point is , or even its attitude toward its liability .\n",
      "it does n't offer audiences every truth across illuminating what its point is , or even its attitude toward its subject .\n",
      "it does n't offer audiences an bit of gripping what its point is , or only its politeness toward its authority .\n",
      "it does n't offer audiences any effort of focussing what its point is , or even its behavior toward its anyone .\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "it does n't offer audiences any lot of bringing what its point is , or even its attitude toward its subject .\n",
      "it does n't offer audiences any way of gripping what its point is , or there its attitude toward its interpretation .\n",
      "it does n't offer audiences these bit of gripping what its point is , or often its attitude toward its respect .\n",
      "it does n't offer audiences a life of gripping what its point is , or even its attitude toward its nature .\n",
      "it does n't offer audiences any manner of gripping what its point is , or enough its attitude toward its subject .\n",
      "it does n't offer audiences any way of engrossing what its point is , or even its ethos toward its subject .\n",
      "it does n't offer audiences any mind while gripping what its point is , or much its attitude toward its subject .\n",
      "it does n't offer audiences any attention of gripping what its point is , or even its attitude toward its subject .\n",
      "it does n't offer audiences any way around gripping what its point is , or even its attitude toward its appendix .\n",
      "it does n't offer audiences another way of gripping what its point is , or even its attitude toward its regard .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: doesn AND point AND offer AND its AND subject\n",
      "Precision: 0.96\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "god doesn't offer it any ease of gripping what its point does, without even it to examine its subject.\n",
      "reason doesn't offer scholars any intentions of gripping what its point was, preferring even merely it debating its subject.\n",
      "literature doesn't offer customers any amount of gripping what its point causes, preferring even as arguments by its subject.\n",
      "socrates doesn't offer about any notion of gripping what its point intends, preferring even further opinion describes its subject.\n",
      "evidence doesn't offer users any type of gripping what its point has, nobody even considers it raises its subject.\n",
      "pbs doesn't offer himself any intentions of gripping what its point makes, rarely even considering questions around its subject.\n",
      "rhetoric doesn't offer students any satisfaction of gripping what its point was, rather even openly directly examines its subject.\n",
      "documentaries doesn't offer audiences any way over gripping approaches its point blank, or even encouraging attitude around my subject.\n",
      "broadway doesn't offer audiences any way how gripping over its point values, or even controlling attitude facing whichever subject.\n",
      "dvd doesn't offer audiences any way by gripping out its point premise, or even encouraging attitude above the subject.\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "pornography doesn't offer on any luxury of gripping what its point holds, suggesting even offers caution examining its subject.\n",
      "poetry doesn't offer ourselves any signs of gripping what its point is, even even outright directly into its subject.\n",
      "humanity doesn't offer him any amount of gripping what its point seeks, although even if that toward its subject.\n",
      "filmmaking doesn'w offer audiences their way of gripping what its point was, emphasizing even its effects as its subject.\n",
      "mtv doesn'j offer audiences good way of gripping what its point implies, whereas even its message explore its subject.\n",
      "fx doesn't offer audiences adequate way of gripping what its point is, perhaps even its credibility from its subject.\n",
      "it doesn'n offer audiences what way or experience while its point is, whereas affecting its attitude toward personal subject.\n",
      "film doesn'to offer audiences any method of gripping what its point involves, its taking her prejudice toward its subject.\n",
      "documentary doesn'not offer audiences any gift of gripping what its point is, taking showing ironic hints toward its subject.\n",
      "slate doesn'ave offer audiences any opportunity of gripping what its point finds, thus moving sentimental responses toward its subject.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test[indices[3]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: rodriguez . . . was unable to reproduce the special spark between the characters that made the first film such a delight .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: between AND rodriguez AND unable\n",
      "Precision: 0.95\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "rodriguez . . . was unable to reproduce the special spark between this voices that made any forthcoming footage such a delight .\n",
      "rodriguez . . . was unable to reproduce the possible curiosity between the figures which made the first movie such this delight .\n",
      "rodriguez . . . was unable to reproduce the special spark between those personalities whatever had the previous trilogy such the amusement .\n",
      "rodriguez . . . was unable to reproduce both special spark between a characters whatever made the first film such a beauty .\n",
      "rodriguez . . . was unable to interpret both extraordinary spark between those characters which supposed any same film such this delight .\n",
      "rodriguez . . . was unable to reproduce the fantastic spark between each characters that made the little film such the enthusiasm .\n",
      "rodriguez . . . was unable to emulate the festive spark between the characters that made the succesful film such a delight .\n",
      "rodriguez . . . was unable to prosper the special propellant between the cameos that worked the first portrayal such a delight .\n",
      "rodriguez . . . was unable to alter the 40th extinguisher between the characters that layed some first adaptation such both delight .\n",
      "rodriguez . . . was unable to reproduce every able detonation between the symbols whatever brought those first installment such a delight .\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "rodriguez . . . was unable to reproduce both necessary detonation between the figures that were each first adaptation such a delight .\n",
      "rodriguez . . . was unable to reproduce the special misfire between each adventures whatever surprised the first film such a delight .\n",
      "rodriguez . . . was unable to reproduce the educational fuel between each characters whatever intended these current film such another passion .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: to AND was AND spark AND unable AND characters AND the\n",
      "Precision: 0.98\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "rodriguez... was unable to produce his special spark between the characters having made no first script show between him.\n",
      "rodriguez... was unable to discover enough special spark between the characters ever made another first series against radio returns.\n",
      "rodriguez... was unable to detect any special spark between the characters when made this first character cast about movies.\n",
      "rodriguez... was unable to share clear special spark between the characters because made to first episode on clint vargas.\n",
      "rodriguez... was unable to extract without special spark between the characters had made him first feature through her again.\n",
      "rodriguez... was unable to convey strong special spark between the characters unless made your first movie of comic story.\n",
      "rodriguez... was unable to see their special spark between the characters than made this first person fan rico scene.\n",
      "rodriguez... was unable to sustain one special spark between the characters who made during first team before into appearance.\n",
      "rodriguez... was unable to develop clear special spark between the characters we made not first impression into by movie.\n",
      "rodriguez... was unable to create feel special spark between the characters or made her first interview una this him.\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[4]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: while the story's undeniably hard to follow , iwai's gorgeous visuals seduce .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: follow AND undeniably AND gorgeous\n",
      "Precision: 0.97\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "while the epilogue becomes undeniably tough to follow , iwai 's gorgeous visuals hug .\n",
      "while a story takes undeniably big to follow , iwai 's gorgeous visuals hug .\n",
      "while the story 's undeniably hard to follow , iwai 's gorgeous visuals hug .\n",
      "while the excerpt is undeniably hard to follow , iwai 's gorgeous visuals seduce .\n",
      "while these story 's undeniably hard to follow , iwai 's gorgeous visuals seduce .\n",
      "while every story holds undeniably stupid to follow , iwai 's gorgeous visuals seduce .\n",
      "while the story 's undeniably fucking to follow , iwai 's gorgeous visuals saucy .\n",
      "while any story has undeniably dirty to follow , iwai 's gorgeous visuals hug .\n",
      "while the story asks undeniably tightest to follow , iwai 's gorgeous moments hug .\n",
      "while each character trys undeniably soft to follow , iwai 's gorgeous imaginations seduce .\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "while all author says undeniably hard to follow , iwai 's gorgeous visuals mummy .\n",
      "while the screenwriter 's undeniably tired to follow , iwai 's gorgeous animators saucy .\n",
      "while the tale thinks undeniably soft to follow , iwai 's gorgeous visuals mummy .\n",
      "while all fable 's undeniably hot to follow , iwai 's gorgeous abstractions mummy .\n",
      "while the author looks undeniably stupid to follow , iwai 's gorgeous characters seduce .\n",
      "while the narrator 's undeniably hard to follow , iwai 's gorgeous vocals mummy .\n",
      "while the story goes undeniably tired to follow , iwai 's gorgeous shaders mummy .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: follow AND seduce\n",
      "Precision: 0.96\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "while the film'music undeniably gorgeous messages follow, clark's gorgeous visuals seduce.\n",
      "while the others'backgrounds undeniably bizarre narratives follow, annie's gorgeous visuals seduce.\n",
      "while the shows'backgrounds undeniably passionate numbers follow, jackson's gorgeous visuals seduce.\n",
      "while the music'stunning undeniably pleasing photos follow, naomi's gorgeous visuals seduce.\n",
      "while the videos'seemingly undeniably provocative pictures follow, leo's gorgeous visuals seduce.\n",
      "while the film'beautiful undeniably compelling effects follow, nina's gorgeous visuals seduce.\n",
      "while the episode'seem undeniably vivid pictures follow, gaga's gorgeous visuals seduce.\n",
      "while the tracks'capt undeniably intricate motifs follow, dante's gorgeous visuals seduce.\n",
      "while the tracks'trademark undeniably energetic interiors follow, rihanna's gorgeous visuals seduce.\n",
      "while the sequels'increasingly undeniably familiar images follow, damon's gorgeous visuals seduce.\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "while the chorus'remains undeniably hard to follow, characters'70s imp were seduce.\n",
      "while woo b'wives few hard paths follow, sparks'dark kisses seems seduce.\n",
      "while his b'80s own hard moments follow, woody'un needs to seduce.\n",
      "when the story's premise hard to follow, iwai's character dreams seduce.\n",
      "yet the story's facts hard to follow, iwai's hero soon seduce.\n",
      "in the story's prequel hard to follow, iwai's constant feels seduce.\n",
      "when the story's story hard to follow, iwai's characters soon seduce.\n",
      "considering the story's conclusion hard to follow, iwai's mind eventually seduce.\n",
      "finding the story's prequel hard to follow, iwai's hero eventually seduce.\n",
      "making the story's path hard to follow, iwai's husband seemingly seduce.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[5]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: i have two words to say about reign of fire . great dragons !\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: dragons AND have AND fire\n",
      "Precision: 0.95\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "i have two phrases to say about reign of fire . great dragons !\n",
      "i have two words to say far reign of fire . cool dragons !\n",
      "i have two words to let now mediocrity into fire . impressive dragons !\n",
      "i have two words to guess about reign of fire . perfect dragons !\n",
      "i have two words to bother about downfall of fire . easy dragons !\n",
      "i have two words to guess somewhere dictatorship that fire . important dragons !\n",
      "i have two sentences to do sometimes predecessor under fire . great dragons !\n",
      "i have two voices to worry about reign among fire . brilliant dragons !\n",
      "i have two scriptures to admit rather vengeance of fire . little dragons !\n",
      "i have two words to say just millenia of fire . great dragons !\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "i have two gospels to know though reign of fire . remarkable dragons !\n",
      "i have two words to feel about harem of fire . happy dragons !\n",
      "i have two words to say still tyranny of fire . great dragons !\n",
      "i have two words to mean though reign of fire . beautiful dragons !\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: dragons AND fire AND say\n",
      "Precision: 0.95\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "i said two words to say the reign of fire. great dragons!\n",
      "i waited two words to say i reign of fire. great dragons!\n",
      "i needed two words to say concerning reign of fire. great dragons!\n",
      "i find two words to say — reign of fire. great dragons!\n",
      "i took two words to say hail reign of fire. great dragons!\n",
      "i expected two words to say bloody reign of fire. great dragons!\n",
      "i have two words to say o reign of fire. great dragons!\n",
      "fire dared enough started to say that go full fire. great dragons!\n",
      "th no went have to say great fire is fire. great dragons!\n",
      "brave said are heard to say go a holy fire. great dragons!\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "i exchanged two words to say dear reign of fire. great dragons!\n",
      "i chose two words to say against reign of fire. great dragons!\n",
      "i want two words to say i reign of fire. great dragons!\n",
      "you we it how to say ae sword and fire. great dragons!\n",
      "we they always liked to say a hail hail fire. great dragons!\n",
      "you and i dare to say “ thou for fire. great dragons!\n",
      "behold when two armies brothers say you reign through fire. angry dragons!\n",
      "i have two sons at say eight out of fire. damned dragons!\n",
      "i have wonderful words anybody say about your dragon fire. great dragons!\n",
      "i have twelve words that say for breath of fire. great dragons!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[6]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: what's next : \" my mother the car ? \"\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: car AND next\n",
      "Precision: 0.99\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "what 's next : \" my friend a car ? \"\n",
      "what 's next : \" my child the car ? \"\n",
      "what 's next : \" my year the car ? \"\n",
      "what 's next : \" my grandchild an car ? \"\n",
      "what 's next : \" my grandparent every car ? \"\n",
      "what 's next : \" my birth any car ? \"\n",
      "what 's next : \" my mother the car ? \"\n",
      "what 's next : \" my cousin the car ? \"\n",
      "what 's next : \" my mama an car ? \"\n",
      "what 's next : \" my babysit the car ? \"\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "what 's next : \" my family both car ? \"\n",
      "what 's next : \" my baby an car ? \"\n",
      "what 's next : \" my child these car ? \"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: next\n",
      "Precision: 0.96\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "mike'the next : \" my or the car? \"\n",
      "they'song next : \" my ride the car? \"\n",
      "evans'll next : \" my gran the car? \"\n",
      "mike'07 next : \" my grandmother the car? \"\n",
      "he'say next : \" my girlfriend the car? \"\n",
      "williams'the next : \" my problem the car? \"\n",
      "i're next : \" my boy the car? \"\n",
      "evans'next next : \" my name the car? \"\n",
      "goin'cause next : \" my aunt the car? \"\n",
      "peter's next : \" my little no you? \"\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "dave'round next : \" my lady the car? \"\n",
      "drake's next : \" my first wedding here? \"\n",
      "questions'right next : \" my mother told now? \"\n",
      "what'about next : \" my mother beat mommy? \"\n",
      "what'rec next : \" my mother killed divorced? \"\n",
      "cbs'ring next : \" you mother beat not? \"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test[indices[7]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: supposedly based upon real , or at least soberly reported incidents , the film ends with a large human tragedy . alas , getting there is not even half the interest .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: getting\n",
      "Precision: 0.98\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "technically oriented upon huge , or than least soberly taken allegations , all installment ends along every entire latent tragedy . alas , getting there is not only half those borrower .\n",
      "even written upon incredible , or around least soberly published incidents , the film means with another large human disaster . alas , getting there is not then half another extent .\n",
      "supposedly compared upon strong , or into worst soberly ascribed consequences , the movie follows around every large humankind tragedy . alas , getting there is not often half the interest .\n",
      "practically focussed upon good , or at worst happily collected accidents , those director ends like a ample knowledge outrage . alas , getting there is not too half another interest .\n",
      "ultimately based upon perfect , or to worst thoughtfully conducted incidents , this slapstick ends despite a large latent hopelessness . alas , getting there is not enough half the interest .\n",
      "evidently based upon real , or arround least soberly concerned authorities , the scene ends with an large human bystander . alas , getting there is not especially half a interest .\n",
      "practically based upon real , or about fewest soberly charged infractions , the actor ends whether a little sentience woe . alas , getting there is not enough half a consideration .\n",
      "supposedly based upon legal , or at worst innocently reported victims , both adaptation happens with no swath latent preparedness . alas , getting there is not ever half both interest .\n",
      "coincidentally based upon real , or on least soberly involved emergencies , the poster seems like a monumental sapiens disaster . alas , getting there is not ever half this extent .\n",
      "supposedly based upon simple , or under least soberly reported combatants , the film ends within a large human tragedy . alas , getting there is not even half the interest .\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "practically based upon real , or at fewest instinctively reported incidents , the film ends with a large human tragedy . alas , getting there is not sure half the interest .\n",
      "perhaps compared upon real , or during least loudly associated infractions , the film ends outside a large human ire . alas , getting there is not even half this interest .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: getting AND supposedly AND there AND incidents AND alas\n",
      "Precision: 0.97\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "supposedly following for observations, or at other soberly reported incidents, the incident invariably to a tragic human tragedy. alas, getting there usually not quite further the interest.\n",
      "supposedly concerning involving individuals, or at all soberly reported incidents, the tragic generally as a genuinely human tragedy. alas, getting there ought not further provoke the interest.\n",
      "supposedly regarding those crimes, or at rarely soberly reported incidents, the police actually be a natural human tragedy. alas, getting there must not precisely spread the interest.\n",
      "supposedly without or emergencies, or at present soberly reported incidents, the police have creates a huge human tragedy. alas, getting there probably not totally boost the interest.\n",
      "supposedly about with details, or at others soberly reported incidents, the weather always witnessing a horrific human tragedy. alas, getting there that not even curb the interest.\n",
      "supposedly via by details, or at sometimes soberly reported incidents, the historical can poses a dreadful human tragedy. alas, getting there usually not hind revive the interest.\n",
      "supposedly through historical meetings, or at occasion soberly reported incidents, the internet supposedly constitutes a devastating human tragedy. alas, getting there that not rep cause the interest.\n",
      "supposedly upon innocent events, or at which soberly reported incidents, the historical itself experienced a wholly human tragedy. alas, getting there ought not be provoke the interest.\n",
      "supposedly upon police occurrences, or at intervals soberly reported incidents, the situation seldom suffer a huge human tragedy. alas, getting there needs not accurately sway the interest.\n",
      "supposedly no ordinary occasions, or at occasionally soberly reported incidents, the public evidently such a potentially human tragedy. alas, getting there means not adequately harm the interest.\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "supposedly based outside real, attempt at observing soberly narrated incidents, although film filled with a horrific disturbing tragedy. alas, getting there cannot hardly even eva him movies.\n",
      "supposedly based very real, look at showing soberly entertaining incidents, which film turns with a shocking personal tragedy. alas, getting there got never even involves this footage.\n",
      "supposedly based amongst real, look at breaking soberly true incidents, every film deal with a bizarre urban tragedy. alas, getting there involves not even helps serious experience.\n",
      "supposedly based above real, aimed at introducing soberly depicting incidents, detective film started with a true human tragedy. alas, getting there never involves even starts funny fun.\n",
      "supposedly based to real, staring at addressing soberly emotional incidents, surreal film loaded with a terrible cultural tragedy. alas, getting there has means even eva funny problems.\n",
      "supposedly taking upon real, personal realistic most soberly staged incidents, the readers begin with a very physical disposition. alas, getting there is not easy worth yet value.\n",
      "supposedly drawing upon real, im incidents in soberly fictional incidents, the world enters with a deep disturbing conclusion. alas, getting there is not about such on here.\n",
      "supposedly arriving upon encounters, but having least soberly reported incidents, because frequently ends with numerous of human souls. alas, getting there is now even half the sentence.\n",
      "supposedly inflicted upon occurrences, usually nor least soberly reported incidents, typically typically ends with numerous minor human encounters. alas, getting there is not even half the population.\n",
      "supposedly based towards real, potentially at least 4 reported incidents, inc in infected with a large human base. alas, getting there must not make without reported accuracy.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[8]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: a well-crafted letdown .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: crafted AND well AND a\n",
      "Precision: 0.97\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "a well - crafted letdown .\n",
      "a well - crafted letdown .\n",
      "a well - crafted letdown .\n",
      "a well - crafted unhappiness .\n",
      "a well - crafted letdown .\n",
      "a well - crafted letdown .\n",
      "a well - crafted letdown .\n",
      "a well - crafted letdown .\n",
      "a well - crafted letdown .\n",
      "a well - crafted desperation .\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "a well - crafted embarrassment .\n",
      "a well - crafted disappointment .\n",
      "a well - crafted embarrassment .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: crafted AND well AND a\n",
      "Precision: 0.98\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "a well - crafted tale.\n",
      "a well - crafted bow.\n",
      "a well - crafted crossbow.\n",
      "a well - crafted doll.\n",
      "a well - crafted necklace.\n",
      "a well - crafted recipe.\n",
      "a well - crafted toy.\n",
      "a well - crafted design.\n",
      "a well - crafted tapestry.\n",
      "a well - crafted toy.\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "a well - crafted script.\n",
      "a well - crafted script.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "text = test[indices[9]]\n",
    "\n",
    "# compute text prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative = class_names[1 - predict_fn([text])[0]]\n",
    "\n",
    "# similarity explanation\n",
    "sim_explanation = explainer_sim.explain(text)\n",
    "\n",
    "# language model explanation\n",
    "lm_explanation = explainer_lm.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: it's just hard to believe that a life like this can sound so dull .\n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: dull\n",
      "Precision: 0.99\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "it 's just hard to believe that no joy like this can sound so dull .\n",
      "it 's so stiff to argue that a life like a can drum so dull .\n",
      "it 's not hard to believe that each moment if an can sound so dull .\n",
      "it 's down hard to agree that a embark like this can flamenco actually dull .\n",
      "it 's scarcely hard to guess that a life like this can sound so dull .\n",
      "it 's not nasty to believe that every life along each can sound so dull .\n",
      "it 's just hard to beleive that an life past this can feel rather dull .\n",
      "it 's obviously hard to believe that a life like this can sound probably dull .\n",
      "it 's just massive to remeber that every life without the can drum so dull .\n",
      "it 's down soft to disagree that a soul as any can sound so dull .\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "it 's kind solid to believe that any voyage inside this can horn anyway dull .\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display similarity explanation\n",
    "print(build_explanation(sim_explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: like\n",
      "Precision: 0.98\n",
      "\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "it'r more hard everyone believe that a life like grandma boring seems so dull.\n",
      "it'z s hard on believe into a life like this you nothing so dull.\n",
      "it'an more hard ya believe living a life like jack rarely times so dull.\n",
      "it'g sometimes hard couples believe from a life like la and was so dull.\n",
      "it'b got hard he believe at a life like ours is or so dull.\n",
      "it'e more hard nobody believe experiencing a life like an this seem so dull.\n",
      "it'ts painfully hard friends believe was a life like you seems looks so dull.\n",
      "it'wasn probably hard readers believe inside a life like la that feel so dull.\n",
      "it'sis pretty hard and believe just a life like this day it so dull.\n",
      "it'ds incredibly hard in believe finding a life like another are being so dull.\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "dave's truly hard chicks believe taking a stuff like this can sound so crazy.\n",
      "today's eyes ability to keep different human feelings like cats can look so many.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display language model explanation\n",
    "print(build_explanation(lm_explanation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibi",
   "language": "python",
   "name": "alibi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
