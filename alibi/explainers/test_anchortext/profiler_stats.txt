Total duration: 0.857883s
File: /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py
File duration: 0.518882s (60.48%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import sys
     2|         0|            0|            0|  0.00%|from line_profiler import LineProfiler
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|import copy
     5|         0|            0|            0|  0.00%|import spacy
     6|         0|            0|            0|  0.00%|import string
     7|         0|            0|            0|  0.00%|import logging
     8|         0|            0|            0|  0.00%|import numpy as np
     9|         0|            0|            0|  0.00%|import tensorflow as tf                  # type: ignore
    10|         0|            0|            0|  0.00%|import tensorflow_probability as tfp     # type: ignore
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|from copy import deepcopy
    13|         0|            0|            0|  0.00%|from functools import partial
    14|         0|            0|            0|  0.00%|from abc import abstractmethod
    15|         0|            0|            0|  0.00%|from typing import Any, Callable, Dict, List, Tuple, TYPE_CHECKING, Union, Optional
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|from alibi.utils.wrappers import ArgmaxTransformer
    18|         0|            0|            0|  0.00%|from alibi.utils.lang_model import LanguageModel
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|from alibi.api.interfaces import Explainer, Explanation
    21|         0|            0|            0|  0.00%|from alibi.api.defaults import DEFAULT_META_ANCHOR, DEFAULT_DATA_ANCHOR
    22|         0|            0|            0|  0.00%|from .anchor_base import AnchorBaseBeam
    23|         0|            0|            0|  0.00%|from .anchor_explanation import AnchorExplanation
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|if TYPE_CHECKING:
    26|         0|            0|            0|  0.00%|    import spacy  # noqa: F811
    27|         0|            0|            0|  0.00%|logger = logging.getLogger(__name__)
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|def _load_spacy_lexeme_prob(nlp: 'spacy.language.Language'):
    31|         0|            0|            0|  0.00%|    """
    32|         0|            0|            0|  0.00%|    This utility function loads the `lexeme_prob` table for a spacy model if it is not present.
    33|         0|            0|            0|  0.00%|    This is required to enable support for different spacy versions.
    34|         0|            0|            0|  0.00%|    """
    35|         0|            0|            0|  0.00%|    import spacy
    36|         0|            0|            0|  0.00%|    SPACY_VERSION = spacy.__version__.split('.')
    37|         0|            0|            0|  0.00%|    MAJOR, MINOR = int(SPACY_VERSION[0]), int(SPACY_VERSION[1])
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|    if MAJOR == 2:
    40|         0|            0|            0|  0.00%|        if MINOR < 3:
    41|         0|            0|            0|  0.00%|            return nlp
    42|         0|            0|            0|  0.00%|        elif MINOR == 3:
    43|         0|            0|            0|  0.00%|            # spacy 2.3.0 moved lexeme_prob into a different package `spacy_lookups_data`
    44|         0|            0|            0|  0.00%|            # https://github.com/explosion/spaCy/issues/5638
    45|         0|            0|            0|  0.00%|            try:
    46|         0|            0|            0|  0.00%|                table = nlp.vocab.lookups_extra.get_table('lexeme_prob')
    47|         0|            0|            0|  0.00%|                # remove the default empty table
    48|         0|            0|            0|  0.00%|                if table == dict():
    49|         0|            0|            0|  0.00%|                    nlp.vocab.lookups_extra.remove_table('lexeme_prob')
    50|         0|            0|            0|  0.00%|            except KeyError:
    51|         0|            0|            0|  0.00%|                pass
    52|         0|            0|            0|  0.00%|            finally:
    53|         0|            0|            0|  0.00%|                # access the `prob` of any word to load the full table
    54|         0|            0|            0|  0.00%|                assert nlp.vocab["a"].prob != -20.0, f"Failed to load the `lexeme_prob` table for model {nlp}"
    55|         0|            0|            0|  0.00%|    elif MAJOR >= 3:
    56|         0|            0|            0|  0.00%|        # in spacy 3.x we need to manually add the tables
    57|         0|            0|            0|  0.00%|        # https://github.com/explosion/spaCy/discussions/6388#discussioncomment-331096
    58|         0|            0|            0|  0.00%|        if 'lexeme_prob' not in nlp.vocab.lookups.tables:
    59|         0|            0|            0|  0.00%|            from spacy.lookups import load_lookups
    60|         0|            0|            0|  0.00%|            lookups = load_lookups(nlp.lang, ['lexeme_prob'])
    61|         0|            0|            0|  0.00%|            nlp.vocab.lookups.add_table('lexeme_prob', lookups.get_table('lexeme_prob'))  # type: ignore
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|    return nlp
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|class Neighbors(object):
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    def __init__(self, nlp_obj: 'spacy.language.Language', n_similar: int = 500, w_prob: float = -15.) -> None:
    69|         0|            0|            0|  0.00%|        """
    70|         0|            0|            0|  0.00%|        Initialize class identifying neighbouring words from the embedding for a given word.
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|        Parameters
    73|         0|            0|            0|  0.00%|        ----------
    74|         0|            0|            0|  0.00%|        nlp_obj
    75|         0|            0|            0|  0.00%|            spaCy model
    76|         0|            0|            0|  0.00%|        n_similar
    77|         0|            0|            0|  0.00%|            Number of similar words to return.
    78|         0|            0|            0|  0.00%|        w_prob
    79|         0|            0|            0|  0.00%|            Smoothed log probability estimate of token's type.
    80|         0|            0|            0|  0.00%|        """
    81|         0|            0|            0|  0.00%|        self.nlp = nlp_obj
    82|         0|            0|            0|  0.00%|        self.w_prob = w_prob
    83|         0|            0|            0|  0.00%|        # list with spaCy lexemes in vocabulary
    84|         0|            0|            0|  0.00%|        # first if statement is a workaround due to some missing keys in models:
    85|         0|            0|            0|  0.00%|        # https://github.com/SeldonIO/alibi/issues/275#issuecomment-665017691
    86|         0|            0|            0|  0.00%|        self.to_check = [self.nlp.vocab[w] for w in self.nlp.vocab.vectors if
    87|         0|            0|            0|  0.00%|                         int(w) in self.nlp.vocab.strings and self.nlp.vocab[w].prob >= self.w_prob]
    88|         0|            0|            0|  0.00%|        self.n_similar = n_similar
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|    def neighbors(self, word: str, tag: str, top_n: int) -> dict:
    91|         0|            0|            0|  0.00%|        """
    92|         0|            0|            0|  0.00%|        Find similar words for a certain word in the vocabulary.
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|        Parameters
    95|         0|            0|            0|  0.00%|        ----------
    96|         0|            0|            0|  0.00%|        word
    97|         0|            0|            0|  0.00%|            Word for which we need to find similar words.
    98|         0|            0|            0|  0.00%|        tag
    99|         0|            0|            0|  0.00%|            Part of speech tag for the words.
   100|         0|            0|            0|  0.00%|        top_n
   101|         0|            0|            0|  0.00%|            Return only top_n neighbors.
   102|         0|            0|            0|  0.00%|
   103|         0|            0|            0|  0.00%|        Returns
   104|         0|            0|            0|  0.00%|        -------
   105|         0|            0|            0|  0.00%|        A dict with two fields. The 'words' field contains a numpy array
   106|         0|            0|            0|  0.00%|        of the top_n most similar words, whereas the fields similarity is
   107|         0|            0|            0|  0.00%|        a numpy array with corresponding word similarities.
   108|         0|            0|            0|  0.00%|        """
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|        # the word itself is excluded so we add one to return the expected number of words
   111|         0|            0|            0|  0.00%|        top_n += 1
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|        texts, similarities = [], []  # type: List, List
   114|         0|            0|            0|  0.00%|        if word in self.nlp.vocab:
   115|         0|            0|            0|  0.00%|            word_vocab = self.nlp.vocab[word]
   116|         0|            0|            0|  0.00%|            queries = [w for w in self.to_check if w.is_lower == word_vocab.is_lower]
   117|         0|            0|            0|  0.00%|            if word_vocab.prob < self.w_prob:
   118|         0|            0|            0|  0.00%|                queries += [word_vocab]
   119|         0|            0|            0|  0.00%|            by_similarity = sorted(queries, key=lambda w: word_vocab.similarity(w), reverse=True)[:self.n_similar]
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|            # Find similar words with the same part of speech
   122|         0|            0|            0|  0.00%|            for lexeme in by_similarity:
   123|         0|            0|            0|  0.00%|                # because we don't add the word itself anymore
   124|         0|            0|            0|  0.00%|                if len(texts) == top_n - 1:
   125|         0|            0|            0|  0.00%|                    break
   126|         0|            0|            0|  0.00%|                token = self.nlp(lexeme.orth_)[0]
   127|         0|            0|            0|  0.00%|                if token.tag_ != tag or token.text == word:
   128|         0|            0|            0|  0.00%|                    continue
   129|         0|            0|            0|  0.00%|                texts.append(token.text)
   130|         0|            0|            0|  0.00%|                similarities.append(word_vocab.similarity(lexeme))
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|        words = np.array(texts) if texts else np.array(texts, dtype='<U')
   133|         0|            0|            0|  0.00%|        return {'words': words, 'similarities': np.array(similarities)}
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|class AnchorTextSampler:
   137|         0|            0|            0|  0.00%|    @abstractmethod
   138|         0|            0|            0|  0.00%|    def set_text(self, text: str):
   139|         0|            0|            0|  0.00%|        pass
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|    @abstractmethod
   142|         0|            0|            0|  0.00%|    def __call__(self, anchor: tuple, num_samples: int):
   143|         0|            0|            0|  0.00%|        pass
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    def _joiner(self, arr: np.ndarray, dtype: np.dtype = None) -> np.ndarray:
   146|         0|            0|            0|  0.00%|        """
   147|         0|            0|            0|  0.00%|        Function to concatenate an np.array of strings along a specified axis.
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|        Parameters
   150|         0|            0|            0|  0.00%|        ----------
   151|         0|            0|            0|  0.00%|        arr
   152|         0|            0|            0|  0.00%|            1D numpy array of strings.
   153|         0|            0|            0|  0.00%|        dtype
   154|         0|            0|            0|  0.00%|           Array type, used to avoid truncation of strings when concatenating along axis.
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|        Returns
   157|         0|            0|            0|  0.00%|        -------
   158|         0|            0|            0|  0.00%|            Array with one element, the concatenation of the strings in the input array.
   159|         0|            0|            0|  0.00%|        """
   160|         0|            0|            0|  0.00%|        if not dtype:
   161|         0|            0|            0|  0.00%|            return np.array(' '.join(arr))
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|        return np.array(' '.join(arr)).astype(dtype)
   164|         0|            0|            0|  0.00%|
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|class UnkownSampler(AnchorTextSampler):
   167|         0|            0|            0|  0.00%|    UNK = "UNK"
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    def __init__(self, nlp: 'spacy.language.Language', perturb_opts: Dict):
   170|         0|            0|            0|  0.00%|        """
   171|         0|            0|            0|  0.00%|        Initialize unknown sampler. This sampler replaces word with the `UNK` token.
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|        Parameters
   174|         0|            0|            0|  0.00%|        ----------
   175|         0|            0|            0|  0.00%|        nlp
   176|         0|            0|            0|  0.00%|            spaCy object.
   177|         0|            0|            0|  0.00%|        perturb_opts
   178|         0|            0|            0|  0.00%|            Perturbation options.
   179|         0|            0|            0|  0.00%|        """
   180|         0|            0|            0|  0.00%|        super(UnkownSampler, self).__init__()
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|        # set nlp and perturbation options
   183|         0|            0|            0|  0.00%|        self.nlp = _load_spacy_lexeme_prob(nlp)
   184|         0|            0|            0|  0.00%|        self.perturb_opts = perturb_opts  # type: Union[Dict, None]
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|        # set nlp object
   187|         0|            0|            0|  0.00%|        self.nlp = _load_spacy_lexeme_prob(nlp)
   188|         0|            0|            0|  0.00%|
   189|         0|            0|            0|  0.00%|        # define buffer for word, punctuation and position
   190|         0|            0|            0|  0.00%|        self.words, self.punctuation, self.positions = [], [], []  # type: List, List, List
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|    def set_text(self, text: str):
   193|         0|            0|            0|  0.00%|        """
   194|         0|            0|            0|  0.00%|        Sets the text to be processed.
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|        Parameters
   197|         0|            0|            0|  0.00%|        ----------
   198|         0|            0|            0|  0.00%|        text
   199|         0|            0|            0|  0.00%|            Text to be processed.
   200|         0|            0|            0|  0.00%|        """
   201|         0|            0|            0|  0.00%|        # process text
   202|         0|            0|            0|  0.00%|        processed = self.nlp(text)                                  # spaCy tokens for text
   203|         0|            0|            0|  0.00%|        self.words = [x.text for x in processed]                    # list with words in text
   204|         0|            0|            0|  0.00%|        self.positions = [x.idx for x in processed]                 # positions of words in text
   205|         0|            0|            0|  0.00%|        self.punctuation = [x for x in processed if x.is_punct]     # list with punctuation in text
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|        # set dtype
   208|         0|            0|            0|  0.00%|        self.set_data_type()
   209|         0|            0|            0|  0.00%|
   210|         0|            0|            0|  0.00%|    def __call__(self, anchor: tuple, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:
   211|         0|            0|            0|  0.00%|        """
   212|         0|            0|            0|  0.00%|        The function returns  an np.array of num_samples where randomly chose features
   213|         0|            0|            0|  0.00%|        except those in anchor are replaced by self.UNK token.
   214|         0|            0|            0|  0.00%|
   215|         0|            0|            0|  0.00%|        Parameters
   216|         0|            0|            0|  0.00%|        ----------
   217|         0|            0|            0|  0.00%|        anchor:
   218|         0|            0|            0|  0.00%|            Indices represent the positions of the words to be kept unchanged.
   219|         0|            0|            0|  0.00%|        num_samples:
   220|         0|            0|            0|  0.00%|            Number of perturbed sentences to be returned.
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|        Returns
   223|         0|            0|            0|  0.00%|        -------
   224|         0|            0|            0|  0.00%|        raw
   225|         0|            0|            0|  0.00%|            Array containing num_samples elements. Each element is a perturbed sentence.
   226|         0|            0|            0|  0.00%|        data
   227|         0|            0|            0|  0.00%|            A (num_samples, m)-dimensional boolean array, where m is the number of tokens
   228|         0|            0|            0|  0.00%|            in the instance to be explained.
   229|         0|            0|            0|  0.00%|        """
   230|         0|            0|            0|  0.00%|        assert self.perturb_opts, "Perturbation options are not set."
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|        # allocate memory for the binary mask and the perturbed instances
   233|         0|            0|            0|  0.00%|        data = np.ones((num_samples, len(self.words)))
   234|         0|            0|            0|  0.00%|        raw = np.zeros((num_samples, len(self.words)), self.dtype)
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|        # fill each row of the raw data matrix with the text instance to be explained
   237|         0|            0|            0|  0.00%|        raw[:] = self.words
   238|         0|            0|            0|  0.00%|
   239|         0|            0|            0|  0.00%|        for i, t in enumerate(self.words):
   240|         0|            0|            0|  0.00%|            # do not perturb words that are in anchor
   241|         0|            0|            0|  0.00%|            if i in anchor:
   242|         0|            0|            0|  0.00%|                continue
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|            # sample the words in the text outside of the anchor that are replaced with UNKs
   245|         0|            0|            0|  0.00%|            n_changed = np.random.binomial(num_samples, self.perturb_opts['sample_proba'])
   246|         0|            0|            0|  0.00%|            changed = np.random.choice(num_samples, n_changed, replace=False)
   247|         0|            0|            0|  0.00%|            raw[changed, i] = UnkownSampler.UNK
   248|         0|            0|            0|  0.00%|            data[changed, i] = 0
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|        # join the words
   251|         0|            0|            0|  0.00%|        raw = np.apply_along_axis(self._joiner, axis=1, arr=raw, dtype=self.dtype)
   252|         0|            0|            0|  0.00%|        return raw, data
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    def set_data_type(self) -> None:
   255|         0|            0|            0|  0.00%|        """
   256|         0|            0|            0|  0.00%|        Working with numpy arrays of strings requires setting the data type to avoid
   257|         0|            0|            0|  0.00%|        truncating examples. This function estimates the longest sentence expected
   258|         0|            0|            0|  0.00%|        during the sampling process, which is used to set the number of characters
   259|         0|            0|            0|  0.00%|        for the samples and examples arrays. This depends on the perturbation method
   260|         0|            0|            0|  0.00%|        used for sampling.
   261|         0|            0|            0|  0.00%|        """
   262|         0|            0|            0|  0.00%|        max_len = max(len(self.UNK), len(max(self.words, key=len)))
   263|         0|            0|            0|  0.00%|        max_sent_len = len(self.words) * max_len + len(self.UNK) * len(self.punctuation) + 1
   264|         0|            0|            0|  0.00%|        self.dtype = '<U' + str(max_sent_len)
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|class SimilaritySampler(AnchorTextSampler):
   268|         0|            0|            0|  0.00%|    def __init__(self, nlp: 'spacy.language.Language', perturb_opts: Dict):
   269|         0|            0|            0|  0.00%|        """
   270|         0|            0|            0|  0.00%|        Initialize similarity sampler. This sampler replaces words with similar words.
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|        Parameters
   273|         0|            0|            0|  0.00%|        ----------
   274|         0|            0|            0|  0.00%|        nlp
   275|         0|            0|            0|  0.00%|            spaCy object.
   276|         0|            0|            0|  0.00%|        perturb_opts
   277|         0|            0|            0|  0.00%|            Perturbation options.
   278|         0|            0|            0|  0.00%|
   279|         0|            0|            0|  0.00%|        """
   280|         0|            0|            0|  0.00%|        super(SimilaritySampler, self).__init__()
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|        # set nlp and perturbation options
   283|         0|            0|            0|  0.00%|        self.nlp = _load_spacy_lexeme_prob(nlp)
   284|         0|            0|            0|  0.00%|        self.perturb_opts = perturb_opts
   285|         0|            0|            0|  0.00%|
   286|         0|            0|            0|  0.00%|        # define synonym generator
   287|         0|            0|            0|  0.00%|        self._synonyms_generator = Neighbors(self.nlp)
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|        # dict containing an np.array of similar words with same part of speech and an np.array of similarities
   290|         0|            0|            0|  0.00%|        self.synonyms = {}  # type: Dict[str, Dict[str, np.ndarray]]
   291|         0|            0|            0|  0.00%|        self.tokens, self.words, self.positions, self.punctuation = [], [], [], []  # type: List, List, List, List
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|    def set_text(self, text: str):
   294|         0|            0|            0|  0.00%|        """
   295|         0|            0|            0|  0.00%|        Sets the text to be processed
   296|         0|            0|            0|  0.00%|
   297|         0|            0|            0|  0.00%|        Parameters
   298|         0|            0|            0|  0.00%|        ----------
   299|         0|            0|            0|  0.00%|        text
   300|         0|            0|            0|  0.00%|          Text to be processed.
   301|         0|            0|            0|  0.00%|        """
   302|         0|            0|            0|  0.00%|        processed = self.nlp(text)                                  # spaCy tokens for text
   303|         0|            0|            0|  0.00%|        self.words = [x.text for x in processed]                    # list with words in text
   304|         0|            0|            0|  0.00%|        self.positions = [x.idx for x in processed]                 # positions of words in text
   305|         0|            0|            0|  0.00%|        self.punctuation = [x for x in processed if x.is_punct]     # punctuation in text
   306|         0|            0|            0|  0.00%|        self.tokens = processed
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|        # find similar words
   309|         0|            0|            0|  0.00%|        self.find_similar_words()
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|        # set dtype
   312|         0|            0|            0|  0.00%|        self.set_data_type()
   313|         0|            0|            0|  0.00%|
   314|         0|            0|            0|  0.00%|    def find_similar_words(self) -> None:
   315|         0|            0|            0|  0.00%|        """
   316|         0|            0|            0|  0.00%|        This function queries a spaCy nlp model to find n similar words with the same
   317|         0|            0|            0|  0.00%|        part of speech for each word in the instance to be explained. For each word
   318|         0|            0|            0|  0.00%|        the search procedure returns a dictionary containing an np.array of words ('words')
   319|         0|            0|            0|  0.00%|        and an np.array of word similarities ('similarities').
   320|         0|            0|            0|  0.00%|        """
   321|         0|            0|            0|  0.00%|        for word, token in zip(self.words, self.tokens):
   322|         0|            0|            0|  0.00%|            if word not in self.synonyms:
   323|         0|            0|            0|  0.00%|                self.synonyms[word] = self._synonyms_generator.neighbors(word, token.tag_, self.perturb_opts['top_n'])
   324|         0|            0|            0|  0.00%|
   325|         0|            0|            0|  0.00%|    def __call__(self, anchor: tuple, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:
   326|         0|            0|            0|  0.00%|        """
   327|         0|            0|            0|  0.00%|        The function returns  an np.array of num_samples where randomly chose features
   328|         0|            0|            0|  0.00%|        except those in anchor are replaced by similar words with the same part of
   329|         0|            0|            0|  0.00%|        speech of tag. See self.perturb_sentence for details of how the replacement works.
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|        Parameters
   332|         0|            0|            0|  0.00%|        ----------
   333|         0|            0|            0|  0.00%|        anchor:
   334|         0|            0|            0|  0.00%|            Indices represent the positions of the words to be kept unchanged.
   335|         0|            0|            0|  0.00%|        num_samples:
   336|         0|            0|            0|  0.00%|            Number of perturbed sentences to be returned.
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|        Returns
   339|         0|            0|            0|  0.00%|        -------
   340|         0|            0|            0|  0.00%|        See perturb_sentence_similarity
   341|         0|            0|            0|  0.00%|        """
   342|         0|            0|            0|  0.00%|        assert self.perturb_opts, "Perturbation options are not set."
   343|         0|            0|            0|  0.00%|        return self.perturb_sentence_similarity(anchor, num_samples, **self.perturb_opts)
   344|         0|            0|            0|  0.00%|
   345|         0|            0|            0|  0.00%|    def perturb_sentence_similarity(self,
   346|         0|            0|            0|  0.00%|                                    present: tuple,
   347|         0|            0|            0|  0.00%|                                    n: int,
   348|         0|            0|            0|  0.00%|                                    sample_proba: float = 0.5,
   349|         0|            0|            0|  0.00%|                                    forbidden: frozenset = frozenset(),
   350|         0|            0|            0|  0.00%|                                    forbidden_tags: frozenset = frozenset(['PRP$']),
   351|         0|            0|            0|  0.00%|                                    forbidden_words: frozenset = frozenset(['be']),
   352|         0|            0|            0|  0.00%|                                    temperature: float = 1.,
   353|         0|            0|            0|  0.00%|                                    pos: frozenset = frozenset(['NOUN', 'VERB', 'ADJ', 'ADV', 'ADP', 'DET']),
   354|         0|            0|            0|  0.00%|                                    use_proba: bool = False,
   355|         0|            0|            0|  0.00%|                                    **kwargs) -> Tuple[np.ndarray, np.ndarray]:
   356|         0|            0|            0|  0.00%|        """
   357|         0|            0|            0|  0.00%|        Perturb the text instance to be explained.
   358|         0|            0|            0|  0.00%|
   359|         0|            0|            0|  0.00%|        Parameters
   360|         0|            0|            0|  0.00%|        ----------
   361|         0|            0|            0|  0.00%|        present
   362|         0|            0|            0|  0.00%|            Word index in the text for the words in the proposed anchor.
   363|         0|            0|            0|  0.00%|        n
   364|         0|            0|            0|  0.00%|            Number of samples used when sampling from the corpus.
   365|         0|            0|            0|  0.00%|        sample_proba
   366|         0|            0|            0|  0.00%|            Sample probability for a word if use_proba is False.
   367|         0|            0|            0|  0.00%|        forbidden
   368|         0|            0|            0|  0.00%|            Forbidden lemmas.
   369|         0|            0|            0|  0.00%|        forbidden_tags
   370|         0|            0|            0|  0.00%|            Forbidden POS tags.
   371|         0|            0|            0|  0.00%|        forbidden_words
   372|         0|            0|            0|  0.00%|            Forbidden words.
   373|         0|            0|            0|  0.00%|        pos
   374|         0|            0|            0|  0.00%|            POS that can be changed during perturbation.
   375|         0|            0|            0|  0.00%|        use_proba
   376|         0|            0|            0|  0.00%|            Bool whether to sample according to a similarity score with the corpus embeddings.
   377|         0|            0|            0|  0.00%|        temperature
   378|         0|            0|            0|  0.00%|            Sample weight hyperparameter if use_proba equals True.
   379|         0|            0|            0|  0.00%|
   380|         0|            0|            0|  0.00%|        Returns
   381|         0|            0|            0|  0.00%|        -------
   382|         0|            0|            0|  0.00%|        raw
   383|         0|            0|            0|  0.00%|            Array of perturbed text instances.
   384|         0|            0|            0|  0.00%|        data
   385|         0|            0|            0|  0.00%|            Matrix with 1s and 0s indicating whether a word in the text
   386|         0|            0|            0|  0.00%|            has not been perturbed for each sample.
   387|         0|            0|            0|  0.00%|        """
   388|         0|            0|            0|  0.00%|        # allocate memory for the binary mask and the perturbed instances
   389|         0|            0|            0|  0.00%|        raw = np.zeros((n, len(self.tokens)), self.dtype)
   390|         0|            0|            0|  0.00%|        data = np.ones((n, len(self.tokens)))
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|        # fill each row of the raw data matrix with the text to be explained
   393|         0|            0|            0|  0.00%|        raw[:] = [x.text for x in self.tokens]
   394|         0|            0|            0|  0.00%|
   395|         0|            0|            0|  0.00%|        for i, t in enumerate(self.tokens):  # apply sampling to each token
   396|         0|            0|            0|  0.00%|            # if the word is part of the anchor, move on to next token
   397|         0|            0|            0|  0.00%|            if i in present:
   398|         0|            0|            0|  0.00%|                continue
   399|         0|            0|            0|  0.00%|
   400|         0|            0|            0|  0.00%|            # check that token does not fall in any forbidden category
   401|         0|            0|            0|  0.00%|            if (t.text not in forbidden_words and t.pos_ in pos and
   402|         0|            0|            0|  0.00%|                    t.lemma_ not in forbidden and t.tag_ not in forbidden_tags):
   403|         0|            0|            0|  0.00%|
   404|         0|            0|            0|  0.00%|                t_neighbors = self.synonyms[t.text]['words']
   405|         0|            0|            0|  0.00%|                # no neighbours with the same tag or word not in spaCy vocabulary
   406|         0|            0|            0|  0.00%|                if t_neighbors.size == 0:
   407|         0|            0|            0|  0.00%|                    continue
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|                n_changed = np.random.binomial(n, sample_proba)
   410|         0|            0|            0|  0.00%|                changed = np.random.choice(n, n_changed, replace=False)
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|                if use_proba:  # use similarity scores to sample changed tokens
   413|         0|            0|            0|  0.00%|                    weights = self.synonyms[t.text]['similarities']
   414|         0|            0|            0|  0.00%|                    weights = np.exp(weights / temperature)  # weighting by temperature (check previous implementation)
   415|         0|            0|            0|  0.00%|                    weights = weights / sum(weights)
   416|         0|            0|            0|  0.00%|                else:
   417|         0|            0|            0|  0.00%|                    weights = np.ones((t_neighbors.shape[0],))
   418|         0|            0|            0|  0.00%|                    weights /= t_neighbors.shape[0]
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|                raw[changed, i] = np.random.choice(t_neighbors, n_changed, p=weights, replace=True)
   421|         0|            0|            0|  0.00%|                data[changed, i] = 0
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|        raw = np.apply_along_axis(self._joiner, axis=1, arr=raw, dtype=self.dtype)
   424|         0|            0|            0|  0.00%|        return raw, data
   425|         0|            0|            0|  0.00%|
   426|         0|            0|            0|  0.00%|    def set_data_type(self) -> None:
   427|         0|            0|            0|  0.00%|        """
   428|         0|            0|            0|  0.00%|        Working with numpy arrays of strings requires setting the data type to avoid
   429|         0|            0|            0|  0.00%|        truncating examples. This function estimates the longest sentence expected
   430|         0|            0|            0|  0.00%|        during the sampling process, which is used to set the number of characters
   431|         0|            0|            0|  0.00%|        for the samples and examples arrays. This depends on the perturbation method
   432|         0|            0|            0|  0.00%|        used for sampling.
   433|         0|            0|            0|  0.00%|        """
   434|         0|            0|            0|  0.00%|        max_len = 0
   435|         0|            0|            0|  0.00%|        max_sent_len = 0
   436|         0|            0|            0|  0.00%|
   437|         0|            0|            0|  0.00%|        for word in self.words:
   438|         0|            0|            0|  0.00%|            similar_words = self.synonyms[word]['words']
   439|         0|            0|            0|  0.00%|            max_len = max(max_len, int(similar_words.dtype.itemsize /
   440|         0|            0|            0|  0.00%|                                       np.dtype(similar_words.dtype.char + '1').itemsize))
   441|         0|            0|            0|  0.00%|            max_sent_len += max_len
   442|         0|            0|            0|  0.00%|            self.dtype = '<U' + str(max_sent_len)
   443|         0|            0|            0|  0.00%|
   444|         0|            0|            0|  0.00%|
   445|         0|            0|            0|  0.00%|class LanguageModelSampler(AnchorTextSampler):
   446|         0|            0|            0|  0.00%|    # filling methods
   447|         0|            0|            0|  0.00%|    FILLING_PARALLEL = 'parallel'
   448|         0|            0|            0|  0.00%|    FILLING_AUTOREGRESSIVE = 'autoregressive'
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|    def __init__(self, model: LanguageModel, perturb_opts: dict,):
   451|         0|            0|            0|  0.00%|        """
   452|         0|            0|            0|  0.00%|        Initialize language model sampler. This sampler replaces words with the ones
   453|         0|            0|            0|  0.00%|        sampled according to the output distribution of the language model. There are
   454|         0|            0|            0|  0.00%|        two modes to use the sampler: `parallel` and `autoregressive`. In the parallel
   455|         0|            0|            0|  0.00%|        mode, all words are replaced at ones. In the `autoregressive` model, the words
   456|         0|            0|            0|  0.00%|        are replaced one by one, starting from left to right. Thus the following words
   457|         0|            0|            0|  0.00%|        are conditioned also on the previous predicted words.
   458|         0|            0|            0|  0.00%|
   459|         0|            0|            0|  0.00%|        Parameters
   460|         0|            0|            0|  0.00%|        ----------
   461|         0|            0|            0|  0.00%|        model
   462|         0|            0|            0|  0.00%|            Transformers masked language model.
   463|         0|            0|            0|  0.00%|        perturb_opts
   464|         0|            0|            0|  0.00%|            Perturbation options.
   465|         0|            0|            0|  0.00%|        """
   466|         0|            0|            0|  0.00%|        super(LanguageModelSampler, self).__init__()
   467|         0|            0|            0|  0.00%|
   468|         0|            0|            0|  0.00%|        # set language model and perturbation options
   469|         0|            0|            0|  0.00%|        self.model = model
   470|         0|            0|            0|  0.00%|        self.perturb_opts = perturb_opts
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|        # Define language model's vocab
   473|         0|            0|            0|  0.00%|        vocab: Dict[str, int] = self.model.tokenizer.get_vocab()
   474|         0|            0|            0|  0.00%|
   475|         0|            0|            0|  0.00%|        # Define masking sampling tensor. This tensor is used to avoid sampling
   476|         0|            0|            0|  0.00%|        # certain tokens from the vocabulary such as: subwords, punctuation, etc.
   477|         0|            0|            0|  0.00%|        self.subwords_mask = np.zeros(len(vocab.keys()), dtype=np.bool_)
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|        for token in vocab:
   480|         0|            0|            0|  0.00%|            # Add subwords in the sampling mask. This means that subwords
   481|         0|            0|            0|  0.00%|            # will not be considered when sampling for the masked words.
   482|         0|            0|            0|  0.00%|            if self.model.is_subword_prefix(token):
   483|         0|            0|            0|  0.00%|                self.subwords_mask[vocab[token]] = True
   484|         0|            0|            0|  0.00%|
   485|         0|            0|            0|  0.00%|            # Add punctuation in the sampling mask. This means that the
   486|         0|            0|            0|  0.00%|            # punctuation will not be considered when sampling for the masked words.
   487|         0|            0|            0|  0.00%|            sample_punctuation: bool = perturb_opts.get('sample_punctuation', False)
   488|         0|            0|            0|  0.00%|            punctuation: str = perturb_opts.get('punctuation', string.punctuation)
   489|         0|            0|            0|  0.00%|
   490|         0|            0|            0|  0.00%|            if (not sample_punctuation) and self.model.is_punctuation(token, punctuation):
   491|         0|            0|            0|  0.00%|                self.subwords_mask[vocab[token]] = True
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|        # define head, tail part of the text
   494|         0|            0|            0|  0.00%|        self.head, self.tail = '', ''  # type: str, str
   495|         0|            0|            0|  0.00%|        self.head_tokens, self.tail_tokens = [], []  # type: List[str], List[str]
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|    def get_sample_ids(self,
   498|         0|            0|            0|  0.00%|                       punctuation: str = string.punctuation,
   499|         0|            0|            0|  0.00%|                       stopwords: Optional[List[str]] = None,
   500|         0|            0|            0|  0.00%|                       **kwargs) -> None:
   501|         0|            0|            0|  0.00%|        """
   502|         0|            0|            0|  0.00%|        Find indices in words which can be perturbed.
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|        Parameters
   505|         0|            0|            0|  0.00%|        ----------
   506|         0|            0|            0|  0.00%|        punctuation
   507|         0|            0|            0|  0.00%|            String of punctuation characters.
   508|         0|            0|            0|  0.00%|        stopwords
   509|         0|            0|            0|  0.00%|            List of stopwords.
   510|         0|            0|            0|  0.00%|        """
   511|         0|            0|            0|  0.00%|        # transform stopwords to lowercase
   512|         0|            0|            0|  0.00%|        if stopwords:
   513|         0|            0|            0|  0.00%|            stopwords = [w.lower().strip() for w in stopwords]
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|        # Initialize list of indices allowed to be perturbed
   516|         0|            0|            0|  0.00%|        ids_sample = list(np.arange(len(self.head_tokens)))
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|        # Define partial function for stopwords checking
   519|         0|            0|            0|  0.00%|        is_stop_word = partial(
   520|         0|            0|            0|  0.00%|            self.model.is_stop_word,
   521|         0|            0|            0|  0.00%|            text=self.head_tokens,
   522|         0|            0|            0|  0.00%|            punctuation=punctuation,
   523|         0|            0|            0|  0.00%|            stopwords=stopwords
   524|         0|            0|            0|  0.00%|        )
   525|         0|            0|            0|  0.00%|
   526|         0|            0|            0|  0.00%|        # lambda expressions to check for a subword
   527|         0|            0|            0|  0.00%|        subword_cond = lambda token, idx: self.model.is_subword_prefix(token)  # noqa: E731
   528|         0|            0|            0|  0.00%|        # lambda experssion to check for a stopword
   529|         0|            0|            0|  0.00%|        stopwords_cond = lambda token, idx: is_stop_word(start_idx=idx)  # noqa: E731
   530|         0|            0|            0|  0.00%|        # lambda expression to check for punctuation
   531|         0|            0|            0|  0.00%|        punctuation_cond = lambda token, idx: self.model.is_punctuation(token, punctuation)  # noqa: E731
   532|         0|            0|            0|  0.00%|
   533|         0|            0|            0|  0.00%|        # Gather all in a list of conditions
   534|         0|            0|            0|  0.00%|        conds = [punctuation_cond, stopwords_cond, subword_cond]
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|        # Remove indices of the tokens that are not allowed to be masked
   537|         0|            0|            0|  0.00%|        for i, token in enumerate(self.head_tokens):
   538|         0|            0|            0|  0.00%|            if any([cond(token, i) for cond in conds]):
   539|         0|            0|            0|  0.00%|                ids_sample.remove(i)
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|        # Save the indices allowed to be masked and the corresponding mapping.
   542|         0|            0|            0|  0.00%|        # The anchor base algorithm alters indices one by one. By saving the mapping
   543|         0|            0|            0|  0.00%|        # and sending only the initial token of a word, we avoid unnecessary sampling.
   544|         0|            0|            0|  0.00%|        # E.g. word = token1 ##token2. Instead of trying two anchors (1 0), (1, 1) - which are
   545|         0|            0|            0|  0.00%|        # equivalent because we take the full word, just try one (1)
   546|         0|            0|            0|  0.00%|        self.ids_sample = np.array(ids_sample)
   547|         0|            0|            0|  0.00%|        self.ids_mapping = {i: id for i, id in enumerate(self.ids_sample)}
   548|         0|            0|            0|  0.00%|
   549|         0|            0|            0|  0.00%|    def set_text(self, text: str):
   550|         0|            0|            0|  0.00%|        """
   551|         0|            0|            0|  0.00%|        Sets the text to be processed
   552|         0|            0|            0|  0.00%|
   553|         0|            0|            0|  0.00%|        Parameters
   554|         0|            0|            0|  0.00%|        ----------
   555|         0|            0|            0|  0.00%|        text
   556|         0|            0|            0|  0.00%|          Text to be processed.
   557|         0|            0|            0|  0.00%|        """
   558|         0|            0|            0|  0.00%|        # Some language models can only work with a limited number of tokens. Thus the text needs
   559|         0|            0|            0|  0.00%|        # to be split in head_text and tail_text. We will only alter the head_tokens.
   560|         0|            0|            0|  0.00%|        self.head, self.tail, self.head_tokens, self.tail_tokens = self.model.head_tail_split(text)
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|        # define indices of the words which can be perturbed
   563|         0|            0|            0|  0.00%|        self.get_sample_ids(**self.perturb_opts)
   564|         0|            0|            0|  0.00%|
   565|         0|            0|            0|  0.00%|        # Set dtypes
   566|         0|            0|            0|  0.00%|        self.set_data_type()
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|    def __call__(self, anchor: tuple, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:
   569|         0|            0|            0|  0.00%|        """
   570|         0|            0|            0|  0.00%|        The function returns  an np.array of num_samples where randomly chose features
   571|         0|            0|            0|  0.00%|        except those in anchor are replaced by words sampled form the language model
   572|         0|            0|            0|  0.00%|        prediction.
   573|         0|            0|            0|  0.00%|
   574|         0|            0|            0|  0.00%|        Parameters
   575|         0|            0|            0|  0.00%|        ----------
   576|         0|            0|            0|  0.00%|        anchor:
   577|         0|            0|            0|  0.00%|            Indices represent the positions of the words to be kept unchanged.
   578|         0|            0|            0|  0.00%|        num_samples:
   579|         0|            0|            0|  0.00%|            Number of perturbed sentences to be returned.
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|        Returns
   582|         0|            0|            0|  0.00%|        -------
   583|         0|            0|            0|  0.00%|        See perturb_sentence
   584|         0|            0|            0|  0.00%|        """
   585|         0|            0|            0|  0.00%|        assert self.perturb_opts, "Perturbation options are not set."
   586|         0|            0|            0|  0.00%|        return self.perturb_sentence(anchor, num_samples, **self.perturb_opts)
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|    def perturb_sentence(self,
   589|         0|            0|            0|  0.00%|                         anchor: tuple,
   590|         0|            0|            0|  0.00%|                         num_samples: int,
   591|         0|            0|            0|  0.00%|                         sample_proba: float = .5,
   592|         0|            0|            0|  0.00%|                         top_n: int = 100,
   593|         0|            0|            0|  0.00%|                         batch_size_lm: int = 32,
   594|         0|            0|            0|  0.00%|                         filling_method: str = "parallel",
   595|         0|            0|            0|  0.00%|                         **kwargs) -> Tuple[np.ndarray, np.ndarray]:
   596|         0|            0|            0|  0.00%|        """
   597|         0|            0|            0|  0.00%|        The function returns  an np.array of num_samples where randomly chose features
   598|         0|            0|            0|  0.00%|        except those in anchor are replaced by similar words.
   599|         0|            0|            0|  0.00%|
   600|         0|            0|            0|  0.00%|        Parameters
   601|         0|            0|            0|  0.00%|        ----------
   602|         0|            0|            0|  0.00%|        anchor:
   603|         0|            0|            0|  0.00%|            Indices represent the positions of the words to be kept unchanged.
   604|         0|            0|            0|  0.00%|        num_samples:
   605|         0|            0|            0|  0.00%|            Number of perturbed sentences to be returned.
   606|         0|            0|            0|  0.00%|        sample_proba:
   607|         0|            0|            0|  0.00%|            Probability of a token being replaced by a similar token.
   608|         0|            0|            0|  0.00%|        top_n:
   609|         0|            0|            0|  0.00%|            Used for top n sampling.
   610|         0|            0|            0|  0.00%|        batch_size_lm:
   611|         0|            0|            0|  0.00%|            Batch size used for language model.
   612|         0|            0|            0|  0.00%|        filling_method:
   613|         0|            0|            0|  0.00%|            Method to fill masked words. Either `parallel` or `ar`.
   614|         0|            0|            0|  0.00%|
   615|         0|            0|            0|  0.00%|        Returns
   616|         0|            0|            0|  0.00%|        -------
   617|         0|            0|            0|  0.00%|        raw
   618|         0|            0|            0|  0.00%|            Array containing num_samples elements. Each element is a perturbed sentence.
   619|         0|            0|            0|  0.00%|        data
   620|         0|            0|            0|  0.00%|            A (num_samples, m)-dimensional boolean array, where m is the number of tokens
   621|         0|            0|            0|  0.00%|            in the instance to be explained.
   622|         0|            0|            0|  0.00%|        """
   623|         0|            0|            0|  0.00%|        # Create the mask
   624|         0|            0|            0|  0.00%|        import pprofile
   625|         0|            0|            0|  0.00%|        profiler = pprofile.Profile()
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|        with profiler:
   628|         0|            0|            0|  0.00%|            raw, data = self.create_mask(
(call)|         1|     0.857838|     0.857838| 99.99%|# /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py:655 create_mask
   629|         0|            0|            0|  0.00%|                anchor=anchor,
   630|         0|            0|            0|  0.00%|                num_samples=num_samples,
   631|         0|            0|            0|  0.00%|                sample_proba=sample_proba,
   632|         0|            0|            0|  0.00%|                filling_method=filling_method,
   633|         0|            0|            0|  0.00%|                **kwargs
   634|         0|            0|            0|  0.00%|            )
   635|         0|            0|            0|  0.00%|        #profiler.print_stats()
   636|         0|            0|            0|  0.00%|        profiler.dump_stats("profiler_stats.txt")
   637|         0|            0|            0|  0.00%|        sys.exit(0)
   638|         0|            0|            0|  0.00%|
   639|         0|            0|            0|  0.00%|        # If the anchor does not covers the entire sentence,
   640|         0|            0|            0|  0.00%|        # then fill in mask with language model
   641|         0|            0|            0|  0.00%|        if len(anchor) != len(self.ids_sample):
   642|         0|            0|            0|  0.00%|            raw, data = self.fill_mask(
   643|         0|            0|            0|  0.00%|                raw=raw, data=data,
   644|         0|            0|            0|  0.00%|                num_samples=num_samples,
   645|         0|            0|            0|  0.00%|                top_n=top_n,
   646|         0|            0|            0|  0.00%|                batch_size_lm=batch_size_lm,
   647|         0|            0|            0|  0.00%|                filling_method=filling_method,
   648|         0|            0|            0|  0.00%|                **kwargs
   649|         0|            0|            0|  0.00%|            )
   650|         0|            0|            0|  0.00%|
   651|         0|            0|            0|  0.00%|        # append tail if it exits
   652|         0|            0|            0|  0.00%|        raw = self._append_tail(raw) if self.tail else raw
   653|         0|            0|            0|  0.00%|        return raw, data
   654|         0|            0|            0|  0.00%|
   655|         1|  1.14441e-05|  1.14441e-05|  0.00%|    def create_mask(self,
   656|         0|            0|            0|  0.00%|                    anchor: tuple,
   657|         0|            0|            0|  0.00%|                    num_samples: int,
   658|         0|            0|            0|  0.00%|                    sample_proba: float = 1.0,
   659|         0|            0|            0|  0.00%|                    filling_method: str = 'parallel',
   660|         0|            0|            0|  0.00%|                    frac_mask_templates: float = 0.1,
   661|         0|            0|            0|  0.00%|                    **kwargs) -> Tuple[np.ndarray, np.ndarray]:
   662|         0|            0|            0|  0.00%|        """
   663|         0|            0|            0|  0.00%|        Create mask for words to be perturbed.
   664|         0|            0|            0|  0.00%|
   665|         0|            0|            0|  0.00%|        Parameters
   666|         0|            0|            0|  0.00%|        ----------
   667|         0|            0|            0|  0.00%|        anchor
   668|         0|            0|            0|  0.00%|            Indices represent the positions of the words to be kept unchanged.
   669|         0|            0|            0|  0.00%|        num_samples
   670|         0|            0|            0|  0.00%|            Number of perturbed sentences to be returned.
   671|         0|            0|            0|  0.00%|        sample_proba
   672|         0|            0|            0|  0.00%|            Probability of a word being replaced.
   673|         0|            0|            0|  0.00%|        filling_method:
   674|         0|            0|            0|  0.00%|            Filling method procedure. Can be `parallel` or `autoregressive`.
   675|         0|            0|            0|  0.00%|            See constructor for more details.
   676|         0|            0|            0|  0.00%|        frac_mask_templates
   677|         0|            0|            0|  0.00%|            Fraction form the number of samples of mask templates
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|        Returns
   680|         0|            0|            0|  0.00%|        -------
   681|         0|            0|            0|  0.00%|        raw
   682|         0|            0|            0|  0.00%|            Array with masked instances.
   683|         0|            0|            0|  0.00%|        data
   684|         0|            0|            0|  0.00%|            A (num_samples, m)-dimensional boolean array, where m is the number of tokens
   685|         0|            0|            0|  0.00%|            in the instance to be explained.
   686|         0|            0|            0|  0.00%|        """
   687|         0|            0|            0|  0.00%|        # make sure that frac_mask_templates is in [0, 1]
   688|         1|  1.93119e-05|  1.93119e-05|  0.00%|        frac_mask_templates = np.clip(frac_mask_templates, 0, 1)
(call)|         1|   0.00043273|   0.00043273|  0.05%|# <__array_function__ internals>:2 clip
   689|         0|            0|            0|  0.00%|
   690|         0|            0|            0|  0.00%|        # compute indices allowed be masked
   691|         1|  5.72205e-06|  5.72205e-06|  0.00%|        all_indices = range(len(self.ids_sample))
   692|         1|  8.10623e-06|  8.10623e-06|  0.00%|        allowed_indices = list(set(all_indices) - set(anchor))
   693|         0|            0|            0|  0.00%|
   694|         1|  4.52995e-06|  4.52995e-06|  0.00%|        if len(allowed_indices) == 0 or filling_method == self.FILLING_AUTOREGRESSIVE:
   695|         0|            0|            0|  0.00%|            # If the anchor covers all the word that can be perturbed (it can happen)
   696|         0|            0|            0|  0.00%|            # then the number of mask_templates should be equal to the number of sampled requested.
   697|         0|            0|            0|  0.00%|            # If the filling method is autoregressive, just generate from the start a `num_sample`
   698|         0|            0|            0|  0.00%|            # masks, cause the computation performance is pretty similar.
   699|         0|            0|            0|  0.00%|            mask_templates = num_samples
   700|         0|            0|            0|  0.00%|        else:
   701|         0|            0|            0|  0.00%|            # If the probability of sampling a word is 1, then all words will be masked.
   702|         0|            0|            0|  0.00%|            # Thus there is no point in generating more than one mask.
   703|         0|            0|            0|  0.00%|            # Otherwise compute the number of masking templates according to the precentage
   704|         0|            0|            0|  0.00%|            # passed as argument and make sure that at least one mask template is generated
   705|         1|  1.33514e-05|  1.33514e-05|  0.00%|            mask_templates = 1 if np.isclose(sample_proba, 1) else max(1, int(num_samples * frac_mask_templates))
(call)|         1|  0.000646591|  0.000646591|  0.08%|# <__array_function__ internals>_1:2 isclose
   706|         0|            0|            0|  0.00%|
   707|         0|            0|            0|  0.00%|        # allocate memory
   708|         1|  1.21593e-05|  1.21593e-05|  0.00%|        data = np.ones((mask_templates, len(self.ids_sample)))
(call)|         1|  6.27041e-05|  6.27041e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py:148 ones
   709|         1|  8.22544e-05|  8.22544e-05|  0.01%|        raw = np.zeros((mask_templates, len(self.head_tokens)), dtype=self.dtype_token)
   710|         0|            0|            0|  0.00%|
   711|         0|            0|            0|  0.00%|        # fill each row of the raw data matrix with the text instance to be explained
   712|         1|  8.34465e-05|  8.34465e-05|  0.01%|        raw[:] = self.head_tokens
   713|         0|            0|            0|  0.00%|
   714|         0|            0|            0|  0.00%|        # create mask
   715|         1|  5.00679e-06|  5.00679e-06|  0.00%|        if len(allowed_indices):
   716|      1001|    0.0019958|  1.99381e-06|  0.23%|            for i in range(mask_templates):
   717|         0|            0|            0|  0.00%|                # Here the sampling of the indices of the word to be masked is done by rows
   718|         0|            0|            0|  0.00%|                # and not by columns as in the other sampling methods. The reason is that
   719|         0|            0|            0|  0.00%|                # is much easier to ensure that at least one word in the sentence is masked.
   720|         0|            0|            0|  0.00%|                # If the sampling is performed over the columns it might be the case
   721|         0|            0|            0|  0.00%|                # that no word in a sentence will be masked.
   722|      1000|    0.0101428|  1.01428e-05|  1.18%|                n_changed = max(1, np.random.binomial(len(allowed_indices), sample_proba))
   723|      1000|    0.0254443|  2.54443e-05|  2.97%|                changed = np.random.choice(allowed_indices, n_changed, replace=False)
(call)|      1000|    0.0683818|  6.83818e-05|  7.97%|# <__array_function__ internals>_5:2 prod
   724|         0|            0|            0|  0.00%|
   725|         0|            0|            0|  0.00%|                # mark the entrance as maks
   726|      1000|   0.00803566|  8.03566e-06|  0.94%|                data[i, changed] = 0
   727|         0|            0|            0|  0.00%|
   728|         0|            0|            0|  0.00%|                # Mask the corresponding words. This requires a mapping from indices
   729|         0|            0|            0|  0.00%|                # to the actual position of the words in the text
   730|     13027|    0.0331752|  2.54665e-06|  3.87%|                changed_mapping = [self.ids_mapping[j] for j in changed]
(call)|      1000|    0.0245609|  2.45609e-05|  2.86%|# /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py:730 <listcomp>
   731|      1000|    0.0131609|  1.31609e-05|  1.53%|                raw[i, changed_mapping] = self.model.mask
(call)|      1000|    0.0111461|  1.11461e-05|  1.30%|# /home/robert/Desktop/seldon/alibi/alibi/utils/lang_model.py:241 mask
   732|         0|            0|            0|  0.00%|
   733|         0|            0|            0|  0.00%|                # Have to remove the subwords of the masked word, which has to be done iteratively
   734|     11027|    0.0244675|  2.21887e-06|  2.85%|                for j in changed_mapping:
   735|     10027|    0.0707059|  7.05155e-06|  8.24%|                    self._remove_subwords(raw=raw, row=i, col=j, **kwargs)
(call)|     10027|     0.388368|  3.87322e-05| 45.27%|# /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py:838 _remove_subwords
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|        # join words
   738|         1|  1.33514e-05|  1.33514e-05|  0.00%|        raw = np.apply_along_axis(self._joiner, axis=1, arr=raw, dtype=self.dtype_sent)
(call)|         1|     0.201409|     0.201409| 23.48%|# <__array_function__ internals>_6:2 apply_along_axis
   739|         1|  4.05312e-06|  4.05312e-06|  0.00%|        return raw, data
   740|         0|            0|            0|  0.00%|
   741|         0|            0|            0|  0.00%|    def _append_tail(self, raw: np.ndarray) -> np.ndarray:
   742|         0|            0|            0|  0.00%|        """
   743|         0|            0|            0|  0.00%|        Appends the tail part of the text to the new sampled head.
   744|         0|            0|            0|  0.00%|
   745|         0|            0|            0|  0.00%|        Parameters
   746|         0|            0|            0|  0.00%|        ----------
   747|         0|            0|            0|  0.00%|        raw
   748|         0|            0|            0|  0.00%|            New sampled heads.
   749|         0|            0|            0|  0.00%|
   750|         0|            0|            0|  0.00%|        Returns
   751|         0|            0|            0|  0.00%|        -------
   752|         0|            0|            0|  0.00%|        full_raw
   753|         0|            0|            0|  0.00%|            Concatenation of the new sampled head with the original tail.
   754|         0|            0|            0|  0.00%|        """
   755|         0|            0|            0|  0.00%|        full_raw = []
   756|         0|            0|            0|  0.00%|
   757|         0|            0|            0|  0.00%|        for i in range(raw.shape[0]):
   758|         0|            0|            0|  0.00%|            new_head_tokens = self.model.tokenizer.tokenize(raw[i])
   759|         0|            0|            0|  0.00%|            new_tokens = new_head_tokens + self.tail_tokens
   760|         0|            0|            0|  0.00%|            full_raw.append(self.model.tokenizer.convert_tokens_to_string(new_tokens))
   761|         0|            0|            0|  0.00%|
   762|         0|            0|            0|  0.00%|        # convert to array and return
   763|         0|            0|            0|  0.00%|        return np.array(full_raw, dtype=self.dtype_sent)
   764|         0|            0|            0|  0.00%|
   765|      1000|   0.00168633|  1.68633e-06|  0.20%|    def _joiner(self, arr: np.ndarray, dtype: np.dtype = None) -> np.ndarray:
   766|         0|            0|            0|  0.00%|        """
   767|         0|            0|            0|  0.00%|        Function to concatenate an np.array of strings along a specified axis.
   768|         0|            0|            0|  0.00%|
   769|         0|            0|            0|  0.00%|        Parameters
   770|         0|            0|            0|  0.00%|        ----------
   771|         0|            0|            0|  0.00%|        arr
   772|         0|            0|            0|  0.00%|            1D numpy array of strings.
   773|         0|            0|            0|  0.00%|        dtype
   774|         0|            0|            0|  0.00%|           Array type, used to avoid truncation of strings when concatenating along axis.
   775|         0|            0|            0|  0.00%|
   776|         0|            0|            0|  0.00%|        Returns
   777|         0|            0|            0|  0.00%|        -------
   778|         0|            0|            0|  0.00%|            Array with one element, the concatenation of the strings in the input array.
   779|         0|            0|            0|  0.00%|        """
   780|     51000|     0.135304|  2.65303e-06| 15.77%|        filtered_arr = list(filter(lambda x: len(x) > 0, arr))
(call)|     25000|    0.0583053|  2.33221e-06|  6.80%|# /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py:780 <lambda>
   781|      1000|   0.00545621|  5.45621e-06|  0.64%|        str_arr = self.model.tokenizer.convert_tokens_to_string(filtered_arr)
(call)|      1000|    0.0178671|  1.78671e-05|  2.08%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py:493 convert_tokens_to_string
   782|         0|            0|            0|  0.00%|
   783|      1000|   0.00153494|  1.53494e-06|  0.18%|        if not dtype:
   784|         0|            0|            0|  0.00%|            return np.array(str_arr)
   785|         0|            0|            0|  0.00%|
   786|      1000|    0.0049994|   4.9994e-06|  0.58%|        return np.array(str_arr).astype(dtype)
   787|         0|            0|            0|  0.00%|
   788|         0|            0|            0|  0.00%|    def fill_mask(self,
   789|         0|            0|            0|  0.00%|                  raw: np.ndarray,
   790|         0|            0|            0|  0.00%|                  data: np.ndarray,
   791|         0|            0|            0|  0.00%|                  num_samples: int,
   792|         0|            0|            0|  0.00%|                  top_n: int = 100,
   793|         0|            0|            0|  0.00%|                  batch_size_lm: int = 32,
   794|         0|            0|            0|  0.00%|                  filling_method: str = "parallel",
   795|         0|            0|            0|  0.00%|                  **kwargs) -> Tuple[np.ndarray, np.ndarray]:
   796|         0|            0|            0|  0.00%|        """
   797|         0|            0|            0|  0.00%|        Fill in the masked tokens with language model.
   798|         0|            0|            0|  0.00%|
   799|         0|            0|            0|  0.00%|        Parameters
   800|         0|            0|            0|  0.00%|        ----------
   801|         0|            0|            0|  0.00%|        raw
   802|         0|            0|            0|  0.00%|            Array of mask templates.
   803|         0|            0|            0|  0.00%|        data
   804|         0|            0|            0|  0.00%|            Binary mask having 0 where the word was masked. Note that
   805|         0|            0|            0|  0.00%|            the width of the data array is equal to the length of id_samples.
   806|         0|            0|            0|  0.00%|        num_samples
   807|         0|            0|            0|  0.00%|            Number of samples to be drawn.
   808|         0|            0|            0|  0.00%|        top_n:
   809|         0|            0|            0|  0.00%|            Use the top n words when sampling.
   810|         0|            0|            0|  0.00%|        batch_size_lm:
   811|         0|            0|            0|  0.00%|            Batch size used for language model.
   812|         0|            0|            0|  0.00%|        filling_method
   813|         0|            0|            0|  0.00%|            Filling method procedure. Can be `parallel` or `autoregressive`.
   814|         0|            0|            0|  0.00%|            See constructor for more details.
   815|         0|            0|            0|  0.00%|
   816|         0|            0|            0|  0.00%|        Returns
   817|         0|            0|            0|  0.00%|        -------
   818|         0|            0|            0|  0.00%|        raw
   819|         0|            0|            0|  0.00%|            Array containing num_samples elements. Each element is a perturbed sentence.
   820|         0|            0|            0|  0.00%|        """
   821|         0|            0|            0|  0.00%|        # chose the perturbation function
   822|         0|            0|            0|  0.00%|        perturb_func = self._perturb_instances_parallel if filling_method == self.FILLING_PARALLEL\
   823|         0|            0|            0|  0.00%|            else self._perturb_instance_ar
   824|         0|            0|            0|  0.00%|
   825|         0|            0|            0|  0.00%|        # perturb instances
   826|         0|            0|            0|  0.00%|        tokens, data = perturb_func(
   827|         0|            0|            0|  0.00%|            raw=raw, data=data,
   828|         0|            0|            0|  0.00%|            num_samples=num_samples,
   829|         0|            0|            0|  0.00%|            batch_size_lm=batch_size_lm,
   830|         0|            0|            0|  0.00%|            top_n=top_n,
   831|         0|            0|            0|  0.00%|            **kwargs
   832|         0|            0|            0|  0.00%|        )
   833|         0|            0|            0|  0.00%|
   834|         0|            0|            0|  0.00%|        # decode the tokens and remove special characters as <pad>, <cls> etc.
   835|         0|            0|            0|  0.00%|        raw = self.model.tokenizer.batch_decode(tokens, **dict(skip_special_tokens=True))
   836|         0|            0|            0|  0.00%|        return np.array(raw), data
   837|         0|            0|            0|  0.00%|
   838|     10027|    0.0158358|  1.57931e-06|  1.85%|    def _remove_subwords(self, raw: np.ndarray, row: int, col: int, punctuation: str = '', **kwargs) -> np.ndarray:
   839|         0|            0|            0|  0.00%|        """
   840|         0|            0|            0|  0.00%|        Deletes the subwords that follow a given token identified by the (row, col) pair in the `raw` matrix.
   841|         0|            0|            0|  0.00%|        A token is considered to be part of a word if is not a punctuation and if has the subword prefix
   842|         0|            0|            0|  0.00%|        specific to the used language model. The subwords are not actually deleted in, but they are replace
   843|         0|            0|            0|  0.00%|        by the empty string ``
   844|         0|            0|            0|  0.00%|
   845|         0|            0|            0|  0.00%|        Parameters
   846|         0|            0|            0|  0.00%|        ----------
   847|         0|            0|            0|  0.00%|        raw
   848|         0|            0|            0|  0.00%|            Array of tokens.
   849|         0|            0|            0|  0.00%|        row
   850|         0|            0|            0|  0.00%|            Row coordinate of the word to be removed.
   851|         0|            0|            0|  0.00%|        col
   852|         0|            0|            0|  0.00%|            Col coodrinate of the word to be removed.
   853|         0|            0|            0|  0.00%|        punctuation
   854|         0|            0|            0|  0.00%|            String containing the punctuation to be considered.
   855|         0|            0|            0|  0.00%|
   856|         0|            0|            0|  0.00%|        Returns
   857|         0|            0|            0|  0.00%|        -------
   858|         0|            0|            0|  0.00%|        raw
   859|         0|            0|            0|  0.00%|            Array of tokens where deleted subwords are replaced by the empty string.
   860|         0|            0|            0|  0.00%|        """
   861|     11010|      0.02561|  2.32606e-06|  2.99%|        for next_col in range(col + 1, len(self.head_tokens)):
   862|         0|            0|            0|  0.00%|            # if encounter a punctuation, just stop
   863|     11010|    0.0622246|  5.65165e-06|  7.25%|            if self.model.is_punctuation(raw[row, next_col], punctuation):
(call)|     11010|     0.180685|   1.6411e-05| 21.06%|# /home/robert/Desktop/seldon/alibi/alibi/utils/lang_model.py:103 is_punctuation
   864|      1503|   0.00224638|   1.4946e-06|  0.26%|                break
   865|         0|            0|            0|  0.00%|
   866|         0|            0|            0|  0.00%|            # if it is a subword prefix, then replace it by empty string
   867|      9507|    0.0480914|  5.05853e-06|  5.61%|            if self.model.is_subword_prefix(raw[row, next_col]):
(call)|      9507|    0.0251737|  2.64791e-06|  2.93%|# /home/robert/Desktop/seldon/alibi/alibi/utils/lang_model.py:245 is_subword_prefix
   868|       983|   0.00206542|  2.10114e-06|  0.24%|                raw[row, next_col] = ''
   869|         0|            0|            0|  0.00%|            else:
   870|      8524|    0.0125413|  1.47129e-06|  1.46%|                break
   871|         0|            0|            0|  0.00%|
   872|     10027|    0.0138946|  1.38571e-06|  1.62%|        return raw
   873|         0|            0|            0|  0.00%|
   874|         0|            0|            0|  0.00%|    def _perturb_instances_parallel(self,
   875|         0|            0|            0|  0.00%|                                    num_samples: int,
   876|         0|            0|            0|  0.00%|                                    raw: np.ndarray,
   877|         0|            0|            0|  0.00%|                                    data: np.ndarray,
   878|         0|            0|            0|  0.00%|                                    top_n: int = 100,
   879|         0|            0|            0|  0.00%|                                    batch_size_lm: int = 32,
   880|         0|            0|            0|  0.00%|                                    temperature: float = 1.0,
   881|         0|            0|            0|  0.00%|                                    use_proba: bool = False,
   882|         0|            0|            0|  0.00%|                                    **kwargs) -> Tuple[np.ndarray, np.ndarray]:
   883|         0|            0|            0|  0.00%|        """
   884|         0|            0|            0|  0.00%|        Perturb the instances in a single forward pass (parallel).
   885|         0|            0|            0|  0.00%|
   886|         0|            0|            0|  0.00%|        Parameters
   887|         0|            0|            0|  0.00%|        ----------
   888|         0|            0|            0|  0.00%|        num_samples
   889|         0|            0|            0|  0.00%|            Number of samples to be generates
   890|         0|            0|            0|  0.00%|        raw
   891|         0|            0|            0|  0.00%|            Array of mask templates. Has `mask_templates` rows
   892|         0|            0|            0|  0.00%|        data
   893|         0|            0|            0|  0.00%|            Binary array having 0 where the tokens are masked. Has `mask_templates` rows.
   894|         0|            0|            0|  0.00%|        top_n:
   895|         0|            0|            0|  0.00%|            Use the top n words when sampling.
   896|         0|            0|            0|  0.00%|        batch_size_lm:
   897|         0|            0|            0|  0.00%|            Batch size used for language model.
   898|         0|            0|            0|  0.00%|        temperature
   899|         0|            0|            0|  0.00%|            Sample weight hyper-parameter.
   900|         0|            0|            0|  0.00%|        use_proba
   901|         0|            0|            0|  0.00%|            Bool whether to sample according to the predicted words distribution
   902|         0|            0|            0|  0.00%|
   903|         0|            0|            0|  0.00%|        Returns
   904|         0|            0|            0|  0.00%|        -------
   905|         0|            0|            0|  0.00%|        sampled_tokens
   906|         0|            0|            0|  0.00%|            Tensor containing the ids of the sampled tokens.
   907|         0|            0|            0|  0.00%|            Has `num_samples` rows.
   908|         0|            0|            0|  0.00%|        sampled_data
   909|         0|            0|            0|  0.00%|            Binary array havin 0 where the tokens were masked.
   910|         0|            0|            0|  0.00%|            Has `num_samples` rows.
   911|         0|            0|            0|  0.00%|        """
   912|         0|            0|            0|  0.00%|        # tokenize instances
   913|         0|            0|            0|  0.00%|        tokens_plus = self.model.tokenizer.batch_encode_plus(list(raw), padding=True, return_tensors='tf')
   914|         0|            0|            0|  0.00%|
   915|         0|            0|            0|  0.00%|        # number of samples to generate per mask template
   916|         0|            0|            0|  0.00%|        reminder = num_samples % len(raw)
   917|         0|            0|            0|  0.00%|        mult_factor = num_samples // len(raw)
   918|         0|            0|            0|  0.00%|
   919|         0|            0|            0|  0.00%|        # fill in masks with language model
   920|         0|            0|            0|  0.00%|        # (mask_template x max_length_sentence x num_tokens)
   921|         0|            0|            0|  0.00%|        logits: np.ndarray = self.model.predict_batch_lm(x=tokens_plus,
   922|         0|            0|            0|  0.00%|                                                         vocab_size=self.model.tokenizer.vocab_size,
   923|         0|            0|            0|  0.00%|                                                         batch_size=batch_size_lm)
   924|         0|            0|            0|  0.00%|
   925|         0|            0|            0|  0.00%|        # select rows and cols where the input the tokens are masked
   926|         0|            0|            0|  0.00%|        tokens = tokens_plus['input_ids']  # (mask_template x max_length_sentence)
   927|         0|            0|            0|  0.00%|        mask_pos = tf.where(tokens == self.model.mask_token)
   928|         0|            0|            0|  0.00%|        mask_row, mask_col = mask_pos[:, 0], mask_pos[:, 1]
   929|         0|            0|            0|  0.00%|
   930|         0|            0|            0|  0.00%|        # buffer containing sampled tokens
   931|         0|            0|            0|  0.00%|        sampled_tokens = np.zeros((num_samples, tokens.shape[1]), dtype=np.int32)
   932|         0|            0|            0|  0.00%|        sampled_data = np.zeros((num_samples, data.shape[1]))
   933|         0|            0|            0|  0.00%|
   934|         0|            0|            0|  0.00%|        # initialize offset
   935|         0|            0|            0|  0.00%|        offset = 0
   936|         0|            0|            0|  0.00%|
   937|         0|            0|            0|  0.00%|        for i in range(logits.shape[0]):
   938|         0|            0|            0|  0.00%|            # select indices corresponding to the current row `i`
   939|         0|            0|            0|  0.00%|            idx = tf.reshape(tf.where(mask_row == i), shape=-1)
   940|         0|            0|            0|  0.00%|
   941|         0|            0|            0|  0.00%|            # select columns corresponding to the current row `i`
   942|         0|            0|            0|  0.00%|            cols = tf.gather(mask_col, idx)
   943|         0|            0|            0|  0.00%|
   944|         0|            0|            0|  0.00%|            # select the logits of the masked input
   945|         0|            0|            0|  0.00%|            logits_mask = logits[i, cols, :]
   946|         0|            0|            0|  0.00%|
   947|         0|            0|            0|  0.00%|            # mask out tokens according to the subword_mask
   948|         0|            0|            0|  0.00%|            logits_mask[:, self.subwords_mask] = -np.inf
   949|         0|            0|            0|  0.00%|
   950|         0|            0|            0|  0.00%|            # select top n tokens from each distribution
   951|         0|            0|            0|  0.00%|            top_k = tf.math.top_k(logits_mask, top_n)
   952|         0|            0|            0|  0.00%|            top_k_logits, top_k_tokens = top_k.values, top_k.indices
   953|         0|            0|            0|  0.00%|
   954|         0|            0|            0|  0.00%|            # create categorical distribution that we can sample the words from
   955|         0|            0|            0|  0.00%|            top_k_logits = (top_k_logits / temperature) if use_proba else (top_k_logits * 0)
   956|         0|            0|            0|  0.00%|            dist = tfp.distributions.Categorical(logits=top_k_logits)
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|            # sample `num_samples` instance for the current mask template
   959|         0|            0|            0|  0.00%|            for j in range(mult_factor + int(reminder > 0)):
   960|         0|            0|            0|  0.00%|                # Compute the buffer index
   961|         0|            0|            0|  0.00%|                idx = i * mult_factor + j + offset
   962|         0|            0|            0|  0.00%|
   963|         0|            0|            0|  0.00%|                # Sample indices
   964|         0|            0|            0|  0.00%|                ids_k = dist.sample()
   965|         0|            0|            0|  0.00%|
   966|         0|            0|            0|  0.00%|                # Set the unmasked tokens and for the masked one and replace them with the samples drawn
   967|         0|            0|            0|  0.00%|                sampled_tokens[idx] = tokens[i]
   968|         0|            0|            0|  0.00%|                sampled_tokens[idx, cols] = tf.gather(top_k_tokens, ids_k, batch_dims=1)
   969|         0|            0|            0|  0.00%|
   970|         0|            0|            0|  0.00%|            # Add the original binary mask which marks the beginning of a masked
   971|         0|            0|            0|  0.00%|            # word, as is needed for the anchor algorithm (backend stuff)
   972|         0|            0|            0|  0.00%|            idx = i * mult_factor
   973|         0|            0|            0|  0.00%|            sampled_data[idx + offset:idx + mult_factor + offset + (reminder > 0)] = data[i]
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|            # decrement reminder and increase counter if reminder is gt 0
   976|         0|            0|            0|  0.00%|            reminder -= 1
   977|         0|            0|            0|  0.00%|            offset += int(reminder > 0)
   978|         0|            0|            0|  0.00%|
   979|         0|            0|            0|  0.00%|        # Check that there are not masked tokens left
   980|         0|            0|            0|  0.00%|        assert np.all(sampled_tokens != self.model.mask_token)
   981|         0|            0|            0|  0.00%|        return sampled_tokens, sampled_data
   982|         0|            0|            0|  0.00%|
   983|         0|            0|            0|  0.00%|    def _perturb_instance_ar(self,
   984|         0|            0|            0|  0.00%|                             num_samples: int,
   985|         0|            0|            0|  0.00%|                             raw: np.ndarray,
   986|         0|            0|            0|  0.00%|                             data: np.ndarray,
   987|         0|            0|            0|  0.00%|                             top_n: int = 100,
   988|         0|            0|            0|  0.00%|                             batch_size: int = 32,
   989|         0|            0|            0|  0.00%|                             temperature: float = 1.0,
   990|         0|            0|            0|  0.00%|                             use_proba: bool = False,
   991|         0|            0|            0|  0.00%|                             **kwargs) -> Tuple[np.ndarray, np.ndarray]:
   992|         0|            0|            0|  0.00%|        """
   993|         0|            0|            0|  0.00%|        Perturb the instances in an autoregressive fashion (sequential).
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|        ----------
   996|         0|            0|            0|  0.00%|        num_samples
   997|         0|            0|            0|  0.00%|            Number of samples to be generates
   998|         0|            0|            0|  0.00%|        raw
   999|         0|            0|            0|  0.00%|            Array of mask templates. Has `mask_templates` rows
  1000|         0|            0|            0|  0.00%|        data
  1001|         0|            0|            0|  0.00%|            Binary array having 0 where the tokens are masked. Has `mask_templates` rows.
  1002|         0|            0|            0|  0.00%|        top_n:
  1003|         0|            0|            0|  0.00%|            Use the top n words when sampling.
  1004|         0|            0|            0|  0.00%|        batch_size_lm:
  1005|         0|            0|            0|  0.00%|            Batch size used for language model.
  1006|         0|            0|            0|  0.00%|        temperature
  1007|         0|            0|            0|  0.00%|            Sample weight hyper-parameter.
  1008|         0|            0|            0|  0.00%|        use_proba
  1009|         0|            0|            0|  0.00%|            Bool whether to sample according to the predicted words distribution
  1010|         0|            0|            0|  0.00%|
  1011|         0|            0|            0|  0.00%|        Returns
  1012|         0|            0|            0|  0.00%|        -------
  1013|         0|            0|            0|  0.00%|        sampled_tokens
  1014|         0|            0|            0|  0.00%|            Tensor containing the ids of the sampled tokens.
  1015|         0|            0|            0|  0.00%|            Has `num_samples` rows.
  1016|         0|            0|            0|  0.00%|        sampled_data
  1017|         0|            0|            0|  0.00%|            Binary array havin 0 where the tokens were masked.
  1018|         0|            0|            0|  0.00%|            Has `num_samples` rows.
  1019|         0|            0|            0|  0.00%|        """
  1020|         0|            0|            0|  0.00%|        # number of samples to generate per mask template
  1021|         0|            0|            0|  0.00%|        assert num_samples == raw.shape[0]
  1022|         0|            0|            0|  0.00%|
  1023|         0|            0|            0|  0.00%|        # tokenize instances
  1024|         0|            0|            0|  0.00%|        tokens_plus = self.model.tokenizer.batch_encode_plus(list(raw), padding=True, return_tensors='tf')
  1025|         0|            0|            0|  0.00%|        tokens = tokens_plus['input_ids'].numpy()  # (mask_template x max_length_sentence)
  1026|         0|            0|            0|  0.00%|
  1027|         0|            0|            0|  0.00%|        # store the column indices for each row where a token is a mask
  1028|         0|            0|            0|  0.00%|        masked_idx = []
  1029|         0|            0|            0|  0.00%|        max_len_idx = -1
  1030|         0|            0|            0|  0.00%|        mask_pos = tf.where(tokens == self.model.mask_token)
  1031|         0|            0|            0|  0.00%|        mask_row, mask_col = mask_pos[:, 0], mask_pos[:, 1]
  1032|         0|            0|            0|  0.00%|
  1033|         0|            0|            0|  0.00%|        for i in range(tokens.shape[0]):
  1034|         0|            0|            0|  0.00%|            # get the columns indexes and store them in the buffer
  1035|         0|            0|            0|  0.00%|            idx = tf.reshape(tf.where(mask_row == i), shape=-1)
  1036|         0|            0|            0|  0.00%|            cols = tf.gather(mask_col, idx)
  1037|         0|            0|            0|  0.00%|            masked_idx.append(cols)
  1038|         0|            0|            0|  0.00%|
  1039|         0|            0|            0|  0.00%|            # update maximum length
  1040|         0|            0|            0|  0.00%|            max_len_idx = max(max_len_idx, len(cols))
  1041|         0|            0|            0|  0.00%|
  1042|         0|            0|            0|  0.00%|        # iterate through all possible columns indexes
  1043|         0|            0|            0|  0.00%|        for i in range(max_len_idx):
  1044|         0|            0|            0|  0.00%|            masked_rows, masked_cols = [], []
  1045|         0|            0|            0|  0.00%|
  1046|         0|            0|            0|  0.00%|            # iterate through all possible examples
  1047|         0|            0|            0|  0.00%|            for row in range(tokens.shape[0]):
  1048|         0|            0|            0|  0.00%|                # this means that the row does not have any more masked columns
  1049|         0|            0|            0|  0.00%|                if len(masked_idx[row]) <= i:
  1050|         0|            0|            0|  0.00%|                    continue
  1051|         0|            0|            0|  0.00%|
  1052|         0|            0|            0|  0.00%|                masked_rows.append(row)
  1053|         0|            0|            0|  0.00%|                masked_cols.append(masked_idx[row][i])
  1054|         0|            0|            0|  0.00%|
  1055|         0|            0|            0|  0.00%|            # compute logits
  1056|         0|            0|            0|  0.00%|            logits: np.ndarray = self.model.predict_batch_lm(
  1057|         0|            0|            0|  0.00%|                tokens_plus,
  1058|         0|            0|            0|  0.00%|                self.model.tokenizer.vocab_size,
  1059|         0|            0|            0|  0.00%|                batch_size
  1060|         0|            0|            0|  0.00%|            )
  1061|         0|            0|            0|  0.00%|
  1062|         0|            0|            0|  0.00%|            # select only the logits of the first masked word in each row
  1063|         0|            0|            0|  0.00%|            logits_mask = logits[masked_rows, masked_cols, :]
  1064|         0|            0|            0|  0.00%|
  1065|         0|            0|            0|  0.00%|            # mask out words according to the subword_mask
  1066|         0|            0|            0|  0.00%|            logits_mask[:, self.subwords_mask] = -np.inf
  1067|         0|            0|            0|  0.00%|
  1068|         0|            0|            0|  0.00%|            # select top n tokens from each distribution
  1069|         0|            0|            0|  0.00%|            top_k = tf.math.top_k(logits_mask, top_n)
  1070|         0|            0|            0|  0.00%|            top_k_logits, top_k_tokens = top_k.values, top_k.indices
  1071|         0|            0|            0|  0.00%|
  1072|         0|            0|            0|  0.00%|            # create categorical distribution that we can sample the words from
  1073|         0|            0|            0|  0.00%|            top_k_logits = (top_k_logits / temperature) if use_proba else (top_k_logits * 0)
  1074|         0|            0|            0|  0.00%|            dist = tfp.distributions.Categorical(logits=top_k_logits)
  1075|         0|            0|            0|  0.00%|
  1076|         0|            0|            0|  0.00%|            # sample indexes
  1077|         0|            0|            0|  0.00%|            ids_k = dist.sample()
  1078|         0|            0|            0|  0.00%|
  1079|         0|            0|            0|  0.00%|            # replace masked tokens with the sampled one
  1080|         0|            0|            0|  0.00%|            tokens[masked_rows, masked_cols] = tf.gather(top_k_tokens, ids_k, batch_dims=1)
  1081|         0|            0|            0|  0.00%|        return tokens, data
  1082|         0|            0|            0|  0.00%|
  1083|         0|            0|            0|  0.00%|    def set_data_type(self) -> None:
  1084|         0|            0|            0|  0.00%|        """
  1085|         0|            0|            0|  0.00%|        Working with numpy arrays of strings requires setting the data type to avoid
  1086|         0|            0|            0|  0.00%|        truncating examples. This function estimates the longest sentence expected
  1087|         0|            0|            0|  0.00%|        during the sampling process, which is used to set the number of characters
  1088|         0|            0|            0|  0.00%|        for the samples and examples arrays. This depends on the perturbation method
  1089|         0|            0|            0|  0.00%|        used for sampling.
  1090|         0|            0|            0|  0.00%|        """
  1091|         0|            0|            0|  0.00%|
  1092|         0|            0|            0|  0.00%|        # get the vocabulary
  1093|         0|            0|            0|  0.00%|        vocab = self.model.tokenizer.get_vocab()
  1094|         0|            0|            0|  0.00%|        max_len = 0
  1095|         0|            0|            0|  0.00%|
  1096|         0|            0|            0|  0.00%|        # go through the vocabulary and compute the maximum length of a token
  1097|         0|            0|            0|  0.00%|        for token in vocab.keys():
  1098|         0|            0|            0|  0.00%|            max_len = len(token) if len(token) > max_len else max_len
  1099|         0|            0|            0|  0.00%|
  1100|         0|            0|            0|  0.00%|        # length of the maximum word. the prefix it is just a precaution.
  1101|         0|            0|            0|  0.00%|        # for example <mask> -> _<mask> which is not in the vocabulary).
  1102|         0|            0|            0|  0.00%|        max_len += len(self.model.SUBWORD_PREFIX)
  1103|         0|            0|            0|  0.00%|
  1104|         0|            0|            0|  0.00%|        # length of the maximum text
  1105|         0|            0|            0|  0.00%|        max_sent_len = (len(self.head_tokens) + len(self.tail_tokens)) * max_len
  1106|         0|            0|            0|  0.00%|
  1107|         0|            0|            0|  0.00%|        # define the types to be used
  1108|         0|            0|            0|  0.00%|        self.dtype_token = '<U' + str(max_len)
  1109|         0|            0|            0|  0.00%|        self.dtype_sent = '<U' + str(max_sent_len)
  1110|         0|            0|            0|  0.00%|
  1111|         0|            0|            0|  0.00%|
  1112|         0|            0|            0|  0.00%|DEFAULT_SAMPLING_UNKNOWN = {
  1113|         0|            0|            0|  0.00%|  "sample_proba": 0.5
  1114|         0|            0|            0|  0.00%|}
  1115|         0|            0|            0|  0.00%|"""
  1116|         0|            0|            0|  0.00%|Default perturbation options for `unknown` sampling
  1117|         0|            0|            0|  0.00%|
  1118|         0|            0|            0|  0.00%|    - ``'sample_proba'``: float, probability of a word to be masked.
  1119|         0|            0|            0|  0.00%|"""
  1120|         0|            0|            0|  0.00%|
  1121|         0|            0|            0|  0.00%|DEFAULT_SAMPLING_SIMILARITY = {
  1122|         0|            0|            0|  0.00%|  "sample_proba": 0.5,
  1123|         0|            0|            0|  0.00%|  "top_n": 100,
  1124|         0|            0|            0|  0.00%|  "temperature": 1.0,
  1125|         0|            0|            0|  0.00%|  "use_proba": False
  1126|         0|            0|            0|  0.00%|}
  1127|         0|            0|            0|  0.00%|"""
  1128|         0|            0|            0|  0.00%|Default perturbation options for `similarity` sampling
  1129|         0|            0|            0|  0.00%|
  1130|         0|            0|            0|  0.00%|    - ``'sample_proba'``: float, probability of a word to be masked.
  1131|         0|            0|            0|  0.00%|
  1132|         0|            0|            0|  0.00%|    - ``'top_n'``: int, number of similar words to sample for perturbations
  1133|         0|            0|            0|  0.00%|
  1134|         0|            0|            0|  0.00%|    - ``'temperature'``: float, sample weight hyper-parameter if `use_proba` equals `True`.
  1135|         0|            0|            0|  0.00%|
  1136|         0|            0|            0|  0.00%|    - ``'use_proba'``: bool, whether to sample according to the words similarity.
  1137|         0|            0|            0|  0.00%|"""
  1138|         0|            0|            0|  0.00%|
  1139|         0|            0|            0|  0.00%|DEFAULT_SAMPLING_LANGUAGE_MODEL = {
  1140|         0|            0|            0|  0.00%|  "filling_method": "parallel",
  1141|         0|            0|            0|  0.00%|  "sample_proba": 0.5,
  1142|         0|            0|            0|  0.00%|  "top_n": 100,
  1143|         0|            0|            0|  0.00%|  "temperature": 1.0,
  1144|         0|            0|            0|  0.00%|  "use_proba": False,
  1145|         0|            0|            0|  0.00%|  "frac_mask_templates": 0.1,
  1146|         0|            0|            0|  0.00%|  "batch_size_lm": 32,
  1147|         0|            0|            0|  0.00%|  "punctuation": string.punctuation,
  1148|         0|            0|            0|  0.00%|  "stopwords": [],
  1149|         0|            0|            0|  0.00%|  "sample_punctuation": False,
  1150|         0|            0|            0|  0.00%|}
  1151|         0|            0|            0|  0.00%|"""
  1152|         0|            0|            0|  0.00%|Default perturbation options for `similarity` sampling
  1153|         0|            0|            0|  0.00%|
  1154|         0|            0|            0|  0.00%|    - ``'filling_method'``: str, filling method for language models. Allowed values: `parallel`, `autoregressive`. \
  1155|         0|            0|            0|  0.00%|    `parallel` method correspond to a single forward pass through the language model. The masked words are sampled \
  1156|         0|            0|            0|  0.00%|    independent, according to the selected probability distribution (see `top_n`, `temperature`, `use_proba`).  \
  1157|         0|            0|            0|  0.00%|    `autoregressive` method fills the words one at the time. This corresponds to multiple forward passes through  \
  1158|         0|            0|            0|  0.00%|    the language model which is computational expensive.
  1159|         0|            0|            0|  0.00%|
  1160|         0|            0|            0|  0.00%|    - ``'sample_proba'``: float, probability of a word to be masked.
  1161|         0|            0|            0|  0.00%|
  1162|         0|            0|            0|  0.00%|    - ``'top_n'``: int, number of similar words to sample for perturbations.
  1163|         0|            0|            0|  0.00%|
  1164|         0|            0|            0|  0.00%|    - ``'temperature'``: float, sample weight hyper-parameter if use_proba equals True.
  1165|         0|            0|            0|  0.00%|
  1166|         0|            0|            0|  0.00%|    - ``'use_proba'``: bool, whether to sample according to the predicted words distribution. If set to `False`,
  1167|         0|            0|            0|  0.00%|    the `top_n` words are sampled uniformly at random.
  1168|         0|            0|            0|  0.00%|
  1169|         0|            0|            0|  0.00%|    - ``frac_mask_template'``: float, fraction from the number of samples of mask templates to be generated. \
  1170|         0|            0|            0|  0.00%|    In each sampling call, will generate int(`frac_mask_templates` * `num_samples`) masking templates. \
  1171|         0|            0|            0|  0.00%|    Lower fraction corresponds to lower computation time since the batch fed to the language model is smaller. \
  1172|         0|            0|            0|  0.00%|    After the words' distributions is predicted for each mask, a total of `num_samples` will be generated by sampling \
  1173|         0|            0|            0|  0.00%|    evenly from each template. Note that lower fraction might correspond to less diverse sample. A `sample_proba` \
  1174|         0|            0|            0|  0.00%|    is `1` corresponds to masking each word. For this case only one masking template will be constructed. \
  1175|         0|            0|            0|  0.00%|    A `filling_method` set to `autoregressive` will generate `num_samples` masking templates regardless of the value \
  1176|         0|            0|            0|  0.00%|    of `frac_mask_templates`.
  1177|         0|            0|            0|  0.00%|
  1178|         0|            0|            0|  0.00%|    - ``batch_size_lm``: int, batch size used for the language model forward pass.
  1179|         0|            0|            0|  0.00%|
  1180|         0|            0|            0|  0.00%|    - ``punctuation``: str, string of punctuation not to be masked.
  1181|         0|            0|            0|  0.00%|
  1182|         0|            0|            0|  0.00%|    - ``stopwords``: List[str], list of words not to be masked.
  1183|         0|            0|            0|  0.00%|
  1184|         0|            0|            0|  0.00%|    - ``sample_punctuation``: bool, whether to sample punctuation to fill the masked words. If `True`, the \
  1185|         0|            0|            0|  0.00%|    punctuation defined in `punctuation` will not be sampled.
  1186|         0|            0|            0|  0.00%|"""
  1187|         0|            0|            0|  0.00%|
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|class AnchorText(Explainer):
  1190|         0|            0|            0|  0.00%|    # sampling methods
  1191|         0|            0|            0|  0.00%|    SAMPLING_UNKNOWN = 'unknown'
  1192|         0|            0|            0|  0.00%|    SAMPLING_SIMILARITY = 'similarity'
  1193|         0|            0|            0|  0.00%|    SAMPLING_LANGUAGE_MODEL = 'language_model'
  1194|         0|            0|            0|  0.00%|
  1195|         0|            0|            0|  0.00%|    # default params
  1196|         0|            0|            0|  0.00%|    DEFAULTS: Dict[str, Dict] = {
  1197|         0|            0|            0|  0.00%|        SAMPLING_UNKNOWN: DEFAULT_SAMPLING_UNKNOWN,
  1198|         0|            0|            0|  0.00%|        SAMPLING_SIMILARITY: DEFAULT_SAMPLING_SIMILARITY,
  1199|         0|            0|            0|  0.00%|        SAMPLING_LANGUAGE_MODEL: DEFAULT_SAMPLING_LANGUAGE_MODEL,
  1200|         0|            0|            0|  0.00%|    }
  1201|         0|            0|            0|  0.00%|
  1202|         0|            0|            0|  0.00%|    # class of samplers
  1203|         0|            0|            0|  0.00%|    CLASS_SAMPLER = {
  1204|         0|            0|            0|  0.00%|        SAMPLING_UNKNOWN: UnkownSampler,
  1205|         0|            0|            0|  0.00%|        SAMPLING_SIMILARITY: SimilaritySampler,
  1206|         0|            0|            0|  0.00%|        SAMPLING_LANGUAGE_MODEL: LanguageModelSampler
  1207|         0|            0|            0|  0.00%|    }
  1208|         0|            0|            0|  0.00%|
  1209|         0|            0|            0|  0.00%|    def __init__(self,
  1210|         0|            0|            0|  0.00%|                 predictor: Callable,
  1211|         0|            0|            0|  0.00%|                 sampling_method: str = 'unknown',
  1212|         0|            0|            0|  0.00%|                 nlp: Optional['spacy.language.Language'] = None,
  1213|         0|            0|            0|  0.00%|                 language_model: Optional[LanguageModel] = None,
  1214|         0|            0|            0|  0.00%|                 seed: int = 0,
  1215|         0|            0|            0|  0.00%|                 **kwargs: Any) -> None:
  1216|         0|            0|            0|  0.00%|        """
  1217|         0|            0|            0|  0.00%|        Initialize anchor text explainer.
  1218|         0|            0|            0|  0.00%|
  1219|         0|            0|            0|  0.00%|        Parameters
  1220|         0|            0|            0|  0.00%|        ----------
  1221|         0|            0|            0|  0.00%|        predictor
  1222|         0|            0|            0|  0.00%|            A callable that takes a tensor of N data points as inputs and returns N outputs.
  1223|         0|            0|            0|  0.00%|        sampling_method
  1224|         0|            0|            0|  0.00%|            Perturbation distribution method.
  1225|         0|            0|            0|  0.00%|            `unknown` perturbation distribution will replace words randomly with UNKs.
  1226|         0|            0|            0|  0.00%|            `similarity` sample according to a similarity scroe with the corpus embeddings.
  1227|         0|            0|            0|  0.00%|            `language_model` sample according the distribution output by a language model.
  1228|         0|            0|            0|  0.00%|        nlp
  1229|         0|            0|            0|  0.00%|            spaCy object when sampling method is `unknown` or `similarity`.
  1230|         0|            0|            0|  0.00%|        language_model
  1231|         0|            0|            0|  0.00%|            Transformers masked language model.
  1232|         0|            0|            0|  0.00%|        seed
  1233|         0|            0|            0|  0.00%|            If set, ensure identical random streams.
  1234|         0|            0|            0|  0.00%|        """
  1235|         0|            0|            0|  0.00%|        super().__init__(meta=copy.deepcopy(DEFAULT_META_ANCHOR))
  1236|         0|            0|            0|  0.00%|        self._seed(seed)
  1237|         0|            0|            0|  0.00%|
  1238|         0|            0|            0|  0.00%|        # set the predictor
  1239|         0|            0|            0|  0.00%|        self.predictor = self._transform_predictor(predictor)
  1240|         0|            0|            0|  0.00%|
  1241|         0|            0|            0|  0.00%|        # define model which can be either spacy object or LanguageModel
  1242|         0|            0|            0|  0.00%|        # the initialization of the model happens in _validate_kwargs
  1243|         0|            0|            0|  0.00%|        self.model: Union['spacy.language.Language', LanguageModel]
  1244|         0|            0|            0|  0.00%|
  1245|         0|            0|            0|  0.00%|        # validate kwargs
  1246|         0|            0|            0|  0.00%|        self.perturb_opts, all_opts = self._validate_kwargs(sampling_method=sampling_method, nlp=nlp,
  1247|         0|            0|            0|  0.00%|                                                            language_model=language_model, **kwargs)
  1248|         0|            0|            0|  0.00%|
  1249|         0|            0|            0|  0.00%|        # set perturbation
  1250|         0|            0|            0|  0.00%|        self.perturbation = self.CLASS_SAMPLER[self.sampling_method](self.model, self.perturb_opts)
  1251|         0|            0|            0|  0.00%|
  1252|         0|            0|            0|  0.00%|        # update metadata
  1253|         0|            0|            0|  0.00%|        self.meta['params'].update(seed=seed)
  1254|         0|            0|            0|  0.00%|        self.meta['params'].update(**all_opts)
  1255|         0|            0|            0|  0.00%|
  1256|         0|            0|            0|  0.00%|    def _validate_kwargs(self,
  1257|         0|            0|            0|  0.00%|                         sampling_method: str,
  1258|         0|            0|            0|  0.00%|                         nlp: Optional['spacy.language.Language'] = None,
  1259|         0|            0|            0|  0.00%|                         language_model: Optional[LanguageModel] = None,
  1260|         0|            0|            0|  0.00%|                         **kwargs: Any) -> Tuple[dict, dict]:
  1261|         0|            0|            0|  0.00%|
  1262|         0|            0|            0|  0.00%|        # set sampling method
  1263|         0|            0|            0|  0.00%|        self.sampling_method = sampling_method.strip().lower()
  1264|         0|            0|            0|  0.00%|        sampling_methods = [
  1265|         0|            0|            0|  0.00%|            self.SAMPLING_UNKNOWN,
  1266|         0|            0|            0|  0.00%|            self.SAMPLING_SIMILARITY,
  1267|         0|            0|            0|  0.00%|            self.SAMPLING_LANGUAGE_MODEL
  1268|         0|            0|            0|  0.00%|        ]
  1269|         0|            0|            0|  0.00%|
  1270|         0|            0|            0|  0.00%|        # validate sampling method
  1271|         0|            0|            0|  0.00%|        if self.sampling_method not in sampling_methods:
  1272|         0|            0|            0|  0.00%|            self.sampling_method = self.SAMPLING_UNKNOWN
  1273|         0|            0|            0|  0.00%|            logger.warning(f"Sampling method {sampling_method} if not valid. "
  1274|         0|            0|            0|  0.00%|                           f"Using the default value `{self.SAMPLING_UNKNOWN}`")
  1275|         0|            0|            0|  0.00%|
  1276|         0|            0|            0|  0.00%|        if sampling_method in [self.SAMPLING_UNKNOWN, self.SAMPLING_SIMILARITY]:
  1277|         0|            0|            0|  0.00%|            if nlp is None:
  1278|         0|            0|            0|  0.00%|                raise ValueError(f"spaCy model can not be `None` when `sampling_method` set to `{sampling_method}`.")
  1279|         0|            0|            0|  0.00%|            # set nlp object
  1280|         0|            0|            0|  0.00%|            self.model = _load_spacy_lexeme_prob(nlp)
  1281|         0|            0|            0|  0.00%|        else:
  1282|         0|            0|            0|  0.00%|            if language_model is None:
  1283|         0|            0|            0|  0.00%|                raise ValueError(f"Language model can not be `None` when `sampling_method` set to `{sampling_method}`")
  1284|         0|            0|            0|  0.00%|            # set language model object
  1285|         0|            0|            0|  0.00%|            self.model = language_model
  1286|         0|            0|            0|  0.00%|
  1287|         0|            0|            0|  0.00%|        # get default args
  1288|         0|            0|            0|  0.00%|        default_args: dict = self.DEFAULTS[self.sampling_method]
  1289|         0|            0|            0|  0.00%|        perturb_opts: dict = deepcopy(default_args)               # contains only the perturbation params
  1290|         0|            0|            0|  0.00%|        all_opts = deepcopy(default_args)                         # contains params + some potential incorrect params
  1291|         0|            0|            0|  0.00%|
  1292|         0|            0|            0|  0.00%|        # compute common keys
  1293|         0|            0|            0|  0.00%|        allowed_keys = set(perturb_opts.keys())
  1294|         0|            0|            0|  0.00%|        provided_keys = set(kwargs.keys())
  1295|         0|            0|            0|  0.00%|        common_keys = allowed_keys & provided_keys
  1296|         0|            0|            0|  0.00%|
  1297|         0|            0|            0|  0.00%|        # incorrect keys
  1298|         0|            0|            0|  0.00%|        if len(common_keys) < len(provided_keys):
  1299|         0|            0|            0|  0.00%|            incorrect_keys = ", ".join(provided_keys - common_keys)
  1300|         0|            0|            0|  0.00%|            logger.warning("The following keys are incorrect: " + incorrect_keys)
  1301|         0|            0|            0|  0.00%|
  1302|         0|            0|            0|  0.00%|        # update defaults args and all params
  1303|         0|            0|            0|  0.00%|        perturb_opts.update({key: kwargs[key] for key in common_keys})
  1304|         0|            0|            0|  0.00%|        all_opts.update(kwargs)
  1305|         0|            0|            0|  0.00%|        return perturb_opts, all_opts
  1306|         0|            0|            0|  0.00%|
  1307|         0|            0|            0|  0.00%|    def sampler(self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True) -> \
  1308|         0|            0|            0|  0.00%|            Union[List[Union[np.ndarray, np.ndarray, np.ndarray, np.ndarray, float, int]], List[np.ndarray]]:
  1309|         0|            0|            0|  0.00%|        """
  1310|         0|            0|            0|  0.00%|        Generate perturbed samples while maintaining features in positions specified in
  1311|         0|            0|            0|  0.00%|        anchor unchanged.
  1312|         0|            0|            0|  0.00%|
  1313|         0|            0|            0|  0.00%|        Parameters
  1314|         0|            0|            0|  0.00%|        ----------
  1315|         0|            0|            0|  0.00%|        anchor
  1316|         0|            0|            0|  0.00%|            int: the position of the anchor in the input batch
  1317|         0|            0|            0|  0.00%|            tuple: the anchor itself, a list of words to be kept unchanged
  1318|         0|            0|            0|  0.00%|        num_samples
  1319|         0|            0|            0|  0.00%|            Number of generated perturbed samples.
  1320|         0|            0|            0|  0.00%|        compute_labels
  1321|         0|            0|            0|  0.00%|            If True, an array of comparisons between predictions on perturbed samples and
  1322|         0|            0|            0|  0.00%|            instance to be explained is returned.
  1323|         0|            0|            0|  0.00%|
  1324|         0|            0|            0|  0.00%|        Returns
  1325|         0|            0|            0|  0.00%|        -------
  1326|         0|            0|            0|  0.00%|            If compute_labels=True, a list containing the following is returned:
  1327|         0|            0|            0|  0.00%|             - covered_true: perturbed examples where the anchor applies and the model prediction
  1328|         0|            0|            0|  0.00%|                    on perturbation is the same as the instance prediction
  1329|         0|            0|            0|  0.00%|             - covered_false: perturbed examples where the anchor applies and the model prediction
  1330|         0|            0|            0|  0.00%|                    is NOT the same as the instance prediction
  1331|         0|            0|            0|  0.00%|             - labels: num_samples ints indicating whether the prediction on the perturbed sample
  1332|         0|            0|            0|  0.00%|                    matches (1) the label of the instance to be explained or not (0)
  1333|         0|            0|            0|  0.00%|             - data: Matrix with 1s and 0s indicating whether a word in the text has been
  1334|         0|            0|            0|  0.00%|                     perturbed for each sample
  1335|         0|            0|            0|  0.00%|             - 1.0: indicates exact coverage is not computed for this algorithm
  1336|         0|            0|            0|  0.00%|             - anchor[0]: position of anchor in the batch request
  1337|         0|            0|            0|  0.00%|            Otherwise, a list containing the data matrix only is returned.
  1338|         0|            0|            0|  0.00%|        """
  1339|         0|            0|            0|  0.00%|
  1340|         0|            0|            0|  0.00%|        raw_data, data = self.perturbation(anchor[1], num_samples)
  1341|         0|            0|            0|  0.00%|
  1342|         0|            0|            0|  0.00%|        # create labels using model predictions as true labels
  1343|         0|            0|            0|  0.00%|        if compute_labels:
  1344|         0|            0|            0|  0.00%|            labels = self.compare_labels(raw_data)
  1345|         0|            0|            0|  0.00%|            covered_true = raw_data[labels][:self.n_covered_ex]
  1346|         0|            0|            0|  0.00%|            covered_false = raw_data[np.logical_not(labels)][:self.n_covered_ex]
  1347|         0|            0|            0|  0.00%|
  1348|         0|            0|            0|  0.00%|            # coverage set to -1.0 as we can't compute 'true' coverage for this model
  1349|         0|            0|            0|  0.00%|            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]
  1350|         0|            0|            0|  0.00%|        else:
  1351|         0|            0|            0|  0.00%|            return [data]
  1352|         0|            0|            0|  0.00%|
  1353|         0|            0|            0|  0.00%|    def compare_labels(self, samples: np.ndarray) -> np.ndarray:
  1354|         0|            0|            0|  0.00%|        """
  1355|         0|            0|            0|  0.00%|        Compute the agreement between a classifier prediction on an instance to be explained
  1356|         0|            0|            0|  0.00%|        and the prediction on a set of samples which have a subset of features fixed to a
  1357|         0|            0|            0|  0.00%|        given value (aka compute the precision of anchors).
  1358|         0|            0|            0|  0.00%|
  1359|         0|            0|            0|  0.00%|        Parameters
  1360|         0|            0|            0|  0.00%|        ----------
  1361|         0|            0|            0|  0.00%|        samples
  1362|         0|            0|            0|  0.00%|            Samples whose labels are to be compared with the instance label.
  1363|         0|            0|            0|  0.00%|
  1364|         0|            0|            0|  0.00%|        Returns
  1365|         0|            0|            0|  0.00%|        -------
  1366|         0|            0|            0|  0.00%|            A boolean array indicating whether the prediction was the same as the instance label.
  1367|         0|            0|            0|  0.00%|        """
  1368|         0|            0|            0|  0.00%|        return self.predictor(samples.tolist()) == self.instance_label
  1369|         0|            0|            0|  0.00%|
  1370|         0|            0|            0|  0.00%|    def explain(self,  # type: ignore
  1371|         0|            0|            0|  0.00%|                text: str,
  1372|         0|            0|            0|  0.00%|                sampling_method: str = 'unknown',
  1373|         0|            0|            0|  0.00%|                threshold: float = 0.95,
  1374|         0|            0|            0|  0.00%|                delta: float = 0.1,
  1375|         0|            0|            0|  0.00%|                tau: float = 0.15,
  1376|         0|            0|            0|  0.00%|                batch_size: int = 100,
  1377|         0|            0|            0|  0.00%|                coverage_samples: int = 10000,
  1378|         0|            0|            0|  0.00%|                beam_size: int = 1,
  1379|         0|            0|            0|  0.00%|                stop_on_first: bool = True,
  1380|         0|            0|            0|  0.00%|                max_anchor_size: int = None,
  1381|         0|            0|            0|  0.00%|                min_samples_start: int = 100,
  1382|         0|            0|            0|  0.00%|                n_covered_ex: int = 10,
  1383|         0|            0|            0|  0.00%|                binary_cache_size: int = 10000,
  1384|         0|            0|            0|  0.00%|                cache_margin: int = 1000,
  1385|         0|            0|            0|  0.00%|                verbose: bool = False,
  1386|         0|            0|            0|  0.00%|                verbose_every: int = 1,
  1387|         0|            0|            0|  0.00%|                **kwargs: Any) -> Explanation:
  1388|         0|            0|            0|  0.00%|        """
  1389|         0|            0|            0|  0.00%|        Explain instance and return anchor with metadata.
  1390|         0|            0|            0|  0.00%|
  1391|         0|            0|            0|  0.00%|        Parameters
  1392|         0|            0|            0|  0.00%|        ----------
  1393|         0|            0|            0|  0.00%|        text
  1394|         0|            0|            0|  0.00%|            Text instance to be explained.
  1395|         0|            0|            0|  0.00%|        sampling_method
  1396|         0|            0|            0|  0.00%|            Perturbation distribution method.
  1397|         0|            0|            0|  0.00%|            `unknown` perturbation distribution will replace words randomly with UNKs.
  1398|         0|            0|            0|  0.00%|            `similarity` sample according to a similarity scroe with the corpus embeddings.
  1399|         0|            0|            0|  0.00%|            `language_model` sample according the distribution output by a language model.
  1400|         0|            0|            0|  0.00%|        threshold
  1401|         0|            0|            0|  0.00%|            Minimum precision threshold.
  1402|         0|            0|            0|  0.00%|        delta
  1403|         0|            0|            0|  0.00%|            Used to compute beta.
  1404|         0|            0|            0|  0.00%|        tau
  1405|         0|            0|            0|  0.00%|            Margin between lower confidence bound and minimum precision or upper bound.
  1406|         0|            0|            0|  0.00%|        batch_size
  1407|         0|            0|            0|  0.00%|            Batch size used for sampling.
  1408|         0|            0|            0|  0.00%|        coverage_samples
  1409|         0|            0|            0|  0.00%|            Number of samples used to estimate coverage from during anchor search.
  1410|         0|            0|            0|  0.00%|        beam_size
  1411|         0|            0|            0|  0.00%|            Number of options kept after each stage of anchor building.
  1412|         0|            0|            0|  0.00%|        stop_on_first
  1413|         0|            0|            0|  0.00%|            If True, the beam search algorithm will return the first anchor that has satisfies the
  1414|         0|            0|            0|  0.00%|            probability constraint.
  1415|         0|            0|            0|  0.00%|        max_anchor_size
  1416|         0|            0|            0|  0.00%|            Maximum number of features to include in an anchor.
  1417|         0|            0|            0|  0.00%|        min_samples_start
  1418|         0|            0|            0|  0.00%|            Number of samples used for anchor search initialisation.
  1419|         0|            0|            0|  0.00%|        n_covered_ex
  1420|         0|            0|            0|  0.00%|            How many examples where anchors apply to store for each anchor sampled during search
  1421|         0|            0|            0|  0.00%|            (both examples where prediction on samples agrees/disagrees with predicted label are stored).
  1422|         0|            0|            0|  0.00%|        binary_cache_size
  1423|         0|            0|            0|  0.00%|            The anchor search pre-allocates binary_cache_size batches for storing the boolean arrays
  1424|         0|            0|            0|  0.00%|            returned during sampling.
  1425|         0|            0|            0|  0.00%|        cache_margin
  1426|         0|            0|            0|  0.00%|            When only max(cache_margin, batch_size) positions in the binary cache remain empty, a new cache
  1427|         0|            0|            0|  0.00%|            of the same size is pre-allocated to continue buffering samples.
  1428|         0|            0|            0|  0.00%|        kwargs
  1429|         0|            0|            0|  0.00%|            Other keyword arguments passed to the anchor beam search and the text sampling and perturbation functions.
  1430|         0|            0|            0|  0.00%|        verbose
  1431|         0|            0|            0|  0.00%|            Display updates during the anchor search iterations.
  1432|         0|            0|            0|  0.00%|        verbose_every
  1433|         0|            0|            0|  0.00%|            Frequency of displayed iterations during anchor search process.
  1434|         0|            0|            0|  0.00%|
  1435|         0|            0|            0|  0.00%|        Returns
  1436|         0|            0|            0|  0.00%|        -------
  1437|         0|            0|            0|  0.00%|        explanation
  1438|         0|            0|            0|  0.00%|            `Explanation` object containing the anchor explaining the instance with additional metadata as attributes.
  1439|         0|            0|            0|  0.00%|        """
  1440|         0|            0|            0|  0.00%|        # get params for storage in meta
  1441|         0|            0|            0|  0.00%|        params = locals()
  1442|         0|            0|            0|  0.00%|        remove = ['text', 'self']
  1443|         0|            0|            0|  0.00%|        for key in remove:
  1444|         0|            0|            0|  0.00%|            params.pop(key)
  1445|         0|            0|            0|  0.00%|
  1446|         0|            0|            0|  0.00%|        # store n_covered_ex positive/negative examples for each anchor
  1447|         0|            0|            0|  0.00%|        self.n_covered_ex = n_covered_ex
  1448|         0|            0|            0|  0.00%|        self.instance_label = self.predictor([text])[0]
  1449|         0|            0|            0|  0.00%|
  1450|         0|            0|            0|  0.00%|        # set sampler
  1451|         0|            0|            0|  0.00%|        self.perturbation.set_text(text)
  1452|         0|            0|            0|  0.00%|
  1453|         0|            0|            0|  0.00%|        # get anchors and add metadata
  1454|         0|            0|            0|  0.00%|        mab = AnchorBaseBeam(
  1455|         0|            0|            0|  0.00%|            samplers=[self.sampler],
  1456|         0|            0|            0|  0.00%|            sample_cache_size=binary_cache_size,
  1457|         0|            0|            0|  0.00%|            cache_margin=cache_margin,
  1458|         0|            0|            0|  0.00%|            **kwargs
  1459|         0|            0|            0|  0.00%|        )
  1460|         0|            0|            0|  0.00%|        result = mab.anchor_beam(
  1461|         0|            0|            0|  0.00%|            delta=delta,
  1462|         0|            0|            0|  0.00%|            epsilon=tau,
  1463|         0|            0|            0|  0.00%|            batch_size=batch_size,
  1464|         0|            0|            0|  0.00%|            desired_confidence=threshold,
  1465|         0|            0|            0|  0.00%|            max_anchor_size=max_anchor_size,
  1466|         0|            0|            0|  0.00%|            min_samples_start=min_samples_start,
  1467|         0|            0|            0|  0.00%|            beam_size=beam_size,
  1468|         0|            0|            0|  0.00%|            coverage_samples=coverage_samples,
  1469|         0|            0|            0|  0.00%|            stop_on_first=stop_on_first,
  1470|         0|            0|            0|  0.00%|            verbose=verbose,
  1471|         0|            0|            0|  0.00%|            verbose_every=verbose_every,
  1472|         0|            0|            0|  0.00%|            **kwargs,
  1473|         0|            0|            0|  0.00%|        )  # type: Any
  1474|         0|            0|            0|  0.00%|
  1475|         0|            0|            0|  0.00%|        if self.sampling_method == self.SAMPLING_LANGUAGE_MODEL:
  1476|         0|            0|            0|  0.00%|            # take the whole word (this point just to the first part of the word)
  1477|         0|            0|            0|  0.00%|            result['positions'] = [self.perturbation.ids_mapping[i] for i in result['feature']]
  1478|         0|            0|            0|  0.00%|            result['names'] = [
  1479|         0|            0|            0|  0.00%|                self.perturbation.model.select_entire_word(
  1480|         0|            0|            0|  0.00%|                    self.perturbation.head_tokens,
  1481|         0|            0|            0|  0.00%|                    idx_feature,
  1482|         0|            0|            0|  0.00%|                    self.perturbation.perturb_opts['punctuation']
  1483|         0|            0|            0|  0.00%|                ) for idx_feature in result['positions']
  1484|         0|            0|            0|  0.00%|            ]
  1485|         0|            0|            0|  0.00%|        else:
  1486|         0|            0|            0|  0.00%|            result['names'] = [self.perturbation.words[x] for x in result['feature']]
  1487|         0|            0|            0|  0.00%|            result['positions'] = [self.perturbation.positions[x] for x in result['feature']]
  1488|         0|            0|            0|  0.00%|
  1489|         0|            0|            0|  0.00%|        # set mab
  1490|         0|            0|            0|  0.00%|        self.mab = mab
  1491|         0|            0|            0|  0.00%|
  1492|         0|            0|            0|  0.00%|        return self.build_explanation(text, result, self.instance_label, params)
  1493|         0|            0|            0|  0.00%|
  1494|         0|            0|            0|  0.00%|    def build_explanation(self, text: str, result: dict, predicted_label: int, params: dict) -> Explanation:
  1495|         0|            0|            0|  0.00%|        """ Uses the metadata returned by the anchor search algorithm together with
  1496|         0|            0|            0|  0.00%|        the instance to be explained to build an explanation object.
  1497|         0|            0|            0|  0.00%|
  1498|         0|            0|            0|  0.00%|        Parameters
  1499|         0|            0|            0|  0.00%|        ----------
  1500|         0|            0|            0|  0.00%|        text
  1501|         0|            0|            0|  0.00%|            Instance to be explained.
  1502|         0|            0|            0|  0.00%|        result
  1503|         0|            0|            0|  0.00%|            Dictionary containing the search result and metadata.
  1504|         0|            0|            0|  0.00%|        predicted_label
  1505|         0|            0|            0|  0.00%|            Label of the instance to be explained. Inferred if not received.
  1506|         0|            0|            0|  0.00%|        params
  1507|         0|            0|            0|  0.00%|            Parameters passed to `explain`
  1508|         0|            0|            0|  0.00%|        """
  1509|         0|            0|            0|  0.00%|
  1510|         0|            0|            0|  0.00%|        result['instance'] = text
  1511|         0|            0|            0|  0.00%|        result['instances'] = [text]  # TODO: should this be an array?
  1512|         0|            0|            0|  0.00%|        result['prediction'] = np.array([predicted_label])
  1513|         0|            0|            0|  0.00%|        exp = AnchorExplanation('text', result)
  1514|         0|            0|            0|  0.00%|
  1515|         0|            0|            0|  0.00%|        # output explanation dictionary
  1516|         0|            0|            0|  0.00%|        data = copy.deepcopy(DEFAULT_DATA_ANCHOR)
  1517|         0|            0|            0|  0.00%|        data.update(anchor=exp.names(),
  1518|         0|            0|            0|  0.00%|                    precision=exp.precision(),
  1519|         0|            0|            0|  0.00%|                    coverage=exp.coverage(),
  1520|         0|            0|            0|  0.00%|                    raw=exp.exp_map)
  1521|         0|            0|            0|  0.00%|
  1522|         0|            0|            0|  0.00%|        # create explanation object
  1523|         0|            0|            0|  0.00%|        explanation = Explanation(meta=copy.deepcopy(self.meta), data=data)
  1524|         0|            0|            0|  0.00%|
  1525|         0|            0|            0|  0.00%|        # params passed to explain
  1526|         0|            0|            0|  0.00%|        explanation.meta['params'].update(params)
  1527|         0|            0|            0|  0.00%|        return explanation
  1528|         0|            0|            0|  0.00%|
  1529|         0|            0|            0|  0.00%|    def _transform_predictor(self, predictor: Callable) -> Callable:
  1530|         0|            0|            0|  0.00%|        # check if predictor returns predicted class or prediction probabilities for each class
  1531|         0|            0|            0|  0.00%|        # if needed adjust predictor so it returns the predicted class
  1532|         0|            0|            0|  0.00%|        if np.argmax(predictor(['Hello world']).shape) == 0:
  1533|         0|            0|            0|  0.00%|            return predictor
  1534|         0|            0|            0|  0.00%|        else:
  1535|         0|            0|            0|  0.00%|            transformer = ArgmaxTransformer(predictor)
  1536|         0|            0|            0|  0.00%|            return transformer
  1537|         0|            0|            0|  0.00%|
  1538|         0|            0|            0|  0.00%|    def reset_predictor(self, predictor: Callable) -> None:
  1539|         0|            0|            0|  0.00%|        self.predictor = self._transform_predictor(predictor)
  1540|         0|            0|            0|  0.00%|
  1541|         0|            0|            0|  0.00%|    def _seed(self, seed: int):
  1542|         0|            0|            0|  0.00%|        np.random.seed(seed)
  1543|         0|            0|            0|  0.00%|        tf.random.set_seed(seed)
File: /home/robert/Desktop/seldon/alibi/alibi/utils/lang_model.py
File duration: 0.212103s (24.72%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import abc
     2|         0|            0|            0|  0.00%|import numpy as np
     3|         0|            0|            0|  0.00%|from typing import List, Optional, Tuple
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|import tensorflow as tf
     6|         0|            0|            0|  0.00%|import transformers
     7|         0|            0|            0|  0.00%|from transformers import TFAutoModelForMaskedLM, AutoTokenizer
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|
    10|         0|            0|            0|  0.00%|class LanguageModel(abc.ABC):
    11|         0|            0|            0|  0.00%|    SUBWORD_PREFIX = ''
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|    def __init__(self, model_path: str):
    14|         0|            0|            0|  0.00%|        """
    15|         0|            0|            0|  0.00%|        Initialize the language model.
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|        Parameters
    18|         0|            0|            0|  0.00%|        ----------
    19|         0|            0|            0|  0.00%|        model_path
    20|         0|            0|            0|  0.00%|            `transformers` package model path.
    21|         0|            0|            0|  0.00%|        """
    22|         0|            0|            0|  0.00%|        self.model_path = model_path
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|        # load tokenizer
    25|         0|            0|            0|  0.00%|        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
    26|         0|            0|            0|  0.00%|
    27|         0|            0|            0|  0.00%|        # load and send model to device
    28|         0|            0|            0|  0.00%|        self.model = TFAutoModelForMaskedLM.from_pretrained(model_path)
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|    @abc.abstractmethod
    31|         0|            0|            0|  0.00%|    def is_subword_prefix(self, token: str) -> bool:
    32|         0|            0|            0|  0.00%|        """
    33|         0|            0|            0|  0.00%|        Checks if the given token in a subword.
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|        Parameters
    36|         0|            0|            0|  0.00%|        ----------
    37|         0|            0|            0|  0.00%|        token
    38|         0|            0|            0|  0.00%|            Token to be checked if it is a subword.
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|        Returns
    41|         0|            0|            0|  0.00%|        -------
    42|         0|            0|            0|  0.00%|        True if the given token is a subword. False otherwise.
    43|         0|            0|            0|  0.00%|        """
    44|         0|            0|            0|  0.00%|        pass
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|    def select_entire_word(self, text: List[str], start_idx: int, punctuation: str) -> str:
    47|         0|            0|            0|  0.00%|        """
    48|         0|            0|            0|  0.00%|        Given a text and the starting index of a word, the function
    49|         0|            0|            0|  0.00%|        selects the entier word.
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|        Parameters
    52|         0|            0|            0|  0.00%|        ----------
    53|         0|            0|            0|  0.00%|        text
    54|         0|            0|            0|  0.00%|            Full text.
    55|         0|            0|            0|  0.00%|        start_idx
    56|         0|            0|            0|  0.00%|            Starting index of a word.
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|        Returns
    59|         0|            0|            0|  0.00%|        -------
    60|         0|            0|            0|  0.00%|        The entire words (this includes the subwords that come after).
    61|         0|            0|            0|  0.00%|        """
    62|         0|            0|            0|  0.00%|        # define the ending index
    63|         0|            0|            0|  0.00%|        end_idx = start_idx + 1
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|        while (end_idx < len(text)):
    66|         0|            0|            0|  0.00%|            # The second condition is necessary for models like Roberta.
    67|         0|            0|            0|  0.00%|            # If the second condition is not included, it can select words like: `word,` instaed of `word`
    68|         0|            0|            0|  0.00%|            if (not self.is_subword_prefix(text[end_idx])) or self.is_punctuation(text[end_idx], punctuation):
    69|         0|            0|            0|  0.00%|                break
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|            end_idx += 1
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|        # convert the tokens into a string
    74|         0|            0|            0|  0.00%|        word = self.tokenizer.convert_tokens_to_string(text[start_idx:end_idx])
    75|         0|            0|            0|  0.00%|        return word
    76|         0|            0|            0|  0.00%|
    77|         0|            0|            0|  0.00%|    def is_stop_word(self, text: List[str], start_idx: int, punctuation: str, stopwords: Optional[List[str]]) -> bool:
    78|         0|            0|            0|  0.00%|        """
    79|         0|            0|            0|  0.00%|        Checks if the given words starting at the given index is in the list of stopwords
    80|         0|            0|            0|  0.00%|
    81|         0|            0|            0|  0.00%|        Parameters
    82|         0|            0|            0|  0.00%|        ----------
    83|         0|            0|            0|  0.00%|        text
    84|         0|            0|            0|  0.00%|            Full text.
    85|         0|            0|            0|  0.00%|        start_idx
    86|         0|            0|            0|  0.00%|            Starting index of a word.
    87|         0|            0|            0|  0.00%|        stopwords:
    88|         0|            0|            0|  0.00%|            List of stop words. The words in this list should be lowercase.
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|        Returns
    91|         0|            0|            0|  0.00%|        -------
    92|         0|            0|            0|  0.00%|        True if the `token` is in the `stopwords` list. False otherwise.
    93|         0|            0|            0|  0.00%|        """
    94|         0|            0|            0|  0.00%|        if not stopwords:
    95|         0|            0|            0|  0.00%|            return False
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|        if self.is_subword_prefix(text[start_idx]):
    98|         0|            0|            0|  0.00%|            return False
    99|         0|            0|            0|  0.00%|
   100|         0|            0|            0|  0.00%|        word = self.select_entire_word(text, start_idx=start_idx, punctuation=punctuation).strip()
   101|         0|            0|            0|  0.00%|        return word.lower() in stopwords
   102|         0|            0|            0|  0.00%|
   103|     11010|    0.0144618|  1.31351e-06|  1.69%|    def is_punctuation(self, token: str, punctuation: str) -> bool:
   104|         0|            0|            0|  0.00%|        """
   105|         0|            0|            0|  0.00%|        Checks if the given token is punctuation.
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|        Parameters
   108|         0|            0|            0|  0.00%|        ----------
   109|         0|            0|            0|  0.00%|        token
   110|         0|            0|            0|  0.00%|            Token to be checked if it is punctuation.
   111|         0|            0|            0|  0.00%|        punctuation
   112|         0|            0|            0|  0.00%|            String containing all punctuation to be considered.
   113|         0|            0|            0|  0.00%|
   114|         0|            0|            0|  0.00%|        Returns
   115|         0|            0|            0|  0.00%|        -------
   116|         0|            0|            0|  0.00%|        True if the `token` is a punctuation. False otherwise.
   117|         0|            0|            0|  0.00%|        """
   118|     11010|    0.0202935|  1.84319e-06|  2.37%|        token = token.replace(self.SUBWORD_PREFIX, '').strip()
   119|     85538|      0.14593|  1.70602e-06| 17.01%|        return all([chr in punctuation for chr in token])
(call)|     11010|    0.0939929|  8.53705e-06| 10.96%|# /home/robert/Desktop/seldon/alibi/alibi/utils/lang_model.py:119 <listcomp>
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|    @property
   122|         0|            0|            0|  0.00%|    @abc.abstractmethod
   123|         0|            0|            0|  0.00%|    def mask(self) -> str:
   124|         0|            0|            0|  0.00%|        """
   125|         0|            0|            0|  0.00%|        Returns the mask token.
   126|         0|            0|            0|  0.00%|        """
   127|         0|            0|            0|  0.00%|        pass
   128|         0|            0|            0|  0.00%|
   129|         0|            0|            0|  0.00%|    @property
   130|         0|            0|            0|  0.00%|    def mask_token(self) -> int:
   131|         0|            0|            0|  0.00%|        """
   132|         0|            0|            0|  0.00%|        Returns the mask token id
   133|         0|            0|            0|  0.00%|        """
   134|         0|            0|            0|  0.00%|        return self.tokenizer.mask_token_id
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|    @property
   137|         0|            0|            0|  0.00%|    def max_num_tokens(self) -> int:
   138|         0|            0|            0|  0.00%|        """
   139|         0|            0|            0|  0.00%|        Returns the maximum number of token allowed by the model.
   140|         0|            0|            0|  0.00%|        """
   141|         0|            0|            0|  0.00%|        return self.model.config.max_position_embeddings
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|    def head_tail_split(self, text: str) -> Tuple[str, Optional[str], List[str], Optional[List[str]]]:
   144|         0|            0|            0|  0.00%|        """
   145|         0|            0|            0|  0.00%|        Split the text in head and tail. Some language models support a maximum
   146|         0|            0|            0|  0.00%|        number of tokens. Thus is necessary to split the text to meet this constraint.
   147|         0|            0|            0|  0.00%|        After the text is split in head and tail, only the head is considered for operation.
   148|         0|            0|            0|  0.00%|        Thus the tail will remain unchanged.
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|        Parameters
   151|         0|            0|            0|  0.00%|        ----------
   152|         0|            0|            0|  0.00%|        text
   153|         0|            0|            0|  0.00%|            Text to be split in head and tail.
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|        Returns
   156|         0|            0|            0|  0.00%|        -------
   157|         0|            0|            0|  0.00%|        Tuple consisting of the head, tail and their corresponding list of tokens.
   158|         0|            0|            0|  0.00%|        """
   159|         0|            0|            0|  0.00%|        text = text.strip()
   160|         0|            0|            0|  0.00%|        if len(text) == 0:
   161|         0|            0|            0|  0.00%|            raise ValueError("The text is empty")
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|        # data = `This is not a wordy sentence` -> tokens = [this, is, not, a, word, ##y, sentence, .]
   164|         0|            0|            0|  0.00%|        tokens: List[str] = self.tokenizer.tokenize(text)
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|        # some models do not have a max length restrictions (e.g. XLNet)
   167|         0|            0|            0|  0.00%|        if self.max_num_tokens == -1 or len(tokens) <= self.max_num_tokens:
   168|         0|            0|            0|  0.00%|            return text, None, tokens, []
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|        # head's length
   171|         0|            0|            0|  0.00%|        head_num_tokens = self.max_num_tokens
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|        # decrease the head length so it contains full words
   174|         0|            0|            0|  0.00%|        while (head_num_tokens > 0) and self.is_subword_prefix(tokens[head_num_tokens]):
   175|         0|            0|            0|  0.00%|            head_num_tokens -= 1
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|        if head_num_tokens == 0:
   178|         0|            0|            0|  0.00%|            raise ValueError("Check the first word in the sentence. Seems it is a very long word")
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|        ids = self.tokenizer.convert_tokens_to_ids(tokens[:head_num_tokens])
   181|         0|            0|            0|  0.00%|        head_text = self.tokenizer.decode(ids).strip()
   182|         0|            0|            0|  0.00%|        tail_text = None
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|        # if the number of tokens exceeds the maximum allowed
   185|         0|            0|            0|  0.00%|        # number, then construct also the tail_text
   186|         0|            0|            0|  0.00%|        if len(tokens) >= head_num_tokens:
   187|         0|            0|            0|  0.00%|            ids = self.tokenizer.convert_tokens_to_ids(tokens[head_num_tokens:])
   188|         0|            0|            0|  0.00%|            tail_text = self.tokenizer.decode(ids).strip()
   189|         0|            0|            0|  0.00%|
   190|         0|            0|            0|  0.00%|        return head_text, tail_text, tokens[:head_num_tokens], tokens[head_num_tokens:]
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|    def predict_batch_lm(self,
   193|         0|            0|            0|  0.00%|                         x: transformers.tokenization_utils_base.BatchEncoding,
   194|         0|            0|            0|  0.00%|                         vocab_size: int,
   195|         0|            0|            0|  0.00%|                         batch_size: int) -> np.ndarray:
   196|         0|            0|            0|  0.00%|        """
   197|         0|            0|            0|  0.00%|        Tensorflow language model batch predictions for AnchorText.
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|        Parameters
   200|         0|            0|            0|  0.00%|        ----------
   201|         0|            0|            0|  0.00%|        x
   202|         0|            0|            0|  0.00%|            Batch of instances.
   203|         0|            0|            0|  0.00%|        vocab_size
   204|         0|            0|            0|  0.00%|            Vocabulary size of language model.
   205|         0|            0|            0|  0.00%|        batch_size
   206|         0|            0|            0|  0.00%|            Batch size used for predictions.
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|        Returns
   209|         0|            0|            0|  0.00%|        -------
   210|         0|            0|            0|  0.00%|        y
   211|         0|            0|            0|  0.00%|            Array with model predictions.
   212|         0|            0|            0|  0.00%|        """
   213|         0|            0|            0|  0.00%|        n, m = x['input_ids'].shape
   214|         0|            0|            0|  0.00%|        y = np.zeros((n, m, vocab_size), dtype=np.float32)
   215|         0|            0|            0|  0.00%|        n_minibatch = int(np.ceil(n / batch_size))
   216|         0|            0|            0|  0.00%|
   217|         0|            0|            0|  0.00%|        for i in range(n_minibatch):
   218|         0|            0|            0|  0.00%|            istart, istop = i * batch_size, min((i + 1) * batch_size, n)
   219|         0|            0|            0|  0.00%|            x_batch = dict()
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|            if 'input_ids' in x.keys():
   222|         0|            0|            0|  0.00%|                x_batch['input_ids'] = x['input_ids'][istart:istop]
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|            if 'token_type_ids' in x.keys():
   225|         0|            0|            0|  0.00%|                x_batch['token_type_ids'] = x['token_type_ids'][istart:istop]
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|            if 'attention_mask' in x.keys():
   228|         0|            0|            0|  0.00%|                x_batch['attention_mask'] = x['attention_mask'][istart:istop]
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|            y[istart:istop] = self.model(**x_batch)[0].numpy()
   231|         0|            0|            0|  0.00%|
   232|         0|            0|            0|  0.00%|        return y
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|
   235|         0|            0|            0|  0.00%|class DistilbertBaseUncased(LanguageModel):
   236|         0|            0|            0|  0.00%|    SUBWORD_PREFIX = '##'
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|    def __init__(self):
   239|         0|            0|            0|  0.00%|        super(DistilbertBaseUncased, self).__init__("distilbert-base-uncased")
   240|         0|            0|            0|  0.00%|
   241|      1000|   0.00151086|  1.51086e-06|  0.18%|    @property
   242|         0|            0|            0|  0.00%|    def mask(self) -> str:
   243|      1000|   0.00473356|  4.73356e-06|  0.55%|        return self.tokenizer.mask_token
(call)|      1000|   0.00490165|  4.90165e-06|  0.57%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1010 mask_token
   244|         0|            0|            0|  0.00%|
   245|      9507|    0.0110316|  1.16037e-06|  1.29%|    def is_subword_prefix(self, token: str) -> bool:
   246|      9507|     0.014142|  1.48754e-06|  1.65%|        return DistilbertBaseUncased.SUBWORD_PREFIX in token
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|class BertBaseUncased(LanguageModel):
   250|         0|            0|            0|  0.00%|    SUBWORD_PREFIX = '##'
   251|         0|            0|            0|  0.00%|
   252|         0|            0|            0|  0.00%|    def __init__(self):
   253|         0|            0|            0|  0.00%|        super(BertBaseUncased, self).__init__("bert-base-uncased")
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|    @property
   256|         0|            0|            0|  0.00%|    def mask(self) -> str:
   257|         0|            0|            0|  0.00%|        return self.tokenizer.mask_token
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    def is_subword_prefix(self, token: str) -> bool:
   260|         0|            0|            0|  0.00%|        return BertBaseUncased.SUBWORD_PREFIX in token
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|class RobertaBase(LanguageModel):
   264|         0|            0|            0|  0.00%|    SUBWORD_PREFIX = 'Ġ'
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|    def __init__(self):
   267|         0|            0|            0|  0.00%|        super(RobertaBase, self).__init__("roberta-base")
   268|         0|            0|            0|  0.00%|
   269|         0|            0|            0|  0.00%|    @property
   270|         0|            0|            0|  0.00%|    def mask(self):
   271|         0|            0|            0|  0.00%|        return RobertaBase.SUBWORD_PREFIX + self.tokenizer.mask_token
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|    def is_subword_prefix(self, token: str) -> bool:
   274|         0|            0|            0|  0.00%|        return RobertaBase.SUBWORD_PREFIX not in token
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py
File duration: 0.0528681s (6.16%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""Module containing non-deprecated functions borrowed from Numeric.
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|"""
     4|         0|            0|            0|  0.00%|import functools
     5|         0|            0|            0|  0.00%|import types
     6|         0|            0|            0|  0.00%|import warnings
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|import numpy as np
     9|         0|            0|            0|  0.00%|from . import multiarray as mu
    10|         0|            0|            0|  0.00%|from . import overrides
    11|         0|            0|            0|  0.00%|from . import umath as um
    12|         0|            0|            0|  0.00%|from . import numerictypes as nt
    13|         0|            0|            0|  0.00%|from ._asarray import asarray, array, asanyarray
    14|         0|            0|            0|  0.00%|from .multiarray import concatenate
    15|         0|            0|            0|  0.00%|from . import _methods
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|_dt_ = nt.sctype2char
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|# functions that are methods
    20|         0|            0|            0|  0.00%|__all__ = [
    21|         0|            0|            0|  0.00%|    'alen', 'all', 'alltrue', 'amax', 'amin', 'any', 'argmax',
    22|         0|            0|            0|  0.00%|    'argmin', 'argpartition', 'argsort', 'around', 'choose', 'clip',
    23|         0|            0|            0|  0.00%|    'compress', 'cumprod', 'cumproduct', 'cumsum', 'diagonal', 'mean',
    24|         0|            0|            0|  0.00%|    'ndim', 'nonzero', 'partition', 'prod', 'product', 'ptp', 'put',
    25|         0|            0|            0|  0.00%|    'ravel', 'repeat', 'reshape', 'resize', 'round_',
    26|         0|            0|            0|  0.00%|    'searchsorted', 'shape', 'size', 'sometrue', 'sort', 'squeeze',
    27|         0|            0|            0|  0.00%|    'std', 'sum', 'swapaxes', 'take', 'trace', 'transpose', 'var',
    28|         0|            0|            0|  0.00%|]
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|_gentype = types.GeneratorType
    31|         0|            0|            0|  0.00%|# save away Python sum
    32|         0|            0|            0|  0.00%|_sum_ = sum
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|array_function_dispatch = functools.partial(
    35|         0|            0|            0|  0.00%|    overrides.array_function_dispatch, module='numpy')
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|
    38|         0|            0|            0|  0.00%|# functions that are now methods
    39|         1|  2.38419e-06|  2.38419e-06|  0.00%|def _wrapit(obj, method, *args, **kwds):
    40|         1|  2.38419e-06|  2.38419e-06|  0.00%|    try:
    41|         1|  4.29153e-06|  4.29153e-06|  0.00%|        wrap = obj.__array_wrap__
    42|         1|  3.09944e-06|  3.09944e-06|  0.00%|    except AttributeError:
    43|         1|   2.6226e-06|   2.6226e-06|  0.00%|        wrap = None
    44|         1|   1.7643e-05|   1.7643e-05|  0.00%|    result = getattr(asarray(obj), method)(*args, **kwds)
(call)|         1|  1.83582e-05|  1.83582e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:23 asarray
(call)|         1|  0.000313997|  0.000313997|  0.04%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py:124 _clip
    45|         1|   2.6226e-06|   2.6226e-06|  0.00%|    if wrap:
    46|         0|            0|            0|  0.00%|        if not isinstance(result, mu.ndarray):
    47|         0|            0|            0|  0.00%|            result = asarray(result)
    48|         0|            0|            0|  0.00%|        result = wrap(result)
    49|         1|  1.90735e-06|  1.90735e-06|  0.00%|    return result
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|
    52|         3|  5.72205e-06|  1.90735e-06|  0.00%|def _wrapfunc(obj, method, *args, **kwds):
    53|         3|  8.10623e-06|  2.70208e-06|  0.00%|    bound = getattr(obj, method, None)
    54|         3|  5.48363e-06|  1.82788e-06|  0.00%|    if bound is None:
    55|         1|  7.39098e-06|  7.39098e-06|  0.00%|        return _wrapit(obj, method, *args, **kwds)
(call)|         1|   0.00036931|   0.00036931|  0.04%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:39 _wrapit
    56|         0|            0|            0|  0.00%|
    57|         2|  2.86102e-06|  1.43051e-06|  0.00%|    try:
    58|         2|  5.96046e-06|  2.98023e-06|  0.00%|        return bound(*args, **kwds)
    59|         0|            0|            0|  0.00%|    except TypeError:
    60|         0|            0|            0|  0.00%|        # A TypeError occurs if the object does have such a method in its
    61|         0|            0|            0|  0.00%|        # class, but its signature is not identical to that of NumPy's. This
    62|         0|            0|            0|  0.00%|        # situation has occurred in the case of a downstream library like
    63|         0|            0|            0|  0.00%|        # 'pandas'.
    64|         0|            0|            0|  0.00%|        #
    65|         0|            0|            0|  0.00%|        # Call _wrapit from within the except clause to ensure a potential
    66|         0|            0|            0|  0.00%|        # exception has a traceback chain.
    67|         0|            0|            0|  0.00%|        return _wrapit(obj, method, *args, **kwds)
    68|         0|            0|            0|  0.00%|
    69|         0|            0|            0|  0.00%|
    70|      1002|   0.00179219|  1.78862e-06|  0.21%|def _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs):
    71|      6010|    0.0127077|  2.11443e-06|  1.48%|    passkwargs = {k: v for k, v in kwargs.items()
(call)|      1002|    0.0107474|   1.0726e-05|  1.25%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:71 <dictcomp>
    72|      3004|   0.00387025|  1.28837e-06|  0.45%|                  if v is not np._NoValue}
    73|         0|            0|            0|  0.00%|
    74|      1002|   0.00203085|   2.0268e-06|  0.24%|    if type(obj) is not mu.ndarray:
    75|      1002|   0.00165558|  1.65227e-06|  0.19%|        try:
    76|      1002|   0.00370264|  3.69525e-06|  0.43%|            reduction = getattr(obj, method)
    77|      1000|   0.00195575|  1.95575e-06|  0.23%|        except AttributeError:
    78|      1000|   0.00179815|  1.79815e-06|  0.21%|            pass
    79|         0|            0|            0|  0.00%|        else:
    80|         0|            0|            0|  0.00%|            # This branch is needed for reductions like any which don't
    81|         0|            0|            0|  0.00%|            # support a dtype.
    82|         2|  3.57628e-06|  1.78814e-06|  0.00%|            if dtype is not None:
    83|         0|            0|            0|  0.00%|                return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)
    84|         0|            0|            0|  0.00%|            else:
    85|         2|  2.02656e-05|  1.01328e-05|  0.00%|                return reduction(axis=axis, out=out, **passkwargs)
(call)|         2|  2.31266e-05|  1.15633e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py:59 _all
    86|         0|            0|            0|  0.00%|
    87|      1000|   0.00843525|  8.43525e-06|  0.98%|    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|def _take_dispatcher(a, indices, axis=None, out=None, mode=None):
    91|         0|            0|            0|  0.00%|    return (a, out)
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|
    94|         0|            0|            0|  0.00%|@array_function_dispatch(_take_dispatcher)
    95|         0|            0|            0|  0.00%|def take(a, indices, axis=None, out=None, mode='raise'):
    96|         0|            0|            0|  0.00%|    """
    97|         0|            0|            0|  0.00%|    Take elements from an array along an axis.
    98|         0|            0|            0|  0.00%|
    99|         0|            0|            0|  0.00%|    When axis is not None, this function does the same thing as "fancy"
   100|         0|            0|            0|  0.00%|    indexing (indexing arrays using arrays); however, it can be easier to use
   101|         0|            0|            0|  0.00%|    if you need elements along a given axis. A call such as
   102|         0|            0|            0|  0.00%|    ``np.take(arr, indices, axis=3)`` is equivalent to
   103|         0|            0|            0|  0.00%|    ``arr[:,:,:,indices,...]``.
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|    Explained without fancy indexing, this is equivalent to the following use
   106|         0|            0|            0|  0.00%|    of `ndindex`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of
   107|         0|            0|            0|  0.00%|    indices::
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|        Ni, Nk = a.shape[:axis], a.shape[axis+1:]
   110|         0|            0|            0|  0.00%|        Nj = indices.shape
   111|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   112|         0|            0|            0|  0.00%|            for jj in ndindex(Nj):
   113|         0|            0|            0|  0.00%|                for kk in ndindex(Nk):
   114|         0|            0|            0|  0.00%|                    out[ii + jj + kk] = a[ii + (indices[jj],) + kk]
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|    Parameters
   117|         0|            0|            0|  0.00%|    ----------
   118|         0|            0|            0|  0.00%|    a : array_like (Ni..., M, Nk...)
   119|         0|            0|            0|  0.00%|        The source array.
   120|         0|            0|            0|  0.00%|    indices : array_like (Nj...)
   121|         0|            0|            0|  0.00%|        The indices of the values to extract.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|        .. versionadded:: 1.8.0
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|        Also allow scalars for indices.
   126|         0|            0|            0|  0.00%|    axis : int, optional
   127|         0|            0|            0|  0.00%|        The axis over which to select values. By default, the flattened
   128|         0|            0|            0|  0.00%|        input array is used.
   129|         0|            0|            0|  0.00%|    out : ndarray, optional (Ni..., Nj..., Nk...)
   130|         0|            0|            0|  0.00%|        If provided, the result will be placed in this array. It should
   131|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype. Note that `out` is always
   132|         0|            0|            0|  0.00%|        buffered if `mode='raise'`; use other modes for better performance.
   133|         0|            0|            0|  0.00%|    mode : {'raise', 'wrap', 'clip'}, optional
   134|         0|            0|            0|  0.00%|        Specifies how out-of-bounds indices will behave.
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|        * 'raise' -- raise an error (default)
   137|         0|            0|            0|  0.00%|        * 'wrap' -- wrap around
   138|         0|            0|            0|  0.00%|        * 'clip' -- clip to the range
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|        'clip' mode means that all indices that are too large are replaced
   141|         0|            0|            0|  0.00%|        by the index that addresses the last element along that axis. Note
   142|         0|            0|            0|  0.00%|        that this disables indexing with negative numbers.
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|    Returns
   145|         0|            0|            0|  0.00%|    -------
   146|         0|            0|            0|  0.00%|    out : ndarray (Ni..., Nj..., Nk...)
   147|         0|            0|            0|  0.00%|        The returned array has the same type as `a`.
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|    See Also
   150|         0|            0|            0|  0.00%|    --------
   151|         0|            0|            0|  0.00%|    compress : Take elements using a boolean mask
   152|         0|            0|            0|  0.00%|    ndarray.take : equivalent method
   153|         0|            0|            0|  0.00%|    take_along_axis : Take elements by matching the array and the index arrays
   154|         0|            0|            0|  0.00%|
   155|         0|            0|            0|  0.00%|    Notes
   156|         0|            0|            0|  0.00%|    -----
   157|         0|            0|            0|  0.00%|
   158|         0|            0|            0|  0.00%|    By eliminating the inner loop in the description above, and using `s_` to
   159|         0|            0|            0|  0.00%|    build simple slice objects, `take` can be expressed  in terms of applying
   160|         0|            0|            0|  0.00%|    fancy indexing to each 1-d slice::
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|        Ni, Nk = a.shape[:axis], a.shape[axis+1:]
   163|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   164|         0|            0|            0|  0.00%|            for kk in ndindex(Nj):
   165|         0|            0|            0|  0.00%|                out[ii + s_[...,] + kk] = a[ii + s_[:,] + kk][indices]
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|    For this reason, it is equivalent to (but faster than) the following use
   168|         0|            0|            0|  0.00%|    of `apply_along_axis`::
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|        out = np.apply_along_axis(lambda a_1d: a_1d[indices], axis, a)
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|    Examples
   173|         0|            0|            0|  0.00%|    --------
   174|         0|            0|            0|  0.00%|    >>> a = [4, 3, 5, 7, 6, 8]
   175|         0|            0|            0|  0.00%|    >>> indices = [0, 1, 4]
   176|         0|            0|            0|  0.00%|    >>> np.take(a, indices)
   177|         0|            0|            0|  0.00%|    array([4, 3, 6])
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|    In this example if `a` is an ndarray, "fancy" indexing can be used.
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|    >>> a = np.array(a)
   182|         0|            0|            0|  0.00%|    >>> a[indices]
   183|         0|            0|            0|  0.00%|    array([4, 3, 6])
   184|         0|            0|            0|  0.00%|
   185|         0|            0|            0|  0.00%|    If `indices` is not one dimensional, the output also has these dimensions.
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|    >>> np.take(a, [[0, 1], [2, 3]])
   188|         0|            0|            0|  0.00%|    array([[4, 3],
   189|         0|            0|            0|  0.00%|           [5, 7]])
   190|         0|            0|            0|  0.00%|    """
   191|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'take', indices, axis=axis, out=out, mode=mode)
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|def _reshape_dispatcher(a, newshape, order=None):
   195|         0|            0|            0|  0.00%|    return (a,)
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|# not deprecated --- copy if necessary, view otherwise
   199|         0|            0|            0|  0.00%|@array_function_dispatch(_reshape_dispatcher)
   200|         0|            0|            0|  0.00%|def reshape(a, newshape, order='C'):
   201|         0|            0|            0|  0.00%|    """
   202|         0|            0|            0|  0.00%|    Gives a new shape to an array without changing its data.
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|    Parameters
   205|         0|            0|            0|  0.00%|    ----------
   206|         0|            0|            0|  0.00%|    a : array_like
   207|         0|            0|            0|  0.00%|        Array to be reshaped.
   208|         0|            0|            0|  0.00%|    newshape : int or tuple of ints
   209|         0|            0|            0|  0.00%|        The new shape should be compatible with the original shape. If
   210|         0|            0|            0|  0.00%|        an integer, then the result will be a 1-D array of that length.
   211|         0|            0|            0|  0.00%|        One shape dimension can be -1. In this case, the value is
   212|         0|            0|            0|  0.00%|        inferred from the length of the array and remaining dimensions.
   213|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A'}, optional
   214|         0|            0|            0|  0.00%|        Read the elements of `a` using this index order, and place the
   215|         0|            0|            0|  0.00%|        elements into the reshaped array using this index order.  'C'
   216|         0|            0|            0|  0.00%|        means to read / write the elements using C-like index order,
   217|         0|            0|            0|  0.00%|        with the last axis index changing fastest, back to the first
   218|         0|            0|            0|  0.00%|        axis index changing slowest. 'F' means to read / write the
   219|         0|            0|            0|  0.00%|        elements using Fortran-like index order, with the first index
   220|         0|            0|            0|  0.00%|        changing fastest, and the last index changing slowest. Note that
   221|         0|            0|            0|  0.00%|        the 'C' and 'F' options take no account of the memory layout of
   222|         0|            0|            0|  0.00%|        the underlying array, and only refer to the order of indexing.
   223|         0|            0|            0|  0.00%|        'A' means to read / write the elements in Fortran-like index
   224|         0|            0|            0|  0.00%|        order if `a` is Fortran *contiguous* in memory, C-like order
   225|         0|            0|            0|  0.00%|        otherwise.
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|    Returns
   228|         0|            0|            0|  0.00%|    -------
   229|         0|            0|            0|  0.00%|    reshaped_array : ndarray
   230|         0|            0|            0|  0.00%|        This will be a new view object if possible; otherwise, it will
   231|         0|            0|            0|  0.00%|        be a copy.  Note there is no guarantee of the *memory layout* (C- or
   232|         0|            0|            0|  0.00%|        Fortran- contiguous) of the returned array.
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|    See Also
   235|         0|            0|            0|  0.00%|    --------
   236|         0|            0|            0|  0.00%|    ndarray.reshape : Equivalent method.
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|    Notes
   239|         0|            0|            0|  0.00%|    -----
   240|         0|            0|            0|  0.00%|    It is not always possible to change the shape of an array without
   241|         0|            0|            0|  0.00%|    copying the data. If you want an error to be raised when the data is copied,
   242|         0|            0|            0|  0.00%|    you should assign the new shape to the shape attribute of the array::
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|     >>> a = np.zeros((10, 2))
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|     # A transpose makes the array non-contiguous
   247|         0|            0|            0|  0.00%|     >>> b = a.T
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|     # Taking a view makes it possible to modify the shape without modifying
   250|         0|            0|            0|  0.00%|     # the initial object.
   251|         0|            0|            0|  0.00%|     >>> c = b.view()
   252|         0|            0|            0|  0.00%|     >>> c.shape = (20)
   253|         0|            0|            0|  0.00%|     Traceback (most recent call last):
   254|         0|            0|            0|  0.00%|        ...
   255|         0|            0|            0|  0.00%|     AttributeError: Incompatible shape for in-place modification. Use
   256|         0|            0|            0|  0.00%|     `.reshape()` to make a copy with the desired shape.
   257|         0|            0|            0|  0.00%|
   258|         0|            0|            0|  0.00%|    The `order` keyword gives the index ordering both for *fetching* the values
   259|         0|            0|            0|  0.00%|    from `a`, and then *placing* the values into the output array.
   260|         0|            0|            0|  0.00%|    For example, let's say you have an array:
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|    >>> a = np.arange(6).reshape((3, 2))
   263|         0|            0|            0|  0.00%|    >>> a
   264|         0|            0|            0|  0.00%|    array([[0, 1],
   265|         0|            0|            0|  0.00%|           [2, 3],
   266|         0|            0|            0|  0.00%|           [4, 5]])
   267|         0|            0|            0|  0.00%|
   268|         0|            0|            0|  0.00%|    You can think of reshaping as first raveling the array (using the given
   269|         0|            0|            0|  0.00%|    index order), then inserting the elements from the raveled array into the
   270|         0|            0|            0|  0.00%|    new array using the same kind of index ordering as was used for the
   271|         0|            0|            0|  0.00%|    raveling.
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|    >>> np.reshape(a, (2, 3)) # C-like index ordering
   274|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   275|         0|            0|            0|  0.00%|           [3, 4, 5]])
   276|         0|            0|            0|  0.00%|    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape
   277|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   278|         0|            0|            0|  0.00%|           [3, 4, 5]])
   279|         0|            0|            0|  0.00%|    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering
   280|         0|            0|            0|  0.00%|    array([[0, 4, 3],
   281|         0|            0|            0|  0.00%|           [2, 1, 5]])
   282|         0|            0|            0|  0.00%|    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')
   283|         0|            0|            0|  0.00%|    array([[0, 4, 3],
   284|         0|            0|            0|  0.00%|           [2, 1, 5]])
   285|         0|            0|            0|  0.00%|
   286|         0|            0|            0|  0.00%|    Examples
   287|         0|            0|            0|  0.00%|    --------
   288|         0|            0|            0|  0.00%|    >>> a = np.array([[1,2,3], [4,5,6]])
   289|         0|            0|            0|  0.00%|    >>> np.reshape(a, 6)
   290|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
   291|         0|            0|            0|  0.00%|    >>> np.reshape(a, 6, order='F')
   292|         0|            0|            0|  0.00%|    array([1, 4, 2, 5, 3, 6])
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2
   295|         0|            0|            0|  0.00%|    array([[1, 2],
   296|         0|            0|            0|  0.00%|           [3, 4],
   297|         0|            0|            0|  0.00%|           [5, 6]])
   298|         0|            0|            0|  0.00%|    """
   299|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'reshape', newshape, order=order)
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|def _choose_dispatcher(a, choices, out=None, mode=None):
   303|         0|            0|            0|  0.00%|    yield a
   304|         0|            0|            0|  0.00%|    yield from choices
   305|         0|            0|            0|  0.00%|    yield out
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|@array_function_dispatch(_choose_dispatcher)
   309|         0|            0|            0|  0.00%|def choose(a, choices, out=None, mode='raise'):
   310|         0|            0|            0|  0.00%|    """
   311|         0|            0|            0|  0.00%|    Construct an array from an index array and a set of arrays to choose from.
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|    First of all, if confused or uncertain, definitely look at the Examples -
   314|         0|            0|            0|  0.00%|    in its full generality, this function is less simple than it might
   315|         0|            0|            0|  0.00%|    seem from the following code description (below ndi =
   316|         0|            0|            0|  0.00%|    `numpy.lib.index_tricks`):
   317|         0|            0|            0|  0.00%|
   318|         0|            0|            0|  0.00%|    ``np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])``.
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|    But this omits some subtleties.  Here is a fully general summary:
   321|         0|            0|            0|  0.00%|
   322|         0|            0|            0|  0.00%|    Given an "index" array (`a`) of integers and a sequence of `n` arrays
   323|         0|            0|            0|  0.00%|    (`choices`), `a` and each choice array are first broadcast, as necessary,
   324|         0|            0|            0|  0.00%|    to arrays of a common shape; calling these *Ba* and *Bchoices[i], i =
   325|         0|            0|            0|  0.00%|    0,...,n-1* we have that, necessarily, ``Ba.shape == Bchoices[i].shape``
   326|         0|            0|            0|  0.00%|    for each `i`.  Then, a new array with shape ``Ba.shape`` is created as
   327|         0|            0|            0|  0.00%|    follows:
   328|         0|            0|            0|  0.00%|
   329|         0|            0|            0|  0.00%|    * if ``mode=raise`` (the default), then, first of all, each element of
   330|         0|            0|            0|  0.00%|      `a` (and thus `Ba`) must be in the range `[0, n-1]`; now, suppose that
   331|         0|            0|            0|  0.00%|      `i` (in that range) is the value at the `(j0, j1, ..., jm)` position
   332|         0|            0|            0|  0.00%|      in `Ba` - then the value at the same position in the new array is the
   333|         0|            0|            0|  0.00%|      value in `Bchoices[i]` at that same position;
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|    * if ``mode=wrap``, values in `a` (and thus `Ba`) may be any (signed)
   336|         0|            0|            0|  0.00%|      integer; modular arithmetic is used to map integers outside the range
   337|         0|            0|            0|  0.00%|      `[0, n-1]` back into that range; and then the new array is constructed
   338|         0|            0|            0|  0.00%|      as above;
   339|         0|            0|            0|  0.00%|
   340|         0|            0|            0|  0.00%|    * if ``mode=clip``, values in `a` (and thus `Ba`) may be any (signed)
   341|         0|            0|            0|  0.00%|      integer; negative integers are mapped to 0; values greater than `n-1`
   342|         0|            0|            0|  0.00%|      are mapped to `n-1`; and then the new array is constructed as above.
   343|         0|            0|            0|  0.00%|
   344|         0|            0|            0|  0.00%|    Parameters
   345|         0|            0|            0|  0.00%|    ----------
   346|         0|            0|            0|  0.00%|    a : int array
   347|         0|            0|            0|  0.00%|        This array must contain integers in `[0, n-1]`, where `n` is the number
   348|         0|            0|            0|  0.00%|        of choices, unless ``mode=wrap`` or ``mode=clip``, in which cases any
   349|         0|            0|            0|  0.00%|        integers are permissible.
   350|         0|            0|            0|  0.00%|    choices : sequence of arrays
   351|         0|            0|            0|  0.00%|        Choice arrays. `a` and all of the choices must be broadcastable to the
   352|         0|            0|            0|  0.00%|        same shape.  If `choices` is itself an array (not recommended), then
   353|         0|            0|            0|  0.00%|        its outermost dimension (i.e., the one corresponding to
   354|         0|            0|            0|  0.00%|        ``choices.shape[0]``) is taken as defining the "sequence".
   355|         0|            0|            0|  0.00%|    out : array, optional
   356|         0|            0|            0|  0.00%|        If provided, the result will be inserted into this array. It should
   357|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype. Note that `out` is always
   358|         0|            0|            0|  0.00%|        buffered if `mode='raise'`; use other modes for better performance.
   359|         0|            0|            0|  0.00%|    mode : {'raise' (default), 'wrap', 'clip'}, optional
   360|         0|            0|            0|  0.00%|        Specifies how indices outside `[0, n-1]` will be treated:
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|          * 'raise' : an exception is raised
   363|         0|            0|            0|  0.00%|          * 'wrap' : value becomes value mod `n`
   364|         0|            0|            0|  0.00%|          * 'clip' : values < 0 are mapped to 0, values > n-1 are mapped to n-1
   365|         0|            0|            0|  0.00%|
   366|         0|            0|            0|  0.00%|    Returns
   367|         0|            0|            0|  0.00%|    -------
   368|         0|            0|            0|  0.00%|    merged_array : array
   369|         0|            0|            0|  0.00%|        The merged result.
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|    Raises
   372|         0|            0|            0|  0.00%|    ------
   373|         0|            0|            0|  0.00%|    ValueError: shape mismatch
   374|         0|            0|            0|  0.00%|        If `a` and each choice array are not all broadcastable to the same
   375|         0|            0|            0|  0.00%|        shape.
   376|         0|            0|            0|  0.00%|
   377|         0|            0|            0|  0.00%|    See Also
   378|         0|            0|            0|  0.00%|    --------
   379|         0|            0|            0|  0.00%|    ndarray.choose : equivalent method
   380|         0|            0|            0|  0.00%|    numpy.take_along_axis : Preferable if `choices` is an array
   381|         0|            0|            0|  0.00%|
   382|         0|            0|            0|  0.00%|    Notes
   383|         0|            0|            0|  0.00%|    -----
   384|         0|            0|            0|  0.00%|    To reduce the chance of misinterpretation, even though the following
   385|         0|            0|            0|  0.00%|    "abuse" is nominally supported, `choices` should neither be, nor be
   386|         0|            0|            0|  0.00%|    thought of as, a single array, i.e., the outermost sequence-like container
   387|         0|            0|            0|  0.00%|    should be either a list or a tuple.
   388|         0|            0|            0|  0.00%|
   389|         0|            0|            0|  0.00%|    Examples
   390|         0|            0|            0|  0.00%|    --------
   391|         0|            0|            0|  0.00%|
   392|         0|            0|            0|  0.00%|    >>> choices = [[0, 1, 2, 3], [10, 11, 12, 13],
   393|         0|            0|            0|  0.00%|    ...   [20, 21, 22, 23], [30, 31, 32, 33]]
   394|         0|            0|            0|  0.00%|    >>> np.choose([2, 3, 1, 0], choices
   395|         0|            0|            0|  0.00%|    ... # the first element of the result will be the first element of the
   396|         0|            0|            0|  0.00%|    ... # third (2+1) "array" in choices, namely, 20; the second element
   397|         0|            0|            0|  0.00%|    ... # will be the second element of the fourth (3+1) choice array, i.e.,
   398|         0|            0|            0|  0.00%|    ... # 31, etc.
   399|         0|            0|            0|  0.00%|    ... )
   400|         0|            0|            0|  0.00%|    array([20, 31, 12,  3])
   401|         0|            0|            0|  0.00%|    >>> np.choose([2, 4, 1, 0], choices, mode='clip') # 4 goes to 3 (4-1)
   402|         0|            0|            0|  0.00%|    array([20, 31, 12,  3])
   403|         0|            0|            0|  0.00%|    >>> # because there are 4 choice arrays
   404|         0|            0|            0|  0.00%|    >>> np.choose([2, 4, 1, 0], choices, mode='wrap') # 4 goes to (4 mod 4)
   405|         0|            0|            0|  0.00%|    array([20,  1, 12,  3])
   406|         0|            0|            0|  0.00%|    >>> # i.e., 0
   407|         0|            0|            0|  0.00%|
   408|         0|            0|            0|  0.00%|    A couple examples illustrating how choose broadcasts:
   409|         0|            0|            0|  0.00%|
   410|         0|            0|            0|  0.00%|    >>> a = [[1, 0, 1], [0, 1, 0], [1, 0, 1]]
   411|         0|            0|            0|  0.00%|    >>> choices = [-10, 10]
   412|         0|            0|            0|  0.00%|    >>> np.choose(a, choices)
   413|         0|            0|            0|  0.00%|    array([[ 10, -10,  10],
   414|         0|            0|            0|  0.00%|           [-10,  10, -10],
   415|         0|            0|            0|  0.00%|           [ 10, -10,  10]])
   416|         0|            0|            0|  0.00%|
   417|         0|            0|            0|  0.00%|    >>> # With thanks to Anne Archibald
   418|         0|            0|            0|  0.00%|    >>> a = np.array([0, 1]).reshape((2,1,1))
   419|         0|            0|            0|  0.00%|    >>> c1 = np.array([1, 2, 3]).reshape((1,3,1))
   420|         0|            0|            0|  0.00%|    >>> c2 = np.array([-1, -2, -3, -4, -5]).reshape((1,1,5))
   421|         0|            0|            0|  0.00%|    >>> np.choose(a, (c1, c2)) # result is 2x3x5, res[0,:,:]=c1, res[1,:,:]=c2
   422|         0|            0|            0|  0.00%|    array([[[ 1,  1,  1,  1,  1],
   423|         0|            0|            0|  0.00%|            [ 2,  2,  2,  2,  2],
   424|         0|            0|            0|  0.00%|            [ 3,  3,  3,  3,  3]],
   425|         0|            0|            0|  0.00%|           [[-1, -2, -3, -4, -5],
   426|         0|            0|            0|  0.00%|            [-1, -2, -3, -4, -5],
   427|         0|            0|            0|  0.00%|            [-1, -2, -3, -4, -5]]])
   428|         0|            0|            0|  0.00%|
   429|         0|            0|            0|  0.00%|    """
   430|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'choose', choices, out=out, mode=mode)
   431|         0|            0|            0|  0.00%|
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|def _repeat_dispatcher(a, repeats, axis=None):
   434|         0|            0|            0|  0.00%|    return (a,)
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|
   437|         0|            0|            0|  0.00%|@array_function_dispatch(_repeat_dispatcher)
   438|         0|            0|            0|  0.00%|def repeat(a, repeats, axis=None):
   439|         0|            0|            0|  0.00%|    """
   440|         0|            0|            0|  0.00%|    Repeat elements of an array.
   441|         0|            0|            0|  0.00%|
   442|         0|            0|            0|  0.00%|    Parameters
   443|         0|            0|            0|  0.00%|    ----------
   444|         0|            0|            0|  0.00%|    a : array_like
   445|         0|            0|            0|  0.00%|        Input array.
   446|         0|            0|            0|  0.00%|    repeats : int or array of ints
   447|         0|            0|            0|  0.00%|        The number of repetitions for each element.  `repeats` is broadcasted
   448|         0|            0|            0|  0.00%|        to fit the shape of the given axis.
   449|         0|            0|            0|  0.00%|    axis : int, optional
   450|         0|            0|            0|  0.00%|        The axis along which to repeat values.  By default, use the
   451|         0|            0|            0|  0.00%|        flattened input array, and return a flat output array.
   452|         0|            0|            0|  0.00%|
   453|         0|            0|            0|  0.00%|    Returns
   454|         0|            0|            0|  0.00%|    -------
   455|         0|            0|            0|  0.00%|    repeated_array : ndarray
   456|         0|            0|            0|  0.00%|        Output array which has the same shape as `a`, except along
   457|         0|            0|            0|  0.00%|        the given axis.
   458|         0|            0|            0|  0.00%|
   459|         0|            0|            0|  0.00%|    See Also
   460|         0|            0|            0|  0.00%|    --------
   461|         0|            0|            0|  0.00%|    tile : Tile an array.
   462|         0|            0|            0|  0.00%|    unique : Find the unique elements of an array.
   463|         0|            0|            0|  0.00%|
   464|         0|            0|            0|  0.00%|    Examples
   465|         0|            0|            0|  0.00%|    --------
   466|         0|            0|            0|  0.00%|    >>> np.repeat(3, 4)
   467|         0|            0|            0|  0.00%|    array([3, 3, 3, 3])
   468|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2],[3,4]])
   469|         0|            0|            0|  0.00%|    >>> np.repeat(x, 2)
   470|         0|            0|            0|  0.00%|    array([1, 1, 2, 2, 3, 3, 4, 4])
   471|         0|            0|            0|  0.00%|    >>> np.repeat(x, 3, axis=1)
   472|         0|            0|            0|  0.00%|    array([[1, 1, 1, 2, 2, 2],
   473|         0|            0|            0|  0.00%|           [3, 3, 3, 4, 4, 4]])
   474|         0|            0|            0|  0.00%|    >>> np.repeat(x, [1, 2], axis=0)
   475|         0|            0|            0|  0.00%|    array([[1, 2],
   476|         0|            0|            0|  0.00%|           [3, 4],
   477|         0|            0|            0|  0.00%|           [3, 4]])
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|    """
   480|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'repeat', repeats, axis=axis)
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|def _put_dispatcher(a, ind, v, mode=None):
   484|         0|            0|            0|  0.00%|    return (a, ind, v)
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|
   487|         0|            0|            0|  0.00%|@array_function_dispatch(_put_dispatcher)
   488|         0|            0|            0|  0.00%|def put(a, ind, v, mode='raise'):
   489|         0|            0|            0|  0.00%|    """
   490|         0|            0|            0|  0.00%|    Replaces specified elements of an array with given values.
   491|         0|            0|            0|  0.00%|
   492|         0|            0|            0|  0.00%|    The indexing works on the flattened target array. `put` is roughly
   493|         0|            0|            0|  0.00%|    equivalent to:
   494|         0|            0|            0|  0.00%|
   495|         0|            0|            0|  0.00%|    ::
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|        a.flat[ind] = v
   498|         0|            0|            0|  0.00%|
   499|         0|            0|            0|  0.00%|    Parameters
   500|         0|            0|            0|  0.00%|    ----------
   501|         0|            0|            0|  0.00%|    a : ndarray
   502|         0|            0|            0|  0.00%|        Target array.
   503|         0|            0|            0|  0.00%|    ind : array_like
   504|         0|            0|            0|  0.00%|        Target indices, interpreted as integers.
   505|         0|            0|            0|  0.00%|    v : array_like
   506|         0|            0|            0|  0.00%|        Values to place in `a` at target indices. If `v` is shorter than
   507|         0|            0|            0|  0.00%|        `ind` it will be repeated as necessary.
   508|         0|            0|            0|  0.00%|    mode : {'raise', 'wrap', 'clip'}, optional
   509|         0|            0|            0|  0.00%|        Specifies how out-of-bounds indices will behave.
   510|         0|            0|            0|  0.00%|
   511|         0|            0|            0|  0.00%|        * 'raise' -- raise an error (default)
   512|         0|            0|            0|  0.00%|        * 'wrap' -- wrap around
   513|         0|            0|            0|  0.00%|        * 'clip' -- clip to the range
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|        'clip' mode means that all indices that are too large are replaced
   516|         0|            0|            0|  0.00%|        by the index that addresses the last element along that axis. Note
   517|         0|            0|            0|  0.00%|        that this disables indexing with negative numbers. In 'raise' mode,
   518|         0|            0|            0|  0.00%|        if an exception occurs the target array may still be modified.
   519|         0|            0|            0|  0.00%|
   520|         0|            0|            0|  0.00%|    See Also
   521|         0|            0|            0|  0.00%|    --------
   522|         0|            0|            0|  0.00%|    putmask, place
   523|         0|            0|            0|  0.00%|    put_along_axis : Put elements by matching the array and the index arrays
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|    Examples
   526|         0|            0|            0|  0.00%|    --------
   527|         0|            0|            0|  0.00%|    >>> a = np.arange(5)
   528|         0|            0|            0|  0.00%|    >>> np.put(a, [0, 2], [-44, -55])
   529|         0|            0|            0|  0.00%|    >>> a
   530|         0|            0|            0|  0.00%|    array([-44,   1, -55,   3,   4])
   531|         0|            0|            0|  0.00%|
   532|         0|            0|            0|  0.00%|    >>> a = np.arange(5)
   533|         0|            0|            0|  0.00%|    >>> np.put(a, 22, -5, mode='clip')
   534|         0|            0|            0|  0.00%|    >>> a
   535|         0|            0|            0|  0.00%|    array([ 0,  1,  2,  3, -5])
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|    """
   538|         0|            0|            0|  0.00%|    try:
   539|         0|            0|            0|  0.00%|        put = a.put
   540|         0|            0|            0|  0.00%|    except AttributeError as e:
   541|         0|            0|            0|  0.00%|        raise TypeError("argument 1 must be numpy.ndarray, "
   542|         0|            0|            0|  0.00%|                        "not {name}".format(name=type(a).__name__)) from e
   543|         0|            0|            0|  0.00%|
   544|         0|            0|            0|  0.00%|    return put(ind, v, mode=mode)
   545|         0|            0|            0|  0.00%|
   546|         0|            0|            0|  0.00%|
   547|         0|            0|            0|  0.00%|def _swapaxes_dispatcher(a, axis1, axis2):
   548|         0|            0|            0|  0.00%|    return (a,)
   549|         0|            0|            0|  0.00%|
   550|         0|            0|            0|  0.00%|
   551|         0|            0|            0|  0.00%|@array_function_dispatch(_swapaxes_dispatcher)
   552|         0|            0|            0|  0.00%|def swapaxes(a, axis1, axis2):
   553|         0|            0|            0|  0.00%|    """
   554|         0|            0|            0|  0.00%|    Interchange two axes of an array.
   555|         0|            0|            0|  0.00%|
   556|         0|            0|            0|  0.00%|    Parameters
   557|         0|            0|            0|  0.00%|    ----------
   558|         0|            0|            0|  0.00%|    a : array_like
   559|         0|            0|            0|  0.00%|        Input array.
   560|         0|            0|            0|  0.00%|    axis1 : int
   561|         0|            0|            0|  0.00%|        First axis.
   562|         0|            0|            0|  0.00%|    axis2 : int
   563|         0|            0|            0|  0.00%|        Second axis.
   564|         0|            0|            0|  0.00%|
   565|         0|            0|            0|  0.00%|    Returns
   566|         0|            0|            0|  0.00%|    -------
   567|         0|            0|            0|  0.00%|    a_swapped : ndarray
   568|         0|            0|            0|  0.00%|        For NumPy >= 1.10.0, if `a` is an ndarray, then a view of `a` is
   569|         0|            0|            0|  0.00%|        returned; otherwise a new array is created. For earlier NumPy
   570|         0|            0|            0|  0.00%|        versions a view of `a` is returned only if the order of the
   571|         0|            0|            0|  0.00%|        axes is changed, otherwise the input array is returned.
   572|         0|            0|            0|  0.00%|
   573|         0|            0|            0|  0.00%|    Examples
   574|         0|            0|            0|  0.00%|    --------
   575|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3]])
   576|         0|            0|            0|  0.00%|    >>> np.swapaxes(x,0,1)
   577|         0|            0|            0|  0.00%|    array([[1],
   578|         0|            0|            0|  0.00%|           [2],
   579|         0|            0|            0|  0.00%|           [3]])
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    >>> x = np.array([[[0,1],[2,3]],[[4,5],[6,7]]])
   582|         0|            0|            0|  0.00%|    >>> x
   583|         0|            0|            0|  0.00%|    array([[[0, 1],
   584|         0|            0|            0|  0.00%|            [2, 3]],
   585|         0|            0|            0|  0.00%|           [[4, 5],
   586|         0|            0|            0|  0.00%|            [6, 7]]])
   587|         0|            0|            0|  0.00%|
   588|         0|            0|            0|  0.00%|    >>> np.swapaxes(x,0,2)
   589|         0|            0|            0|  0.00%|    array([[[0, 4],
   590|         0|            0|            0|  0.00%|            [2, 6]],
   591|         0|            0|            0|  0.00%|           [[1, 5],
   592|         0|            0|            0|  0.00%|            [3, 7]]])
   593|         0|            0|            0|  0.00%|
   594|         0|            0|            0|  0.00%|    """
   595|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'swapaxes', axis1, axis2)
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|
   598|         2|  3.09944e-06|  1.54972e-06|  0.00%|def _transpose_dispatcher(a, axes=None):
   599|         2|  4.52995e-06|  2.26498e-06|  0.00%|    return (a,)
   600|         0|            0|            0|  0.00%|
   601|         0|            0|            0|  0.00%|
   602|         2|  4.29153e-06|  2.14577e-06|  0.00%|@array_function_dispatch(_transpose_dispatcher)
   603|         0|            0|            0|  0.00%|def transpose(a, axes=None):
   604|         0|            0|            0|  0.00%|    """
   605|         0|            0|            0|  0.00%|    Reverse or permute the axes of an array; returns the modified array.
   606|         0|            0|            0|  0.00%|
   607|         0|            0|            0|  0.00%|    For an array a with two axes, transpose(a) gives the matrix transpose.
   608|         0|            0|            0|  0.00%|
   609|         0|            0|            0|  0.00%|    Parameters
   610|         0|            0|            0|  0.00%|    ----------
   611|         0|            0|            0|  0.00%|    a : array_like
   612|         0|            0|            0|  0.00%|        Input array.
   613|         0|            0|            0|  0.00%|    axes : tuple or list of ints, optional
   614|         0|            0|            0|  0.00%|        If specified, it must be a tuple or list which contains a permutation of
   615|         0|            0|            0|  0.00%|        [0,1,..,N-1] where N is the number of axes of a.  The i'th axis of the
   616|         0|            0|            0|  0.00%|        returned array will correspond to the axis numbered ``axes[i]`` of the
   617|         0|            0|            0|  0.00%|        input.  If not specified, defaults to ``range(a.ndim)[::-1]``, which
   618|         0|            0|            0|  0.00%|        reverses the order of the axes.
   619|         0|            0|            0|  0.00%|
   620|         0|            0|            0|  0.00%|    Returns
   621|         0|            0|            0|  0.00%|    -------
   622|         0|            0|            0|  0.00%|    p : ndarray
   623|         0|            0|            0|  0.00%|        `a` with its axes permuted.  A view is returned whenever
   624|         0|            0|            0|  0.00%|        possible.
   625|         0|            0|            0|  0.00%|
   626|         0|            0|            0|  0.00%|    See Also
   627|         0|            0|            0|  0.00%|    --------
   628|         0|            0|            0|  0.00%|    moveaxis
   629|         0|            0|            0|  0.00%|    argsort
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|    Notes
   632|         0|            0|            0|  0.00%|    -----
   633|         0|            0|            0|  0.00%|    Use `transpose(a, argsort(axes))` to invert the transposition of tensors
   634|         0|            0|            0|  0.00%|    when using the `axes` keyword argument.
   635|         0|            0|            0|  0.00%|
   636|         0|            0|            0|  0.00%|    Transposing a 1-D array returns an unchanged view of the original array.
   637|         0|            0|            0|  0.00%|
   638|         0|            0|            0|  0.00%|    Examples
   639|         0|            0|            0|  0.00%|    --------
   640|         0|            0|            0|  0.00%|    >>> x = np.arange(4).reshape((2,2))
   641|         0|            0|            0|  0.00%|    >>> x
   642|         0|            0|            0|  0.00%|    array([[0, 1],
   643|         0|            0|            0|  0.00%|           [2, 3]])
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|    >>> np.transpose(x)
   646|         0|            0|            0|  0.00%|    array([[0, 2],
   647|         0|            0|            0|  0.00%|           [1, 3]])
   648|         0|            0|            0|  0.00%|
   649|         0|            0|            0|  0.00%|    >>> x = np.ones((1, 2, 3))
   650|         0|            0|            0|  0.00%|    >>> np.transpose(x, (1, 0, 2)).shape
   651|         0|            0|            0|  0.00%|    (2, 1, 3)
   652|         0|            0|            0|  0.00%|
   653|         0|            0|            0|  0.00%|    >>> x = np.ones((2, 3, 4, 5))
   654|         0|            0|            0|  0.00%|    >>> np.transpose(x).shape
   655|         0|            0|            0|  0.00%|    (5, 4, 3, 2)
   656|         0|            0|            0|  0.00%|
   657|         0|            0|            0|  0.00%|    """
   658|         2|  1.28746e-05|   6.4373e-06|  0.00%|    return _wrapfunc(a, 'transpose', axes)
(call)|         2|  2.09808e-05|  1.04904e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:52 _wrapfunc
   659|         0|            0|            0|  0.00%|
   660|         0|            0|            0|  0.00%|
   661|         0|            0|            0|  0.00%|def _partition_dispatcher(a, kth, axis=None, kind=None, order=None):
   662|         0|            0|            0|  0.00%|    return (a,)
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|
   665|         0|            0|            0|  0.00%|@array_function_dispatch(_partition_dispatcher)
   666|         0|            0|            0|  0.00%|def partition(a, kth, axis=-1, kind='introselect', order=None):
   667|         0|            0|            0|  0.00%|    """
   668|         0|            0|            0|  0.00%|    Return a partitioned copy of an array.
   669|         0|            0|            0|  0.00%|
   670|         0|            0|            0|  0.00%|    Creates a copy of the array with its elements rearranged in such a
   671|         0|            0|            0|  0.00%|    way that the value of the element in k-th position is in the
   672|         0|            0|            0|  0.00%|    position it would be in a sorted array. All elements smaller than
   673|         0|            0|            0|  0.00%|    the k-th element are moved before this element and all equal or
   674|         0|            0|            0|  0.00%|    greater are moved behind it. The ordering of the elements in the two
   675|         0|            0|            0|  0.00%|    partitions is undefined.
   676|         0|            0|            0|  0.00%|
   677|         0|            0|            0|  0.00%|    .. versionadded:: 1.8.0
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|    Parameters
   680|         0|            0|            0|  0.00%|    ----------
   681|         0|            0|            0|  0.00%|    a : array_like
   682|         0|            0|            0|  0.00%|        Array to be sorted.
   683|         0|            0|            0|  0.00%|    kth : int or sequence of ints
   684|         0|            0|            0|  0.00%|        Element index to partition by. The k-th value of the element
   685|         0|            0|            0|  0.00%|        will be in its final sorted position and all smaller elements
   686|         0|            0|            0|  0.00%|        will be moved before it and all equal or greater elements behind
   687|         0|            0|            0|  0.00%|        it. The order of all elements in the partitions is undefined. If
   688|         0|            0|            0|  0.00%|        provided with a sequence of k-th it will partition all elements
   689|         0|            0|            0|  0.00%|        indexed by k-th  of them into their sorted position at once.
   690|         0|            0|            0|  0.00%|    axis : int or None, optional
   691|         0|            0|            0|  0.00%|        Axis along which to sort. If None, the array is flattened before
   692|         0|            0|            0|  0.00%|        sorting. The default is -1, which sorts along the last axis.
   693|         0|            0|            0|  0.00%|    kind : {'introselect'}, optional
   694|         0|            0|            0|  0.00%|        Selection algorithm. Default is 'introselect'.
   695|         0|            0|            0|  0.00%|    order : str or list of str, optional
   696|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument
   697|         0|            0|            0|  0.00%|        specifies which fields to compare first, second, etc.  A single
   698|         0|            0|            0|  0.00%|        field can be specified as a string.  Not all fields need be
   699|         0|            0|            0|  0.00%|        specified, but unspecified fields will still be used, in the
   700|         0|            0|            0|  0.00%|        order in which they come up in the dtype, to break ties.
   701|         0|            0|            0|  0.00%|
   702|         0|            0|            0|  0.00%|    Returns
   703|         0|            0|            0|  0.00%|    -------
   704|         0|            0|            0|  0.00%|    partitioned_array : ndarray
   705|         0|            0|            0|  0.00%|        Array of the same type and shape as `a`.
   706|         0|            0|            0|  0.00%|
   707|         0|            0|            0|  0.00%|    See Also
   708|         0|            0|            0|  0.00%|    --------
   709|         0|            0|            0|  0.00%|    ndarray.partition : Method to sort an array in-place.
   710|         0|            0|            0|  0.00%|    argpartition : Indirect partition.
   711|         0|            0|            0|  0.00%|    sort : Full sorting
   712|         0|            0|            0|  0.00%|
   713|         0|            0|            0|  0.00%|    Notes
   714|         0|            0|            0|  0.00%|    -----
   715|         0|            0|            0|  0.00%|    The various selection algorithms are characterized by their average
   716|         0|            0|            0|  0.00%|    speed, worst case performance, work space size, and whether they are
   717|         0|            0|            0|  0.00%|    stable. A stable sort keeps items with the same key in the same
   718|         0|            0|            0|  0.00%|    relative order. The available algorithms have the following
   719|         0|            0|            0|  0.00%|    properties:
   720|         0|            0|            0|  0.00%|
   721|         0|            0|            0|  0.00%|    ================= ======= ============= ============ =======
   722|         0|            0|            0|  0.00%|       kind            speed   worst case    work space  stable
   723|         0|            0|            0|  0.00%|    ================= ======= ============= ============ =======
   724|         0|            0|            0|  0.00%|    'introselect'        1        O(n)           0         no
   725|         0|            0|            0|  0.00%|    ================= ======= ============= ============ =======
   726|         0|            0|            0|  0.00%|
   727|         0|            0|            0|  0.00%|    All the partition algorithms make temporary copies of the data when
   728|         0|            0|            0|  0.00%|    partitioning along any but the last axis.  Consequently,
   729|         0|            0|            0|  0.00%|    partitioning along the last axis is faster and uses less space than
   730|         0|            0|            0|  0.00%|    partitioning along any other axis.
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|    The sort order for complex numbers is lexicographic. If both the
   733|         0|            0|            0|  0.00%|    real and imaginary parts are non-nan then the order is determined by
   734|         0|            0|            0|  0.00%|    the real parts except when they are equal, in which case the order
   735|         0|            0|            0|  0.00%|    is determined by the imaginary parts.
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|    Examples
   738|         0|            0|            0|  0.00%|    --------
   739|         0|            0|            0|  0.00%|    >>> a = np.array([3, 4, 2, 1])
   740|         0|            0|            0|  0.00%|    >>> np.partition(a, 3)
   741|         0|            0|            0|  0.00%|    array([2, 1, 3, 4])
   742|         0|            0|            0|  0.00%|
   743|         0|            0|            0|  0.00%|    >>> np.partition(a, (1, 3))
   744|         0|            0|            0|  0.00%|    array([1, 2, 3, 4])
   745|         0|            0|            0|  0.00%|
   746|         0|            0|            0|  0.00%|    """
   747|         0|            0|            0|  0.00%|    if axis is None:
   748|         0|            0|            0|  0.00%|        # flatten returns (1, N) for np.matrix, so always use the last axis
   749|         0|            0|            0|  0.00%|        a = asanyarray(a).flatten()
   750|         0|            0|            0|  0.00%|        axis = -1
   751|         0|            0|            0|  0.00%|    else:
   752|         0|            0|            0|  0.00%|        a = asanyarray(a).copy(order="K")
   753|         0|            0|            0|  0.00%|    a.partition(kth, axis=axis, kind=kind, order=order)
   754|         0|            0|            0|  0.00%|    return a
   755|         0|            0|            0|  0.00%|
   756|         0|            0|            0|  0.00%|
   757|         0|            0|            0|  0.00%|def _argpartition_dispatcher(a, kth, axis=None, kind=None, order=None):
   758|         0|            0|            0|  0.00%|    return (a,)
   759|         0|            0|            0|  0.00%|
   760|         0|            0|            0|  0.00%|
   761|         0|            0|            0|  0.00%|@array_function_dispatch(_argpartition_dispatcher)
   762|         0|            0|            0|  0.00%|def argpartition(a, kth, axis=-1, kind='introselect', order=None):
   763|         0|            0|            0|  0.00%|    """
   764|         0|            0|            0|  0.00%|    Perform an indirect partition along the given axis using the
   765|         0|            0|            0|  0.00%|    algorithm specified by the `kind` keyword. It returns an array of
   766|         0|            0|            0|  0.00%|    indices of the same shape as `a` that index data along the given
   767|         0|            0|            0|  0.00%|    axis in partitioned order.
   768|         0|            0|            0|  0.00%|
   769|         0|            0|            0|  0.00%|    .. versionadded:: 1.8.0
   770|         0|            0|            0|  0.00%|
   771|         0|            0|            0|  0.00%|    Parameters
   772|         0|            0|            0|  0.00%|    ----------
   773|         0|            0|            0|  0.00%|    a : array_like
   774|         0|            0|            0|  0.00%|        Array to sort.
   775|         0|            0|            0|  0.00%|    kth : int or sequence of ints
   776|         0|            0|            0|  0.00%|        Element index to partition by. The k-th element will be in its
   777|         0|            0|            0|  0.00%|        final sorted position and all smaller elements will be moved
   778|         0|            0|            0|  0.00%|        before it and all larger elements behind it. The order all
   779|         0|            0|            0|  0.00%|        elements in the partitions is undefined. If provided with a
   780|         0|            0|            0|  0.00%|        sequence of k-th it will partition all of them into their sorted
   781|         0|            0|            0|  0.00%|        position at once.
   782|         0|            0|            0|  0.00%|    axis : int or None, optional
   783|         0|            0|            0|  0.00%|        Axis along which to sort. The default is -1 (the last axis). If
   784|         0|            0|            0|  0.00%|        None, the flattened array is used.
   785|         0|            0|            0|  0.00%|    kind : {'introselect'}, optional
   786|         0|            0|            0|  0.00%|        Selection algorithm. Default is 'introselect'
   787|         0|            0|            0|  0.00%|    order : str or list of str, optional
   788|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument
   789|         0|            0|            0|  0.00%|        specifies which fields to compare first, second, etc. A single
   790|         0|            0|            0|  0.00%|        field can be specified as a string, and not all fields need be
   791|         0|            0|            0|  0.00%|        specified, but unspecified fields will still be used, in the
   792|         0|            0|            0|  0.00%|        order in which they come up in the dtype, to break ties.
   793|         0|            0|            0|  0.00%|
   794|         0|            0|            0|  0.00%|    Returns
   795|         0|            0|            0|  0.00%|    -------
   796|         0|            0|            0|  0.00%|    index_array : ndarray, int
   797|         0|            0|            0|  0.00%|        Array of indices that partition `a` along the specified axis.
   798|         0|            0|            0|  0.00%|        If `a` is one-dimensional, ``a[index_array]`` yields a partitioned `a`.
   799|         0|            0|            0|  0.00%|        More generally, ``np.take_along_axis(a, index_array, axis=a)`` always
   800|         0|            0|            0|  0.00%|        yields the partitioned `a`, irrespective of dimensionality.
   801|         0|            0|            0|  0.00%|
   802|         0|            0|            0|  0.00%|    See Also
   803|         0|            0|            0|  0.00%|    --------
   804|         0|            0|            0|  0.00%|    partition : Describes partition algorithms used.
   805|         0|            0|            0|  0.00%|    ndarray.partition : Inplace partition.
   806|         0|            0|            0|  0.00%|    argsort : Full indirect sort.
   807|         0|            0|            0|  0.00%|    take_along_axis : Apply ``index_array`` from argpartition
   808|         0|            0|            0|  0.00%|                      to an array as if by calling partition.
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|    Notes
   811|         0|            0|            0|  0.00%|    -----
   812|         0|            0|            0|  0.00%|    See `partition` for notes on the different selection algorithms.
   813|         0|            0|            0|  0.00%|
   814|         0|            0|            0|  0.00%|    Examples
   815|         0|            0|            0|  0.00%|    --------
   816|         0|            0|            0|  0.00%|    One dimensional array:
   817|         0|            0|            0|  0.00%|
   818|         0|            0|            0|  0.00%|    >>> x = np.array([3, 4, 2, 1])
   819|         0|            0|            0|  0.00%|    >>> x[np.argpartition(x, 3)]
   820|         0|            0|            0|  0.00%|    array([2, 1, 3, 4])
   821|         0|            0|            0|  0.00%|    >>> x[np.argpartition(x, (1, 3))]
   822|         0|            0|            0|  0.00%|    array([1, 2, 3, 4])
   823|         0|            0|            0|  0.00%|
   824|         0|            0|            0|  0.00%|    >>> x = [3, 4, 2, 1]
   825|         0|            0|            0|  0.00%|    >>> np.array(x)[np.argpartition(x, 3)]
   826|         0|            0|            0|  0.00%|    array([2, 1, 3, 4])
   827|         0|            0|            0|  0.00%|
   828|         0|            0|            0|  0.00%|    Multi-dimensional array:
   829|         0|            0|            0|  0.00%|
   830|         0|            0|            0|  0.00%|    >>> x = np.array([[3, 4, 2], [1, 3, 1]])
   831|         0|            0|            0|  0.00%|    >>> index_array = np.argpartition(x, kth=1, axis=-1)
   832|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, index_array, axis=-1)  # same as np.partition(x, kth=1)
   833|         0|            0|            0|  0.00%|    array([[2, 3, 4],
   834|         0|            0|            0|  0.00%|           [1, 1, 3]])
   835|         0|            0|            0|  0.00%|
   836|         0|            0|            0|  0.00%|    """
   837|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)
   838|         0|            0|            0|  0.00%|
   839|         0|            0|            0|  0.00%|
   840|         0|            0|            0|  0.00%|def _sort_dispatcher(a, axis=None, kind=None, order=None):
   841|         0|            0|            0|  0.00%|    return (a,)
   842|         0|            0|            0|  0.00%|
   843|         0|            0|            0|  0.00%|
   844|         0|            0|            0|  0.00%|@array_function_dispatch(_sort_dispatcher)
   845|         0|            0|            0|  0.00%|def sort(a, axis=-1, kind=None, order=None):
   846|         0|            0|            0|  0.00%|    """
   847|         0|            0|            0|  0.00%|    Return a sorted copy of an array.
   848|         0|            0|            0|  0.00%|
   849|         0|            0|            0|  0.00%|    Parameters
   850|         0|            0|            0|  0.00%|    ----------
   851|         0|            0|            0|  0.00%|    a : array_like
   852|         0|            0|            0|  0.00%|        Array to be sorted.
   853|         0|            0|            0|  0.00%|    axis : int or None, optional
   854|         0|            0|            0|  0.00%|        Axis along which to sort. If None, the array is flattened before
   855|         0|            0|            0|  0.00%|        sorting. The default is -1, which sorts along the last axis.
   856|         0|            0|            0|  0.00%|    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional
   857|         0|            0|            0|  0.00%|        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'
   858|         0|            0|            0|  0.00%|        and 'mergesort' use timsort or radix sort under the covers and, in general,
   859|         0|            0|            0|  0.00%|        the actual implementation will vary with data type. The 'mergesort' option
   860|         0|            0|            0|  0.00%|        is retained for backwards compatibility.
   861|         0|            0|            0|  0.00%|
   862|         0|            0|            0|  0.00%|        .. versionchanged:: 1.15.0.
   863|         0|            0|            0|  0.00%|           The 'stable' option was added.
   864|         0|            0|            0|  0.00%|
   865|         0|            0|            0|  0.00%|    order : str or list of str, optional
   866|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument specifies
   867|         0|            0|            0|  0.00%|        which fields to compare first, second, etc.  A single field can
   868|         0|            0|            0|  0.00%|        be specified as a string, and not all fields need be specified,
   869|         0|            0|            0|  0.00%|        but unspecified fields will still be used, in the order in which
   870|         0|            0|            0|  0.00%|        they come up in the dtype, to break ties.
   871|         0|            0|            0|  0.00%|
   872|         0|            0|            0|  0.00%|    Returns
   873|         0|            0|            0|  0.00%|    -------
   874|         0|            0|            0|  0.00%|    sorted_array : ndarray
   875|         0|            0|            0|  0.00%|        Array of the same type and shape as `a`.
   876|         0|            0|            0|  0.00%|
   877|         0|            0|            0|  0.00%|    See Also
   878|         0|            0|            0|  0.00%|    --------
   879|         0|            0|            0|  0.00%|    ndarray.sort : Method to sort an array in-place.
   880|         0|            0|            0|  0.00%|    argsort : Indirect sort.
   881|         0|            0|            0|  0.00%|    lexsort : Indirect stable sort on multiple keys.
   882|         0|            0|            0|  0.00%|    searchsorted : Find elements in a sorted array.
   883|         0|            0|            0|  0.00%|    partition : Partial sort.
   884|         0|            0|            0|  0.00%|
   885|         0|            0|            0|  0.00%|    Notes
   886|         0|            0|            0|  0.00%|    -----
   887|         0|            0|            0|  0.00%|    The various sorting algorithms are characterized by their average speed,
   888|         0|            0|            0|  0.00%|    worst case performance, work space size, and whether they are stable. A
   889|         0|            0|            0|  0.00%|    stable sort keeps items with the same key in the same relative
   890|         0|            0|            0|  0.00%|    order. The four algorithms implemented in NumPy have the following
   891|         0|            0|            0|  0.00%|    properties:
   892|         0|            0|            0|  0.00%|
   893|         0|            0|            0|  0.00%|    =========== ======= ============= ============ ========
   894|         0|            0|            0|  0.00%|       kind      speed   worst case    work space   stable
   895|         0|            0|            0|  0.00%|    =========== ======= ============= ============ ========
   896|         0|            0|            0|  0.00%|    'quicksort'    1     O(n^2)            0          no
   897|         0|            0|            0|  0.00%|    'heapsort'     3     O(n*log(n))       0          no
   898|         0|            0|            0|  0.00%|    'mergesort'    2     O(n*log(n))      ~n/2        yes
   899|         0|            0|            0|  0.00%|    'timsort'      2     O(n*log(n))      ~n/2        yes
   900|         0|            0|            0|  0.00%|    =========== ======= ============= ============ ========
   901|         0|            0|            0|  0.00%|
   902|         0|            0|            0|  0.00%|    .. note:: The datatype determines which of 'mergesort' or 'timsort'
   903|         0|            0|            0|  0.00%|       is actually used, even if 'mergesort' is specified. User selection
   904|         0|            0|            0|  0.00%|       at a finer scale is not currently available.
   905|         0|            0|            0|  0.00%|
   906|         0|            0|            0|  0.00%|    All the sort algorithms make temporary copies of the data when
   907|         0|            0|            0|  0.00%|    sorting along any but the last axis.  Consequently, sorting along
   908|         0|            0|            0|  0.00%|    the last axis is faster and uses less space than sorting along
   909|         0|            0|            0|  0.00%|    any other axis.
   910|         0|            0|            0|  0.00%|
   911|         0|            0|            0|  0.00%|    The sort order for complex numbers is lexicographic. If both the real
   912|         0|            0|            0|  0.00%|    and imaginary parts are non-nan then the order is determined by the
   913|         0|            0|            0|  0.00%|    real parts except when they are equal, in which case the order is
   914|         0|            0|            0|  0.00%|    determined by the imaginary parts.
   915|         0|            0|            0|  0.00%|
   916|         0|            0|            0|  0.00%|    Previous to numpy 1.4.0 sorting real and complex arrays containing nan
   917|         0|            0|            0|  0.00%|    values led to undefined behaviour. In numpy versions >= 1.4.0 nan
   918|         0|            0|            0|  0.00%|    values are sorted to the end. The extended sort order is:
   919|         0|            0|            0|  0.00%|
   920|         0|            0|            0|  0.00%|      * Real: [R, nan]
   921|         0|            0|            0|  0.00%|      * Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]
   922|         0|            0|            0|  0.00%|
   923|         0|            0|            0|  0.00%|    where R is a non-nan real value. Complex values with the same nan
   924|         0|            0|            0|  0.00%|    placements are sorted according to the non-nan part if it exists.
   925|         0|            0|            0|  0.00%|    Non-nan values are sorted as before.
   926|         0|            0|            0|  0.00%|
   927|         0|            0|            0|  0.00%|    .. versionadded:: 1.12.0
   928|         0|            0|            0|  0.00%|
   929|         0|            0|            0|  0.00%|    quicksort has been changed to `introsort <https://en.wikipedia.org/wiki/Introsort>`_.
   930|         0|            0|            0|  0.00%|    When sorting does not make enough progress it switches to
   931|         0|            0|            0|  0.00%|    `heapsort <https://en.wikipedia.org/wiki/Heapsort>`_.
   932|         0|            0|            0|  0.00%|    This implementation makes quicksort O(n*log(n)) in the worst case.
   933|         0|            0|            0|  0.00%|
   934|         0|            0|            0|  0.00%|    'stable' automatically chooses the best stable sorting algorithm
   935|         0|            0|            0|  0.00%|    for the data type being sorted.
   936|         0|            0|            0|  0.00%|    It, along with 'mergesort' is currently mapped to
   937|         0|            0|            0|  0.00%|    `timsort <https://en.wikipedia.org/wiki/Timsort>`_
   938|         0|            0|            0|  0.00%|    or `radix sort <https://en.wikipedia.org/wiki/Radix_sort>`_
   939|         0|            0|            0|  0.00%|    depending on the data type.
   940|         0|            0|            0|  0.00%|    API forward compatibility currently limits the
   941|         0|            0|            0|  0.00%|    ability to select the implementation and it is hardwired for the different
   942|         0|            0|            0|  0.00%|    data types.
   943|         0|            0|            0|  0.00%|
   944|         0|            0|            0|  0.00%|    .. versionadded:: 1.17.0
   945|         0|            0|            0|  0.00%|
   946|         0|            0|            0|  0.00%|    Timsort is added for better performance on already or nearly
   947|         0|            0|            0|  0.00%|    sorted data. On random data timsort is almost identical to
   948|         0|            0|            0|  0.00%|    mergesort. It is now used for stable sort while quicksort is still the
   949|         0|            0|            0|  0.00%|    default sort if none is chosen. For timsort details, refer to
   950|         0|            0|            0|  0.00%|    `CPython listsort.txt <https://github.com/python/cpython/blob/3.7/Objects/listsort.txt>`_.
   951|         0|            0|            0|  0.00%|    'mergesort' and 'stable' are mapped to radix sort for integer data types. Radix sort is an
   952|         0|            0|            0|  0.00%|    O(n) sort instead of O(n log n).
   953|         0|            0|            0|  0.00%|
   954|         0|            0|            0|  0.00%|    .. versionchanged:: 1.18.0
   955|         0|            0|            0|  0.00%|
   956|         0|            0|            0|  0.00%|    NaT now sorts to the end of arrays for consistency with NaN.
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|    Examples
   959|         0|            0|            0|  0.00%|    --------
   960|         0|            0|            0|  0.00%|    >>> a = np.array([[1,4],[3,1]])
   961|         0|            0|            0|  0.00%|    >>> np.sort(a)                # sort along the last axis
   962|         0|            0|            0|  0.00%|    array([[1, 4],
   963|         0|            0|            0|  0.00%|           [1, 3]])
   964|         0|            0|            0|  0.00%|    >>> np.sort(a, axis=None)     # sort the flattened array
   965|         0|            0|            0|  0.00%|    array([1, 1, 3, 4])
   966|         0|            0|            0|  0.00%|    >>> np.sort(a, axis=0)        # sort along the first axis
   967|         0|            0|            0|  0.00%|    array([[1, 1],
   968|         0|            0|            0|  0.00%|           [3, 4]])
   969|         0|            0|            0|  0.00%|
   970|         0|            0|            0|  0.00%|    Use the `order` keyword to specify a field to use when sorting a
   971|         0|            0|            0|  0.00%|    structured array:
   972|         0|            0|            0|  0.00%|
   973|         0|            0|            0|  0.00%|    >>> dtype = [('name', 'S10'), ('height', float), ('age', int)]
   974|         0|            0|            0|  0.00%|    >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38),
   975|         0|            0|            0|  0.00%|    ...           ('Galahad', 1.7, 38)]
   976|         0|            0|            0|  0.00%|    >>> a = np.array(values, dtype=dtype)       # create a structured array
   977|         0|            0|            0|  0.00%|    >>> np.sort(a, order='height')                        # doctest: +SKIP
   978|         0|            0|            0|  0.00%|    array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41),
   979|         0|            0|            0|  0.00%|           ('Lancelot', 1.8999999999999999, 38)],
   980|         0|            0|            0|  0.00%|          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])
   981|         0|            0|            0|  0.00%|
   982|         0|            0|            0|  0.00%|    Sort by age, then height if ages are equal:
   983|         0|            0|            0|  0.00%|
   984|         0|            0|            0|  0.00%|    >>> np.sort(a, order=['age', 'height'])               # doctest: +SKIP
   985|         0|            0|            0|  0.00%|    array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38),
   986|         0|            0|            0|  0.00%|           ('Arthur', 1.8, 41)],
   987|         0|            0|            0|  0.00%|          dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])
   988|         0|            0|            0|  0.00%|
   989|         0|            0|            0|  0.00%|    """
   990|         0|            0|            0|  0.00%|    if axis is None:
   991|         0|            0|            0|  0.00%|        # flatten returns (1, N) for np.matrix, so always use the last axis
   992|         0|            0|            0|  0.00%|        a = asanyarray(a).flatten()
   993|         0|            0|            0|  0.00%|        axis = -1
   994|         0|            0|            0|  0.00%|    else:
   995|         0|            0|            0|  0.00%|        a = asanyarray(a).copy(order="K")
   996|         0|            0|            0|  0.00%|    a.sort(axis=axis, kind=kind, order=order)
   997|         0|            0|            0|  0.00%|    return a
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|
  1000|         0|            0|            0|  0.00%|def _argsort_dispatcher(a, axis=None, kind=None, order=None):
  1001|         0|            0|            0|  0.00%|    return (a,)
  1002|         0|            0|            0|  0.00%|
  1003|         0|            0|            0|  0.00%|
  1004|         0|            0|            0|  0.00%|@array_function_dispatch(_argsort_dispatcher)
  1005|         0|            0|            0|  0.00%|def argsort(a, axis=-1, kind=None, order=None):
  1006|         0|            0|            0|  0.00%|    """
  1007|         0|            0|            0|  0.00%|    Returns the indices that would sort an array.
  1008|         0|            0|            0|  0.00%|
  1009|         0|            0|            0|  0.00%|    Perform an indirect sort along the given axis using the algorithm specified
  1010|         0|            0|            0|  0.00%|    by the `kind` keyword. It returns an array of indices of the same shape as
  1011|         0|            0|            0|  0.00%|    `a` that index data along the given axis in sorted order.
  1012|         0|            0|            0|  0.00%|
  1013|         0|            0|            0|  0.00%|    Parameters
  1014|         0|            0|            0|  0.00%|    ----------
  1015|         0|            0|            0|  0.00%|    a : array_like
  1016|         0|            0|            0|  0.00%|        Array to sort.
  1017|         0|            0|            0|  0.00%|    axis : int or None, optional
  1018|         0|            0|            0|  0.00%|        Axis along which to sort.  The default is -1 (the last axis). If None,
  1019|         0|            0|            0|  0.00%|        the flattened array is used.
  1020|         0|            0|            0|  0.00%|    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional
  1021|         0|            0|            0|  0.00%|        Sorting algorithm. The default is 'quicksort'. Note that both 'stable'
  1022|         0|            0|            0|  0.00%|        and 'mergesort' use timsort under the covers and, in general, the
  1023|         0|            0|            0|  0.00%|        actual implementation will vary with data type. The 'mergesort' option
  1024|         0|            0|            0|  0.00%|        is retained for backwards compatibility.
  1025|         0|            0|            0|  0.00%|
  1026|         0|            0|            0|  0.00%|        .. versionchanged:: 1.15.0.
  1027|         0|            0|            0|  0.00%|           The 'stable' option was added.
  1028|         0|            0|            0|  0.00%|    order : str or list of str, optional
  1029|         0|            0|            0|  0.00%|        When `a` is an array with fields defined, this argument specifies
  1030|         0|            0|            0|  0.00%|        which fields to compare first, second, etc.  A single field can
  1031|         0|            0|            0|  0.00%|        be specified as a string, and not all fields need be specified,
  1032|         0|            0|            0|  0.00%|        but unspecified fields will still be used, in the order in which
  1033|         0|            0|            0|  0.00%|        they come up in the dtype, to break ties.
  1034|         0|            0|            0|  0.00%|
  1035|         0|            0|            0|  0.00%|    Returns
  1036|         0|            0|            0|  0.00%|    -------
  1037|         0|            0|            0|  0.00%|    index_array : ndarray, int
  1038|         0|            0|            0|  0.00%|        Array of indices that sort `a` along the specified `axis`.
  1039|         0|            0|            0|  0.00%|        If `a` is one-dimensional, ``a[index_array]`` yields a sorted `a`.
  1040|         0|            0|            0|  0.00%|        More generally, ``np.take_along_axis(a, index_array, axis=axis)``
  1041|         0|            0|            0|  0.00%|        always yields the sorted `a`, irrespective of dimensionality.
  1042|         0|            0|            0|  0.00%|
  1043|         0|            0|            0|  0.00%|    See Also
  1044|         0|            0|            0|  0.00%|    --------
  1045|         0|            0|            0|  0.00%|    sort : Describes sorting algorithms used.
  1046|         0|            0|            0|  0.00%|    lexsort : Indirect stable sort with multiple keys.
  1047|         0|            0|            0|  0.00%|    ndarray.sort : Inplace sort.
  1048|         0|            0|            0|  0.00%|    argpartition : Indirect partial sort.
  1049|         0|            0|            0|  0.00%|    take_along_axis : Apply ``index_array`` from argsort
  1050|         0|            0|            0|  0.00%|                      to an array as if by calling sort.
  1051|         0|            0|            0|  0.00%|
  1052|         0|            0|            0|  0.00%|    Notes
  1053|         0|            0|            0|  0.00%|    -----
  1054|         0|            0|            0|  0.00%|    See `sort` for notes on the different sorting algorithms.
  1055|         0|            0|            0|  0.00%|
  1056|         0|            0|            0|  0.00%|    As of NumPy 1.4.0 `argsort` works with real/complex arrays containing
  1057|         0|            0|            0|  0.00%|    nan values. The enhanced sort order is documented in `sort`.
  1058|         0|            0|            0|  0.00%|
  1059|         0|            0|            0|  0.00%|    Examples
  1060|         0|            0|            0|  0.00%|    --------
  1061|         0|            0|            0|  0.00%|    One dimensional array:
  1062|         0|            0|            0|  0.00%|
  1063|         0|            0|            0|  0.00%|    >>> x = np.array([3, 1, 2])
  1064|         0|            0|            0|  0.00%|    >>> np.argsort(x)
  1065|         0|            0|            0|  0.00%|    array([1, 2, 0])
  1066|         0|            0|            0|  0.00%|
  1067|         0|            0|            0|  0.00%|    Two-dimensional array:
  1068|         0|            0|            0|  0.00%|
  1069|         0|            0|            0|  0.00%|    >>> x = np.array([[0, 3], [2, 2]])
  1070|         0|            0|            0|  0.00%|    >>> x
  1071|         0|            0|            0|  0.00%|    array([[0, 3],
  1072|         0|            0|            0|  0.00%|           [2, 2]])
  1073|         0|            0|            0|  0.00%|
  1074|         0|            0|            0|  0.00%|    >>> ind = np.argsort(x, axis=0)  # sorts along first axis (down)
  1075|         0|            0|            0|  0.00%|    >>> ind
  1076|         0|            0|            0|  0.00%|    array([[0, 1],
  1077|         0|            0|            0|  0.00%|           [1, 0]])
  1078|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, ind, axis=0)  # same as np.sort(x, axis=0)
  1079|         0|            0|            0|  0.00%|    array([[0, 2],
  1080|         0|            0|            0|  0.00%|           [2, 3]])
  1081|         0|            0|            0|  0.00%|
  1082|         0|            0|            0|  0.00%|    >>> ind = np.argsort(x, axis=1)  # sorts along last axis (across)
  1083|         0|            0|            0|  0.00%|    >>> ind
  1084|         0|            0|            0|  0.00%|    array([[0, 1],
  1085|         0|            0|            0|  0.00%|           [0, 1]])
  1086|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, ind, axis=1)  # same as np.sort(x, axis=1)
  1087|         0|            0|            0|  0.00%|    array([[0, 3],
  1088|         0|            0|            0|  0.00%|           [2, 2]])
  1089|         0|            0|            0|  0.00%|
  1090|         0|            0|            0|  0.00%|    Indices of the sorted elements of a N-dimensional array:
  1091|         0|            0|            0|  0.00%|
  1092|         0|            0|            0|  0.00%|    >>> ind = np.unravel_index(np.argsort(x, axis=None), x.shape)
  1093|         0|            0|            0|  0.00%|    >>> ind
  1094|         0|            0|            0|  0.00%|    (array([0, 1, 1, 0]), array([0, 0, 1, 1]))
  1095|         0|            0|            0|  0.00%|    >>> x[ind]  # same as np.sort(x, axis=None)
  1096|         0|            0|            0|  0.00%|    array([0, 2, 2, 3])
  1097|         0|            0|            0|  0.00%|
  1098|         0|            0|            0|  0.00%|    Sorting with keys:
  1099|         0|            0|            0|  0.00%|
  1100|         0|            0|            0|  0.00%|    >>> x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')])
  1101|         0|            0|            0|  0.00%|    >>> x
  1102|         0|            0|            0|  0.00%|    array([(1, 0), (0, 1)],
  1103|         0|            0|            0|  0.00%|          dtype=[('x', '<i4'), ('y', '<i4')])
  1104|         0|            0|            0|  0.00%|
  1105|         0|            0|            0|  0.00%|    >>> np.argsort(x, order=('x','y'))
  1106|         0|            0|            0|  0.00%|    array([1, 0])
  1107|         0|            0|            0|  0.00%|
  1108|         0|            0|            0|  0.00%|    >>> np.argsort(x, order=('y','x'))
  1109|         0|            0|            0|  0.00%|    array([0, 1])
  1110|         0|            0|            0|  0.00%|
  1111|         0|            0|            0|  0.00%|    """
  1112|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)
  1113|         0|            0|            0|  0.00%|
  1114|         0|            0|            0|  0.00%|
  1115|         0|            0|            0|  0.00%|def _argmax_dispatcher(a, axis=None, out=None):
  1116|         0|            0|            0|  0.00%|    return (a, out)
  1117|         0|            0|            0|  0.00%|
  1118|         0|            0|            0|  0.00%|
  1119|         0|            0|            0|  0.00%|@array_function_dispatch(_argmax_dispatcher)
  1120|         0|            0|            0|  0.00%|def argmax(a, axis=None, out=None):
  1121|         0|            0|            0|  0.00%|    """
  1122|         0|            0|            0|  0.00%|    Returns the indices of the maximum values along an axis.
  1123|         0|            0|            0|  0.00%|
  1124|         0|            0|            0|  0.00%|    Parameters
  1125|         0|            0|            0|  0.00%|    ----------
  1126|         0|            0|            0|  0.00%|    a : array_like
  1127|         0|            0|            0|  0.00%|        Input array.
  1128|         0|            0|            0|  0.00%|    axis : int, optional
  1129|         0|            0|            0|  0.00%|        By default, the index is into the flattened array, otherwise
  1130|         0|            0|            0|  0.00%|        along the specified axis.
  1131|         0|            0|            0|  0.00%|    out : array, optional
  1132|         0|            0|            0|  0.00%|        If provided, the result will be inserted into this array. It should
  1133|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype.
  1134|         0|            0|            0|  0.00%|
  1135|         0|            0|            0|  0.00%|    Returns
  1136|         0|            0|            0|  0.00%|    -------
  1137|         0|            0|            0|  0.00%|    index_array : ndarray of ints
  1138|         0|            0|            0|  0.00%|        Array of indices into the array. It has the same shape as `a.shape`
  1139|         0|            0|            0|  0.00%|        with the dimension along `axis` removed.
  1140|         0|            0|            0|  0.00%|
  1141|         0|            0|            0|  0.00%|    See Also
  1142|         0|            0|            0|  0.00%|    --------
  1143|         0|            0|            0|  0.00%|    ndarray.argmax, argmin
  1144|         0|            0|            0|  0.00%|    amax : The maximum value along a given axis.
  1145|         0|            0|            0|  0.00%|    unravel_index : Convert a flat index into an index tuple.
  1146|         0|            0|            0|  0.00%|    take_along_axis : Apply ``np.expand_dims(index_array, axis)``
  1147|         0|            0|            0|  0.00%|                      from argmax to an array as if by calling max.
  1148|         0|            0|            0|  0.00%|
  1149|         0|            0|            0|  0.00%|    Notes
  1150|         0|            0|            0|  0.00%|    -----
  1151|         0|            0|            0|  0.00%|    In case of multiple occurrences of the maximum values, the indices
  1152|         0|            0|            0|  0.00%|    corresponding to the first occurrence are returned.
  1153|         0|            0|            0|  0.00%|
  1154|         0|            0|            0|  0.00%|    Examples
  1155|         0|            0|            0|  0.00%|    --------
  1156|         0|            0|            0|  0.00%|    >>> a = np.arange(6).reshape(2,3) + 10
  1157|         0|            0|            0|  0.00%|    >>> a
  1158|         0|            0|            0|  0.00%|    array([[10, 11, 12],
  1159|         0|            0|            0|  0.00%|           [13, 14, 15]])
  1160|         0|            0|            0|  0.00%|    >>> np.argmax(a)
  1161|         0|            0|            0|  0.00%|    5
  1162|         0|            0|            0|  0.00%|    >>> np.argmax(a, axis=0)
  1163|         0|            0|            0|  0.00%|    array([1, 1, 1])
  1164|         0|            0|            0|  0.00%|    >>> np.argmax(a, axis=1)
  1165|         0|            0|            0|  0.00%|    array([2, 2])
  1166|         0|            0|            0|  0.00%|
  1167|         0|            0|            0|  0.00%|    Indexes of the maximal elements of a N-dimensional array:
  1168|         0|            0|            0|  0.00%|
  1169|         0|            0|            0|  0.00%|    >>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)
  1170|         0|            0|            0|  0.00%|    >>> ind
  1171|         0|            0|            0|  0.00%|    (1, 2)
  1172|         0|            0|            0|  0.00%|    >>> a[ind]
  1173|         0|            0|            0|  0.00%|    15
  1174|         0|            0|            0|  0.00%|
  1175|         0|            0|            0|  0.00%|    >>> b = np.arange(6)
  1176|         0|            0|            0|  0.00%|    >>> b[1] = 5
  1177|         0|            0|            0|  0.00%|    >>> b
  1178|         0|            0|            0|  0.00%|    array([0, 5, 2, 3, 4, 5])
  1179|         0|            0|            0|  0.00%|    >>> np.argmax(b)  # Only the first occurrence is returned.
  1180|         0|            0|            0|  0.00%|    1
  1181|         0|            0|            0|  0.00%|
  1182|         0|            0|            0|  0.00%|    >>> x = np.array([[4,2,3], [1,0,3]])
  1183|         0|            0|            0|  0.00%|    >>> index_array = np.argmax(x, axis=-1)
  1184|         0|            0|            0|  0.00%|    >>> # Same as np.max(x, axis=-1, keepdims=True)
  1185|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)
  1186|         0|            0|            0|  0.00%|    array([[4],
  1187|         0|            0|            0|  0.00%|           [3]])
  1188|         0|            0|            0|  0.00%|    >>> # Same as np.max(x, axis=-1)
  1189|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)
  1190|         0|            0|            0|  0.00%|    array([4, 3])
  1191|         0|            0|            0|  0.00%|
  1192|         0|            0|            0|  0.00%|    """
  1193|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argmax', axis=axis, out=out)
  1194|         0|            0|            0|  0.00%|
  1195|         0|            0|            0|  0.00%|
  1196|         0|            0|            0|  0.00%|def _argmin_dispatcher(a, axis=None, out=None):
  1197|         0|            0|            0|  0.00%|    return (a, out)
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|
  1200|         0|            0|            0|  0.00%|@array_function_dispatch(_argmin_dispatcher)
  1201|         0|            0|            0|  0.00%|def argmin(a, axis=None, out=None):
  1202|         0|            0|            0|  0.00%|    """
  1203|         0|            0|            0|  0.00%|    Returns the indices of the minimum values along an axis.
  1204|         0|            0|            0|  0.00%|
  1205|         0|            0|            0|  0.00%|    Parameters
  1206|         0|            0|            0|  0.00%|    ----------
  1207|         0|            0|            0|  0.00%|    a : array_like
  1208|         0|            0|            0|  0.00%|        Input array.
  1209|         0|            0|            0|  0.00%|    axis : int, optional
  1210|         0|            0|            0|  0.00%|        By default, the index is into the flattened array, otherwise
  1211|         0|            0|            0|  0.00%|        along the specified axis.
  1212|         0|            0|            0|  0.00%|    out : array, optional
  1213|         0|            0|            0|  0.00%|        If provided, the result will be inserted into this array. It should
  1214|         0|            0|            0|  0.00%|        be of the appropriate shape and dtype.
  1215|         0|            0|            0|  0.00%|
  1216|         0|            0|            0|  0.00%|    Returns
  1217|         0|            0|            0|  0.00%|    -------
  1218|         0|            0|            0|  0.00%|    index_array : ndarray of ints
  1219|         0|            0|            0|  0.00%|        Array of indices into the array. It has the same shape as `a.shape`
  1220|         0|            0|            0|  0.00%|        with the dimension along `axis` removed.
  1221|         0|            0|            0|  0.00%|
  1222|         0|            0|            0|  0.00%|    See Also
  1223|         0|            0|            0|  0.00%|    --------
  1224|         0|            0|            0|  0.00%|    ndarray.argmin, argmax
  1225|         0|            0|            0|  0.00%|    amin : The minimum value along a given axis.
  1226|         0|            0|            0|  0.00%|    unravel_index : Convert a flat index into an index tuple.
  1227|         0|            0|            0|  0.00%|    take_along_axis : Apply ``np.expand_dims(index_array, axis)``
  1228|         0|            0|            0|  0.00%|                      from argmin to an array as if by calling min.
  1229|         0|            0|            0|  0.00%|
  1230|         0|            0|            0|  0.00%|    Notes
  1231|         0|            0|            0|  0.00%|    -----
  1232|         0|            0|            0|  0.00%|    In case of multiple occurrences of the minimum values, the indices
  1233|         0|            0|            0|  0.00%|    corresponding to the first occurrence are returned.
  1234|         0|            0|            0|  0.00%|
  1235|         0|            0|            0|  0.00%|    Examples
  1236|         0|            0|            0|  0.00%|    --------
  1237|         0|            0|            0|  0.00%|    >>> a = np.arange(6).reshape(2,3) + 10
  1238|         0|            0|            0|  0.00%|    >>> a
  1239|         0|            0|            0|  0.00%|    array([[10, 11, 12],
  1240|         0|            0|            0|  0.00%|           [13, 14, 15]])
  1241|         0|            0|            0|  0.00%|    >>> np.argmin(a)
  1242|         0|            0|            0|  0.00%|    0
  1243|         0|            0|            0|  0.00%|    >>> np.argmin(a, axis=0)
  1244|         0|            0|            0|  0.00%|    array([0, 0, 0])
  1245|         0|            0|            0|  0.00%|    >>> np.argmin(a, axis=1)
  1246|         0|            0|            0|  0.00%|    array([0, 0])
  1247|         0|            0|            0|  0.00%|
  1248|         0|            0|            0|  0.00%|    Indices of the minimum elements of a N-dimensional array:
  1249|         0|            0|            0|  0.00%|
  1250|         0|            0|            0|  0.00%|    >>> ind = np.unravel_index(np.argmin(a, axis=None), a.shape)
  1251|         0|            0|            0|  0.00%|    >>> ind
  1252|         0|            0|            0|  0.00%|    (0, 0)
  1253|         0|            0|            0|  0.00%|    >>> a[ind]
  1254|         0|            0|            0|  0.00%|    10
  1255|         0|            0|            0|  0.00%|
  1256|         0|            0|            0|  0.00%|    >>> b = np.arange(6) + 10
  1257|         0|            0|            0|  0.00%|    >>> b[4] = 10
  1258|         0|            0|            0|  0.00%|    >>> b
  1259|         0|            0|            0|  0.00%|    array([10, 11, 12, 13, 10, 15])
  1260|         0|            0|            0|  0.00%|    >>> np.argmin(b)  # Only the first occurrence is returned.
  1261|         0|            0|            0|  0.00%|    0
  1262|         0|            0|            0|  0.00%|
  1263|         0|            0|            0|  0.00%|    >>> x = np.array([[4,2,3], [1,0,3]])
  1264|         0|            0|            0|  0.00%|    >>> index_array = np.argmin(x, axis=-1)
  1265|         0|            0|            0|  0.00%|    >>> # Same as np.min(x, axis=-1, keepdims=True)
  1266|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)
  1267|         0|            0|            0|  0.00%|    array([[2],
  1268|         0|            0|            0|  0.00%|           [0]])
  1269|         0|            0|            0|  0.00%|    >>> # Same as np.max(x, axis=-1)
  1270|         0|            0|            0|  0.00%|    >>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)
  1271|         0|            0|            0|  0.00%|    array([2, 0])
  1272|         0|            0|            0|  0.00%|
  1273|         0|            0|            0|  0.00%|    """
  1274|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'argmin', axis=axis, out=out)
  1275|         0|            0|            0|  0.00%|
  1276|         0|            0|            0|  0.00%|
  1277|         0|            0|            0|  0.00%|def _searchsorted_dispatcher(a, v, side=None, sorter=None):
  1278|         0|            0|            0|  0.00%|    return (a, v, sorter)
  1279|         0|            0|            0|  0.00%|
  1280|         0|            0|            0|  0.00%|
  1281|         0|            0|            0|  0.00%|@array_function_dispatch(_searchsorted_dispatcher)
  1282|         0|            0|            0|  0.00%|def searchsorted(a, v, side='left', sorter=None):
  1283|         0|            0|            0|  0.00%|    """
  1284|         0|            0|            0|  0.00%|    Find indices where elements should be inserted to maintain order.
  1285|         0|            0|            0|  0.00%|
  1286|         0|            0|            0|  0.00%|    Find the indices into a sorted array `a` such that, if the
  1287|         0|            0|            0|  0.00%|    corresponding elements in `v` were inserted before the indices, the
  1288|         0|            0|            0|  0.00%|    order of `a` would be preserved.
  1289|         0|            0|            0|  0.00%|
  1290|         0|            0|            0|  0.00%|    Assuming that `a` is sorted:
  1291|         0|            0|            0|  0.00%|
  1292|         0|            0|            0|  0.00%|    ======  ============================
  1293|         0|            0|            0|  0.00%|    `side`  returned index `i` satisfies
  1294|         0|            0|            0|  0.00%|    ======  ============================
  1295|         0|            0|            0|  0.00%|    left    ``a[i-1] < v <= a[i]``
  1296|         0|            0|            0|  0.00%|    right   ``a[i-1] <= v < a[i]``
  1297|         0|            0|            0|  0.00%|    ======  ============================
  1298|         0|            0|            0|  0.00%|
  1299|         0|            0|            0|  0.00%|    Parameters
  1300|         0|            0|            0|  0.00%|    ----------
  1301|         0|            0|            0|  0.00%|    a : 1-D array_like
  1302|         0|            0|            0|  0.00%|        Input array. If `sorter` is None, then it must be sorted in
  1303|         0|            0|            0|  0.00%|        ascending order, otherwise `sorter` must be an array of indices
  1304|         0|            0|            0|  0.00%|        that sort it.
  1305|         0|            0|            0|  0.00%|    v : array_like
  1306|         0|            0|            0|  0.00%|        Values to insert into `a`.
  1307|         0|            0|            0|  0.00%|    side : {'left', 'right'}, optional
  1308|         0|            0|            0|  0.00%|        If 'left', the index of the first suitable location found is given.
  1309|         0|            0|            0|  0.00%|        If 'right', return the last such index.  If there is no suitable
  1310|         0|            0|            0|  0.00%|        index, return either 0 or N (where N is the length of `a`).
  1311|         0|            0|            0|  0.00%|    sorter : 1-D array_like, optional
  1312|         0|            0|            0|  0.00%|        Optional array of integer indices that sort array a into ascending
  1313|         0|            0|            0|  0.00%|        order. They are typically the result of argsort.
  1314|         0|            0|            0|  0.00%|
  1315|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  1316|         0|            0|            0|  0.00%|
  1317|         0|            0|            0|  0.00%|    Returns
  1318|         0|            0|            0|  0.00%|    -------
  1319|         0|            0|            0|  0.00%|    indices : array of ints
  1320|         0|            0|            0|  0.00%|        Array of insertion points with the same shape as `v`.
  1321|         0|            0|            0|  0.00%|
  1322|         0|            0|            0|  0.00%|    See Also
  1323|         0|            0|            0|  0.00%|    --------
  1324|         0|            0|            0|  0.00%|    sort : Return a sorted copy of an array.
  1325|         0|            0|            0|  0.00%|    histogram : Produce histogram from 1-D data.
  1326|         0|            0|            0|  0.00%|
  1327|         0|            0|            0|  0.00%|    Notes
  1328|         0|            0|            0|  0.00%|    -----
  1329|         0|            0|            0|  0.00%|    Binary search is used to find the required insertion points.
  1330|         0|            0|            0|  0.00%|
  1331|         0|            0|            0|  0.00%|    As of NumPy 1.4.0 `searchsorted` works with real/complex arrays containing
  1332|         0|            0|            0|  0.00%|    `nan` values. The enhanced sort order is documented in `sort`.
  1333|         0|            0|            0|  0.00%|
  1334|         0|            0|            0|  0.00%|    This function uses the same algorithm as the builtin python `bisect.bisect_left`
  1335|         0|            0|            0|  0.00%|    (``side='left'``) and `bisect.bisect_right` (``side='right'``) functions,
  1336|         0|            0|            0|  0.00%|    which is also vectorized in the `v` argument.
  1337|         0|            0|            0|  0.00%|
  1338|         0|            0|            0|  0.00%|    Examples
  1339|         0|            0|            0|  0.00%|    --------
  1340|         0|            0|            0|  0.00%|    >>> np.searchsorted([1,2,3,4,5], 3)
  1341|         0|            0|            0|  0.00%|    2
  1342|         0|            0|            0|  0.00%|    >>> np.searchsorted([1,2,3,4,5], 3, side='right')
  1343|         0|            0|            0|  0.00%|    3
  1344|         0|            0|            0|  0.00%|    >>> np.searchsorted([1,2,3,4,5], [-10, 10, 2, 3])
  1345|         0|            0|            0|  0.00%|    array([0, 5, 1, 2])
  1346|         0|            0|            0|  0.00%|
  1347|         0|            0|            0|  0.00%|    """
  1348|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)
  1349|         0|            0|            0|  0.00%|
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|def _resize_dispatcher(a, new_shape):
  1352|         0|            0|            0|  0.00%|    return (a,)
  1353|         0|            0|            0|  0.00%|
  1354|         0|            0|            0|  0.00%|
  1355|         0|            0|            0|  0.00%|@array_function_dispatch(_resize_dispatcher)
  1356|         0|            0|            0|  0.00%|def resize(a, new_shape):
  1357|         0|            0|            0|  0.00%|    """
  1358|         0|            0|            0|  0.00%|    Return a new array with the specified shape.
  1359|         0|            0|            0|  0.00%|
  1360|         0|            0|            0|  0.00%|    If the new array is larger than the original array, then the new
  1361|         0|            0|            0|  0.00%|    array is filled with repeated copies of `a`.  Note that this behavior
  1362|         0|            0|            0|  0.00%|    is different from a.resize(new_shape) which fills with zeros instead
  1363|         0|            0|            0|  0.00%|    of repeated copies of `a`.
  1364|         0|            0|            0|  0.00%|
  1365|         0|            0|            0|  0.00%|    Parameters
  1366|         0|            0|            0|  0.00%|    ----------
  1367|         0|            0|            0|  0.00%|    a : array_like
  1368|         0|            0|            0|  0.00%|        Array to be resized.
  1369|         0|            0|            0|  0.00%|
  1370|         0|            0|            0|  0.00%|    new_shape : int or tuple of int
  1371|         0|            0|            0|  0.00%|        Shape of resized array.
  1372|         0|            0|            0|  0.00%|
  1373|         0|            0|            0|  0.00%|    Returns
  1374|         0|            0|            0|  0.00%|    -------
  1375|         0|            0|            0|  0.00%|    reshaped_array : ndarray
  1376|         0|            0|            0|  0.00%|        The new array is formed from the data in the old array, repeated
  1377|         0|            0|            0|  0.00%|        if necessary to fill out the required number of elements.  The
  1378|         0|            0|            0|  0.00%|        data are repeated in the order that they are stored in memory.
  1379|         0|            0|            0|  0.00%|
  1380|         0|            0|            0|  0.00%|    See Also
  1381|         0|            0|            0|  0.00%|    --------
  1382|         0|            0|            0|  0.00%|    np.reshape : Reshape an array without changing the total size.
  1383|         0|            0|            0|  0.00%|    np.pad : Enlarge and pad an array.
  1384|         0|            0|            0|  0.00%|    np.repeat: Repeat elements of an array.
  1385|         0|            0|            0|  0.00%|    ndarray.resize : resize an array in-place.
  1386|         0|            0|            0|  0.00%|
  1387|         0|            0|            0|  0.00%|    Notes
  1388|         0|            0|            0|  0.00%|    -----
  1389|         0|            0|            0|  0.00%|    When the total size of the array does not change `~numpy.reshape` should
  1390|         0|            0|            0|  0.00%|    be used.  In most other cases either indexing (to reduce the size)
  1391|         0|            0|            0|  0.00%|    or padding (to increase the size) may be a more appropriate solution.
  1392|         0|            0|            0|  0.00%|
  1393|         0|            0|            0|  0.00%|    Warning: This functionality does **not** consider axes separately,
  1394|         0|            0|            0|  0.00%|    i.e. it does not apply interpolation/extrapolation.
  1395|         0|            0|            0|  0.00%|    It fills the return array with the required number of elements, taken
  1396|         0|            0|            0|  0.00%|    from `a` as they are laid out in memory, disregarding strides and axes.
  1397|         0|            0|            0|  0.00%|    (This is in case the new shape is smaller. For larger, see above.)
  1398|         0|            0|            0|  0.00%|    This functionality is therefore not suitable to resize images,
  1399|         0|            0|            0|  0.00%|    or data where each axis represents a separate and distinct entity.
  1400|         0|            0|            0|  0.00%|
  1401|         0|            0|            0|  0.00%|    Examples
  1402|         0|            0|            0|  0.00%|    --------
  1403|         0|            0|            0|  0.00%|    >>> a=np.array([[0,1],[2,3]])
  1404|         0|            0|            0|  0.00%|    >>> np.resize(a,(2,3))
  1405|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1406|         0|            0|            0|  0.00%|           [3, 0, 1]])
  1407|         0|            0|            0|  0.00%|    >>> np.resize(a,(1,4))
  1408|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3]])
  1409|         0|            0|            0|  0.00%|    >>> np.resize(a,(2,4))
  1410|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3],
  1411|         0|            0|            0|  0.00%|           [0, 1, 2, 3]])
  1412|         0|            0|            0|  0.00%|
  1413|         0|            0|            0|  0.00%|    """
  1414|         0|            0|            0|  0.00%|    if isinstance(new_shape, (int, nt.integer)):
  1415|         0|            0|            0|  0.00%|        new_shape = (new_shape,)
  1416|         0|            0|            0|  0.00%|
  1417|         0|            0|            0|  0.00%|    a = ravel(a)
  1418|         0|            0|            0|  0.00%|
  1419|         0|            0|            0|  0.00%|    new_size = 1
  1420|         0|            0|            0|  0.00%|    for dim_length in new_shape:
  1421|         0|            0|            0|  0.00%|        new_size *= dim_length
  1422|         0|            0|            0|  0.00%|        if dim_length < 0:
  1423|         0|            0|            0|  0.00%|            raise ValueError('all elements of `new_shape` must be non-negative')
  1424|         0|            0|            0|  0.00%|
  1425|         0|            0|            0|  0.00%|    if a.size == 0 or new_size == 0:
  1426|         0|            0|            0|  0.00%|        # First case must zero fill. The second would have repeats == 0.
  1427|         0|            0|            0|  0.00%|        return np.zeros_like(a, shape=new_shape)
  1428|         0|            0|            0|  0.00%|
  1429|         0|            0|            0|  0.00%|    repeats = -(-new_size // a.size)  # ceil division
  1430|         0|            0|            0|  0.00%|    a = concatenate((a,) * repeats)[:new_size]
  1431|         0|            0|            0|  0.00%|
  1432|         0|            0|            0|  0.00%|    return reshape(a, new_shape)
  1433|         0|            0|            0|  0.00%|
  1434|         0|            0|            0|  0.00%|
  1435|         0|            0|            0|  0.00%|def _squeeze_dispatcher(a, axis=None):
  1436|         0|            0|            0|  0.00%|    return (a,)
  1437|         0|            0|            0|  0.00%|
  1438|         0|            0|            0|  0.00%|
  1439|         0|            0|            0|  0.00%|@array_function_dispatch(_squeeze_dispatcher)
  1440|         0|            0|            0|  0.00%|def squeeze(a, axis=None):
  1441|         0|            0|            0|  0.00%|    """
  1442|         0|            0|            0|  0.00%|    Remove axes of length one from `a`.
  1443|         0|            0|            0|  0.00%|
  1444|         0|            0|            0|  0.00%|    Parameters
  1445|         0|            0|            0|  0.00%|    ----------
  1446|         0|            0|            0|  0.00%|    a : array_like
  1447|         0|            0|            0|  0.00%|        Input data.
  1448|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  1449|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  1450|         0|            0|            0|  0.00%|
  1451|         0|            0|            0|  0.00%|        Selects a subset of the entries of length one in the
  1452|         0|            0|            0|  0.00%|        shape. If an axis is selected with shape entry greater than
  1453|         0|            0|            0|  0.00%|        one, an error is raised.
  1454|         0|            0|            0|  0.00%|
  1455|         0|            0|            0|  0.00%|    Returns
  1456|         0|            0|            0|  0.00%|    -------
  1457|         0|            0|            0|  0.00%|    squeezed : ndarray
  1458|         0|            0|            0|  0.00%|        The input array, but with all or a subset of the
  1459|         0|            0|            0|  0.00%|        dimensions of length 1 removed. This is always `a` itself
  1460|         0|            0|            0|  0.00%|        or a view into `a`. Note that if all axes are squeezed,
  1461|         0|            0|            0|  0.00%|        the result is a 0d array and not a scalar.
  1462|         0|            0|            0|  0.00%|
  1463|         0|            0|            0|  0.00%|    Raises
  1464|         0|            0|            0|  0.00%|    ------
  1465|         0|            0|            0|  0.00%|    ValueError
  1466|         0|            0|            0|  0.00%|        If `axis` is not None, and an axis being squeezed is not of length 1
  1467|         0|            0|            0|  0.00%|
  1468|         0|            0|            0|  0.00%|    See Also
  1469|         0|            0|            0|  0.00%|    --------
  1470|         0|            0|            0|  0.00%|    expand_dims : The inverse operation, adding entries of length one
  1471|         0|            0|            0|  0.00%|    reshape : Insert, remove, and combine dimensions, and resize existing ones
  1472|         0|            0|            0|  0.00%|
  1473|         0|            0|            0|  0.00%|    Examples
  1474|         0|            0|            0|  0.00%|    --------
  1475|         0|            0|            0|  0.00%|    >>> x = np.array([[[0], [1], [2]]])
  1476|         0|            0|            0|  0.00%|    >>> x.shape
  1477|         0|            0|            0|  0.00%|    (1, 3, 1)
  1478|         0|            0|            0|  0.00%|    >>> np.squeeze(x).shape
  1479|         0|            0|            0|  0.00%|    (3,)
  1480|         0|            0|            0|  0.00%|    >>> np.squeeze(x, axis=0).shape
  1481|         0|            0|            0|  0.00%|    (3, 1)
  1482|         0|            0|            0|  0.00%|    >>> np.squeeze(x, axis=1).shape
  1483|         0|            0|            0|  0.00%|    Traceback (most recent call last):
  1484|         0|            0|            0|  0.00%|    ...
  1485|         0|            0|            0|  0.00%|    ValueError: cannot select an axis to squeeze out which has size not equal to one
  1486|         0|            0|            0|  0.00%|    >>> np.squeeze(x, axis=2).shape
  1487|         0|            0|            0|  0.00%|    (1, 3)
  1488|         0|            0|            0|  0.00%|    >>> x = np.array([[1234]])
  1489|         0|            0|            0|  0.00%|    >>> x.shape
  1490|         0|            0|            0|  0.00%|    (1, 1)
  1491|         0|            0|            0|  0.00%|    >>> np.squeeze(x)
  1492|         0|            0|            0|  0.00%|    array(1234)  # 0d array
  1493|         0|            0|            0|  0.00%|    >>> np.squeeze(x).shape
  1494|         0|            0|            0|  0.00%|    ()
  1495|         0|            0|            0|  0.00%|    >>> np.squeeze(x)[()]
  1496|         0|            0|            0|  0.00%|    1234
  1497|         0|            0|            0|  0.00%|
  1498|         0|            0|            0|  0.00%|    """
  1499|         0|            0|            0|  0.00%|    try:
  1500|         0|            0|            0|  0.00%|        squeeze = a.squeeze
  1501|         0|            0|            0|  0.00%|    except AttributeError:
  1502|         0|            0|            0|  0.00%|        return _wrapit(a, 'squeeze', axis=axis)
  1503|         0|            0|            0|  0.00%|    if axis is None:
  1504|         0|            0|            0|  0.00%|        return squeeze()
  1505|         0|            0|            0|  0.00%|    else:
  1506|         0|            0|            0|  0.00%|        return squeeze(axis=axis)
  1507|         0|            0|            0|  0.00%|
  1508|         0|            0|            0|  0.00%|
  1509|         0|            0|            0|  0.00%|def _diagonal_dispatcher(a, offset=None, axis1=None, axis2=None):
  1510|         0|            0|            0|  0.00%|    return (a,)
  1511|         0|            0|            0|  0.00%|
  1512|         0|            0|            0|  0.00%|
  1513|         0|            0|            0|  0.00%|@array_function_dispatch(_diagonal_dispatcher)
  1514|         0|            0|            0|  0.00%|def diagonal(a, offset=0, axis1=0, axis2=1):
  1515|         0|            0|            0|  0.00%|    """
  1516|         0|            0|            0|  0.00%|    Return specified diagonals.
  1517|         0|            0|            0|  0.00%|
  1518|         0|            0|            0|  0.00%|    If `a` is 2-D, returns the diagonal of `a` with the given offset,
  1519|         0|            0|            0|  0.00%|    i.e., the collection of elements of the form ``a[i, i+offset]``.  If
  1520|         0|            0|            0|  0.00%|    `a` has more than two dimensions, then the axes specified by `axis1`
  1521|         0|            0|            0|  0.00%|    and `axis2` are used to determine the 2-D sub-array whose diagonal is
  1522|         0|            0|            0|  0.00%|    returned.  The shape of the resulting array can be determined by
  1523|         0|            0|            0|  0.00%|    removing `axis1` and `axis2` and appending an index to the right equal
  1524|         0|            0|            0|  0.00%|    to the size of the resulting diagonals.
  1525|         0|            0|            0|  0.00%|
  1526|         0|            0|            0|  0.00%|    In versions of NumPy prior to 1.7, this function always returned a new,
  1527|         0|            0|            0|  0.00%|    independent array containing a copy of the values in the diagonal.
  1528|         0|            0|            0|  0.00%|
  1529|         0|            0|            0|  0.00%|    In NumPy 1.7 and 1.8, it continues to return a copy of the diagonal,
  1530|         0|            0|            0|  0.00%|    but depending on this fact is deprecated. Writing to the resulting
  1531|         0|            0|            0|  0.00%|    array continues to work as it used to, but a FutureWarning is issued.
  1532|         0|            0|            0|  0.00%|
  1533|         0|            0|            0|  0.00%|    Starting in NumPy 1.9 it returns a read-only view on the original array.
  1534|         0|            0|            0|  0.00%|    Attempting to write to the resulting array will produce an error.
  1535|         0|            0|            0|  0.00%|
  1536|         0|            0|            0|  0.00%|    In some future release, it will return a read/write view and writing to
  1537|         0|            0|            0|  0.00%|    the returned array will alter your original array.  The returned array
  1538|         0|            0|            0|  0.00%|    will have the same type as the input array.
  1539|         0|            0|            0|  0.00%|
  1540|         0|            0|            0|  0.00%|    If you don't write to the array returned by this function, then you can
  1541|         0|            0|            0|  0.00%|    just ignore all of the above.
  1542|         0|            0|            0|  0.00%|
  1543|         0|            0|            0|  0.00%|    If you depend on the current behavior, then we suggest copying the
  1544|         0|            0|            0|  0.00%|    returned array explicitly, i.e., use ``np.diagonal(a).copy()`` instead
  1545|         0|            0|            0|  0.00%|    of just ``np.diagonal(a)``. This will work with both past and future
  1546|         0|            0|            0|  0.00%|    versions of NumPy.
  1547|         0|            0|            0|  0.00%|
  1548|         0|            0|            0|  0.00%|    Parameters
  1549|         0|            0|            0|  0.00%|    ----------
  1550|         0|            0|            0|  0.00%|    a : array_like
  1551|         0|            0|            0|  0.00%|        Array from which the diagonals are taken.
  1552|         0|            0|            0|  0.00%|    offset : int, optional
  1553|         0|            0|            0|  0.00%|        Offset of the diagonal from the main diagonal.  Can be positive or
  1554|         0|            0|            0|  0.00%|        negative.  Defaults to main diagonal (0).
  1555|         0|            0|            0|  0.00%|    axis1 : int, optional
  1556|         0|            0|            0|  0.00%|        Axis to be used as the first axis of the 2-D sub-arrays from which
  1557|         0|            0|            0|  0.00%|        the diagonals should be taken.  Defaults to first axis (0).
  1558|         0|            0|            0|  0.00%|    axis2 : int, optional
  1559|         0|            0|            0|  0.00%|        Axis to be used as the second axis of the 2-D sub-arrays from
  1560|         0|            0|            0|  0.00%|        which the diagonals should be taken. Defaults to second axis (1).
  1561|         0|            0|            0|  0.00%|
  1562|         0|            0|            0|  0.00%|    Returns
  1563|         0|            0|            0|  0.00%|    -------
  1564|         0|            0|            0|  0.00%|    array_of_diagonals : ndarray
  1565|         0|            0|            0|  0.00%|        If `a` is 2-D, then a 1-D array containing the diagonal and of the
  1566|         0|            0|            0|  0.00%|        same type as `a` is returned unless `a` is a `matrix`, in which case
  1567|         0|            0|            0|  0.00%|        a 1-D array rather than a (2-D) `matrix` is returned in order to
  1568|         0|            0|            0|  0.00%|        maintain backward compatibility.
  1569|         0|            0|            0|  0.00%|
  1570|         0|            0|            0|  0.00%|        If ``a.ndim > 2``, then the dimensions specified by `axis1` and `axis2`
  1571|         0|            0|            0|  0.00%|        are removed, and a new axis inserted at the end corresponding to the
  1572|         0|            0|            0|  0.00%|        diagonal.
  1573|         0|            0|            0|  0.00%|
  1574|         0|            0|            0|  0.00%|    Raises
  1575|         0|            0|            0|  0.00%|    ------
  1576|         0|            0|            0|  0.00%|    ValueError
  1577|         0|            0|            0|  0.00%|        If the dimension of `a` is less than 2.
  1578|         0|            0|            0|  0.00%|
  1579|         0|            0|            0|  0.00%|    See Also
  1580|         0|            0|            0|  0.00%|    --------
  1581|         0|            0|            0|  0.00%|    diag : MATLAB work-a-like for 1-D and 2-D arrays.
  1582|         0|            0|            0|  0.00%|    diagflat : Create diagonal arrays.
  1583|         0|            0|            0|  0.00%|    trace : Sum along diagonals.
  1584|         0|            0|            0|  0.00%|
  1585|         0|            0|            0|  0.00%|    Examples
  1586|         0|            0|            0|  0.00%|    --------
  1587|         0|            0|            0|  0.00%|    >>> a = np.arange(4).reshape(2,2)
  1588|         0|            0|            0|  0.00%|    >>> a
  1589|         0|            0|            0|  0.00%|    array([[0, 1],
  1590|         0|            0|            0|  0.00%|           [2, 3]])
  1591|         0|            0|            0|  0.00%|    >>> a.diagonal()
  1592|         0|            0|            0|  0.00%|    array([0, 3])
  1593|         0|            0|            0|  0.00%|    >>> a.diagonal(1)
  1594|         0|            0|            0|  0.00%|    array([1])
  1595|         0|            0|            0|  0.00%|
  1596|         0|            0|            0|  0.00%|    A 3-D example:
  1597|         0|            0|            0|  0.00%|
  1598|         0|            0|            0|  0.00%|    >>> a = np.arange(8).reshape(2,2,2); a
  1599|         0|            0|            0|  0.00%|    array([[[0, 1],
  1600|         0|            0|            0|  0.00%|            [2, 3]],
  1601|         0|            0|            0|  0.00%|           [[4, 5],
  1602|         0|            0|            0|  0.00%|            [6, 7]]])
  1603|         0|            0|            0|  0.00%|    >>> a.diagonal(0,  # Main diagonals of two arrays created by skipping
  1604|         0|            0|            0|  0.00%|    ...            0,  # across the outer(left)-most axis last and
  1605|         0|            0|            0|  0.00%|    ...            1)  # the "middle" (row) axis first.
  1606|         0|            0|            0|  0.00%|    array([[0, 6],
  1607|         0|            0|            0|  0.00%|           [1, 7]])
  1608|         0|            0|            0|  0.00%|
  1609|         0|            0|            0|  0.00%|    The sub-arrays whose main diagonals we just obtained; note that each
  1610|         0|            0|            0|  0.00%|    corresponds to fixing the right-most (column) axis, and that the
  1611|         0|            0|            0|  0.00%|    diagonals are "packed" in rows.
  1612|         0|            0|            0|  0.00%|
  1613|         0|            0|            0|  0.00%|    >>> a[:,:,0]  # main diagonal is [0 6]
  1614|         0|            0|            0|  0.00%|    array([[0, 2],
  1615|         0|            0|            0|  0.00%|           [4, 6]])
  1616|         0|            0|            0|  0.00%|    >>> a[:,:,1]  # main diagonal is [1 7]
  1617|         0|            0|            0|  0.00%|    array([[1, 3],
  1618|         0|            0|            0|  0.00%|           [5, 7]])
  1619|         0|            0|            0|  0.00%|
  1620|         0|            0|            0|  0.00%|    The anti-diagonal can be obtained by reversing the order of elements
  1621|         0|            0|            0|  0.00%|    using either `numpy.flipud` or `numpy.fliplr`.
  1622|         0|            0|            0|  0.00%|
  1623|         0|            0|            0|  0.00%|    >>> a = np.arange(9).reshape(3, 3)
  1624|         0|            0|            0|  0.00%|    >>> a
  1625|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1626|         0|            0|            0|  0.00%|           [3, 4, 5],
  1627|         0|            0|            0|  0.00%|           [6, 7, 8]])
  1628|         0|            0|            0|  0.00%|    >>> np.fliplr(a).diagonal()  # Horizontal flip
  1629|         0|            0|            0|  0.00%|    array([2, 4, 6])
  1630|         0|            0|            0|  0.00%|    >>> np.flipud(a).diagonal()  # Vertical flip
  1631|         0|            0|            0|  0.00%|    array([6, 4, 2])
  1632|         0|            0|            0|  0.00%|
  1633|         0|            0|            0|  0.00%|    Note that the order in which the diagonal is retrieved varies depending
  1634|         0|            0|            0|  0.00%|    on the flip function.
  1635|         0|            0|            0|  0.00%|    """
  1636|         0|            0|            0|  0.00%|    if isinstance(a, np.matrix):
  1637|         0|            0|            0|  0.00%|        # Make diagonal of matrix 1-D to preserve backward compatibility.
  1638|         0|            0|            0|  0.00%|        return asarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)
  1639|         0|            0|            0|  0.00%|    else:
  1640|         0|            0|            0|  0.00%|        return asanyarray(a).diagonal(offset=offset, axis1=axis1, axis2=axis2)
  1641|         0|            0|            0|  0.00%|
  1642|         0|            0|            0|  0.00%|
  1643|         0|            0|            0|  0.00%|def _trace_dispatcher(
  1644|         0|            0|            0|  0.00%|        a, offset=None, axis1=None, axis2=None, dtype=None, out=None):
  1645|         0|            0|            0|  0.00%|    return (a, out)
  1646|         0|            0|            0|  0.00%|
  1647|         0|            0|            0|  0.00%|
  1648|         0|            0|            0|  0.00%|@array_function_dispatch(_trace_dispatcher)
  1649|         0|            0|            0|  0.00%|def trace(a, offset=0, axis1=0, axis2=1, dtype=None, out=None):
  1650|         0|            0|            0|  0.00%|    """
  1651|         0|            0|            0|  0.00%|    Return the sum along diagonals of the array.
  1652|         0|            0|            0|  0.00%|
  1653|         0|            0|            0|  0.00%|    If `a` is 2-D, the sum along its diagonal with the given offset
  1654|         0|            0|            0|  0.00%|    is returned, i.e., the sum of elements ``a[i,i+offset]`` for all i.
  1655|         0|            0|            0|  0.00%|
  1656|         0|            0|            0|  0.00%|    If `a` has more than two dimensions, then the axes specified by axis1 and
  1657|         0|            0|            0|  0.00%|    axis2 are used to determine the 2-D sub-arrays whose traces are returned.
  1658|         0|            0|            0|  0.00%|    The shape of the resulting array is the same as that of `a` with `axis1`
  1659|         0|            0|            0|  0.00%|    and `axis2` removed.
  1660|         0|            0|            0|  0.00%|
  1661|         0|            0|            0|  0.00%|    Parameters
  1662|         0|            0|            0|  0.00%|    ----------
  1663|         0|            0|            0|  0.00%|    a : array_like
  1664|         0|            0|            0|  0.00%|        Input array, from which the diagonals are taken.
  1665|         0|            0|            0|  0.00%|    offset : int, optional
  1666|         0|            0|            0|  0.00%|        Offset of the diagonal from the main diagonal. Can be both positive
  1667|         0|            0|            0|  0.00%|        and negative. Defaults to 0.
  1668|         0|            0|            0|  0.00%|    axis1, axis2 : int, optional
  1669|         0|            0|            0|  0.00%|        Axes to be used as the first and second axis of the 2-D sub-arrays
  1670|         0|            0|            0|  0.00%|        from which the diagonals should be taken. Defaults are the first two
  1671|         0|            0|            0|  0.00%|        axes of `a`.
  1672|         0|            0|            0|  0.00%|    dtype : dtype, optional
  1673|         0|            0|            0|  0.00%|        Determines the data-type of the returned array and of the accumulator
  1674|         0|            0|            0|  0.00%|        where the elements are summed. If dtype has the value None and `a` is
  1675|         0|            0|            0|  0.00%|        of integer type of precision less than the default integer
  1676|         0|            0|            0|  0.00%|        precision, then the default integer precision is used. Otherwise,
  1677|         0|            0|            0|  0.00%|        the precision is the same as that of `a`.
  1678|         0|            0|            0|  0.00%|    out : ndarray, optional
  1679|         0|            0|            0|  0.00%|        Array into which the output is placed. Its type is preserved and
  1680|         0|            0|            0|  0.00%|        it must be of the right shape to hold the output.
  1681|         0|            0|            0|  0.00%|
  1682|         0|            0|            0|  0.00%|    Returns
  1683|         0|            0|            0|  0.00%|    -------
  1684|         0|            0|            0|  0.00%|    sum_along_diagonals : ndarray
  1685|         0|            0|            0|  0.00%|        If `a` is 2-D, the sum along the diagonal is returned.  If `a` has
  1686|         0|            0|            0|  0.00%|        larger dimensions, then an array of sums along diagonals is returned.
  1687|         0|            0|            0|  0.00%|
  1688|         0|            0|            0|  0.00%|    See Also
  1689|         0|            0|            0|  0.00%|    --------
  1690|         0|            0|            0|  0.00%|    diag, diagonal, diagflat
  1691|         0|            0|            0|  0.00%|
  1692|         0|            0|            0|  0.00%|    Examples
  1693|         0|            0|            0|  0.00%|    --------
  1694|         0|            0|            0|  0.00%|    >>> np.trace(np.eye(3))
  1695|         0|            0|            0|  0.00%|    3.0
  1696|         0|            0|            0|  0.00%|    >>> a = np.arange(8).reshape((2,2,2))
  1697|         0|            0|            0|  0.00%|    >>> np.trace(a)
  1698|         0|            0|            0|  0.00%|    array([6, 8])
  1699|         0|            0|            0|  0.00%|
  1700|         0|            0|            0|  0.00%|    >>> a = np.arange(24).reshape((2,2,2,3))
  1701|         0|            0|            0|  0.00%|    >>> np.trace(a).shape
  1702|         0|            0|            0|  0.00%|    (2, 3)
  1703|         0|            0|            0|  0.00%|
  1704|         0|            0|            0|  0.00%|    """
  1705|         0|            0|            0|  0.00%|    if isinstance(a, np.matrix):
  1706|         0|            0|            0|  0.00%|        # Get trace of matrix via an array to preserve backward compatibility.
  1707|         0|            0|            0|  0.00%|        return asarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)
  1708|         0|            0|            0|  0.00%|    else:
  1709|         0|            0|            0|  0.00%|        return asanyarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)
  1710|         0|            0|            0|  0.00%|
  1711|         0|            0|            0|  0.00%|
  1712|         0|            0|            0|  0.00%|def _ravel_dispatcher(a, order=None):
  1713|         0|            0|            0|  0.00%|    return (a,)
  1714|         0|            0|            0|  0.00%|
  1715|         0|            0|            0|  0.00%|
  1716|         0|            0|            0|  0.00%|@array_function_dispatch(_ravel_dispatcher)
  1717|         0|            0|            0|  0.00%|def ravel(a, order='C'):
  1718|         0|            0|            0|  0.00%|    """Return a contiguous flattened array.
  1719|         0|            0|            0|  0.00%|
  1720|         0|            0|            0|  0.00%|    A 1-D array, containing the elements of the input, is returned.  A copy is
  1721|         0|            0|            0|  0.00%|    made only if needed.
  1722|         0|            0|            0|  0.00%|
  1723|         0|            0|            0|  0.00%|    As of NumPy 1.10, the returned array will have the same type as the input
  1724|         0|            0|            0|  0.00%|    array. (for example, a masked array will be returned for a masked array
  1725|         0|            0|            0|  0.00%|    input)
  1726|         0|            0|            0|  0.00%|
  1727|         0|            0|            0|  0.00%|    Parameters
  1728|         0|            0|            0|  0.00%|    ----------
  1729|         0|            0|            0|  0.00%|    a : array_like
  1730|         0|            0|            0|  0.00%|        Input array.  The elements in `a` are read in the order specified by
  1731|         0|            0|            0|  0.00%|        `order`, and packed as a 1-D array.
  1732|         0|            0|            0|  0.00%|    order : {'C','F', 'A', 'K'}, optional
  1733|         0|            0|            0|  0.00%|
  1734|         0|            0|            0|  0.00%|        The elements of `a` are read using this index order. 'C' means
  1735|         0|            0|            0|  0.00%|        to index the elements in row-major, C-style order,
  1736|         0|            0|            0|  0.00%|        with the last axis index changing fastest, back to the first
  1737|         0|            0|            0|  0.00%|        axis index changing slowest.  'F' means to index the elements
  1738|         0|            0|            0|  0.00%|        in column-major, Fortran-style order, with the
  1739|         0|            0|            0|  0.00%|        first index changing fastest, and the last index changing
  1740|         0|            0|            0|  0.00%|        slowest. Note that the 'C' and 'F' options take no account of
  1741|         0|            0|            0|  0.00%|        the memory layout of the underlying array, and only refer to
  1742|         0|            0|            0|  0.00%|        the order of axis indexing.  'A' means to read the elements in
  1743|         0|            0|            0|  0.00%|        Fortran-like index order if `a` is Fortran *contiguous* in
  1744|         0|            0|            0|  0.00%|        memory, C-like order otherwise.  'K' means to read the
  1745|         0|            0|            0|  0.00%|        elements in the order they occur in memory, except for
  1746|         0|            0|            0|  0.00%|        reversing the data when strides are negative.  By default, 'C'
  1747|         0|            0|            0|  0.00%|        index order is used.
  1748|         0|            0|            0|  0.00%|
  1749|         0|            0|            0|  0.00%|    Returns
  1750|         0|            0|            0|  0.00%|    -------
  1751|         0|            0|            0|  0.00%|    y : array_like
  1752|         0|            0|            0|  0.00%|        y is an array of the same subtype as `a`, with shape ``(a.size,)``.
  1753|         0|            0|            0|  0.00%|        Note that matrices are special cased for backward compatibility, if `a`
  1754|         0|            0|            0|  0.00%|        is a matrix, then y is a 1-D ndarray.
  1755|         0|            0|            0|  0.00%|
  1756|         0|            0|            0|  0.00%|    See Also
  1757|         0|            0|            0|  0.00%|    --------
  1758|         0|            0|            0|  0.00%|    ndarray.flat : 1-D iterator over an array.
  1759|         0|            0|            0|  0.00%|    ndarray.flatten : 1-D array copy of the elements of an array
  1760|         0|            0|            0|  0.00%|                      in row-major order.
  1761|         0|            0|            0|  0.00%|    ndarray.reshape : Change the shape of an array without changing its data.
  1762|         0|            0|            0|  0.00%|
  1763|         0|            0|            0|  0.00%|    Notes
  1764|         0|            0|            0|  0.00%|    -----
  1765|         0|            0|            0|  0.00%|    In row-major, C-style order, in two dimensions, the row index
  1766|         0|            0|            0|  0.00%|    varies the slowest, and the column index the quickest.  This can
  1767|         0|            0|            0|  0.00%|    be generalized to multiple dimensions, where row-major order
  1768|         0|            0|            0|  0.00%|    implies that the index along the first axis varies slowest, and
  1769|         0|            0|            0|  0.00%|    the index along the last quickest.  The opposite holds for
  1770|         0|            0|            0|  0.00%|    column-major, Fortran-style index ordering.
  1771|         0|            0|            0|  0.00%|
  1772|         0|            0|            0|  0.00%|    When a view is desired in as many cases as possible, ``arr.reshape(-1)``
  1773|         0|            0|            0|  0.00%|    may be preferable.
  1774|         0|            0|            0|  0.00%|
  1775|         0|            0|            0|  0.00%|    Examples
  1776|         0|            0|            0|  0.00%|    --------
  1777|         0|            0|            0|  0.00%|    It is equivalent to ``reshape(-1, order=order)``.
  1778|         0|            0|            0|  0.00%|
  1779|         0|            0|            0|  0.00%|    >>> x = np.array([[1, 2, 3], [4, 5, 6]])
  1780|         0|            0|            0|  0.00%|    >>> np.ravel(x)
  1781|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
  1782|         0|            0|            0|  0.00%|
  1783|         0|            0|            0|  0.00%|    >>> x.reshape(-1)
  1784|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
  1785|         0|            0|            0|  0.00%|
  1786|         0|            0|            0|  0.00%|    >>> np.ravel(x, order='F')
  1787|         0|            0|            0|  0.00%|    array([1, 4, 2, 5, 3, 6])
  1788|         0|            0|            0|  0.00%|
  1789|         0|            0|            0|  0.00%|    When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:
  1790|         0|            0|            0|  0.00%|
  1791|         0|            0|            0|  0.00%|    >>> np.ravel(x.T)
  1792|         0|            0|            0|  0.00%|    array([1, 4, 2, 5, 3, 6])
  1793|         0|            0|            0|  0.00%|    >>> np.ravel(x.T, order='A')
  1794|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
  1795|         0|            0|            0|  0.00%|
  1796|         0|            0|            0|  0.00%|    When ``order`` is 'K', it will preserve orderings that are neither 'C'
  1797|         0|            0|            0|  0.00%|    nor 'F', but won't reverse axes:
  1798|         0|            0|            0|  0.00%|
  1799|         0|            0|            0|  0.00%|    >>> a = np.arange(3)[::-1]; a
  1800|         0|            0|            0|  0.00%|    array([2, 1, 0])
  1801|         0|            0|            0|  0.00%|    >>> a.ravel(order='C')
  1802|         0|            0|            0|  0.00%|    array([2, 1, 0])
  1803|         0|            0|            0|  0.00%|    >>> a.ravel(order='K')
  1804|         0|            0|            0|  0.00%|    array([2, 1, 0])
  1805|         0|            0|            0|  0.00%|
  1806|         0|            0|            0|  0.00%|    >>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a
  1807|         0|            0|            0|  0.00%|    array([[[ 0,  2,  4],
  1808|         0|            0|            0|  0.00%|            [ 1,  3,  5]],
  1809|         0|            0|            0|  0.00%|           [[ 6,  8, 10],
  1810|         0|            0|            0|  0.00%|            [ 7,  9, 11]]])
  1811|         0|            0|            0|  0.00%|    >>> a.ravel(order='C')
  1812|         0|            0|            0|  0.00%|    array([ 0,  2,  4,  1,  3,  5,  6,  8, 10,  7,  9, 11])
  1813|         0|            0|            0|  0.00%|    >>> a.ravel(order='K')
  1814|         0|            0|            0|  0.00%|    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
  1815|         0|            0|            0|  0.00%|
  1816|         0|            0|            0|  0.00%|    """
  1817|         0|            0|            0|  0.00%|    if isinstance(a, np.matrix):
  1818|         0|            0|            0|  0.00%|        return asarray(a).ravel(order=order)
  1819|         0|            0|            0|  0.00%|    else:
  1820|         0|            0|            0|  0.00%|        return asanyarray(a).ravel(order=order)
  1821|         0|            0|            0|  0.00%|
  1822|         0|            0|            0|  0.00%|
  1823|         0|            0|            0|  0.00%|def _nonzero_dispatcher(a):
  1824|         0|            0|            0|  0.00%|    return (a,)
  1825|         0|            0|            0|  0.00%|
  1826|         0|            0|            0|  0.00%|
  1827|         0|            0|            0|  0.00%|@array_function_dispatch(_nonzero_dispatcher)
  1828|         0|            0|            0|  0.00%|def nonzero(a):
  1829|         0|            0|            0|  0.00%|    """
  1830|         0|            0|            0|  0.00%|    Return the indices of the elements that are non-zero.
  1831|         0|            0|            0|  0.00%|
  1832|         0|            0|            0|  0.00%|    Returns a tuple of arrays, one for each dimension of `a`,
  1833|         0|            0|            0|  0.00%|    containing the indices of the non-zero elements in that
  1834|         0|            0|            0|  0.00%|    dimension. The values in `a` are always tested and returned in
  1835|         0|            0|            0|  0.00%|    row-major, C-style order.
  1836|         0|            0|            0|  0.00%|
  1837|         0|            0|            0|  0.00%|    To group the indices by element, rather than dimension, use `argwhere`,
  1838|         0|            0|            0|  0.00%|    which returns a row for each non-zero element.
  1839|         0|            0|            0|  0.00%|
  1840|         0|            0|            0|  0.00%|    .. note::
  1841|         0|            0|            0|  0.00%|
  1842|         0|            0|            0|  0.00%|       When called on a zero-d array or scalar, ``nonzero(a)`` is treated
  1843|         0|            0|            0|  0.00%|       as ``nonzero(atleast_1d(a))``.
  1844|         0|            0|            0|  0.00%|
  1845|         0|            0|            0|  0.00%|       .. deprecated:: 1.17.0
  1846|         0|            0|            0|  0.00%|
  1847|         0|            0|            0|  0.00%|          Use `atleast_1d` explicitly if this behavior is deliberate.
  1848|         0|            0|            0|  0.00%|
  1849|         0|            0|            0|  0.00%|    Parameters
  1850|         0|            0|            0|  0.00%|    ----------
  1851|         0|            0|            0|  0.00%|    a : array_like
  1852|         0|            0|            0|  0.00%|        Input array.
  1853|         0|            0|            0|  0.00%|
  1854|         0|            0|            0|  0.00%|    Returns
  1855|         0|            0|            0|  0.00%|    -------
  1856|         0|            0|            0|  0.00%|    tuple_of_arrays : tuple
  1857|         0|            0|            0|  0.00%|        Indices of elements that are non-zero.
  1858|         0|            0|            0|  0.00%|
  1859|         0|            0|            0|  0.00%|    See Also
  1860|         0|            0|            0|  0.00%|    --------
  1861|         0|            0|            0|  0.00%|    flatnonzero :
  1862|         0|            0|            0|  0.00%|        Return indices that are non-zero in the flattened version of the input
  1863|         0|            0|            0|  0.00%|        array.
  1864|         0|            0|            0|  0.00%|    ndarray.nonzero :
  1865|         0|            0|            0|  0.00%|        Equivalent ndarray method.
  1866|         0|            0|            0|  0.00%|    count_nonzero :
  1867|         0|            0|            0|  0.00%|        Counts the number of non-zero elements in the input array.
  1868|         0|            0|            0|  0.00%|
  1869|         0|            0|            0|  0.00%|    Notes
  1870|         0|            0|            0|  0.00%|    -----
  1871|         0|            0|            0|  0.00%|    While the nonzero values can be obtained with ``a[nonzero(a)]``, it is
  1872|         0|            0|            0|  0.00%|    recommended to use ``x[x.astype(bool)]`` or ``x[x != 0]`` instead, which
  1873|         0|            0|            0|  0.00%|    will correctly handle 0-d arrays.
  1874|         0|            0|            0|  0.00%|
  1875|         0|            0|            0|  0.00%|    Examples
  1876|         0|            0|            0|  0.00%|    --------
  1877|         0|            0|            0|  0.00%|    >>> x = np.array([[3, 0, 0], [0, 4, 0], [5, 6, 0]])
  1878|         0|            0|            0|  0.00%|    >>> x
  1879|         0|            0|            0|  0.00%|    array([[3, 0, 0],
  1880|         0|            0|            0|  0.00%|           [0, 4, 0],
  1881|         0|            0|            0|  0.00%|           [5, 6, 0]])
  1882|         0|            0|            0|  0.00%|    >>> np.nonzero(x)
  1883|         0|            0|            0|  0.00%|    (array([0, 1, 2, 2]), array([0, 1, 0, 1]))
  1884|         0|            0|            0|  0.00%|
  1885|         0|            0|            0|  0.00%|    >>> x[np.nonzero(x)]
  1886|         0|            0|            0|  0.00%|    array([3, 4, 5, 6])
  1887|         0|            0|            0|  0.00%|    >>> np.transpose(np.nonzero(x))
  1888|         0|            0|            0|  0.00%|    array([[0, 0],
  1889|         0|            0|            0|  0.00%|           [1, 1],
  1890|         0|            0|            0|  0.00%|           [2, 0],
  1891|         0|            0|            0|  0.00%|           [2, 1]])
  1892|         0|            0|            0|  0.00%|
  1893|         0|            0|            0|  0.00%|    A common use for ``nonzero`` is to find the indices of an array, where
  1894|         0|            0|            0|  0.00%|    a condition is True.  Given an array `a`, the condition `a` > 3 is a
  1895|         0|            0|            0|  0.00%|    boolean array and since False is interpreted as 0, np.nonzero(a > 3)
  1896|         0|            0|            0|  0.00%|    yields the indices of the `a` where the condition is true.
  1897|         0|            0|            0|  0.00%|
  1898|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
  1899|         0|            0|            0|  0.00%|    >>> a > 3
  1900|         0|            0|            0|  0.00%|    array([[False, False, False],
  1901|         0|            0|            0|  0.00%|           [ True,  True,  True],
  1902|         0|            0|            0|  0.00%|           [ True,  True,  True]])
  1903|         0|            0|            0|  0.00%|    >>> np.nonzero(a > 3)
  1904|         0|            0|            0|  0.00%|    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))
  1905|         0|            0|            0|  0.00%|
  1906|         0|            0|            0|  0.00%|    Using this result to index `a` is equivalent to using the mask directly:
  1907|         0|            0|            0|  0.00%|
  1908|         0|            0|            0|  0.00%|    >>> a[np.nonzero(a > 3)]
  1909|         0|            0|            0|  0.00%|    array([4, 5, 6, 7, 8, 9])
  1910|         0|            0|            0|  0.00%|    >>> a[a > 3]  # prefer this spelling
  1911|         0|            0|            0|  0.00%|    array([4, 5, 6, 7, 8, 9])
  1912|         0|            0|            0|  0.00%|
  1913|         0|            0|            0|  0.00%|    ``nonzero`` can also be called as a method of the array.
  1914|         0|            0|            0|  0.00%|
  1915|         0|            0|            0|  0.00%|    >>> (a > 3).nonzero()
  1916|         0|            0|            0|  0.00%|    (array([1, 1, 1, 2, 2, 2]), array([0, 1, 2, 0, 1, 2]))
  1917|         0|            0|            0|  0.00%|
  1918|         0|            0|            0|  0.00%|    """
  1919|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'nonzero')
  1920|         0|            0|            0|  0.00%|
  1921|         0|            0|            0|  0.00%|
  1922|         0|            0|            0|  0.00%|def _shape_dispatcher(a):
  1923|         0|            0|            0|  0.00%|    return (a,)
  1924|         0|            0|            0|  0.00%|
  1925|         0|            0|            0|  0.00%|
  1926|         0|            0|            0|  0.00%|@array_function_dispatch(_shape_dispatcher)
  1927|         0|            0|            0|  0.00%|def shape(a):
  1928|         0|            0|            0|  0.00%|    """
  1929|         0|            0|            0|  0.00%|    Return the shape of an array.
  1930|         0|            0|            0|  0.00%|
  1931|         0|            0|            0|  0.00%|    Parameters
  1932|         0|            0|            0|  0.00%|    ----------
  1933|         0|            0|            0|  0.00%|    a : array_like
  1934|         0|            0|            0|  0.00%|        Input array.
  1935|         0|            0|            0|  0.00%|
  1936|         0|            0|            0|  0.00%|    Returns
  1937|         0|            0|            0|  0.00%|    -------
  1938|         0|            0|            0|  0.00%|    shape : tuple of ints
  1939|         0|            0|            0|  0.00%|        The elements of the shape tuple give the lengths of the
  1940|         0|            0|            0|  0.00%|        corresponding array dimensions.
  1941|         0|            0|            0|  0.00%|
  1942|         0|            0|            0|  0.00%|    See Also
  1943|         0|            0|            0|  0.00%|    --------
  1944|         0|            0|            0|  0.00%|    len
  1945|         0|            0|            0|  0.00%|    ndarray.shape : Equivalent array method.
  1946|         0|            0|            0|  0.00%|
  1947|         0|            0|            0|  0.00%|    Examples
  1948|         0|            0|            0|  0.00%|    --------
  1949|         0|            0|            0|  0.00%|    >>> np.shape(np.eye(3))
  1950|         0|            0|            0|  0.00%|    (3, 3)
  1951|         0|            0|            0|  0.00%|    >>> np.shape([[1, 2]])
  1952|         0|            0|            0|  0.00%|    (1, 2)
  1953|         0|            0|            0|  0.00%|    >>> np.shape([0])
  1954|         0|            0|            0|  0.00%|    (1,)
  1955|         0|            0|            0|  0.00%|    >>> np.shape(0)
  1956|         0|            0|            0|  0.00%|    ()
  1957|         0|            0|            0|  0.00%|
  1958|         0|            0|            0|  0.00%|    >>> a = np.array([(1, 2), (3, 4)], dtype=[('x', 'i4'), ('y', 'i4')])
  1959|         0|            0|            0|  0.00%|    >>> np.shape(a)
  1960|         0|            0|            0|  0.00%|    (2,)
  1961|         0|            0|            0|  0.00%|    >>> a.shape
  1962|         0|            0|            0|  0.00%|    (2,)
  1963|         0|            0|            0|  0.00%|
  1964|         0|            0|            0|  0.00%|    """
  1965|         0|            0|            0|  0.00%|    try:
  1966|         0|            0|            0|  0.00%|        result = a.shape
  1967|         0|            0|            0|  0.00%|    except AttributeError:
  1968|         0|            0|            0|  0.00%|        result = asarray(a).shape
  1969|         0|            0|            0|  0.00%|    return result
  1970|         0|            0|            0|  0.00%|
  1971|         0|            0|            0|  0.00%|
  1972|         0|            0|            0|  0.00%|def _compress_dispatcher(condition, a, axis=None, out=None):
  1973|         0|            0|            0|  0.00%|    return (condition, a, out)
  1974|         0|            0|            0|  0.00%|
  1975|         0|            0|            0|  0.00%|
  1976|         0|            0|            0|  0.00%|@array_function_dispatch(_compress_dispatcher)
  1977|         0|            0|            0|  0.00%|def compress(condition, a, axis=None, out=None):
  1978|         0|            0|            0|  0.00%|    """
  1979|         0|            0|            0|  0.00%|    Return selected slices of an array along given axis.
  1980|         0|            0|            0|  0.00%|
  1981|         0|            0|            0|  0.00%|    When working along a given axis, a slice along that axis is returned in
  1982|         0|            0|            0|  0.00%|    `output` for each index where `condition` evaluates to True. When
  1983|         0|            0|            0|  0.00%|    working on a 1-D array, `compress` is equivalent to `extract`.
  1984|         0|            0|            0|  0.00%|
  1985|         0|            0|            0|  0.00%|    Parameters
  1986|         0|            0|            0|  0.00%|    ----------
  1987|         0|            0|            0|  0.00%|    condition : 1-D array of bools
  1988|         0|            0|            0|  0.00%|        Array that selects which entries to return. If len(condition)
  1989|         0|            0|            0|  0.00%|        is less than the size of `a` along the given axis, then output is
  1990|         0|            0|            0|  0.00%|        truncated to the length of the condition array.
  1991|         0|            0|            0|  0.00%|    a : array_like
  1992|         0|            0|            0|  0.00%|        Array from which to extract a part.
  1993|         0|            0|            0|  0.00%|    axis : int, optional
  1994|         0|            0|            0|  0.00%|        Axis along which to take slices. If None (default), work on the
  1995|         0|            0|            0|  0.00%|        flattened array.
  1996|         0|            0|            0|  0.00%|    out : ndarray, optional
  1997|         0|            0|            0|  0.00%|        Output array.  Its type is preserved and it must be of the right
  1998|         0|            0|            0|  0.00%|        shape to hold the output.
  1999|         0|            0|            0|  0.00%|
  2000|         0|            0|            0|  0.00%|    Returns
  2001|         0|            0|            0|  0.00%|    -------
  2002|         0|            0|            0|  0.00%|    compressed_array : ndarray
  2003|         0|            0|            0|  0.00%|        A copy of `a` without the slices along axis for which `condition`
  2004|         0|            0|            0|  0.00%|        is false.
  2005|         0|            0|            0|  0.00%|
  2006|         0|            0|            0|  0.00%|    See Also
  2007|         0|            0|            0|  0.00%|    --------
  2008|         0|            0|            0|  0.00%|    take, choose, diag, diagonal, select
  2009|         0|            0|            0|  0.00%|    ndarray.compress : Equivalent method in ndarray
  2010|         0|            0|            0|  0.00%|    extract: Equivalent method when working on 1-D arrays
  2011|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  2012|         0|            0|            0|  0.00%|
  2013|         0|            0|            0|  0.00%|    Examples
  2014|         0|            0|            0|  0.00%|    --------
  2015|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4], [5, 6]])
  2016|         0|            0|            0|  0.00%|    >>> a
  2017|         0|            0|            0|  0.00%|    array([[1, 2],
  2018|         0|            0|            0|  0.00%|           [3, 4],
  2019|         0|            0|            0|  0.00%|           [5, 6]])
  2020|         0|            0|            0|  0.00%|    >>> np.compress([0, 1], a, axis=0)
  2021|         0|            0|            0|  0.00%|    array([[3, 4]])
  2022|         0|            0|            0|  0.00%|    >>> np.compress([False, True, True], a, axis=0)
  2023|         0|            0|            0|  0.00%|    array([[3, 4],
  2024|         0|            0|            0|  0.00%|           [5, 6]])
  2025|         0|            0|            0|  0.00%|    >>> np.compress([False, True], a, axis=1)
  2026|         0|            0|            0|  0.00%|    array([[2],
  2027|         0|            0|            0|  0.00%|           [4],
  2028|         0|            0|            0|  0.00%|           [6]])
  2029|         0|            0|            0|  0.00%|
  2030|         0|            0|            0|  0.00%|    Working on the flattened array does not return slices along an axis but
  2031|         0|            0|            0|  0.00%|    selects elements.
  2032|         0|            0|            0|  0.00%|
  2033|         0|            0|            0|  0.00%|    >>> np.compress([False, True], a)
  2034|         0|            0|            0|  0.00%|    array([2])
  2035|         0|            0|            0|  0.00%|
  2036|         0|            0|            0|  0.00%|    """
  2037|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'compress', condition, axis=axis, out=out)
  2038|         0|            0|            0|  0.00%|
  2039|         0|            0|            0|  0.00%|
  2040|         1|   2.6226e-06|   2.6226e-06|  0.00%|def _clip_dispatcher(a, a_min, a_max, out=None, **kwargs):
  2041|         1|  5.24521e-06|  5.24521e-06|  0.00%|    return (a, a_min, a_max)
  2042|         0|            0|            0|  0.00%|
  2043|         0|            0|            0|  0.00%|
  2044|         1|  3.09944e-06|  3.09944e-06|  0.00%|@array_function_dispatch(_clip_dispatcher)
  2045|         0|            0|            0|  0.00%|def clip(a, a_min, a_max, out=None, **kwargs):
  2046|         0|            0|            0|  0.00%|    """
  2047|         0|            0|            0|  0.00%|    Clip (limit) the values in an array.
  2048|         0|            0|            0|  0.00%|
  2049|         0|            0|            0|  0.00%|    Given an interval, values outside the interval are clipped to
  2050|         0|            0|            0|  0.00%|    the interval edges.  For example, if an interval of ``[0, 1]``
  2051|         0|            0|            0|  0.00%|    is specified, values smaller than 0 become 0, and values larger
  2052|         0|            0|            0|  0.00%|    than 1 become 1.
  2053|         0|            0|            0|  0.00%|
  2054|         0|            0|            0|  0.00%|    Equivalent to but faster than ``np.minimum(a_max, np.maximum(a, a_min))``.
  2055|         0|            0|            0|  0.00%|
  2056|         0|            0|            0|  0.00%|    No check is performed to ensure ``a_min < a_max``.
  2057|         0|            0|            0|  0.00%|
  2058|         0|            0|            0|  0.00%|    Parameters
  2059|         0|            0|            0|  0.00%|    ----------
  2060|         0|            0|            0|  0.00%|    a : array_like
  2061|         0|            0|            0|  0.00%|        Array containing elements to clip.
  2062|         0|            0|            0|  0.00%|    a_min, a_max : array_like or None
  2063|         0|            0|            0|  0.00%|        Minimum and maximum value. If ``None``, clipping is not performed on
  2064|         0|            0|            0|  0.00%|        the corresponding edge. Only one of `a_min` and `a_max` may be
  2065|         0|            0|            0|  0.00%|        ``None``. Both are broadcast against `a`.
  2066|         0|            0|            0|  0.00%|    out : ndarray, optional
  2067|         0|            0|            0|  0.00%|        The results will be placed in this array. It may be the input
  2068|         0|            0|            0|  0.00%|        array for in-place clipping.  `out` must be of the right shape
  2069|         0|            0|            0|  0.00%|        to hold the output.  Its type is preserved.
  2070|         0|            0|            0|  0.00%|    **kwargs
  2071|         0|            0|            0|  0.00%|        For other keyword-only arguments, see the
  2072|         0|            0|            0|  0.00%|        :ref:`ufunc docs <ufuncs.kwargs>`.
  2073|         0|            0|            0|  0.00%|
  2074|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2075|         0|            0|            0|  0.00%|
  2076|         0|            0|            0|  0.00%|    Returns
  2077|         0|            0|            0|  0.00%|    -------
  2078|         0|            0|            0|  0.00%|    clipped_array : ndarray
  2079|         0|            0|            0|  0.00%|        An array with the elements of `a`, but where values
  2080|         0|            0|            0|  0.00%|        < `a_min` are replaced with `a_min`, and those > `a_max`
  2081|         0|            0|            0|  0.00%|        with `a_max`.
  2082|         0|            0|            0|  0.00%|
  2083|         0|            0|            0|  0.00%|    See Also
  2084|         0|            0|            0|  0.00%|    --------
  2085|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  2086|         0|            0|            0|  0.00%|
  2087|         0|            0|            0|  0.00%|    Examples
  2088|         0|            0|            0|  0.00%|    --------
  2089|         0|            0|            0|  0.00%|    >>> a = np.arange(10)
  2090|         0|            0|            0|  0.00%|    >>> np.clip(a, 1, 8)
  2091|         0|            0|            0|  0.00%|    array([1, 1, 2, 3, 4, 5, 6, 7, 8, 8])
  2092|         0|            0|            0|  0.00%|    >>> a
  2093|         0|            0|            0|  0.00%|    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
  2094|         0|            0|            0|  0.00%|    >>> np.clip(a, 3, 6, out=a)
  2095|         0|            0|            0|  0.00%|    array([3, 3, 3, 3, 4, 5, 6, 6, 6, 6])
  2096|         0|            0|            0|  0.00%|    >>> a = np.arange(10)
  2097|         0|            0|            0|  0.00%|    >>> a
  2098|         0|            0|            0|  0.00%|    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
  2099|         0|            0|            0|  0.00%|    >>> np.clip(a, [3, 4, 1, 1, 1, 4, 4, 4, 4, 4], 8)
  2100|         0|            0|            0|  0.00%|    array([3, 4, 2, 3, 4, 5, 6, 7, 8, 8])
  2101|         0|            0|            0|  0.00%|
  2102|         0|            0|            0|  0.00%|    """
  2103|         1|  9.05991e-06|  9.05991e-06|  0.00%|    return _wrapfunc(a, 'clip', a_min, a_max, out=out, **kwargs)
(call)|         1|  0.000383854|  0.000383854|  0.04%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:52 _wrapfunc
  2104|         0|            0|            0|  0.00%|
  2105|         0|            0|            0|  0.00%|
  2106|         0|            0|            0|  0.00%|def _sum_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  2107|         0|            0|            0|  0.00%|                    initial=None, where=None):
  2108|         0|            0|            0|  0.00%|    return (a, out)
  2109|         0|            0|            0|  0.00%|
  2110|         0|            0|            0|  0.00%|
  2111|         0|            0|            0|  0.00%|@array_function_dispatch(_sum_dispatcher)
  2112|         0|            0|            0|  0.00%|def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  2113|         0|            0|            0|  0.00%|        initial=np._NoValue, where=np._NoValue):
  2114|         0|            0|            0|  0.00%|    """
  2115|         0|            0|            0|  0.00%|    Sum of array elements over a given axis.
  2116|         0|            0|            0|  0.00%|
  2117|         0|            0|            0|  0.00%|    Parameters
  2118|         0|            0|            0|  0.00%|    ----------
  2119|         0|            0|            0|  0.00%|    a : array_like
  2120|         0|            0|            0|  0.00%|        Elements to sum.
  2121|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2122|         0|            0|            0|  0.00%|        Axis or axes along which a sum is performed.  The default,
  2123|         0|            0|            0|  0.00%|        axis=None, will sum all of the elements of the input array.  If
  2124|         0|            0|            0|  0.00%|        axis is negative it counts from the last to the first axis.
  2125|         0|            0|            0|  0.00%|
  2126|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2127|         0|            0|            0|  0.00%|
  2128|         0|            0|            0|  0.00%|        If axis is a tuple of ints, a sum is performed on all of the axes
  2129|         0|            0|            0|  0.00%|        specified in the tuple instead of a single axis or all the axes as
  2130|         0|            0|            0|  0.00%|        before.
  2131|         0|            0|            0|  0.00%|    dtype : dtype, optional
  2132|         0|            0|            0|  0.00%|        The type of the returned array and of the accumulator in which the
  2133|         0|            0|            0|  0.00%|        elements are summed.  The dtype of `a` is used by default unless `a`
  2134|         0|            0|            0|  0.00%|        has an integer dtype of less precision than the default platform
  2135|         0|            0|            0|  0.00%|        integer.  In that case, if `a` is signed then the platform integer
  2136|         0|            0|            0|  0.00%|        is used while if `a` is unsigned then an unsigned integer of the
  2137|         0|            0|            0|  0.00%|        same precision as the platform integer is used.
  2138|         0|            0|            0|  0.00%|    out : ndarray, optional
  2139|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  2140|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type of the output
  2141|         0|            0|            0|  0.00%|        values will be cast if necessary.
  2142|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2143|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2144|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2145|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2146|         0|            0|            0|  0.00%|
  2147|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2148|         0|            0|            0|  0.00%|        passed through to the `sum` method of sub-classes of
  2149|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2150|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2151|         0|            0|            0|  0.00%|        exceptions will be raised.
  2152|         0|            0|            0|  0.00%|    initial : scalar, optional
  2153|         0|            0|            0|  0.00%|        Starting value for the sum. See `~numpy.ufunc.reduce` for details.
  2154|         0|            0|            0|  0.00%|
  2155|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2156|         0|            0|            0|  0.00%|
  2157|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2158|         0|            0|            0|  0.00%|        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.
  2159|         0|            0|            0|  0.00%|
  2160|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2161|         0|            0|            0|  0.00%|
  2162|         0|            0|            0|  0.00%|    Returns
  2163|         0|            0|            0|  0.00%|    -------
  2164|         0|            0|            0|  0.00%|    sum_along_axis : ndarray
  2165|         0|            0|            0|  0.00%|        An array with the same shape as `a`, with the specified
  2166|         0|            0|            0|  0.00%|        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar
  2167|         0|            0|            0|  0.00%|        is returned.  If an output array is specified, a reference to
  2168|         0|            0|            0|  0.00%|        `out` is returned.
  2169|         0|            0|            0|  0.00%|
  2170|         0|            0|            0|  0.00%|    See Also
  2171|         0|            0|            0|  0.00%|    --------
  2172|         0|            0|            0|  0.00%|    ndarray.sum : Equivalent method.
  2173|         0|            0|            0|  0.00%|
  2174|         0|            0|            0|  0.00%|    add.reduce : Equivalent functionality of `add`.
  2175|         0|            0|            0|  0.00%|
  2176|         0|            0|            0|  0.00%|    cumsum : Cumulative sum of array elements.
  2177|         0|            0|            0|  0.00%|
  2178|         0|            0|            0|  0.00%|    trapz : Integration of array values using the composite trapezoidal rule.
  2179|         0|            0|            0|  0.00%|
  2180|         0|            0|            0|  0.00%|    mean, average
  2181|         0|            0|            0|  0.00%|
  2182|         0|            0|            0|  0.00%|    Notes
  2183|         0|            0|            0|  0.00%|    -----
  2184|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  2185|         0|            0|            0|  0.00%|    raised on overflow.
  2186|         0|            0|            0|  0.00%|
  2187|         0|            0|            0|  0.00%|    The sum of an empty array is the neutral element 0:
  2188|         0|            0|            0|  0.00%|
  2189|         0|            0|            0|  0.00%|    >>> np.sum([])
  2190|         0|            0|            0|  0.00%|    0.0
  2191|         0|            0|            0|  0.00%|
  2192|         0|            0|            0|  0.00%|    For floating point numbers the numerical precision of sum (and
  2193|         0|            0|            0|  0.00%|    ``np.add.reduce``) is in general limited by directly adding each number
  2194|         0|            0|            0|  0.00%|    individually to the result causing rounding errors in every step.
  2195|         0|            0|            0|  0.00%|    However, often numpy will use a  numerically better approach (partial
  2196|         0|            0|            0|  0.00%|    pairwise summation) leading to improved precision in many use-cases.
  2197|         0|            0|            0|  0.00%|    This improved precision is always provided when no ``axis`` is given.
  2198|         0|            0|            0|  0.00%|    When ``axis`` is given, it will depend on which axis is summed.
  2199|         0|            0|            0|  0.00%|    Technically, to provide the best speed possible, the improved precision
  2200|         0|            0|            0|  0.00%|    is only used when the summation is along the fast axis in memory.
  2201|         0|            0|            0|  0.00%|    Note that the exact precision may vary depending on other parameters.
  2202|         0|            0|            0|  0.00%|    In contrast to NumPy, Python's ``math.fsum`` function uses a slower but
  2203|         0|            0|            0|  0.00%|    more precise approach to summation.
  2204|         0|            0|            0|  0.00%|    Especially when summing a large number of lower precision floating point
  2205|         0|            0|            0|  0.00%|    numbers, such as ``float32``, numerical errors can become significant.
  2206|         0|            0|            0|  0.00%|    In such cases it can be advisable to use `dtype="float64"` to use a higher
  2207|         0|            0|            0|  0.00%|    precision for the output.
  2208|         0|            0|            0|  0.00%|
  2209|         0|            0|            0|  0.00%|    Examples
  2210|         0|            0|            0|  0.00%|    --------
  2211|         0|            0|            0|  0.00%|    >>> np.sum([0.5, 1.5])
  2212|         0|            0|            0|  0.00%|    2.0
  2213|         0|            0|            0|  0.00%|    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)
  2214|         0|            0|            0|  0.00%|    1
  2215|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [0, 5]])
  2216|         0|            0|            0|  0.00%|    6
  2217|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [0, 5]], axis=0)
  2218|         0|            0|            0|  0.00%|    array([0, 6])
  2219|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [0, 5]], axis=1)
  2220|         0|            0|            0|  0.00%|    array([1, 5])
  2221|         0|            0|            0|  0.00%|    >>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)
  2222|         0|            0|            0|  0.00%|    array([1., 5.])
  2223|         0|            0|            0|  0.00%|
  2224|         0|            0|            0|  0.00%|    If the accumulator is too small, overflow occurs:
  2225|         0|            0|            0|  0.00%|
  2226|         0|            0|            0|  0.00%|    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)
  2227|         0|            0|            0|  0.00%|    -128
  2228|         0|            0|            0|  0.00%|
  2229|         0|            0|            0|  0.00%|    You can also start the sum with a value other than zero:
  2230|         0|            0|            0|  0.00%|
  2231|         0|            0|            0|  0.00%|    >>> np.sum([10], initial=5)
  2232|         0|            0|            0|  0.00%|    15
  2233|         0|            0|            0|  0.00%|    """
  2234|         0|            0|            0|  0.00%|    if isinstance(a, _gentype):
  2235|         0|            0|            0|  0.00%|        # 2018-02-25, 1.15.0
  2236|         0|            0|            0|  0.00%|        warnings.warn(
  2237|         0|            0|            0|  0.00%|            "Calling np.sum(generator) is deprecated, and in the future will give a different result. "
  2238|         0|            0|            0|  0.00%|            "Use np.sum(np.fromiter(generator)) or the python sum builtin instead.",
  2239|         0|            0|            0|  0.00%|            DeprecationWarning, stacklevel=3)
  2240|         0|            0|            0|  0.00%|
  2241|         0|            0|            0|  0.00%|        res = _sum_(a)
  2242|         0|            0|            0|  0.00%|        if out is not None:
  2243|         0|            0|            0|  0.00%|            out[...] = res
  2244|         0|            0|            0|  0.00%|            return out
  2245|         0|            0|            0|  0.00%|        return res
  2246|         0|            0|            0|  0.00%|
  2247|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
  2248|         0|            0|            0|  0.00%|                          initial=initial, where=where)
  2249|         0|            0|            0|  0.00%|
  2250|         0|            0|            0|  0.00%|
  2251|         0|            0|            0|  0.00%|def _any_dispatcher(a, axis=None, out=None, keepdims=None, *,
  2252|         0|            0|            0|  0.00%|                    where=np._NoValue):
  2253|         0|            0|            0|  0.00%|    return (a, where, out)
  2254|         0|            0|            0|  0.00%|
  2255|         0|            0|            0|  0.00%|
  2256|         0|            0|            0|  0.00%|@array_function_dispatch(_any_dispatcher)
  2257|         0|            0|            0|  0.00%|def any(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):
  2258|         0|            0|            0|  0.00%|    """
  2259|         0|            0|            0|  0.00%|    Test whether any array element along a given axis evaluates to True.
  2260|         0|            0|            0|  0.00%|
  2261|         0|            0|            0|  0.00%|    Returns single boolean unless `axis` is not ``None``
  2262|         0|            0|            0|  0.00%|
  2263|         0|            0|            0|  0.00%|    Parameters
  2264|         0|            0|            0|  0.00%|    ----------
  2265|         0|            0|            0|  0.00%|    a : array_like
  2266|         0|            0|            0|  0.00%|        Input array or object that can be converted to an array.
  2267|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2268|         0|            0|            0|  0.00%|        Axis or axes along which a logical OR reduction is performed.
  2269|         0|            0|            0|  0.00%|        The default (``axis=None``) is to perform a logical OR over all
  2270|         0|            0|            0|  0.00%|        the dimensions of the input array. `axis` may be negative, in
  2271|         0|            0|            0|  0.00%|        which case it counts from the last to the first axis.
  2272|         0|            0|            0|  0.00%|
  2273|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2274|         0|            0|            0|  0.00%|
  2275|         0|            0|            0|  0.00%|        If this is a tuple of ints, a reduction is performed on multiple
  2276|         0|            0|            0|  0.00%|        axes, instead of a single axis or all the axes as before.
  2277|         0|            0|            0|  0.00%|    out : ndarray, optional
  2278|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.  It must have
  2279|         0|            0|            0|  0.00%|        the same shape as the expected output and its type is preserved
  2280|         0|            0|            0|  0.00%|        (e.g., if it is of type float, then it will remain so, returning
  2281|         0|            0|            0|  0.00%|        1.0 for True and 0.0 for False, regardless of the type of `a`).
  2282|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  2283|         0|            0|            0|  0.00%|
  2284|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2285|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2286|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2287|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2288|         0|            0|            0|  0.00%|
  2289|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2290|         0|            0|            0|  0.00%|        passed through to the `any` method of sub-classes of
  2291|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2292|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2293|         0|            0|            0|  0.00%|        exceptions will be raised.
  2294|         0|            0|            0|  0.00%|
  2295|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2296|         0|            0|            0|  0.00%|        Elements to include in checking for any `True` values.
  2297|         0|            0|            0|  0.00%|        See `~numpy.ufunc.reduce` for details.
  2298|         0|            0|            0|  0.00%|
  2299|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  2300|         0|            0|            0|  0.00%|
  2301|         0|            0|            0|  0.00%|    Returns
  2302|         0|            0|            0|  0.00%|    -------
  2303|         0|            0|            0|  0.00%|    any : bool or ndarray
  2304|         0|            0|            0|  0.00%|        A new boolean or `ndarray` is returned unless `out` is specified,
  2305|         0|            0|            0|  0.00%|        in which case a reference to `out` is returned.
  2306|         0|            0|            0|  0.00%|
  2307|         0|            0|            0|  0.00%|    See Also
  2308|         0|            0|            0|  0.00%|    --------
  2309|         0|            0|            0|  0.00%|    ndarray.any : equivalent method
  2310|         0|            0|            0|  0.00%|
  2311|         0|            0|            0|  0.00%|    all : Test whether all elements along a given axis evaluate to True.
  2312|         0|            0|            0|  0.00%|
  2313|         0|            0|            0|  0.00%|    Notes
  2314|         0|            0|            0|  0.00%|    -----
  2315|         0|            0|            0|  0.00%|    Not a Number (NaN), positive infinity and negative infinity evaluate
  2316|         0|            0|            0|  0.00%|    to `True` because these are not equal to zero.
  2317|         0|            0|            0|  0.00%|
  2318|         0|            0|            0|  0.00%|    Examples
  2319|         0|            0|            0|  0.00%|    --------
  2320|         0|            0|            0|  0.00%|    >>> np.any([[True, False], [True, True]])
  2321|         0|            0|            0|  0.00%|    True
  2322|         0|            0|            0|  0.00%|
  2323|         0|            0|            0|  0.00%|    >>> np.any([[True, False], [False, False]], axis=0)
  2324|         0|            0|            0|  0.00%|    array([ True, False])
  2325|         0|            0|            0|  0.00%|
  2326|         0|            0|            0|  0.00%|    >>> np.any([-1, 0, 5])
  2327|         0|            0|            0|  0.00%|    True
  2328|         0|            0|            0|  0.00%|
  2329|         0|            0|            0|  0.00%|    >>> np.any(np.nan)
  2330|         0|            0|            0|  0.00%|    True
  2331|         0|            0|            0|  0.00%|
  2332|         0|            0|            0|  0.00%|    >>> np.any([[True, False], [False, False]], where=[[False], [True]])
  2333|         0|            0|            0|  0.00%|    False
  2334|         0|            0|            0|  0.00%|
  2335|         0|            0|            0|  0.00%|    >>> o=np.array(False)
  2336|         0|            0|            0|  0.00%|    >>> z=np.any([-1, 4, 5], out=o)
  2337|         0|            0|            0|  0.00%|    >>> z, o
  2338|         0|            0|            0|  0.00%|    (array(True), array(True))
  2339|         0|            0|            0|  0.00%|    >>> # Check now that z is a reference to o
  2340|         0|            0|            0|  0.00%|    >>> z is o
  2341|         0|            0|            0|  0.00%|    True
  2342|         0|            0|            0|  0.00%|    >>> id(z), id(o) # identity of z and o              # doctest: +SKIP
  2343|         0|            0|            0|  0.00%|    (191614240, 191614240)
  2344|         0|            0|            0|  0.00%|
  2345|         0|            0|            0|  0.00%|    """
  2346|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.logical_or, 'any', axis, None, out,
  2347|         0|            0|            0|  0.00%|                          keepdims=keepdims, where=where)
  2348|         0|            0|            0|  0.00%|
  2349|         0|            0|            0|  0.00%|
  2350|         2|  3.33786e-06|  1.66893e-06|  0.00%|def _all_dispatcher(a, axis=None, out=None, keepdims=None, *,
  2351|         0|            0|            0|  0.00%|                    where=None):
  2352|         2|   3.8147e-06|  1.90735e-06|  0.00%|    return (a, where, out)
  2353|         0|            0|            0|  0.00%|
  2354|         0|            0|            0|  0.00%|
  2355|         2|  5.00679e-06|   2.5034e-06|  0.00%|@array_function_dispatch(_all_dispatcher)
  2356|         0|            0|            0|  0.00%|def all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):
  2357|         0|            0|            0|  0.00%|    """
  2358|         0|            0|            0|  0.00%|    Test whether all array elements along a given axis evaluate to True.
  2359|         0|            0|            0|  0.00%|
  2360|         0|            0|            0|  0.00%|    Parameters
  2361|         0|            0|            0|  0.00%|    ----------
  2362|         0|            0|            0|  0.00%|    a : array_like
  2363|         0|            0|            0|  0.00%|        Input array or object that can be converted to an array.
  2364|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2365|         0|            0|            0|  0.00%|        Axis or axes along which a logical AND reduction is performed.
  2366|         0|            0|            0|  0.00%|        The default (``axis=None``) is to perform a logical AND over all
  2367|         0|            0|            0|  0.00%|        the dimensions of the input array. `axis` may be negative, in
  2368|         0|            0|            0|  0.00%|        which case it counts from the last to the first axis.
  2369|         0|            0|            0|  0.00%|
  2370|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2371|         0|            0|            0|  0.00%|
  2372|         0|            0|            0|  0.00%|        If this is a tuple of ints, a reduction is performed on multiple
  2373|         0|            0|            0|  0.00%|        axes, instead of a single axis or all the axes as before.
  2374|         0|            0|            0|  0.00%|    out : ndarray, optional
  2375|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.
  2376|         0|            0|            0|  0.00%|        It must have the same shape as the expected output and its
  2377|         0|            0|            0|  0.00%|        type is preserved (e.g., if ``dtype(out)`` is float, the result
  2378|         0|            0|            0|  0.00%|        will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more
  2379|         0|            0|            0|  0.00%|        details.
  2380|         0|            0|            0|  0.00%|
  2381|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2382|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2383|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2384|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2385|         0|            0|            0|  0.00%|
  2386|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2387|         0|            0|            0|  0.00%|        passed through to the `all` method of sub-classes of
  2388|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2389|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2390|         0|            0|            0|  0.00%|        exceptions will be raised.
  2391|         0|            0|            0|  0.00%|
  2392|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2393|         0|            0|            0|  0.00%|        Elements to include in checking for all `True` values.
  2394|         0|            0|            0|  0.00%|        See `~numpy.ufunc.reduce` for details.
  2395|         0|            0|            0|  0.00%|
  2396|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  2397|         0|            0|            0|  0.00%|
  2398|         0|            0|            0|  0.00%|    Returns
  2399|         0|            0|            0|  0.00%|    -------
  2400|         0|            0|            0|  0.00%|    all : ndarray, bool
  2401|         0|            0|            0|  0.00%|        A new boolean or array is returned unless `out` is specified,
  2402|         0|            0|            0|  0.00%|        in which case a reference to `out` is returned.
  2403|         0|            0|            0|  0.00%|
  2404|         0|            0|            0|  0.00%|    See Also
  2405|         0|            0|            0|  0.00%|    --------
  2406|         0|            0|            0|  0.00%|    ndarray.all : equivalent method
  2407|         0|            0|            0|  0.00%|
  2408|         0|            0|            0|  0.00%|    any : Test whether any element along a given axis evaluates to True.
  2409|         0|            0|            0|  0.00%|
  2410|         0|            0|            0|  0.00%|    Notes
  2411|         0|            0|            0|  0.00%|    -----
  2412|         0|            0|            0|  0.00%|    Not a Number (NaN), positive infinity and negative infinity
  2413|         0|            0|            0|  0.00%|    evaluate to `True` because these are not equal to zero.
  2414|         0|            0|            0|  0.00%|
  2415|         0|            0|            0|  0.00%|    Examples
  2416|         0|            0|            0|  0.00%|    --------
  2417|         0|            0|            0|  0.00%|    >>> np.all([[True,False],[True,True]])
  2418|         0|            0|            0|  0.00%|    False
  2419|         0|            0|            0|  0.00%|
  2420|         0|            0|            0|  0.00%|    >>> np.all([[True,False],[True,True]], axis=0)
  2421|         0|            0|            0|  0.00%|    array([ True, False])
  2422|         0|            0|            0|  0.00%|
  2423|         0|            0|            0|  0.00%|    >>> np.all([-1, 4, 5])
  2424|         0|            0|            0|  0.00%|    True
  2425|         0|            0|            0|  0.00%|
  2426|         0|            0|            0|  0.00%|    >>> np.all([1.0, np.nan])
  2427|         0|            0|            0|  0.00%|    True
  2428|         0|            0|            0|  0.00%|
  2429|         0|            0|            0|  0.00%|    >>> np.all([[True, True], [False, True]], where=[[True], [False]])
  2430|         0|            0|            0|  0.00%|    True
  2431|         0|            0|            0|  0.00%|
  2432|         0|            0|            0|  0.00%|    >>> o=np.array(False)
  2433|         0|            0|            0|  0.00%|    >>> z=np.all([-1, 4, 5], out=o)
  2434|         0|            0|            0|  0.00%|    >>> id(z), id(o), z
  2435|         0|            0|            0|  0.00%|    (28293632, 28293632, array(True)) # may vary
  2436|         0|            0|            0|  0.00%|
  2437|         0|            0|            0|  0.00%|    """
  2438|         4|  2.00272e-05|  5.00679e-06|  0.00%|    return _wrapreduction(a, np.logical_and, 'all', axis, None, out,
(call)|         2|  9.94205e-05|  4.97103e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:70 _wrapreduction
  2439|         2|  3.33786e-06|  1.66893e-06|  0.00%|                          keepdims=keepdims, where=where)
  2440|         0|            0|            0|  0.00%|
  2441|         0|            0|            0|  0.00%|
  2442|         0|            0|            0|  0.00%|def _cumsum_dispatcher(a, axis=None, dtype=None, out=None):
  2443|         0|            0|            0|  0.00%|    return (a, out)
  2444|         0|            0|            0|  0.00%|
  2445|         0|            0|            0|  0.00%|
  2446|         0|            0|            0|  0.00%|@array_function_dispatch(_cumsum_dispatcher)
  2447|         0|            0|            0|  0.00%|def cumsum(a, axis=None, dtype=None, out=None):
  2448|         0|            0|            0|  0.00%|    """
  2449|         0|            0|            0|  0.00%|    Return the cumulative sum of the elements along a given axis.
  2450|         0|            0|            0|  0.00%|
  2451|         0|            0|            0|  0.00%|    Parameters
  2452|         0|            0|            0|  0.00%|    ----------
  2453|         0|            0|            0|  0.00%|    a : array_like
  2454|         0|            0|            0|  0.00%|        Input array.
  2455|         0|            0|            0|  0.00%|    axis : int, optional
  2456|         0|            0|            0|  0.00%|        Axis along which the cumulative sum is computed. The default
  2457|         0|            0|            0|  0.00%|        (None) is to compute the cumsum over the flattened array.
  2458|         0|            0|            0|  0.00%|    dtype : dtype, optional
  2459|         0|            0|            0|  0.00%|        Type of the returned array and of the accumulator in which the
  2460|         0|            0|            0|  0.00%|        elements are summed.  If `dtype` is not specified, it defaults
  2461|         0|            0|            0|  0.00%|        to the dtype of `a`, unless `a` has an integer dtype with a
  2462|         0|            0|            0|  0.00%|        precision less than that of the default platform integer.  In
  2463|         0|            0|            0|  0.00%|        that case, the default platform integer is used.
  2464|         0|            0|            0|  0.00%|    out : ndarray, optional
  2465|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must
  2466|         0|            0|            0|  0.00%|        have the same shape and buffer length as the expected output
  2467|         0|            0|            0|  0.00%|        but the type will be cast if necessary. See :ref:`ufuncs-output-type` for
  2468|         0|            0|            0|  0.00%|        more details.
  2469|         0|            0|            0|  0.00%|
  2470|         0|            0|            0|  0.00%|    Returns
  2471|         0|            0|            0|  0.00%|    -------
  2472|         0|            0|            0|  0.00%|    cumsum_along_axis : ndarray.
  2473|         0|            0|            0|  0.00%|        A new array holding the result is returned unless `out` is
  2474|         0|            0|            0|  0.00%|        specified, in which case a reference to `out` is returned. The
  2475|         0|            0|            0|  0.00%|        result has the same size as `a`, and the same shape as `a` if
  2476|         0|            0|            0|  0.00%|        `axis` is not None or `a` is a 1-d array.
  2477|         0|            0|            0|  0.00%|
  2478|         0|            0|            0|  0.00%|
  2479|         0|            0|            0|  0.00%|    See Also
  2480|         0|            0|            0|  0.00%|    --------
  2481|         0|            0|            0|  0.00%|    sum : Sum array elements.
  2482|         0|            0|            0|  0.00%|
  2483|         0|            0|            0|  0.00%|    trapz : Integration of array values using the composite trapezoidal rule.
  2484|         0|            0|            0|  0.00%|
  2485|         0|            0|            0|  0.00%|    diff :  Calculate the n-th discrete difference along given axis.
  2486|         0|            0|            0|  0.00%|
  2487|         0|            0|            0|  0.00%|    Notes
  2488|         0|            0|            0|  0.00%|    -----
  2489|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  2490|         0|            0|            0|  0.00%|    raised on overflow.
  2491|         0|            0|            0|  0.00%|
  2492|         0|            0|            0|  0.00%|    Examples
  2493|         0|            0|            0|  0.00%|    --------
  2494|         0|            0|            0|  0.00%|    >>> a = np.array([[1,2,3], [4,5,6]])
  2495|         0|            0|            0|  0.00%|    >>> a
  2496|         0|            0|            0|  0.00%|    array([[1, 2, 3],
  2497|         0|            0|            0|  0.00%|           [4, 5, 6]])
  2498|         0|            0|            0|  0.00%|    >>> np.cumsum(a)
  2499|         0|            0|            0|  0.00%|    array([ 1,  3,  6, 10, 15, 21])
  2500|         0|            0|            0|  0.00%|    >>> np.cumsum(a, dtype=float)     # specifies type of output value(s)
  2501|         0|            0|            0|  0.00%|    array([  1.,   3.,   6.,  10.,  15.,  21.])
  2502|         0|            0|            0|  0.00%|
  2503|         0|            0|            0|  0.00%|    >>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns
  2504|         0|            0|            0|  0.00%|    array([[1, 2, 3],
  2505|         0|            0|            0|  0.00%|           [5, 7, 9]])
  2506|         0|            0|            0|  0.00%|    >>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows
  2507|         0|            0|            0|  0.00%|    array([[ 1,  3,  6],
  2508|         0|            0|            0|  0.00%|           [ 4,  9, 15]])
  2509|         0|            0|            0|  0.00%|
  2510|         0|            0|            0|  0.00%|    """
  2511|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)
  2512|         0|            0|            0|  0.00%|
  2513|         0|            0|            0|  0.00%|
  2514|         0|            0|            0|  0.00%|def _ptp_dispatcher(a, axis=None, out=None, keepdims=None):
  2515|         0|            0|            0|  0.00%|    return (a, out)
  2516|         0|            0|            0|  0.00%|
  2517|         0|            0|            0|  0.00%|
  2518|         0|            0|            0|  0.00%|@array_function_dispatch(_ptp_dispatcher)
  2519|         0|            0|            0|  0.00%|def ptp(a, axis=None, out=None, keepdims=np._NoValue):
  2520|         0|            0|            0|  0.00%|    """
  2521|         0|            0|            0|  0.00%|    Range of values (maximum - minimum) along an axis.
  2522|         0|            0|            0|  0.00%|
  2523|         0|            0|            0|  0.00%|    The name of the function comes from the acronym for 'peak to peak'.
  2524|         0|            0|            0|  0.00%|
  2525|         0|            0|            0|  0.00%|    .. warning::
  2526|         0|            0|            0|  0.00%|        `ptp` preserves the data type of the array. This means the
  2527|         0|            0|            0|  0.00%|        return value for an input of signed integers with n bits
  2528|         0|            0|            0|  0.00%|        (e.g. `np.int8`, `np.int16`, etc) is also a signed integer
  2529|         0|            0|            0|  0.00%|        with n bits.  In that case, peak-to-peak values greater than
  2530|         0|            0|            0|  0.00%|        ``2**(n-1)-1`` will be returned as negative values. An example
  2531|         0|            0|            0|  0.00%|        with a work-around is shown below.
  2532|         0|            0|            0|  0.00%|
  2533|         0|            0|            0|  0.00%|    Parameters
  2534|         0|            0|            0|  0.00%|    ----------
  2535|         0|            0|            0|  0.00%|    a : array_like
  2536|         0|            0|            0|  0.00%|        Input values.
  2537|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2538|         0|            0|            0|  0.00%|        Axis along which to find the peaks.  By default, flatten the
  2539|         0|            0|            0|  0.00%|        array.  `axis` may be negative, in
  2540|         0|            0|            0|  0.00%|        which case it counts from the last to the first axis.
  2541|         0|            0|            0|  0.00%|
  2542|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2543|         0|            0|            0|  0.00%|
  2544|         0|            0|            0|  0.00%|        If this is a tuple of ints, a reduction is performed on multiple
  2545|         0|            0|            0|  0.00%|        axes, instead of a single axis or all the axes as before.
  2546|         0|            0|            0|  0.00%|    out : array_like
  2547|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must
  2548|         0|            0|            0|  0.00%|        have the same shape and buffer length as the expected output,
  2549|         0|            0|            0|  0.00%|        but the type of the output values will be cast if necessary.
  2550|         0|            0|            0|  0.00%|
  2551|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2552|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2553|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2554|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2555|         0|            0|            0|  0.00%|
  2556|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2557|         0|            0|            0|  0.00%|        passed through to the `ptp` method of sub-classes of
  2558|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2559|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2560|         0|            0|            0|  0.00%|        exceptions will be raised.
  2561|         0|            0|            0|  0.00%|
  2562|         0|            0|            0|  0.00%|    Returns
  2563|         0|            0|            0|  0.00%|    -------
  2564|         0|            0|            0|  0.00%|    ptp : ndarray
  2565|         0|            0|            0|  0.00%|        A new array holding the result, unless `out` was
  2566|         0|            0|            0|  0.00%|        specified, in which case a reference to `out` is returned.
  2567|         0|            0|            0|  0.00%|
  2568|         0|            0|            0|  0.00%|    Examples
  2569|         0|            0|            0|  0.00%|    --------
  2570|         0|            0|            0|  0.00%|    >>> x = np.array([[4, 9, 2, 10],
  2571|         0|            0|            0|  0.00%|    ...               [6, 9, 7, 12]])
  2572|         0|            0|            0|  0.00%|
  2573|         0|            0|            0|  0.00%|    >>> np.ptp(x, axis=1)
  2574|         0|            0|            0|  0.00%|    array([8, 6])
  2575|         0|            0|            0|  0.00%|
  2576|         0|            0|            0|  0.00%|    >>> np.ptp(x, axis=0)
  2577|         0|            0|            0|  0.00%|    array([2, 0, 5, 2])
  2578|         0|            0|            0|  0.00%|
  2579|         0|            0|            0|  0.00%|    >>> np.ptp(x)
  2580|         0|            0|            0|  0.00%|    10
  2581|         0|            0|            0|  0.00%|
  2582|         0|            0|            0|  0.00%|    This example shows that a negative value can be returned when
  2583|         0|            0|            0|  0.00%|    the input is an array of signed integers.
  2584|         0|            0|            0|  0.00%|
  2585|         0|            0|            0|  0.00%|    >>> y = np.array([[1, 127],
  2586|         0|            0|            0|  0.00%|    ...               [0, 127],
  2587|         0|            0|            0|  0.00%|    ...               [-1, 127],
  2588|         0|            0|            0|  0.00%|    ...               [-2, 127]], dtype=np.int8)
  2589|         0|            0|            0|  0.00%|    >>> np.ptp(y, axis=1)
  2590|         0|            0|            0|  0.00%|    array([ 126,  127, -128, -127], dtype=int8)
  2591|         0|            0|            0|  0.00%|
  2592|         0|            0|            0|  0.00%|    A work-around is to use the `view()` method to view the result as
  2593|         0|            0|            0|  0.00%|    unsigned integers with the same bit width:
  2594|         0|            0|            0|  0.00%|
  2595|         0|            0|            0|  0.00%|    >>> np.ptp(y, axis=1).view(np.uint8)
  2596|         0|            0|            0|  0.00%|    array([126, 127, 128, 129], dtype=uint8)
  2597|         0|            0|            0|  0.00%|
  2598|         0|            0|            0|  0.00%|    """
  2599|         0|            0|            0|  0.00%|    kwargs = {}
  2600|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  2601|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  2602|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  2603|         0|            0|            0|  0.00%|        try:
  2604|         0|            0|            0|  0.00%|            ptp = a.ptp
  2605|         0|            0|            0|  0.00%|        except AttributeError:
  2606|         0|            0|            0|  0.00%|            pass
  2607|         0|            0|            0|  0.00%|        else:
  2608|         0|            0|            0|  0.00%|            return ptp(axis=axis, out=out, **kwargs)
  2609|         0|            0|            0|  0.00%|    return _methods._ptp(a, axis=axis, out=out, **kwargs)
  2610|         0|            0|            0|  0.00%|
  2611|         0|            0|            0|  0.00%|
  2612|         0|            0|            0|  0.00%|def _amax_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,
  2613|         0|            0|            0|  0.00%|                     where=None):
  2614|         0|            0|            0|  0.00%|    return (a, out)
  2615|         0|            0|            0|  0.00%|
  2616|         0|            0|            0|  0.00%|
  2617|         0|            0|            0|  0.00%|@array_function_dispatch(_amax_dispatcher)
  2618|         0|            0|            0|  0.00%|def amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,
  2619|         0|            0|            0|  0.00%|         where=np._NoValue):
  2620|         0|            0|            0|  0.00%|    """
  2621|         0|            0|            0|  0.00%|    Return the maximum of an array or maximum along an axis.
  2622|         0|            0|            0|  0.00%|
  2623|         0|            0|            0|  0.00%|    Parameters
  2624|         0|            0|            0|  0.00%|    ----------
  2625|         0|            0|            0|  0.00%|    a : array_like
  2626|         0|            0|            0|  0.00%|        Input data.
  2627|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2628|         0|            0|            0|  0.00%|        Axis or axes along which to operate.  By default, flattened input is
  2629|         0|            0|            0|  0.00%|        used.
  2630|         0|            0|            0|  0.00%|
  2631|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2632|         0|            0|            0|  0.00%|
  2633|         0|            0|            0|  0.00%|        If this is a tuple of ints, the maximum is selected over multiple axes,
  2634|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  2635|         0|            0|            0|  0.00%|    out : ndarray, optional
  2636|         0|            0|            0|  0.00%|        Alternative output array in which to place the result.  Must
  2637|         0|            0|            0|  0.00%|        be of the same shape and buffer length as the expected output.
  2638|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  2639|         0|            0|            0|  0.00%|
  2640|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2641|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2642|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2643|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2644|         0|            0|            0|  0.00%|
  2645|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2646|         0|            0|            0|  0.00%|        passed through to the `amax` method of sub-classes of
  2647|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2648|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2649|         0|            0|            0|  0.00%|        exceptions will be raised.
  2650|         0|            0|            0|  0.00%|
  2651|         0|            0|            0|  0.00%|    initial : scalar, optional
  2652|         0|            0|            0|  0.00%|        The minimum value of an output element. Must be present to allow
  2653|         0|            0|            0|  0.00%|        computation on empty slice. See `~numpy.ufunc.reduce` for details.
  2654|         0|            0|            0|  0.00%|
  2655|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2656|         0|            0|            0|  0.00%|
  2657|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2658|         0|            0|            0|  0.00%|        Elements to compare for the maximum. See `~numpy.ufunc.reduce`
  2659|         0|            0|            0|  0.00%|        for details.
  2660|         0|            0|            0|  0.00%|
  2661|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2662|         0|            0|            0|  0.00%|
  2663|         0|            0|            0|  0.00%|    Returns
  2664|         0|            0|            0|  0.00%|    -------
  2665|         0|            0|            0|  0.00%|    amax : ndarray or scalar
  2666|         0|            0|            0|  0.00%|        Maximum of `a`. If `axis` is None, the result is a scalar value.
  2667|         0|            0|            0|  0.00%|        If `axis` is given, the result is an array of dimension
  2668|         0|            0|            0|  0.00%|        ``a.ndim - 1``.
  2669|         0|            0|            0|  0.00%|
  2670|         0|            0|            0|  0.00%|    See Also
  2671|         0|            0|            0|  0.00%|    --------
  2672|         0|            0|            0|  0.00%|    amin :
  2673|         0|            0|            0|  0.00%|        The minimum value of an array along a given axis, propagating any NaNs.
  2674|         0|            0|            0|  0.00%|    nanmax :
  2675|         0|            0|            0|  0.00%|        The maximum value of an array along a given axis, ignoring any NaNs.
  2676|         0|            0|            0|  0.00%|    maximum :
  2677|         0|            0|            0|  0.00%|        Element-wise maximum of two arrays, propagating any NaNs.
  2678|         0|            0|            0|  0.00%|    fmax :
  2679|         0|            0|            0|  0.00%|        Element-wise maximum of two arrays, ignoring any NaNs.
  2680|         0|            0|            0|  0.00%|    argmax :
  2681|         0|            0|            0|  0.00%|        Return the indices of the maximum values.
  2682|         0|            0|            0|  0.00%|
  2683|         0|            0|            0|  0.00%|    nanmin, minimum, fmin
  2684|         0|            0|            0|  0.00%|
  2685|         0|            0|            0|  0.00%|    Notes
  2686|         0|            0|            0|  0.00%|    -----
  2687|         0|            0|            0|  0.00%|    NaN values are propagated, that is if at least one item is NaN, the
  2688|         0|            0|            0|  0.00%|    corresponding max value will be NaN as well. To ignore NaN values
  2689|         0|            0|            0|  0.00%|    (MATLAB behavior), please use nanmax.
  2690|         0|            0|            0|  0.00%|
  2691|         0|            0|            0|  0.00%|    Don't use `amax` for element-wise comparison of 2 arrays; when
  2692|         0|            0|            0|  0.00%|    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than
  2693|         0|            0|            0|  0.00%|    ``amax(a, axis=0)``.
  2694|         0|            0|            0|  0.00%|
  2695|         0|            0|            0|  0.00%|    Examples
  2696|         0|            0|            0|  0.00%|    --------
  2697|         0|            0|            0|  0.00%|    >>> a = np.arange(4).reshape((2,2))
  2698|         0|            0|            0|  0.00%|    >>> a
  2699|         0|            0|            0|  0.00%|    array([[0, 1],
  2700|         0|            0|            0|  0.00%|           [2, 3]])
  2701|         0|            0|            0|  0.00%|    >>> np.amax(a)           # Maximum of the flattened array
  2702|         0|            0|            0|  0.00%|    3
  2703|         0|            0|            0|  0.00%|    >>> np.amax(a, axis=0)   # Maxima along the first axis
  2704|         0|            0|            0|  0.00%|    array([2, 3])
  2705|         0|            0|            0|  0.00%|    >>> np.amax(a, axis=1)   # Maxima along the second axis
  2706|         0|            0|            0|  0.00%|    array([1, 3])
  2707|         0|            0|            0|  0.00%|    >>> np.amax(a, where=[False, True], initial=-1, axis=0)
  2708|         0|            0|            0|  0.00%|    array([-1,  3])
  2709|         0|            0|            0|  0.00%|    >>> b = np.arange(5, dtype=float)
  2710|         0|            0|            0|  0.00%|    >>> b[2] = np.NaN
  2711|         0|            0|            0|  0.00%|    >>> np.amax(b)
  2712|         0|            0|            0|  0.00%|    nan
  2713|         0|            0|            0|  0.00%|    >>> np.amax(b, where=~np.isnan(b), initial=-1)
  2714|         0|            0|            0|  0.00%|    4.0
  2715|         0|            0|            0|  0.00%|    >>> np.nanmax(b)
  2716|         0|            0|            0|  0.00%|    4.0
  2717|         0|            0|            0|  0.00%|
  2718|         0|            0|            0|  0.00%|    You can use an initial value to compute the maximum of an empty slice, or
  2719|         0|            0|            0|  0.00%|    to initialize it to a different value:
  2720|         0|            0|            0|  0.00%|
  2721|         0|            0|            0|  0.00%|    >>> np.max([[-50], [10]], axis=-1, initial=0)
  2722|         0|            0|            0|  0.00%|    array([ 0, 10])
  2723|         0|            0|            0|  0.00%|
  2724|         0|            0|            0|  0.00%|    Notice that the initial value is used as one of the elements for which the
  2725|         0|            0|            0|  0.00%|    maximum is determined, unlike for the default argument Python's max
  2726|         0|            0|            0|  0.00%|    function, which is only used for empty iterables.
  2727|         0|            0|            0|  0.00%|
  2728|         0|            0|            0|  0.00%|    >>> np.max([5], initial=6)
  2729|         0|            0|            0|  0.00%|    6
  2730|         0|            0|            0|  0.00%|    >>> max([5], default=6)
  2731|         0|            0|            0|  0.00%|    5
  2732|         0|            0|            0|  0.00%|    """
  2733|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  2734|         0|            0|            0|  0.00%|                          keepdims=keepdims, initial=initial, where=where)
  2735|         0|            0|            0|  0.00%|
  2736|         0|            0|            0|  0.00%|
  2737|         0|            0|            0|  0.00%|def _amin_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,
  2738|         0|            0|            0|  0.00%|                     where=None):
  2739|         0|            0|            0|  0.00%|    return (a, out)
  2740|         0|            0|            0|  0.00%|
  2741|         0|            0|            0|  0.00%|
  2742|         0|            0|            0|  0.00%|@array_function_dispatch(_amin_dispatcher)
  2743|         0|            0|            0|  0.00%|def amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,
  2744|         0|            0|            0|  0.00%|         where=np._NoValue):
  2745|         0|            0|            0|  0.00%|    """
  2746|         0|            0|            0|  0.00%|    Return the minimum of an array or minimum along an axis.
  2747|         0|            0|            0|  0.00%|
  2748|         0|            0|            0|  0.00%|    Parameters
  2749|         0|            0|            0|  0.00%|    ----------
  2750|         0|            0|            0|  0.00%|    a : array_like
  2751|         0|            0|            0|  0.00%|        Input data.
  2752|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2753|         0|            0|            0|  0.00%|        Axis or axes along which to operate.  By default, flattened input is
  2754|         0|            0|            0|  0.00%|        used.
  2755|         0|            0|            0|  0.00%|
  2756|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2757|         0|            0|            0|  0.00%|
  2758|         0|            0|            0|  0.00%|        If this is a tuple of ints, the minimum is selected over multiple axes,
  2759|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  2760|         0|            0|            0|  0.00%|    out : ndarray, optional
  2761|         0|            0|            0|  0.00%|        Alternative output array in which to place the result.  Must
  2762|         0|            0|            0|  0.00%|        be of the same shape and buffer length as the expected output.
  2763|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  2764|         0|            0|            0|  0.00%|
  2765|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2766|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  2767|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  2768|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  2769|         0|            0|            0|  0.00%|
  2770|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2771|         0|            0|            0|  0.00%|        passed through to the `amin` method of sub-classes of
  2772|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2773|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2774|         0|            0|            0|  0.00%|        exceptions will be raised.
  2775|         0|            0|            0|  0.00%|
  2776|         0|            0|            0|  0.00%|    initial : scalar, optional
  2777|         0|            0|            0|  0.00%|        The maximum value of an output element. Must be present to allow
  2778|         0|            0|            0|  0.00%|        computation on empty slice. See `~numpy.ufunc.reduce` for details.
  2779|         0|            0|            0|  0.00%|
  2780|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2781|         0|            0|            0|  0.00%|
  2782|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2783|         0|            0|            0|  0.00%|        Elements to compare for the minimum. See `~numpy.ufunc.reduce`
  2784|         0|            0|            0|  0.00%|        for details.
  2785|         0|            0|            0|  0.00%|
  2786|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2787|         0|            0|            0|  0.00%|
  2788|         0|            0|            0|  0.00%|    Returns
  2789|         0|            0|            0|  0.00%|    -------
  2790|         0|            0|            0|  0.00%|    amin : ndarray or scalar
  2791|         0|            0|            0|  0.00%|        Minimum of `a`. If `axis` is None, the result is a scalar value.
  2792|         0|            0|            0|  0.00%|        If `axis` is given, the result is an array of dimension
  2793|         0|            0|            0|  0.00%|        ``a.ndim - 1``.
  2794|         0|            0|            0|  0.00%|
  2795|         0|            0|            0|  0.00%|    See Also
  2796|         0|            0|            0|  0.00%|    --------
  2797|         0|            0|            0|  0.00%|    amax :
  2798|         0|            0|            0|  0.00%|        The maximum value of an array along a given axis, propagating any NaNs.
  2799|         0|            0|            0|  0.00%|    nanmin :
  2800|         0|            0|            0|  0.00%|        The minimum value of an array along a given axis, ignoring any NaNs.
  2801|         0|            0|            0|  0.00%|    minimum :
  2802|         0|            0|            0|  0.00%|        Element-wise minimum of two arrays, propagating any NaNs.
  2803|         0|            0|            0|  0.00%|    fmin :
  2804|         0|            0|            0|  0.00%|        Element-wise minimum of two arrays, ignoring any NaNs.
  2805|         0|            0|            0|  0.00%|    argmin :
  2806|         0|            0|            0|  0.00%|        Return the indices of the minimum values.
  2807|         0|            0|            0|  0.00%|
  2808|         0|            0|            0|  0.00%|    nanmax, maximum, fmax
  2809|         0|            0|            0|  0.00%|
  2810|         0|            0|            0|  0.00%|    Notes
  2811|         0|            0|            0|  0.00%|    -----
  2812|         0|            0|            0|  0.00%|    NaN values are propagated, that is if at least one item is NaN, the
  2813|         0|            0|            0|  0.00%|    corresponding min value will be NaN as well. To ignore NaN values
  2814|         0|            0|            0|  0.00%|    (MATLAB behavior), please use nanmin.
  2815|         0|            0|            0|  0.00%|
  2816|         0|            0|            0|  0.00%|    Don't use `amin` for element-wise comparison of 2 arrays; when
  2817|         0|            0|            0|  0.00%|    ``a.shape[0]`` is 2, ``minimum(a[0], a[1])`` is faster than
  2818|         0|            0|            0|  0.00%|    ``amin(a, axis=0)``.
  2819|         0|            0|            0|  0.00%|
  2820|         0|            0|            0|  0.00%|    Examples
  2821|         0|            0|            0|  0.00%|    --------
  2822|         0|            0|            0|  0.00%|    >>> a = np.arange(4).reshape((2,2))
  2823|         0|            0|            0|  0.00%|    >>> a
  2824|         0|            0|            0|  0.00%|    array([[0, 1],
  2825|         0|            0|            0|  0.00%|           [2, 3]])
  2826|         0|            0|            0|  0.00%|    >>> np.amin(a)           # Minimum of the flattened array
  2827|         0|            0|            0|  0.00%|    0
  2828|         0|            0|            0|  0.00%|    >>> np.amin(a, axis=0)   # Minima along the first axis
  2829|         0|            0|            0|  0.00%|    array([0, 1])
  2830|         0|            0|            0|  0.00%|    >>> np.amin(a, axis=1)   # Minima along the second axis
  2831|         0|            0|            0|  0.00%|    array([0, 2])
  2832|         0|            0|            0|  0.00%|    >>> np.amin(a, where=[False, True], initial=10, axis=0)
  2833|         0|            0|            0|  0.00%|    array([10,  1])
  2834|         0|            0|            0|  0.00%|
  2835|         0|            0|            0|  0.00%|    >>> b = np.arange(5, dtype=float)
  2836|         0|            0|            0|  0.00%|    >>> b[2] = np.NaN
  2837|         0|            0|            0|  0.00%|    >>> np.amin(b)
  2838|         0|            0|            0|  0.00%|    nan
  2839|         0|            0|            0|  0.00%|    >>> np.amin(b, where=~np.isnan(b), initial=10)
  2840|         0|            0|            0|  0.00%|    0.0
  2841|         0|            0|            0|  0.00%|    >>> np.nanmin(b)
  2842|         0|            0|            0|  0.00%|    0.0
  2843|         0|            0|            0|  0.00%|
  2844|         0|            0|            0|  0.00%|    >>> np.min([[-50], [10]], axis=-1, initial=0)
  2845|         0|            0|            0|  0.00%|    array([-50,   0])
  2846|         0|            0|            0|  0.00%|
  2847|         0|            0|            0|  0.00%|    Notice that the initial value is used as one of the elements for which the
  2848|         0|            0|            0|  0.00%|    minimum is determined, unlike for the default argument Python's max
  2849|         0|            0|            0|  0.00%|    function, which is only used for empty iterables.
  2850|         0|            0|            0|  0.00%|
  2851|         0|            0|            0|  0.00%|    Notice that this isn't the same as Python's ``default`` argument.
  2852|         0|            0|            0|  0.00%|
  2853|         0|            0|            0|  0.00%|    >>> np.min([6], initial=5)
  2854|         0|            0|            0|  0.00%|    5
  2855|         0|            0|            0|  0.00%|    >>> min([6], default=5)
  2856|         0|            0|            0|  0.00%|    6
  2857|         0|            0|            0|  0.00%|    """
  2858|         0|            0|            0|  0.00%|    return _wrapreduction(a, np.minimum, 'min', axis, None, out,
  2859|         0|            0|            0|  0.00%|                          keepdims=keepdims, initial=initial, where=where)
  2860|         0|            0|            0|  0.00%|
  2861|         0|            0|            0|  0.00%|
  2862|         0|            0|            0|  0.00%|def _alen_dispathcer(a):
  2863|         0|            0|            0|  0.00%|    return (a,)
  2864|         0|            0|            0|  0.00%|
  2865|         0|            0|            0|  0.00%|
  2866|         0|            0|            0|  0.00%|@array_function_dispatch(_alen_dispathcer)
  2867|         0|            0|            0|  0.00%|def alen(a):
  2868|         0|            0|            0|  0.00%|    """
  2869|         0|            0|            0|  0.00%|    Return the length of the first dimension of the input array.
  2870|         0|            0|            0|  0.00%|
  2871|         0|            0|            0|  0.00%|    .. deprecated:: 1.18
  2872|         0|            0|            0|  0.00%|       `numpy.alen` is deprecated, use `len` instead.
  2873|         0|            0|            0|  0.00%|
  2874|         0|            0|            0|  0.00%|    Parameters
  2875|         0|            0|            0|  0.00%|    ----------
  2876|         0|            0|            0|  0.00%|    a : array_like
  2877|         0|            0|            0|  0.00%|       Input array.
  2878|         0|            0|            0|  0.00%|
  2879|         0|            0|            0|  0.00%|    Returns
  2880|         0|            0|            0|  0.00%|    -------
  2881|         0|            0|            0|  0.00%|    alen : int
  2882|         0|            0|            0|  0.00%|       Length of the first dimension of `a`.
  2883|         0|            0|            0|  0.00%|
  2884|         0|            0|            0|  0.00%|    See Also
  2885|         0|            0|            0|  0.00%|    --------
  2886|         0|            0|            0|  0.00%|    shape, size
  2887|         0|            0|            0|  0.00%|
  2888|         0|            0|            0|  0.00%|    Examples
  2889|         0|            0|            0|  0.00%|    --------
  2890|         0|            0|            0|  0.00%|    >>> a = np.zeros((7,4,5))
  2891|         0|            0|            0|  0.00%|    >>> a.shape[0]
  2892|         0|            0|            0|  0.00%|    7
  2893|         0|            0|            0|  0.00%|    >>> np.alen(a)
  2894|         0|            0|            0|  0.00%|    7
  2895|         0|            0|            0|  0.00%|
  2896|         0|            0|            0|  0.00%|    """
  2897|         0|            0|            0|  0.00%|    # NumPy 1.18.0, 2019-08-02
  2898|         0|            0|            0|  0.00%|    warnings.warn(
  2899|         0|            0|            0|  0.00%|        "`np.alen` is deprecated, use `len` instead",
  2900|         0|            0|            0|  0.00%|        DeprecationWarning, stacklevel=2)
  2901|         0|            0|            0|  0.00%|    try:
  2902|         0|            0|            0|  0.00%|        return len(a)
  2903|         0|            0|            0|  0.00%|    except TypeError:
  2904|         0|            0|            0|  0.00%|        return len(array(a, ndmin=1))
  2905|         0|            0|            0|  0.00%|
  2906|         0|            0|            0|  0.00%|
  2907|      1000|   0.00143266|  1.43266e-06|  0.17%|def _prod_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None,
  2908|         0|            0|            0|  0.00%|                     initial=None, where=None):
  2909|      1000|   0.00170231|  1.70231e-06|  0.20%|    return (a, out)
  2910|         0|            0|            0|  0.00%|
  2911|         0|            0|            0|  0.00%|
  2912|      1000|   0.00138807|  1.38807e-06|  0.16%|@array_function_dispatch(_prod_dispatcher)
  2913|         0|            0|            0|  0.00%|def prod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,
  2914|         0|            0|            0|  0.00%|         initial=np._NoValue, where=np._NoValue):
  2915|         0|            0|            0|  0.00%|    """
  2916|         0|            0|            0|  0.00%|    Return the product of array elements over a given axis.
  2917|         0|            0|            0|  0.00%|
  2918|         0|            0|            0|  0.00%|    Parameters
  2919|         0|            0|            0|  0.00%|    ----------
  2920|         0|            0|            0|  0.00%|    a : array_like
  2921|         0|            0|            0|  0.00%|        Input data.
  2922|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  2923|         0|            0|            0|  0.00%|        Axis or axes along which a product is performed.  The default,
  2924|         0|            0|            0|  0.00%|        axis=None, will calculate the product of all the elements in the
  2925|         0|            0|            0|  0.00%|        input array. If axis is negative it counts from the last to the
  2926|         0|            0|            0|  0.00%|        first axis.
  2927|         0|            0|            0|  0.00%|
  2928|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  2929|         0|            0|            0|  0.00%|
  2930|         0|            0|            0|  0.00%|        If axis is a tuple of ints, a product is performed on all of the
  2931|         0|            0|            0|  0.00%|        axes specified in the tuple instead of a single axis or all the
  2932|         0|            0|            0|  0.00%|        axes as before.
  2933|         0|            0|            0|  0.00%|    dtype : dtype, optional
  2934|         0|            0|            0|  0.00%|        The type of the returned array, as well as of the accumulator in
  2935|         0|            0|            0|  0.00%|        which the elements are multiplied.  The dtype of `a` is used by
  2936|         0|            0|            0|  0.00%|        default unless `a` has an integer dtype of less precision than the
  2937|         0|            0|            0|  0.00%|        default platform integer.  In that case, if `a` is signed then the
  2938|         0|            0|            0|  0.00%|        platform integer is used while if `a` is unsigned then an unsigned
  2939|         0|            0|            0|  0.00%|        integer of the same precision as the platform integer is used.
  2940|         0|            0|            0|  0.00%|    out : ndarray, optional
  2941|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  2942|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type of the output
  2943|         0|            0|            0|  0.00%|        values will be cast if necessary.
  2944|         0|            0|            0|  0.00%|    keepdims : bool, optional
  2945|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left in the
  2946|         0|            0|            0|  0.00%|        result as dimensions with size one. With this option, the result
  2947|         0|            0|            0|  0.00%|        will broadcast correctly against the input array.
  2948|         0|            0|            0|  0.00%|
  2949|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  2950|         0|            0|            0|  0.00%|        passed through to the `prod` method of sub-classes of
  2951|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  2952|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  2953|         0|            0|            0|  0.00%|        exceptions will be raised.
  2954|         0|            0|            0|  0.00%|    initial : scalar, optional
  2955|         0|            0|            0|  0.00%|        The starting value for this product. See `~numpy.ufunc.reduce` for details.
  2956|         0|            0|            0|  0.00%|
  2957|         0|            0|            0|  0.00%|        .. versionadded:: 1.15.0
  2958|         0|            0|            0|  0.00%|
  2959|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  2960|         0|            0|            0|  0.00%|        Elements to include in the product. See `~numpy.ufunc.reduce` for details.
  2961|         0|            0|            0|  0.00%|
  2962|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  2963|         0|            0|            0|  0.00%|
  2964|         0|            0|            0|  0.00%|    Returns
  2965|         0|            0|            0|  0.00%|    -------
  2966|         0|            0|            0|  0.00%|    product_along_axis : ndarray, see `dtype` parameter above.
  2967|         0|            0|            0|  0.00%|        An array shaped as `a` but with the specified axis removed.
  2968|         0|            0|            0|  0.00%|        Returns a reference to `out` if specified.
  2969|         0|            0|            0|  0.00%|
  2970|         0|            0|            0|  0.00%|    See Also
  2971|         0|            0|            0|  0.00%|    --------
  2972|         0|            0|            0|  0.00%|    ndarray.prod : equivalent method
  2973|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  2974|         0|            0|            0|  0.00%|
  2975|         0|            0|            0|  0.00%|    Notes
  2976|         0|            0|            0|  0.00%|    -----
  2977|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  2978|         0|            0|            0|  0.00%|    raised on overflow.  That means that, on a 32-bit platform:
  2979|         0|            0|            0|  0.00%|
  2980|         0|            0|            0|  0.00%|    >>> x = np.array([536870910, 536870910, 536870910, 536870910])
  2981|         0|            0|            0|  0.00%|    >>> np.prod(x)
  2982|         0|            0|            0|  0.00%|    16 # may vary
  2983|         0|            0|            0|  0.00%|
  2984|         0|            0|            0|  0.00%|    The product of an empty array is the neutral element 1:
  2985|         0|            0|            0|  0.00%|
  2986|         0|            0|            0|  0.00%|    >>> np.prod([])
  2987|         0|            0|            0|  0.00%|    1.0
  2988|         0|            0|            0|  0.00%|
  2989|         0|            0|            0|  0.00%|    Examples
  2990|         0|            0|            0|  0.00%|    --------
  2991|         0|            0|            0|  0.00%|    By default, calculate the product of all elements:
  2992|         0|            0|            0|  0.00%|
  2993|         0|            0|            0|  0.00%|    >>> np.prod([1.,2.])
  2994|         0|            0|            0|  0.00%|    2.0
  2995|         0|            0|            0|  0.00%|
  2996|         0|            0|            0|  0.00%|    Even when the input array is two-dimensional:
  2997|         0|            0|            0|  0.00%|
  2998|         0|            0|            0|  0.00%|    >>> np.prod([[1.,2.],[3.,4.]])
  2999|         0|            0|            0|  0.00%|    24.0
  3000|         0|            0|            0|  0.00%|
  3001|         0|            0|            0|  0.00%|    But we can also specify the axis over which to multiply:
  3002|         0|            0|            0|  0.00%|
  3003|         0|            0|            0|  0.00%|    >>> np.prod([[1.,2.],[3.,4.]], axis=1)
  3004|         0|            0|            0|  0.00%|    array([  2.,  12.])
  3005|         0|            0|            0|  0.00%|
  3006|         0|            0|            0|  0.00%|    Or select specific elements to include:
  3007|         0|            0|            0|  0.00%|
  3008|         0|            0|            0|  0.00%|    >>> np.prod([1., np.nan, 3.], where=[True, False, True])
  3009|         0|            0|            0|  0.00%|    3.0
  3010|         0|            0|            0|  0.00%|
  3011|         0|            0|            0|  0.00%|    If the type of `x` is unsigned, then the output type is
  3012|         0|            0|            0|  0.00%|    the unsigned platform integer:
  3013|         0|            0|            0|  0.00%|
  3014|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3], dtype=np.uint8)
  3015|         0|            0|            0|  0.00%|    >>> np.prod(x).dtype == np.uint
  3016|         0|            0|            0|  0.00%|    True
  3017|         0|            0|            0|  0.00%|
  3018|         0|            0|            0|  0.00%|    If `x` is of a signed integer type, then the output type
  3019|         0|            0|            0|  0.00%|    is the default platform integer:
  3020|         0|            0|            0|  0.00%|
  3021|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3], dtype=np.int8)
  3022|         0|            0|            0|  0.00%|    >>> np.prod(x).dtype == int
  3023|         0|            0|            0|  0.00%|    True
  3024|         0|            0|            0|  0.00%|
  3025|         0|            0|            0|  0.00%|    You can also start the product with a value other than one:
  3026|         0|            0|            0|  0.00%|
  3027|         0|            0|            0|  0.00%|    >>> np.prod([1, 2], initial=5)
  3028|         0|            0|            0|  0.00%|    10
  3029|         0|            0|            0|  0.00%|    """
  3030|      2000|   0.00866079|   4.3304e-06|  1.01%|    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,
(call)|      1000|    0.0378959|  3.78959e-05|  4.42%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:70 _wrapreduction
  3031|      1000|    0.0014832|   1.4832e-06|  0.17%|                          keepdims=keepdims, initial=initial, where=where)
  3032|         0|            0|            0|  0.00%|
  3033|         0|            0|            0|  0.00%|
  3034|         0|            0|            0|  0.00%|def _cumprod_dispatcher(a, axis=None, dtype=None, out=None):
  3035|         0|            0|            0|  0.00%|    return (a, out)
  3036|         0|            0|            0|  0.00%|
  3037|         0|            0|            0|  0.00%|
  3038|         0|            0|            0|  0.00%|@array_function_dispatch(_cumprod_dispatcher)
  3039|         0|            0|            0|  0.00%|def cumprod(a, axis=None, dtype=None, out=None):
  3040|         0|            0|            0|  0.00%|    """
  3041|         0|            0|            0|  0.00%|    Return the cumulative product of elements along a given axis.
  3042|         0|            0|            0|  0.00%|
  3043|         0|            0|            0|  0.00%|    Parameters
  3044|         0|            0|            0|  0.00%|    ----------
  3045|         0|            0|            0|  0.00%|    a : array_like
  3046|         0|            0|            0|  0.00%|        Input array.
  3047|         0|            0|            0|  0.00%|    axis : int, optional
  3048|         0|            0|            0|  0.00%|        Axis along which the cumulative product is computed.  By default
  3049|         0|            0|            0|  0.00%|        the input is flattened.
  3050|         0|            0|            0|  0.00%|    dtype : dtype, optional
  3051|         0|            0|            0|  0.00%|        Type of the returned array, as well as of the accumulator in which
  3052|         0|            0|            0|  0.00%|        the elements are multiplied.  If *dtype* is not specified, it
  3053|         0|            0|            0|  0.00%|        defaults to the dtype of `a`, unless `a` has an integer dtype with
  3054|         0|            0|            0|  0.00%|        a precision less than that of the default platform integer.  In
  3055|         0|            0|            0|  0.00%|        that case, the default platform integer is used instead.
  3056|         0|            0|            0|  0.00%|    out : ndarray, optional
  3057|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must
  3058|         0|            0|            0|  0.00%|        have the same shape and buffer length as the expected output
  3059|         0|            0|            0|  0.00%|        but the type of the resulting values will be cast if necessary.
  3060|         0|            0|            0|  0.00%|
  3061|         0|            0|            0|  0.00%|    Returns
  3062|         0|            0|            0|  0.00%|    -------
  3063|         0|            0|            0|  0.00%|    cumprod : ndarray
  3064|         0|            0|            0|  0.00%|        A new array holding the result is returned unless `out` is
  3065|         0|            0|            0|  0.00%|        specified, in which case a reference to out is returned.
  3066|         0|            0|            0|  0.00%|
  3067|         0|            0|            0|  0.00%|    See Also
  3068|         0|            0|            0|  0.00%|    --------
  3069|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3070|         0|            0|            0|  0.00%|
  3071|         0|            0|            0|  0.00%|    Notes
  3072|         0|            0|            0|  0.00%|    -----
  3073|         0|            0|            0|  0.00%|    Arithmetic is modular when using integer types, and no error is
  3074|         0|            0|            0|  0.00%|    raised on overflow.
  3075|         0|            0|            0|  0.00%|
  3076|         0|            0|            0|  0.00%|    Examples
  3077|         0|            0|            0|  0.00%|    --------
  3078|         0|            0|            0|  0.00%|    >>> a = np.array([1,2,3])
  3079|         0|            0|            0|  0.00%|    >>> np.cumprod(a) # intermediate results 1, 1*2
  3080|         0|            0|            0|  0.00%|    ...               # total product 1*2*3 = 6
  3081|         0|            0|            0|  0.00%|    array([1, 2, 6])
  3082|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6]])
  3083|         0|            0|            0|  0.00%|    >>> np.cumprod(a, dtype=float) # specify type of output
  3084|         0|            0|            0|  0.00%|    array([   1.,    2.,    6.,   24.,  120.,  720.])
  3085|         0|            0|            0|  0.00%|
  3086|         0|            0|            0|  0.00%|    The cumulative product for each column (i.e., over the rows) of `a`:
  3087|         0|            0|            0|  0.00%|
  3088|         0|            0|            0|  0.00%|    >>> np.cumprod(a, axis=0)
  3089|         0|            0|            0|  0.00%|    array([[ 1,  2,  3],
  3090|         0|            0|            0|  0.00%|           [ 4, 10, 18]])
  3091|         0|            0|            0|  0.00%|
  3092|         0|            0|            0|  0.00%|    The cumulative product for each row (i.e. over the columns) of `a`:
  3093|         0|            0|            0|  0.00%|
  3094|         0|            0|            0|  0.00%|    >>> np.cumprod(a,axis=1)
  3095|         0|            0|            0|  0.00%|    array([[  1,   2,   6],
  3096|         0|            0|            0|  0.00%|           [  4,  20, 120]])
  3097|         0|            0|            0|  0.00%|
  3098|         0|            0|            0|  0.00%|    """
  3099|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'cumprod', axis=axis, dtype=dtype, out=out)
  3100|         0|            0|            0|  0.00%|
  3101|         0|            0|            0|  0.00%|
  3102|         2|  2.71797e-05|  1.35899e-05|  0.00%|def _ndim_dispatcher(a):
  3103|         2|  3.57628e-06|  1.78814e-06|  0.00%|    return (a,)
  3104|         0|            0|            0|  0.00%|
  3105|         0|            0|            0|  0.00%|
  3106|         2|  4.29153e-06|  2.14577e-06|  0.00%|@array_function_dispatch(_ndim_dispatcher)
  3107|         0|            0|            0|  0.00%|def ndim(a):
  3108|         0|            0|            0|  0.00%|    """
  3109|         0|            0|            0|  0.00%|    Return the number of dimensions of an array.
  3110|         0|            0|            0|  0.00%|
  3111|         0|            0|            0|  0.00%|    Parameters
  3112|         0|            0|            0|  0.00%|    ----------
  3113|         0|            0|            0|  0.00%|    a : array_like
  3114|         0|            0|            0|  0.00%|        Input array.  If it is not already an ndarray, a conversion is
  3115|         0|            0|            0|  0.00%|        attempted.
  3116|         0|            0|            0|  0.00%|
  3117|         0|            0|            0|  0.00%|    Returns
  3118|         0|            0|            0|  0.00%|    -------
  3119|         0|            0|            0|  0.00%|    number_of_dimensions : int
  3120|         0|            0|            0|  0.00%|        The number of dimensions in `a`.  Scalars are zero-dimensional.
  3121|         0|            0|            0|  0.00%|
  3122|         0|            0|            0|  0.00%|    See Also
  3123|         0|            0|            0|  0.00%|    --------
  3124|         0|            0|            0|  0.00%|    ndarray.ndim : equivalent method
  3125|         0|            0|            0|  0.00%|    shape : dimensions of array
  3126|         0|            0|            0|  0.00%|    ndarray.shape : dimensions of array
  3127|         0|            0|            0|  0.00%|
  3128|         0|            0|            0|  0.00%|    Examples
  3129|         0|            0|            0|  0.00%|    --------
  3130|         0|            0|            0|  0.00%|    >>> np.ndim([[1,2,3],[4,5,6]])
  3131|         0|            0|            0|  0.00%|    2
  3132|         0|            0|            0|  0.00%|    >>> np.ndim(np.array([[1,2,3],[4,5,6]]))
  3133|         0|            0|            0|  0.00%|    2
  3134|         0|            0|            0|  0.00%|    >>> np.ndim(1)
  3135|         0|            0|            0|  0.00%|    0
  3136|         0|            0|            0|  0.00%|
  3137|         0|            0|            0|  0.00%|    """
  3138|         2|  1.93119e-05|  9.65595e-06|  0.00%|    try:
  3139|         2|  5.96046e-06|  2.98023e-06|  0.00%|        return a.ndim
  3140|         2|  3.09944e-06|  1.54972e-06|  0.00%|    except AttributeError:
  3141|         2|  1.26362e-05|  6.31809e-06|  0.00%|        return asarray(a).ndim
(call)|         2|   3.0756e-05|   1.5378e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:23 asarray
  3142|         0|            0|            0|  0.00%|
  3143|         0|            0|            0|  0.00%|
  3144|         0|            0|            0|  0.00%|def _size_dispatcher(a, axis=None):
  3145|         0|            0|            0|  0.00%|    return (a,)
  3146|         0|            0|            0|  0.00%|
  3147|         0|            0|            0|  0.00%|
  3148|         0|            0|            0|  0.00%|@array_function_dispatch(_size_dispatcher)
  3149|         0|            0|            0|  0.00%|def size(a, axis=None):
  3150|         0|            0|            0|  0.00%|    """
  3151|         0|            0|            0|  0.00%|    Return the number of elements along a given axis.
  3152|         0|            0|            0|  0.00%|
  3153|         0|            0|            0|  0.00%|    Parameters
  3154|         0|            0|            0|  0.00%|    ----------
  3155|         0|            0|            0|  0.00%|    a : array_like
  3156|         0|            0|            0|  0.00%|        Input data.
  3157|         0|            0|            0|  0.00%|    axis : int, optional
  3158|         0|            0|            0|  0.00%|        Axis along which the elements are counted.  By default, give
  3159|         0|            0|            0|  0.00%|        the total number of elements.
  3160|         0|            0|            0|  0.00%|
  3161|         0|            0|            0|  0.00%|    Returns
  3162|         0|            0|            0|  0.00%|    -------
  3163|         0|            0|            0|  0.00%|    element_count : int
  3164|         0|            0|            0|  0.00%|        Number of elements along the specified axis.
  3165|         0|            0|            0|  0.00%|
  3166|         0|            0|            0|  0.00%|    See Also
  3167|         0|            0|            0|  0.00%|    --------
  3168|         0|            0|            0|  0.00%|    shape : dimensions of array
  3169|         0|            0|            0|  0.00%|    ndarray.shape : dimensions of array
  3170|         0|            0|            0|  0.00%|    ndarray.size : number of elements in array
  3171|         0|            0|            0|  0.00%|
  3172|         0|            0|            0|  0.00%|    Examples
  3173|         0|            0|            0|  0.00%|    --------
  3174|         0|            0|            0|  0.00%|    >>> a = np.array([[1,2,3],[4,5,6]])
  3175|         0|            0|            0|  0.00%|    >>> np.size(a)
  3176|         0|            0|            0|  0.00%|    6
  3177|         0|            0|            0|  0.00%|    >>> np.size(a,1)
  3178|         0|            0|            0|  0.00%|    3
  3179|         0|            0|            0|  0.00%|    >>> np.size(a,0)
  3180|         0|            0|            0|  0.00%|    2
  3181|         0|            0|            0|  0.00%|
  3182|         0|            0|            0|  0.00%|    """
  3183|         0|            0|            0|  0.00%|    if axis is None:
  3184|         0|            0|            0|  0.00%|        try:
  3185|         0|            0|            0|  0.00%|            return a.size
  3186|         0|            0|            0|  0.00%|        except AttributeError:
  3187|         0|            0|            0|  0.00%|            return asarray(a).size
  3188|         0|            0|            0|  0.00%|    else:
  3189|         0|            0|            0|  0.00%|        try:
  3190|         0|            0|            0|  0.00%|            return a.shape[axis]
  3191|         0|            0|            0|  0.00%|        except AttributeError:
  3192|         0|            0|            0|  0.00%|            return asarray(a).shape[axis]
  3193|         0|            0|            0|  0.00%|
  3194|         0|            0|            0|  0.00%|
  3195|         0|            0|            0|  0.00%|def _around_dispatcher(a, decimals=None, out=None):
  3196|         0|            0|            0|  0.00%|    return (a, out)
  3197|         0|            0|            0|  0.00%|
  3198|         0|            0|            0|  0.00%|
  3199|         0|            0|            0|  0.00%|@array_function_dispatch(_around_dispatcher)
  3200|         0|            0|            0|  0.00%|def around(a, decimals=0, out=None):
  3201|         0|            0|            0|  0.00%|    """
  3202|         0|            0|            0|  0.00%|    Evenly round to the given number of decimals.
  3203|         0|            0|            0|  0.00%|
  3204|         0|            0|            0|  0.00%|    Parameters
  3205|         0|            0|            0|  0.00%|    ----------
  3206|         0|            0|            0|  0.00%|    a : array_like
  3207|         0|            0|            0|  0.00%|        Input data.
  3208|         0|            0|            0|  0.00%|    decimals : int, optional
  3209|         0|            0|            0|  0.00%|        Number of decimal places to round to (default: 0).  If
  3210|         0|            0|            0|  0.00%|        decimals is negative, it specifies the number of positions to
  3211|         0|            0|            0|  0.00%|        the left of the decimal point.
  3212|         0|            0|            0|  0.00%|    out : ndarray, optional
  3213|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  3214|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type of the output
  3215|         0|            0|            0|  0.00%|        values will be cast if necessary. See :ref:`ufuncs-output-type` for more
  3216|         0|            0|            0|  0.00%|        details.
  3217|         0|            0|            0|  0.00%|
  3218|         0|            0|            0|  0.00%|    Returns
  3219|         0|            0|            0|  0.00%|    -------
  3220|         0|            0|            0|  0.00%|    rounded_array : ndarray
  3221|         0|            0|            0|  0.00%|        An array of the same type as `a`, containing the rounded values.
  3222|         0|            0|            0|  0.00%|        Unless `out` was specified, a new array is created.  A reference to
  3223|         0|            0|            0|  0.00%|        the result is returned.
  3224|         0|            0|            0|  0.00%|
  3225|         0|            0|            0|  0.00%|        The real and imaginary parts of complex numbers are rounded
  3226|         0|            0|            0|  0.00%|        separately.  The result of rounding a float is a float.
  3227|         0|            0|            0|  0.00%|
  3228|         0|            0|            0|  0.00%|    See Also
  3229|         0|            0|            0|  0.00%|    --------
  3230|         0|            0|            0|  0.00%|    ndarray.round : equivalent method
  3231|         0|            0|            0|  0.00%|
  3232|         0|            0|            0|  0.00%|    ceil, fix, floor, rint, trunc
  3233|         0|            0|            0|  0.00%|
  3234|         0|            0|            0|  0.00%|
  3235|         0|            0|            0|  0.00%|    Notes
  3236|         0|            0|            0|  0.00%|    -----
  3237|         0|            0|            0|  0.00%|    For values exactly halfway between rounded decimal values, NumPy
  3238|         0|            0|            0|  0.00%|    rounds to the nearest even value. Thus 1.5 and 2.5 round to 2.0,
  3239|         0|            0|            0|  0.00%|    -0.5 and 0.5 round to 0.0, etc.
  3240|         0|            0|            0|  0.00%|
  3241|         0|            0|            0|  0.00%|    ``np.around`` uses a fast but sometimes inexact algorithm to round
  3242|         0|            0|            0|  0.00%|    floating-point datatypes. For positive `decimals` it is equivalent to
  3243|         0|            0|            0|  0.00%|    ``np.true_divide(np.rint(a * 10**decimals), 10**decimals)``, which has
  3244|         0|            0|            0|  0.00%|    error due to the inexact representation of decimal fractions in the IEEE
  3245|         0|            0|            0|  0.00%|    floating point standard [1]_ and errors introduced when scaling by powers
  3246|         0|            0|            0|  0.00%|    of ten. For instance, note the extra "1" in the following:
  3247|         0|            0|            0|  0.00%|
  3248|         0|            0|            0|  0.00%|        >>> np.round(56294995342131.5, 3)
  3249|         0|            0|            0|  0.00%|        56294995342131.51
  3250|         0|            0|            0|  0.00%|
  3251|         0|            0|            0|  0.00%|    If your goal is to print such values with a fixed number of decimals, it is
  3252|         0|            0|            0|  0.00%|    preferable to use numpy's float printing routines to limit the number of
  3253|         0|            0|            0|  0.00%|    printed decimals:
  3254|         0|            0|            0|  0.00%|
  3255|         0|            0|            0|  0.00%|        >>> np.format_float_positional(56294995342131.5, precision=3)
  3256|         0|            0|            0|  0.00%|        '56294995342131.5'
  3257|         0|            0|            0|  0.00%|
  3258|         0|            0|            0|  0.00%|    The float printing routines use an accurate but much more computationally
  3259|         0|            0|            0|  0.00%|    demanding algorithm to compute the number of digits after the decimal
  3260|         0|            0|            0|  0.00%|    point.
  3261|         0|            0|            0|  0.00%|
  3262|         0|            0|            0|  0.00%|    Alternatively, Python's builtin `round` function uses a more accurate
  3263|         0|            0|            0|  0.00%|    but slower algorithm for 64-bit floating point values:
  3264|         0|            0|            0|  0.00%|
  3265|         0|            0|            0|  0.00%|        >>> round(56294995342131.5, 3)
  3266|         0|            0|            0|  0.00%|        56294995342131.5
  3267|         0|            0|            0|  0.00%|        >>> np.round(16.055, 2), round(16.055, 2)  # equals 16.0549999999999997
  3268|         0|            0|            0|  0.00%|        (16.06, 16.05)
  3269|         0|            0|            0|  0.00%|
  3270|         0|            0|            0|  0.00%|
  3271|         0|            0|            0|  0.00%|    References
  3272|         0|            0|            0|  0.00%|    ----------
  3273|         0|            0|            0|  0.00%|    .. [1] "Lecture Notes on the Status of IEEE 754", William Kahan,
  3274|         0|            0|            0|  0.00%|           https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
  3275|         0|            0|            0|  0.00%|    .. [2] "How Futile are Mindless Assessments of
  3276|         0|            0|            0|  0.00%|           Roundoff in Floating-Point Computation?", William Kahan,
  3277|         0|            0|            0|  0.00%|           https://people.eecs.berkeley.edu/~wkahan/Mindless.pdf
  3278|         0|            0|            0|  0.00%|
  3279|         0|            0|            0|  0.00%|    Examples
  3280|         0|            0|            0|  0.00%|    --------
  3281|         0|            0|            0|  0.00%|    >>> np.around([0.37, 1.64])
  3282|         0|            0|            0|  0.00%|    array([0.,  2.])
  3283|         0|            0|            0|  0.00%|    >>> np.around([0.37, 1.64], decimals=1)
  3284|         0|            0|            0|  0.00%|    array([0.4,  1.6])
  3285|         0|            0|            0|  0.00%|    >>> np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value
  3286|         0|            0|            0|  0.00%|    array([0.,  2.,  2.,  4.,  4.])
  3287|         0|            0|            0|  0.00%|    >>> np.around([1,2,3,11], decimals=1) # ndarray of ints is returned
  3288|         0|            0|            0|  0.00%|    array([ 1,  2,  3, 11])
  3289|         0|            0|            0|  0.00%|    >>> np.around([1,2,3,11], decimals=-1)
  3290|         0|            0|            0|  0.00%|    array([ 0,  0,  0, 10])
  3291|         0|            0|            0|  0.00%|
  3292|         0|            0|            0|  0.00%|    """
  3293|         0|            0|            0|  0.00%|    return _wrapfunc(a, 'round', decimals=decimals, out=out)
  3294|         0|            0|            0|  0.00%|
  3295|         0|            0|            0|  0.00%|
  3296|         0|            0|            0|  0.00%|def _mean_dispatcher(a, axis=None, dtype=None, out=None, keepdims=None, *,
  3297|         0|            0|            0|  0.00%|                     where=None):
  3298|         0|            0|            0|  0.00%|    return (a, where, out)
  3299|         0|            0|            0|  0.00%|
  3300|         0|            0|            0|  0.00%|
  3301|         0|            0|            0|  0.00%|@array_function_dispatch(_mean_dispatcher)
  3302|         0|            0|            0|  0.00%|def mean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue, *,
  3303|         0|            0|            0|  0.00%|         where=np._NoValue):
  3304|         0|            0|            0|  0.00%|    """
  3305|         0|            0|            0|  0.00%|    Compute the arithmetic mean along the specified axis.
  3306|         0|            0|            0|  0.00%|
  3307|         0|            0|            0|  0.00%|    Returns the average of the array elements.  The average is taken over
  3308|         0|            0|            0|  0.00%|    the flattened array by default, otherwise over the specified axis.
  3309|         0|            0|            0|  0.00%|    `float64` intermediate and return values are used for integer inputs.
  3310|         0|            0|            0|  0.00%|
  3311|         0|            0|            0|  0.00%|    Parameters
  3312|         0|            0|            0|  0.00%|    ----------
  3313|         0|            0|            0|  0.00%|    a : array_like
  3314|         0|            0|            0|  0.00%|        Array containing numbers whose mean is desired. If `a` is not an
  3315|         0|            0|            0|  0.00%|        array, a conversion is attempted.
  3316|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  3317|         0|            0|            0|  0.00%|        Axis or axes along which the means are computed. The default is to
  3318|         0|            0|            0|  0.00%|        compute the mean of the flattened array.
  3319|         0|            0|            0|  0.00%|
  3320|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  3321|         0|            0|            0|  0.00%|
  3322|         0|            0|            0|  0.00%|        If this is a tuple of ints, a mean is performed over multiple axes,
  3323|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  3324|         0|            0|            0|  0.00%|    dtype : data-type, optional
  3325|         0|            0|            0|  0.00%|        Type to use in computing the mean.  For integer inputs, the default
  3326|         0|            0|            0|  0.00%|        is `float64`; for floating point inputs, it is the same as the
  3327|         0|            0|            0|  0.00%|        input dtype.
  3328|         0|            0|            0|  0.00%|    out : ndarray, optional
  3329|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.  The default
  3330|         0|            0|            0|  0.00%|        is ``None``; if provided, it must have the same shape as the
  3331|         0|            0|            0|  0.00%|        expected output, but the type will be cast if necessary.
  3332|         0|            0|            0|  0.00%|        See :ref:`ufuncs-output-type` for more details.
  3333|         0|            0|            0|  0.00%|
  3334|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3335|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  3336|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  3337|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  3338|         0|            0|            0|  0.00%|
  3339|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3340|         0|            0|            0|  0.00%|        passed through to the `mean` method of sub-classes of
  3341|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3342|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3343|         0|            0|            0|  0.00%|        exceptions will be raised.
  3344|         0|            0|            0|  0.00%|
  3345|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3346|         0|            0|            0|  0.00%|        Elements to include in the mean. See `~numpy.ufunc.reduce` for details.
  3347|         0|            0|            0|  0.00%|
  3348|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  3349|         0|            0|            0|  0.00%|
  3350|         0|            0|            0|  0.00%|    Returns
  3351|         0|            0|            0|  0.00%|    -------
  3352|         0|            0|            0|  0.00%|    m : ndarray, see dtype parameter above
  3353|         0|            0|            0|  0.00%|        If `out=None`, returns a new array containing the mean values,
  3354|         0|            0|            0|  0.00%|        otherwise a reference to the output array is returned.
  3355|         0|            0|            0|  0.00%|
  3356|         0|            0|            0|  0.00%|    See Also
  3357|         0|            0|            0|  0.00%|    --------
  3358|         0|            0|            0|  0.00%|    average : Weighted average
  3359|         0|            0|            0|  0.00%|    std, var, nanmean, nanstd, nanvar
  3360|         0|            0|            0|  0.00%|
  3361|         0|            0|            0|  0.00%|    Notes
  3362|         0|            0|            0|  0.00%|    -----
  3363|         0|            0|            0|  0.00%|    The arithmetic mean is the sum of the elements along the axis divided
  3364|         0|            0|            0|  0.00%|    by the number of elements.
  3365|         0|            0|            0|  0.00%|
  3366|         0|            0|            0|  0.00%|    Note that for floating-point input, the mean is computed using the
  3367|         0|            0|            0|  0.00%|    same precision the input has.  Depending on the input data, this can
  3368|         0|            0|            0|  0.00%|    cause the results to be inaccurate, especially for `float32` (see
  3369|         0|            0|            0|  0.00%|    example below).  Specifying a higher-precision accumulator using the
  3370|         0|            0|            0|  0.00%|    `dtype` keyword can alleviate this issue.
  3371|         0|            0|            0|  0.00%|
  3372|         0|            0|            0|  0.00%|    By default, `float16` results are computed using `float32` intermediates
  3373|         0|            0|            0|  0.00%|    for extra precision.
  3374|         0|            0|            0|  0.00%|
  3375|         0|            0|            0|  0.00%|    Examples
  3376|         0|            0|            0|  0.00%|    --------
  3377|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
  3378|         0|            0|            0|  0.00%|    >>> np.mean(a)
  3379|         0|            0|            0|  0.00%|    2.5
  3380|         0|            0|            0|  0.00%|    >>> np.mean(a, axis=0)
  3381|         0|            0|            0|  0.00%|    array([2., 3.])
  3382|         0|            0|            0|  0.00%|    >>> np.mean(a, axis=1)
  3383|         0|            0|            0|  0.00%|    array([1.5, 3.5])
  3384|         0|            0|            0|  0.00%|
  3385|         0|            0|            0|  0.00%|    In single precision, `mean` can be inaccurate:
  3386|         0|            0|            0|  0.00%|
  3387|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 512*512), dtype=np.float32)
  3388|         0|            0|            0|  0.00%|    >>> a[0, :] = 1.0
  3389|         0|            0|            0|  0.00%|    >>> a[1, :] = 0.1
  3390|         0|            0|            0|  0.00%|    >>> np.mean(a)
  3391|         0|            0|            0|  0.00%|    0.54999924
  3392|         0|            0|            0|  0.00%|
  3393|         0|            0|            0|  0.00%|    Computing the mean in float64 is more accurate:
  3394|         0|            0|            0|  0.00%|
  3395|         0|            0|            0|  0.00%|    >>> np.mean(a, dtype=np.float64)
  3396|         0|            0|            0|  0.00%|    0.55000000074505806 # may vary
  3397|         0|            0|            0|  0.00%|
  3398|         0|            0|            0|  0.00%|    Specifying a where argument:
  3399|         0|            0|            0|  0.00%|    >>> a = np.array([[5, 9, 13], [14, 10, 12], [11, 15, 19]])
  3400|         0|            0|            0|  0.00%|    >>> np.mean(a)
  3401|         0|            0|            0|  0.00%|    12.0
  3402|         0|            0|            0|  0.00%|    >>> np.mean(a, where=[[True], [False], [False]])
  3403|         0|            0|            0|  0.00%|    9.0
  3404|         0|            0|            0|  0.00%|
  3405|         0|            0|            0|  0.00%|    """
  3406|         0|            0|            0|  0.00%|    kwargs = {}
  3407|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  3408|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  3409|         0|            0|            0|  0.00%|    if where is not np._NoValue:
  3410|         0|            0|            0|  0.00%|        kwargs['where'] = where
  3411|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  3412|         0|            0|            0|  0.00%|        try:
  3413|         0|            0|            0|  0.00%|            mean = a.mean
  3414|         0|            0|            0|  0.00%|        except AttributeError:
  3415|         0|            0|            0|  0.00%|            pass
  3416|         0|            0|            0|  0.00%|        else:
  3417|         0|            0|            0|  0.00%|            return mean(axis=axis, dtype=dtype, out=out, **kwargs)
  3418|         0|            0|            0|  0.00%|
  3419|         0|            0|            0|  0.00%|    return _methods._mean(a, axis=axis, dtype=dtype,
  3420|         0|            0|            0|  0.00%|                          out=out, **kwargs)
  3421|         0|            0|            0|  0.00%|
  3422|         0|            0|            0|  0.00%|
  3423|         0|            0|            0|  0.00%|def _std_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,
  3424|         0|            0|            0|  0.00%|                    keepdims=None, *, where=None):
  3425|         0|            0|            0|  0.00%|    return (a, where, out)
  3426|         0|            0|            0|  0.00%|
  3427|         0|            0|            0|  0.00%|
  3428|         0|            0|            0|  0.00%|@array_function_dispatch(_std_dispatcher)
  3429|         0|            0|            0|  0.00%|def std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,
  3430|         0|            0|            0|  0.00%|        where=np._NoValue):
  3431|         0|            0|            0|  0.00%|    """
  3432|         0|            0|            0|  0.00%|    Compute the standard deviation along the specified axis.
  3433|         0|            0|            0|  0.00%|
  3434|         0|            0|            0|  0.00%|    Returns the standard deviation, a measure of the spread of a distribution,
  3435|         0|            0|            0|  0.00%|    of the array elements. The standard deviation is computed for the
  3436|         0|            0|            0|  0.00%|    flattened array by default, otherwise over the specified axis.
  3437|         0|            0|            0|  0.00%|
  3438|         0|            0|            0|  0.00%|    Parameters
  3439|         0|            0|            0|  0.00%|    ----------
  3440|         0|            0|            0|  0.00%|    a : array_like
  3441|         0|            0|            0|  0.00%|        Calculate the standard deviation of these values.
  3442|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  3443|         0|            0|            0|  0.00%|        Axis or axes along which the standard deviation is computed. The
  3444|         0|            0|            0|  0.00%|        default is to compute the standard deviation of the flattened array.
  3445|         0|            0|            0|  0.00%|
  3446|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  3447|         0|            0|            0|  0.00%|
  3448|         0|            0|            0|  0.00%|        If this is a tuple of ints, a standard deviation is performed over
  3449|         0|            0|            0|  0.00%|        multiple axes, instead of a single axis or all the axes as before.
  3450|         0|            0|            0|  0.00%|    dtype : dtype, optional
  3451|         0|            0|            0|  0.00%|        Type to use in computing the standard deviation. For arrays of
  3452|         0|            0|            0|  0.00%|        integer type the default is float64, for arrays of float types it is
  3453|         0|            0|            0|  0.00%|        the same as the array type.
  3454|         0|            0|            0|  0.00%|    out : ndarray, optional
  3455|         0|            0|            0|  0.00%|        Alternative output array in which to place the result. It must have
  3456|         0|            0|            0|  0.00%|        the same shape as the expected output but the type (of the calculated
  3457|         0|            0|            0|  0.00%|        values) will be cast if necessary.
  3458|         0|            0|            0|  0.00%|    ddof : int, optional
  3459|         0|            0|            0|  0.00%|        Means Delta Degrees of Freedom.  The divisor used in calculations
  3460|         0|            0|            0|  0.00%|        is ``N - ddof``, where ``N`` represents the number of elements.
  3461|         0|            0|            0|  0.00%|        By default `ddof` is zero.
  3462|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3463|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  3464|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  3465|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  3466|         0|            0|            0|  0.00%|
  3467|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3468|         0|            0|            0|  0.00%|        passed through to the `std` method of sub-classes of
  3469|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3470|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3471|         0|            0|            0|  0.00%|        exceptions will be raised.
  3472|         0|            0|            0|  0.00%|
  3473|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3474|         0|            0|            0|  0.00%|        Elements to include in the standard deviation.
  3475|         0|            0|            0|  0.00%|        See `~numpy.ufunc.reduce` for details.
  3476|         0|            0|            0|  0.00%|
  3477|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  3478|         0|            0|            0|  0.00%|
  3479|         0|            0|            0|  0.00%|    Returns
  3480|         0|            0|            0|  0.00%|    -------
  3481|         0|            0|            0|  0.00%|    standard_deviation : ndarray, see dtype parameter above.
  3482|         0|            0|            0|  0.00%|        If `out` is None, return a new array containing the standard deviation,
  3483|         0|            0|            0|  0.00%|        otherwise return a reference to the output array.
  3484|         0|            0|            0|  0.00%|
  3485|         0|            0|            0|  0.00%|    See Also
  3486|         0|            0|            0|  0.00%|    --------
  3487|         0|            0|            0|  0.00%|    var, mean, nanmean, nanstd, nanvar
  3488|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3489|         0|            0|            0|  0.00%|
  3490|         0|            0|            0|  0.00%|    Notes
  3491|         0|            0|            0|  0.00%|    -----
  3492|         0|            0|            0|  0.00%|    The standard deviation is the square root of the average of the squared
  3493|         0|            0|            0|  0.00%|    deviations from the mean, i.e., ``std = sqrt(mean(x))``, where
  3494|         0|            0|            0|  0.00%|    ``x = abs(a - a.mean())**2``.
  3495|         0|            0|            0|  0.00%|
  3496|         0|            0|            0|  0.00%|    The average squared deviation is typically calculated as ``x.sum() / N``,
  3497|         0|            0|            0|  0.00%|    where ``N = len(x)``. If, however, `ddof` is specified, the divisor
  3498|         0|            0|            0|  0.00%|    ``N - ddof`` is used instead. In standard statistical practice, ``ddof=1``
  3499|         0|            0|            0|  0.00%|    provides an unbiased estimator of the variance of the infinite population.
  3500|         0|            0|            0|  0.00%|    ``ddof=0`` provides a maximum likelihood estimate of the variance for
  3501|         0|            0|            0|  0.00%|    normally distributed variables. The standard deviation computed in this
  3502|         0|            0|            0|  0.00%|    function is the square root of the estimated variance, so even with
  3503|         0|            0|            0|  0.00%|    ``ddof=1``, it will not be an unbiased estimate of the standard deviation
  3504|         0|            0|            0|  0.00%|    per se.
  3505|         0|            0|            0|  0.00%|
  3506|         0|            0|            0|  0.00%|    Note that, for complex numbers, `std` takes the absolute
  3507|         0|            0|            0|  0.00%|    value before squaring, so that the result is always real and nonnegative.
  3508|         0|            0|            0|  0.00%|
  3509|         0|            0|            0|  0.00%|    For floating-point input, the *std* is computed using the same
  3510|         0|            0|            0|  0.00%|    precision the input has. Depending on the input data, this can cause
  3511|         0|            0|            0|  0.00%|    the results to be inaccurate, especially for float32 (see example below).
  3512|         0|            0|            0|  0.00%|    Specifying a higher-accuracy accumulator using the `dtype` keyword can
  3513|         0|            0|            0|  0.00%|    alleviate this issue.
  3514|         0|            0|            0|  0.00%|
  3515|         0|            0|            0|  0.00%|    Examples
  3516|         0|            0|            0|  0.00%|    --------
  3517|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
  3518|         0|            0|            0|  0.00%|    >>> np.std(a)
  3519|         0|            0|            0|  0.00%|    1.1180339887498949 # may vary
  3520|         0|            0|            0|  0.00%|    >>> np.std(a, axis=0)
  3521|         0|            0|            0|  0.00%|    array([1.,  1.])
  3522|         0|            0|            0|  0.00%|    >>> np.std(a, axis=1)
  3523|         0|            0|            0|  0.00%|    array([0.5,  0.5])
  3524|         0|            0|            0|  0.00%|
  3525|         0|            0|            0|  0.00%|    In single precision, std() can be inaccurate:
  3526|         0|            0|            0|  0.00%|
  3527|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 512*512), dtype=np.float32)
  3528|         0|            0|            0|  0.00%|    >>> a[0, :] = 1.0
  3529|         0|            0|            0|  0.00%|    >>> a[1, :] = 0.1
  3530|         0|            0|            0|  0.00%|    >>> np.std(a)
  3531|         0|            0|            0|  0.00%|    0.45000005
  3532|         0|            0|            0|  0.00%|
  3533|         0|            0|            0|  0.00%|    Computing the standard deviation in float64 is more accurate:
  3534|         0|            0|            0|  0.00%|
  3535|         0|            0|            0|  0.00%|    >>> np.std(a, dtype=np.float64)
  3536|         0|            0|            0|  0.00%|    0.44999999925494177 # may vary
  3537|         0|            0|            0|  0.00%|
  3538|         0|            0|            0|  0.00%|    Specifying a where argument:
  3539|         0|            0|            0|  0.00%|
  3540|         0|            0|            0|  0.00%|    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])
  3541|         0|            0|            0|  0.00%|    >>> np.std(a)
  3542|         0|            0|            0|  0.00%|    2.614064523559687 # may vary
  3543|         0|            0|            0|  0.00%|    >>> np.std(a, where=[[True], [True], [False]])
  3544|         0|            0|            0|  0.00%|    2.0
  3545|         0|            0|            0|  0.00%|
  3546|         0|            0|            0|  0.00%|    """
  3547|         0|            0|            0|  0.00%|    kwargs = {}
  3548|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  3549|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  3550|         0|            0|            0|  0.00%|    if where is not np._NoValue:
  3551|         0|            0|            0|  0.00%|        kwargs['where'] = where
  3552|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  3553|         0|            0|            0|  0.00%|        try:
  3554|         0|            0|            0|  0.00%|            std = a.std
  3555|         0|            0|            0|  0.00%|        except AttributeError:
  3556|         0|            0|            0|  0.00%|            pass
  3557|         0|            0|            0|  0.00%|        else:
  3558|         0|            0|            0|  0.00%|            return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)
  3559|         0|            0|            0|  0.00%|
  3560|         0|            0|            0|  0.00%|    return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
  3561|         0|            0|            0|  0.00%|                         **kwargs)
  3562|         0|            0|            0|  0.00%|
  3563|         0|            0|            0|  0.00%|
  3564|         0|            0|            0|  0.00%|def _var_dispatcher(a, axis=None, dtype=None, out=None, ddof=None,
  3565|         0|            0|            0|  0.00%|                    keepdims=None, *, where=None):
  3566|         0|            0|            0|  0.00%|    return (a, where, out)
  3567|         0|            0|            0|  0.00%|
  3568|         0|            0|            0|  0.00%|
  3569|         0|            0|            0|  0.00%|@array_function_dispatch(_var_dispatcher)
  3570|         0|            0|            0|  0.00%|def var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue, *,
  3571|         0|            0|            0|  0.00%|        where=np._NoValue):
  3572|         0|            0|            0|  0.00%|    """
  3573|         0|            0|            0|  0.00%|    Compute the variance along the specified axis.
  3574|         0|            0|            0|  0.00%|
  3575|         0|            0|            0|  0.00%|    Returns the variance of the array elements, a measure of the spread of a
  3576|         0|            0|            0|  0.00%|    distribution.  The variance is computed for the flattened array by
  3577|         0|            0|            0|  0.00%|    default, otherwise over the specified axis.
  3578|         0|            0|            0|  0.00%|
  3579|         0|            0|            0|  0.00%|    Parameters
  3580|         0|            0|            0|  0.00%|    ----------
  3581|         0|            0|            0|  0.00%|    a : array_like
  3582|         0|            0|            0|  0.00%|        Array containing numbers whose variance is desired.  If `a` is not an
  3583|         0|            0|            0|  0.00%|        array, a conversion is attempted.
  3584|         0|            0|            0|  0.00%|    axis : None or int or tuple of ints, optional
  3585|         0|            0|            0|  0.00%|        Axis or axes along which the variance is computed.  The default is to
  3586|         0|            0|            0|  0.00%|        compute the variance of the flattened array.
  3587|         0|            0|            0|  0.00%|
  3588|         0|            0|            0|  0.00%|        .. versionadded:: 1.7.0
  3589|         0|            0|            0|  0.00%|
  3590|         0|            0|            0|  0.00%|        If this is a tuple of ints, a variance is performed over multiple axes,
  3591|         0|            0|            0|  0.00%|        instead of a single axis or all the axes as before.
  3592|         0|            0|            0|  0.00%|    dtype : data-type, optional
  3593|         0|            0|            0|  0.00%|        Type to use in computing the variance.  For arrays of integer type
  3594|         0|            0|            0|  0.00%|        the default is `float64`; for arrays of float types it is the same as
  3595|         0|            0|            0|  0.00%|        the array type.
  3596|         0|            0|            0|  0.00%|    out : ndarray, optional
  3597|         0|            0|            0|  0.00%|        Alternate output array in which to place the result.  It must have
  3598|         0|            0|            0|  0.00%|        the same shape as the expected output, but the type is cast if
  3599|         0|            0|            0|  0.00%|        necessary.
  3600|         0|            0|            0|  0.00%|    ddof : int, optional
  3601|         0|            0|            0|  0.00%|        "Delta Degrees of Freedom": the divisor used in the calculation is
  3602|         0|            0|            0|  0.00%|        ``N - ddof``, where ``N`` represents the number of elements. By
  3603|         0|            0|            0|  0.00%|        default `ddof` is zero.
  3604|         0|            0|            0|  0.00%|    keepdims : bool, optional
  3605|         0|            0|            0|  0.00%|        If this is set to True, the axes which are reduced are left
  3606|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
  3607|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
  3608|         0|            0|            0|  0.00%|
  3609|         0|            0|            0|  0.00%|        If the default value is passed, then `keepdims` will not be
  3610|         0|            0|            0|  0.00%|        passed through to the `var` method of sub-classes of
  3611|         0|            0|            0|  0.00%|        `ndarray`, however any non-default value will be.  If the
  3612|         0|            0|            0|  0.00%|        sub-class' method does not implement `keepdims` any
  3613|         0|            0|            0|  0.00%|        exceptions will be raised.
  3614|         0|            0|            0|  0.00%|
  3615|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  3616|         0|            0|            0|  0.00%|        Elements to include in the variance. See `~numpy.ufunc.reduce` for
  3617|         0|            0|            0|  0.00%|        details.
  3618|         0|            0|            0|  0.00%|
  3619|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  3620|         0|            0|            0|  0.00%|
  3621|         0|            0|            0|  0.00%|    Returns
  3622|         0|            0|            0|  0.00%|    -------
  3623|         0|            0|            0|  0.00%|    variance : ndarray, see dtype parameter above
  3624|         0|            0|            0|  0.00%|        If ``out=None``, returns a new array containing the variance;
  3625|         0|            0|            0|  0.00%|        otherwise, a reference to the output array is returned.
  3626|         0|            0|            0|  0.00%|
  3627|         0|            0|            0|  0.00%|    See Also
  3628|         0|            0|            0|  0.00%|    --------
  3629|         0|            0|            0|  0.00%|    std, mean, nanmean, nanstd, nanvar
  3630|         0|            0|            0|  0.00%|    :ref:`ufuncs-output-type`
  3631|         0|            0|            0|  0.00%|
  3632|         0|            0|            0|  0.00%|    Notes
  3633|         0|            0|            0|  0.00%|    -----
  3634|         0|            0|            0|  0.00%|    The variance is the average of the squared deviations from the mean,
  3635|         0|            0|            0|  0.00%|    i.e.,  ``var = mean(x)``, where ``x = abs(a - a.mean())**2``.
  3636|         0|            0|            0|  0.00%|
  3637|         0|            0|            0|  0.00%|    The mean is typically calculated as ``x.sum() / N``, where ``N = len(x)``.
  3638|         0|            0|            0|  0.00%|    If, however, `ddof` is specified, the divisor ``N - ddof`` is used
  3639|         0|            0|            0|  0.00%|    instead.  In standard statistical practice, ``ddof=1`` provides an
  3640|         0|            0|            0|  0.00%|    unbiased estimator of the variance of a hypothetical infinite population.
  3641|         0|            0|            0|  0.00%|    ``ddof=0`` provides a maximum likelihood estimate of the variance for
  3642|         0|            0|            0|  0.00%|    normally distributed variables.
  3643|         0|            0|            0|  0.00%|
  3644|         0|            0|            0|  0.00%|    Note that for complex numbers, the absolute value is taken before
  3645|         0|            0|            0|  0.00%|    squaring, so that the result is always real and nonnegative.
  3646|         0|            0|            0|  0.00%|
  3647|         0|            0|            0|  0.00%|    For floating-point input, the variance is computed using the same
  3648|         0|            0|            0|  0.00%|    precision the input has.  Depending on the input data, this can cause
  3649|         0|            0|            0|  0.00%|    the results to be inaccurate, especially for `float32` (see example
  3650|         0|            0|            0|  0.00%|    below).  Specifying a higher-accuracy accumulator using the ``dtype``
  3651|         0|            0|            0|  0.00%|    keyword can alleviate this issue.
  3652|         0|            0|            0|  0.00%|
  3653|         0|            0|            0|  0.00%|    Examples
  3654|         0|            0|            0|  0.00%|    --------
  3655|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
  3656|         0|            0|            0|  0.00%|    >>> np.var(a)
  3657|         0|            0|            0|  0.00%|    1.25
  3658|         0|            0|            0|  0.00%|    >>> np.var(a, axis=0)
  3659|         0|            0|            0|  0.00%|    array([1.,  1.])
  3660|         0|            0|            0|  0.00%|    >>> np.var(a, axis=1)
  3661|         0|            0|            0|  0.00%|    array([0.25,  0.25])
  3662|         0|            0|            0|  0.00%|
  3663|         0|            0|            0|  0.00%|    In single precision, var() can be inaccurate:
  3664|         0|            0|            0|  0.00%|
  3665|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 512*512), dtype=np.float32)
  3666|         0|            0|            0|  0.00%|    >>> a[0, :] = 1.0
  3667|         0|            0|            0|  0.00%|    >>> a[1, :] = 0.1
  3668|         0|            0|            0|  0.00%|    >>> np.var(a)
  3669|         0|            0|            0|  0.00%|    0.20250003
  3670|         0|            0|            0|  0.00%|
  3671|         0|            0|            0|  0.00%|    Computing the variance in float64 is more accurate:
  3672|         0|            0|            0|  0.00%|
  3673|         0|            0|            0|  0.00%|    >>> np.var(a, dtype=np.float64)
  3674|         0|            0|            0|  0.00%|    0.20249999932944759 # may vary
  3675|         0|            0|            0|  0.00%|    >>> ((1-0.55)**2 + (0.1-0.55)**2)/2
  3676|         0|            0|            0|  0.00%|    0.2025
  3677|         0|            0|            0|  0.00%|
  3678|         0|            0|            0|  0.00%|    Specifying a where argument:
  3679|         0|            0|            0|  0.00%|
  3680|         0|            0|            0|  0.00%|    >>> a = np.array([[14, 8, 11, 10], [7, 9, 10, 11], [10, 15, 5, 10]])
  3681|         0|            0|            0|  0.00%|    >>> np.var(a)
  3682|         0|            0|            0|  0.00%|    6.833333333333333 # may vary
  3683|         0|            0|            0|  0.00%|    >>> np.var(a, where=[[True], [True], [False]])
  3684|         0|            0|            0|  0.00%|    4.0
  3685|         0|            0|            0|  0.00%|
  3686|         0|            0|            0|  0.00%|    """
  3687|         0|            0|            0|  0.00%|    kwargs = {}
  3688|         0|            0|            0|  0.00%|    if keepdims is not np._NoValue:
  3689|         0|            0|            0|  0.00%|        kwargs['keepdims'] = keepdims
  3690|         0|            0|            0|  0.00%|    if where is not np._NoValue:
  3691|         0|            0|            0|  0.00%|        kwargs['where'] = where
  3692|         0|            0|            0|  0.00%|
  3693|         0|            0|            0|  0.00%|    if type(a) is not mu.ndarray:
  3694|         0|            0|            0|  0.00%|        try:
  3695|         0|            0|            0|  0.00%|            var = a.var
  3696|         0|            0|            0|  0.00%|
  3697|         0|            0|            0|  0.00%|        except AttributeError:
  3698|         0|            0|            0|  0.00%|            pass
  3699|         0|            0|            0|  0.00%|        else:
  3700|         0|            0|            0|  0.00%|            return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)
  3701|         0|            0|            0|  0.00%|
  3702|         0|            0|            0|  0.00%|    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
  3703|         0|            0|            0|  0.00%|                         **kwargs)
  3704|         0|            0|            0|  0.00%|
  3705|         0|            0|            0|  0.00%|
  3706|         0|            0|            0|  0.00%|# Aliases of other functions. These have their own definitions only so that
  3707|         0|            0|            0|  0.00%|# they can have unique docstrings.
  3708|         0|            0|            0|  0.00%|
  3709|         0|            0|            0|  0.00%|@array_function_dispatch(_around_dispatcher)
  3710|         0|            0|            0|  0.00%|def round_(a, decimals=0, out=None):
  3711|         0|            0|            0|  0.00%|    """
  3712|         0|            0|            0|  0.00%|    Round an array to the given number of decimals.
  3713|         0|            0|            0|  0.00%|
  3714|         0|            0|            0|  0.00%|    See Also
  3715|         0|            0|            0|  0.00%|    --------
  3716|         0|            0|            0|  0.00%|    around : equivalent function; see for details.
  3717|         0|            0|            0|  0.00%|    """
  3718|         0|            0|            0|  0.00%|    return around(a, decimals=decimals, out=out)
  3719|         0|            0|            0|  0.00%|
  3720|         0|            0|            0|  0.00%|
  3721|         0|            0|            0|  0.00%|@array_function_dispatch(_prod_dispatcher, verify=False)
  3722|         0|            0|            0|  0.00%|def product(*args, **kwargs):
  3723|         0|            0|            0|  0.00%|    """
  3724|         0|            0|            0|  0.00%|    Return the product of array elements over a given axis.
  3725|         0|            0|            0|  0.00%|
  3726|         0|            0|            0|  0.00%|    See Also
  3727|         0|            0|            0|  0.00%|    --------
  3728|         0|            0|            0|  0.00%|    prod : equivalent function; see for details.
  3729|         0|            0|            0|  0.00%|    """
  3730|         0|            0|            0|  0.00%|    return prod(*args, **kwargs)
  3731|         0|            0|            0|  0.00%|
  3732|         0|            0|            0|  0.00%|
  3733|         0|            0|            0|  0.00%|@array_function_dispatch(_cumprod_dispatcher, verify=False)
  3734|         0|            0|            0|  0.00%|def cumproduct(*args, **kwargs):
  3735|         0|            0|            0|  0.00%|    """
  3736|         0|            0|            0|  0.00%|    Return the cumulative product over the given axis.
  3737|         0|            0|            0|  0.00%|
  3738|         0|            0|            0|  0.00%|    See Also
  3739|         0|            0|            0|  0.00%|    --------
  3740|         0|            0|            0|  0.00%|    cumprod : equivalent function; see for details.
  3741|         0|            0|            0|  0.00%|    """
  3742|         0|            0|            0|  0.00%|    return cumprod(*args, **kwargs)
  3743|         0|            0|            0|  0.00%|
  3744|         0|            0|            0|  0.00%|
  3745|         0|            0|            0|  0.00%|@array_function_dispatch(_any_dispatcher, verify=False)
  3746|         0|            0|            0|  0.00%|def sometrue(*args, **kwargs):
  3747|         0|            0|            0|  0.00%|    """
  3748|         0|            0|            0|  0.00%|    Check whether some values are true.
  3749|         0|            0|            0|  0.00%|
  3750|         0|            0|            0|  0.00%|    Refer to `any` for full documentation.
  3751|         0|            0|            0|  0.00%|
  3752|         0|            0|            0|  0.00%|    See Also
  3753|         0|            0|            0|  0.00%|    --------
  3754|         0|            0|            0|  0.00%|    any : equivalent function; see for details.
  3755|         0|            0|            0|  0.00%|    """
  3756|         0|            0|            0|  0.00%|    return any(*args, **kwargs)
  3757|         0|            0|            0|  0.00%|
  3758|         0|            0|            0|  0.00%|
  3759|         0|            0|            0|  0.00%|@array_function_dispatch(_all_dispatcher, verify=False)
  3760|         0|            0|            0|  0.00%|def alltrue(*args, **kwargs):
  3761|         0|            0|            0|  0.00%|    """
  3762|         0|            0|            0|  0.00%|    Check if all elements of input array are true.
  3763|         0|            0|            0|  0.00%|
  3764|         0|            0|            0|  0.00%|    See Also
  3765|         0|            0|            0|  0.00%|    --------
  3766|         0|            0|            0|  0.00%|    numpy.all : Equivalent function; see for details.
  3767|         0|            0|            0|  0.00%|    """
  3768|         0|            0|            0|  0.00%|    return all(*args, **kwargs)
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/shape_base.py
File duration: 0.0244811s (2.85%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import functools
     2|         0|            0|            0|  0.00%|
     3|         0|            0|            0|  0.00%|import numpy.core.numeric as _nx
     4|         0|            0|            0|  0.00%|from numpy.core.numeric import (
     5|         0|            0|            0|  0.00%|    asarray, zeros, outer, concatenate, array, asanyarray
     6|         0|            0|            0|  0.00%|    )
     7|         0|            0|            0|  0.00%|from numpy.core.fromnumeric import reshape, transpose
     8|         0|            0|            0|  0.00%|from numpy.core.multiarray import normalize_axis_index
     9|         0|            0|            0|  0.00%|from numpy.core import overrides
    10|         0|            0|            0|  0.00%|from numpy.core import vstack, atleast_3d
    11|         0|            0|            0|  0.00%|from numpy.core.numeric import normalize_axis_tuple
    12|         0|            0|            0|  0.00%|from numpy.core.shape_base import _arrays_for_stack_dispatcher
    13|         0|            0|            0|  0.00%|from numpy.lib.index_tricks import ndindex
    14|         0|            0|            0|  0.00%|from numpy.matrixlib.defmatrix import matrix  # this raises all the right alarm bells
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|__all__ = [
    18|         0|            0|            0|  0.00%|    'column_stack', 'row_stack', 'dstack', 'array_split', 'split',
    19|         0|            0|            0|  0.00%|    'hsplit', 'vsplit', 'dsplit', 'apply_over_axes', 'expand_dims',
    20|         0|            0|            0|  0.00%|    'apply_along_axis', 'kron', 'tile', 'get_array_wrap', 'take_along_axis',
    21|         0|            0|            0|  0.00%|    'put_along_axis'
    22|         0|            0|            0|  0.00%|    ]
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|array_function_dispatch = functools.partial(
    26|         0|            0|            0|  0.00%|    overrides.array_function_dispatch, module='numpy')
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|def _make_along_axis_idx(arr_shape, indices, axis):
    30|         0|            0|            0|  0.00%|    # compute dimensions to iterate over
    31|         0|            0|            0|  0.00%|    if not _nx.issubdtype(indices.dtype, _nx.integer):
    32|         0|            0|            0|  0.00%|        raise IndexError('`indices` must be an integer array')
    33|         0|            0|            0|  0.00%|    if len(arr_shape) != indices.ndim:
    34|         0|            0|            0|  0.00%|        raise ValueError(
    35|         0|            0|            0|  0.00%|            "`indices` and `arr` must have the same number of dimensions")
    36|         0|            0|            0|  0.00%|    shape_ones = (1,) * indices.ndim
    37|         0|            0|            0|  0.00%|    dest_dims = list(range(axis)) + [None] + list(range(axis+1, indices.ndim))
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|    # build a fancy index, consisting of orthogonal aranges, with the
    40|         0|            0|            0|  0.00%|    # requested index inserted at the right location
    41|         0|            0|            0|  0.00%|    fancy_index = []
    42|         0|            0|            0|  0.00%|    for dim, n in zip(dest_dims, arr_shape):
    43|         0|            0|            0|  0.00%|        if dim is None:
    44|         0|            0|            0|  0.00%|            fancy_index.append(indices)
    45|         0|            0|            0|  0.00%|        else:
    46|         0|            0|            0|  0.00%|            ind_shape = shape_ones[:dim] + (-1,) + shape_ones[dim+1:]
    47|         0|            0|            0|  0.00%|            fancy_index.append(_nx.arange(n).reshape(ind_shape))
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|    return tuple(fancy_index)
    50|         0|            0|            0|  0.00%|
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|def _take_along_axis_dispatcher(arr, indices, axis):
    53|         0|            0|            0|  0.00%|    return (arr, indices)
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|
    56|         0|            0|            0|  0.00%|@array_function_dispatch(_take_along_axis_dispatcher)
    57|         0|            0|            0|  0.00%|def take_along_axis(arr, indices, axis):
    58|         0|            0|            0|  0.00%|    """
    59|         0|            0|            0|  0.00%|    Take values from the input array by matching 1d index and data slices.
    60|         0|            0|            0|  0.00%|
    61|         0|            0|            0|  0.00%|    This iterates over matching 1d slices oriented along the specified axis in
    62|         0|            0|            0|  0.00%|    the index and data arrays, and uses the former to look up values in the
    63|         0|            0|            0|  0.00%|    latter. These slices can be different lengths.
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|    Functions returning an index along an axis, like `argsort` and
    66|         0|            0|            0|  0.00%|    `argpartition`, produce suitable indices for this function.
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|    .. versionadded:: 1.15.0
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|    Parameters
    71|         0|            0|            0|  0.00%|    ----------
    72|         0|            0|            0|  0.00%|    arr: ndarray (Ni..., M, Nk...)
    73|         0|            0|            0|  0.00%|        Source array
    74|         0|            0|            0|  0.00%|    indices: ndarray (Ni..., J, Nk...)
    75|         0|            0|            0|  0.00%|        Indices to take along each 1d slice of `arr`. This must match the
    76|         0|            0|            0|  0.00%|        dimension of arr, but dimensions Ni and Nj only need to broadcast
    77|         0|            0|            0|  0.00%|        against `arr`.
    78|         0|            0|            0|  0.00%|    axis: int
    79|         0|            0|            0|  0.00%|        The axis to take 1d slices along. If axis is None, the input array is
    80|         0|            0|            0|  0.00%|        treated as if it had first been flattened to 1d, for consistency with
    81|         0|            0|            0|  0.00%|        `sort` and `argsort`.
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|    Returns
    84|         0|            0|            0|  0.00%|    -------
    85|         0|            0|            0|  0.00%|    out: ndarray (Ni..., J, Nk...)
    86|         0|            0|            0|  0.00%|        The indexed result.
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|    Notes
    89|         0|            0|            0|  0.00%|    -----
    90|         0|            0|            0|  0.00%|    This is equivalent to (but faster than) the following use of `ndindex` and
    91|         0|            0|            0|  0.00%|    `s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|        Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]
    94|         0|            0|            0|  0.00%|        J = indices.shape[axis]  # Need not equal M
    95|         0|            0|            0|  0.00%|        out = np.empty(Ni + (J,) + Nk)
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
    98|         0|            0|            0|  0.00%|            for kk in ndindex(Nk):
    99|         0|            0|            0|  0.00%|                a_1d       = a      [ii + s_[:,] + kk]
   100|         0|            0|            0|  0.00%|                indices_1d = indices[ii + s_[:,] + kk]
   101|         0|            0|            0|  0.00%|                out_1d     = out    [ii + s_[:,] + kk]
   102|         0|            0|            0|  0.00%|                for j in range(J):
   103|         0|            0|            0|  0.00%|                    out_1d[j] = a_1d[indices_1d[j]]
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|    Equivalently, eliminating the inner loop, the last two lines would be::
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|                out_1d[:] = a_1d[indices_1d]
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|    See Also
   110|         0|            0|            0|  0.00%|    --------
   111|         0|            0|            0|  0.00%|    take : Take along an axis, using the same indices for every 1d slice
   112|         0|            0|            0|  0.00%|    put_along_axis :
   113|         0|            0|            0|  0.00%|        Put values into the destination array by matching 1d index and data slices
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|    Examples
   116|         0|            0|            0|  0.00%|    --------
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|    For this sample array
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|    >>> a = np.array([[10, 30, 20], [60, 40, 50]])
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|    We can sort either by using sort directly, or argsort and this function
   123|         0|            0|            0|  0.00%|
   124|         0|            0|            0|  0.00%|    >>> np.sort(a, axis=1)
   125|         0|            0|            0|  0.00%|    array([[10, 20, 30],
   126|         0|            0|            0|  0.00%|           [40, 50, 60]])
   127|         0|            0|            0|  0.00%|    >>> ai = np.argsort(a, axis=1); ai
   128|         0|            0|            0|  0.00%|    array([[0, 2, 1],
   129|         0|            0|            0|  0.00%|           [1, 2, 0]])
   130|         0|            0|            0|  0.00%|    >>> np.take_along_axis(a, ai, axis=1)
   131|         0|            0|            0|  0.00%|    array([[10, 20, 30],
   132|         0|            0|            0|  0.00%|           [40, 50, 60]])
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    The same works for max and min, if you expand the dimensions:
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|    >>> np.expand_dims(np.max(a, axis=1), axis=1)
   137|         0|            0|            0|  0.00%|    array([[30],
   138|         0|            0|            0|  0.00%|           [60]])
   139|         0|            0|            0|  0.00%|    >>> ai = np.expand_dims(np.argmax(a, axis=1), axis=1)
   140|         0|            0|            0|  0.00%|    >>> ai
   141|         0|            0|            0|  0.00%|    array([[1],
   142|         0|            0|            0|  0.00%|           [0]])
   143|         0|            0|            0|  0.00%|    >>> np.take_along_axis(a, ai, axis=1)
   144|         0|            0|            0|  0.00%|    array([[30],
   145|         0|            0|            0|  0.00%|           [60]])
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|    If we want to get the max and min at the same time, we can stack the
   148|         0|            0|            0|  0.00%|    indices first
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    >>> ai_min = np.expand_dims(np.argmin(a, axis=1), axis=1)
   151|         0|            0|            0|  0.00%|    >>> ai_max = np.expand_dims(np.argmax(a, axis=1), axis=1)
   152|         0|            0|            0|  0.00%|    >>> ai = np.concatenate([ai_min, ai_max], axis=1)
   153|         0|            0|            0|  0.00%|    >>> ai
   154|         0|            0|            0|  0.00%|    array([[0, 1],
   155|         0|            0|            0|  0.00%|           [1, 0]])
   156|         0|            0|            0|  0.00%|    >>> np.take_along_axis(a, ai, axis=1)
   157|         0|            0|            0|  0.00%|    array([[10, 30],
   158|         0|            0|            0|  0.00%|           [40, 60]])
   159|         0|            0|            0|  0.00%|    """
   160|         0|            0|            0|  0.00%|    # normalize inputs
   161|         0|            0|            0|  0.00%|    if axis is None:
   162|         0|            0|            0|  0.00%|        arr = arr.flat
   163|         0|            0|            0|  0.00%|        arr_shape = (len(arr),)  # flatiter has no .shape
   164|         0|            0|            0|  0.00%|        axis = 0
   165|         0|            0|            0|  0.00%|    else:
   166|         0|            0|            0|  0.00%|        axis = normalize_axis_index(axis, arr.ndim)
   167|         0|            0|            0|  0.00%|        arr_shape = arr.shape
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    # use the fancy index
   170|         0|            0|            0|  0.00%|    return arr[_make_along_axis_idx(arr_shape, indices, axis)]
   171|         0|            0|            0|  0.00%|
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|def _put_along_axis_dispatcher(arr, indices, values, axis):
   174|         0|            0|            0|  0.00%|    return (arr, indices, values)
   175|         0|            0|            0|  0.00%|
   176|         0|            0|            0|  0.00%|
   177|         0|            0|            0|  0.00%|@array_function_dispatch(_put_along_axis_dispatcher)
   178|         0|            0|            0|  0.00%|def put_along_axis(arr, indices, values, axis):
   179|         0|            0|            0|  0.00%|    """
   180|         0|            0|            0|  0.00%|    Put values into the destination array by matching 1d index and data slices.
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|    This iterates over matching 1d slices oriented along the specified axis in
   183|         0|            0|            0|  0.00%|    the index and data arrays, and uses the former to place values into the
   184|         0|            0|            0|  0.00%|    latter. These slices can be different lengths.
   185|         0|            0|            0|  0.00%|
   186|         0|            0|            0|  0.00%|    Functions returning an index along an axis, like `argsort` and
   187|         0|            0|            0|  0.00%|    `argpartition`, produce suitable indices for this function.
   188|         0|            0|            0|  0.00%|
   189|         0|            0|            0|  0.00%|    .. versionadded:: 1.15.0
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|    Parameters
   192|         0|            0|            0|  0.00%|    ----------
   193|         0|            0|            0|  0.00%|    arr: ndarray (Ni..., M, Nk...)
   194|         0|            0|            0|  0.00%|        Destination array.
   195|         0|            0|            0|  0.00%|    indices: ndarray (Ni..., J, Nk...)
   196|         0|            0|            0|  0.00%|        Indices to change along each 1d slice of `arr`. This must match the
   197|         0|            0|            0|  0.00%|        dimension of arr, but dimensions in Ni and Nj may be 1 to broadcast
   198|         0|            0|            0|  0.00%|        against `arr`.
   199|         0|            0|            0|  0.00%|    values: array_like (Ni..., J, Nk...)
   200|         0|            0|            0|  0.00%|        values to insert at those indices. Its shape and dimension are
   201|         0|            0|            0|  0.00%|        broadcast to match that of `indices`.
   202|         0|            0|            0|  0.00%|    axis: int
   203|         0|            0|            0|  0.00%|        The axis to take 1d slices along. If axis is None, the destination
   204|         0|            0|            0|  0.00%|        array is treated as if a flattened 1d view had been created of it.
   205|         0|            0|            0|  0.00%|
   206|         0|            0|            0|  0.00%|    Notes
   207|         0|            0|            0|  0.00%|    -----
   208|         0|            0|            0|  0.00%|    This is equivalent to (but faster than) the following use of `ndindex` and
   209|         0|            0|            0|  0.00%|    `s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::
   210|         0|            0|            0|  0.00%|
   211|         0|            0|            0|  0.00%|        Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]
   212|         0|            0|            0|  0.00%|        J = indices.shape[axis]  # Need not equal M
   213|         0|            0|            0|  0.00%|
   214|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   215|         0|            0|            0|  0.00%|            for kk in ndindex(Nk):
   216|         0|            0|            0|  0.00%|                a_1d       = a      [ii + s_[:,] + kk]
   217|         0|            0|            0|  0.00%|                indices_1d = indices[ii + s_[:,] + kk]
   218|         0|            0|            0|  0.00%|                values_1d  = values [ii + s_[:,] + kk]
   219|         0|            0|            0|  0.00%|                for j in range(J):
   220|         0|            0|            0|  0.00%|                    a_1d[indices_1d[j]] = values_1d[j]
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|    Equivalently, eliminating the inner loop, the last two lines would be::
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|                a_1d[indices_1d] = values_1d
   225|         0|            0|            0|  0.00%|
   226|         0|            0|            0|  0.00%|    See Also
   227|         0|            0|            0|  0.00%|    --------
   228|         0|            0|            0|  0.00%|    take_along_axis :
   229|         0|            0|            0|  0.00%|        Take values from the input array by matching 1d index and data slices
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|    Examples
   232|         0|            0|            0|  0.00%|    --------
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|    For this sample array
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|    >>> a = np.array([[10, 30, 20], [60, 40, 50]])
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|    We can replace the maximum values with:
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|    >>> ai = np.expand_dims(np.argmax(a, axis=1), axis=1)
   241|         0|            0|            0|  0.00%|    >>> ai
   242|         0|            0|            0|  0.00%|    array([[1],
   243|         0|            0|            0|  0.00%|           [0]])
   244|         0|            0|            0|  0.00%|    >>> np.put_along_axis(a, ai, 99, axis=1)
   245|         0|            0|            0|  0.00%|    >>> a
   246|         0|            0|            0|  0.00%|    array([[10, 99, 20],
   247|         0|            0|            0|  0.00%|           [99, 40, 50]])
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|    """
   250|         0|            0|            0|  0.00%|    # normalize inputs
   251|         0|            0|            0|  0.00%|    if axis is None:
   252|         0|            0|            0|  0.00%|        arr = arr.flat
   253|         0|            0|            0|  0.00%|        axis = 0
   254|         0|            0|            0|  0.00%|        arr_shape = (len(arr),)  # flatiter has no .shape
   255|         0|            0|            0|  0.00%|    else:
   256|         0|            0|            0|  0.00%|        axis = normalize_axis_index(axis, arr.ndim)
   257|         0|            0|            0|  0.00%|        arr_shape = arr.shape
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    # use the fancy index
   260|         0|            0|            0|  0.00%|    arr[_make_along_axis_idx(arr_shape, indices, axis)] = values
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|
   263|         1|   2.6226e-06|   2.6226e-06|  0.00%|def _apply_along_axis_dispatcher(func1d, axis, arr, *args, **kwargs):
   264|         1|  6.19888e-06|  6.19888e-06|  0.00%|    return (arr,)
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|
   267|         1|  6.67572e-06|  6.67572e-06|  0.00%|@array_function_dispatch(_apply_along_axis_dispatcher)
   268|         0|            0|            0|  0.00%|def apply_along_axis(func1d, axis, arr, *args, **kwargs):
   269|         0|            0|            0|  0.00%|    """
   270|         0|            0|            0|  0.00%|    Apply a function to 1-D slices along the given axis.
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    Execute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays
   273|         0|            0|            0|  0.00%|    and `a` is a 1-D slice of `arr` along `axis`.
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    This is equivalent to (but faster than) the following use of `ndindex` and
   276|         0|            0|            0|  0.00%|    `s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of indices::
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|        Ni, Nk = a.shape[:axis], a.shape[axis+1:]
   279|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   280|         0|            0|            0|  0.00%|            for kk in ndindex(Nk):
   281|         0|            0|            0|  0.00%|                f = func1d(arr[ii + s_[:,] + kk])
   282|         0|            0|            0|  0.00%|                Nj = f.shape
   283|         0|            0|            0|  0.00%|                for jj in ndindex(Nj):
   284|         0|            0|            0|  0.00%|                    out[ii + jj + kk] = f[jj]
   285|         0|            0|            0|  0.00%|
   286|         0|            0|            0|  0.00%|    Equivalently, eliminating the inner loop, this can be expressed as::
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|        Ni, Nk = a.shape[:axis], a.shape[axis+1:]
   289|         0|            0|            0|  0.00%|        for ii in ndindex(Ni):
   290|         0|            0|            0|  0.00%|            for kk in ndindex(Nk):
   291|         0|            0|            0|  0.00%|                out[ii + s_[...,] + kk] = func1d(arr[ii + s_[:,] + kk])
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|    Parameters
   294|         0|            0|            0|  0.00%|    ----------
   295|         0|            0|            0|  0.00%|    func1d : function (M,) -> (Nj...)
   296|         0|            0|            0|  0.00%|        This function should accept 1-D arrays. It is applied to 1-D
   297|         0|            0|            0|  0.00%|        slices of `arr` along the specified axis.
   298|         0|            0|            0|  0.00%|    axis : integer
   299|         0|            0|            0|  0.00%|        Axis along which `arr` is sliced.
   300|         0|            0|            0|  0.00%|    arr : ndarray (Ni..., M, Nk...)
   301|         0|            0|            0|  0.00%|        Input array.
   302|         0|            0|            0|  0.00%|    args : any
   303|         0|            0|            0|  0.00%|        Additional arguments to `func1d`.
   304|         0|            0|            0|  0.00%|    kwargs : any
   305|         0|            0|            0|  0.00%|        Additional named arguments to `func1d`.
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|        .. versionadded:: 1.9.0
   308|         0|            0|            0|  0.00%|
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|    Returns
   311|         0|            0|            0|  0.00%|    -------
   312|         0|            0|            0|  0.00%|    out : ndarray  (Ni..., Nj..., Nk...)
   313|         0|            0|            0|  0.00%|        The output array. The shape of `out` is identical to the shape of
   314|         0|            0|            0|  0.00%|        `arr`, except along the `axis` dimension. This axis is removed, and
   315|         0|            0|            0|  0.00%|        replaced with new dimensions equal to the shape of the return value
   316|         0|            0|            0|  0.00%|        of `func1d`. So if `func1d` returns a scalar `out` will have one
   317|         0|            0|            0|  0.00%|        fewer dimensions than `arr`.
   318|         0|            0|            0|  0.00%|
   319|         0|            0|            0|  0.00%|    See Also
   320|         0|            0|            0|  0.00%|    --------
   321|         0|            0|            0|  0.00%|    apply_over_axes : Apply a function repeatedly over multiple axes.
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|    Examples
   324|         0|            0|            0|  0.00%|    --------
   325|         0|            0|            0|  0.00%|    >>> def my_func(a):
   326|         0|            0|            0|  0.00%|    ...     \"\"\"Average first and last element of a 1-D array\"\"\"
   327|         0|            0|            0|  0.00%|    ...     return (a[0] + a[-1]) * 0.5
   328|         0|            0|            0|  0.00%|    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])
   329|         0|            0|            0|  0.00%|    >>> np.apply_along_axis(my_func, 0, b)
   330|         0|            0|            0|  0.00%|    array([4., 5., 6.])
   331|         0|            0|            0|  0.00%|    >>> np.apply_along_axis(my_func, 1, b)
   332|         0|            0|            0|  0.00%|    array([2.,  5.,  8.])
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|    For a function that returns a 1D array, the number of dimensions in
   335|         0|            0|            0|  0.00%|    `outarr` is the same as `arr`.
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    >>> b = np.array([[8,1,7], [4,3,9], [5,2,6]])
   338|         0|            0|            0|  0.00%|    >>> np.apply_along_axis(sorted, 1, b)
   339|         0|            0|            0|  0.00%|    array([[1, 7, 8],
   340|         0|            0|            0|  0.00%|           [3, 4, 9],
   341|         0|            0|            0|  0.00%|           [2, 5, 6]])
   342|         0|            0|            0|  0.00%|
   343|         0|            0|            0|  0.00%|    For a function that returns a higher dimensional array, those dimensions
   344|         0|            0|            0|  0.00%|    are inserted in place of the `axis` dimension.
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])
   347|         0|            0|            0|  0.00%|    >>> np.apply_along_axis(np.diag, -1, b)
   348|         0|            0|            0|  0.00%|    array([[[1, 0, 0],
   349|         0|            0|            0|  0.00%|            [0, 2, 0],
   350|         0|            0|            0|  0.00%|            [0, 0, 3]],
   351|         0|            0|            0|  0.00%|           [[4, 0, 0],
   352|         0|            0|            0|  0.00%|            [0, 5, 0],
   353|         0|            0|            0|  0.00%|            [0, 0, 6]],
   354|         0|            0|            0|  0.00%|           [[7, 0, 0],
   355|         0|            0|            0|  0.00%|            [0, 8, 0],
   356|         0|            0|            0|  0.00%|            [0, 0, 9]]])
   357|         0|            0|            0|  0.00%|    """
   358|         0|            0|            0|  0.00%|    # handle negative axes
   359|         1|  1.00136e-05|  1.00136e-05|  0.00%|    arr = asanyarray(arr)
(call)|         1|  7.39098e-06|  7.39098e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:110 asanyarray
   360|         1|  4.29153e-06|  4.29153e-06|  0.00%|    nd = arr.ndim
   361|         1|  4.29153e-06|  4.29153e-06|  0.00%|    axis = normalize_axis_index(axis, nd)
   362|         0|            0|            0|  0.00%|
   363|         0|            0|            0|  0.00%|    # arr, with the iteration axis at the end
   364|         1|  1.07288e-05|  1.07288e-05|  0.00%|    in_dims = list(range(nd))
   365|         1|  9.29832e-06|  9.29832e-06|  0.00%|    inarr_view = transpose(arr, in_dims[:axis] + in_dims[axis+1:] + [axis])
(call)|         1|  4.74453e-05|  4.74453e-05|  0.01%|# <__array_function__ internals>_7:2 transpose
   366|         0|            0|            0|  0.00%|
   367|         0|            0|            0|  0.00%|    # compute indices for the iteration axes, and append a trailing ellipsis to
   368|         0|            0|            0|  0.00%|    # prevent 0d arrays decaying to scalars, which fixes gh-8642
   369|         1|  1.00136e-05|  1.00136e-05|  0.00%|    inds = ndindex(inarr_view.shape[:-1])
(call)|         1|  0.000245333|  0.000245333|  0.03%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/index_tricks.py:647 __init__
   370|      2003|   0.00597787|  2.98446e-06|  0.70%|    inds = (ind + (Ellipsis,) for ind in inds)
(call)|         1|  4.05312e-06|  4.05312e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/index_tricks.py:655 __iter__
(call)|      1001|   0.00446773|  4.46326e-06|  0.52%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/index_tricks.py:674 __next__
   371|         0|            0|            0|  0.00%|
   372|         0|            0|            0|  0.00%|    # invoke the function on the first item
   373|         1|  3.09944e-06|  3.09944e-06|  0.00%|    try:
   374|         1|  7.86781e-06|  7.86781e-06|  0.00%|        ind0 = next(inds)
(call)|         1|  1.66893e-05|  1.66893e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/shape_base.py:370 <genexpr>
   375|         0|            0|            0|  0.00%|    except StopIteration as e:
   376|         0|            0|            0|  0.00%|        raise ValueError(
   377|         0|            0|            0|  0.00%|            'Cannot apply_along_axis when any iteration dimensions are 0'
   378|         0|            0|            0|  0.00%|        ) from None
   379|         1|  2.02656e-05|  2.02656e-05|  0.00%|    res = asanyarray(func1d(inarr_view[ind0], *args, **kwargs))
(call)|         1|  0.000211954|  0.000211954|  0.02%|# /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py:765 _joiner
(call)|         1|  6.67572e-06|  6.67572e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:110 asanyarray
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    # build a buffer for storing evaluations of func1d.
   382|         0|            0|            0|  0.00%|    # remove the requested axis, and add the new ones on the end.
   383|         0|            0|            0|  0.00%|    # laid out so that each write is contiguous.
   384|         0|            0|            0|  0.00%|    # for a tuple index inds, buff[inds] = func1d(inarr_view[inds])
   385|         1|  7.51019e-05|  7.51019e-05|  0.01%|    buff = zeros(inarr_view.shape[:-1] + res.shape, res.dtype)
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|    # permutation of axes such that out = buff.transpose(buff_permute)
   388|         1|   6.4373e-06|   6.4373e-06|  0.00%|    buff_dims = list(range(buff.ndim))
   389|         1|  1.90735e-06|  1.90735e-06|  0.00%|    buff_permute = (
   390|         3|  8.58307e-06|  2.86102e-06|  0.00%|        buff_dims[0 : axis] +
   391|         1|  3.09944e-06|  3.09944e-06|  0.00%|        buff_dims[buff.ndim-res.ndim : buff.ndim] +
   392|         1|  2.38419e-06|  2.38419e-06|  0.00%|        buff_dims[axis : buff.ndim-res.ndim]
   393|         0|            0|            0|  0.00%|    )
   394|         0|            0|            0|  0.00%|
   395|         0|            0|            0|  0.00%|    # matrices have a nasty __array_prepare__ and __array_wrap__
   396|         1|  6.91414e-06|  6.91414e-06|  0.00%|    if not isinstance(res, matrix):
   397|         1|  4.05312e-06|  4.05312e-06|  0.00%|        buff = res.__array_prepare__(buff)
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|    # save the first result, then compute and save all remaining results
   400|         1|  5.00679e-06|  5.00679e-06|  0.00%|    buff[ind0] = res
   401|      1000|   0.00543571|  5.43571e-06|  0.63%|    for ind in inds:
(call)|      1000|    0.0104194|  1.04194e-05|  1.21%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/shape_base.py:370 <genexpr>
   402|       999|    0.0128303|  1.28431e-05|  1.50%|        buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))
(call)|       999|     0.166636|  0.000166803| 19.42%|# /home/robert/Desktop/seldon/alibi/alibi/explainers/anchor_text.py:765 _joiner
(call)|       999|   0.00522304|  5.22826e-06|  0.61%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:110 asanyarray
   403|         0|            0|            0|  0.00%|
   404|         1|  3.09944e-06|  3.09944e-06|  0.00%|    if not isinstance(res, matrix):
   405|         0|            0|            0|  0.00%|        # wrap the array, to preserve subclasses
   406|         1|  1.57356e-05|  1.57356e-05|  0.00%|        buff = res.__array_wrap__(buff)
   407|         0|            0|            0|  0.00%|
   408|         0|            0|            0|  0.00%|        # finally, rotate the inserted axes back to where they belong
   409|         1|  9.53674e-06|  9.53674e-06|  0.00%|        return transpose(buff, buff_permute)
(call)|         1|  3.79086e-05|  3.79086e-05|  0.00%|# <__array_function__ internals>_7:2 transpose
   410|         0|            0|            0|  0.00%|
   411|         0|            0|            0|  0.00%|    else:
   412|         0|            0|            0|  0.00%|        # matrices have to be transposed first, because they collapse dimensions!
   413|         0|            0|            0|  0.00%|        out_arr = transpose(buff, buff_permute)
   414|         0|            0|            0|  0.00%|        return res.__array_wrap__(out_arr)
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|
   417|         0|            0|            0|  0.00%|def _apply_over_axes_dispatcher(func, a, axes):
   418|         0|            0|            0|  0.00%|    return (a,)
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|
   421|         0|            0|            0|  0.00%|@array_function_dispatch(_apply_over_axes_dispatcher)
   422|         0|            0|            0|  0.00%|def apply_over_axes(func, a, axes):
   423|         0|            0|            0|  0.00%|    """
   424|         0|            0|            0|  0.00%|    Apply a function repeatedly over multiple axes.
   425|         0|            0|            0|  0.00%|
   426|         0|            0|            0|  0.00%|    `func` is called as `res = func(a, axis)`, where `axis` is the first
   427|         0|            0|            0|  0.00%|    element of `axes`.  The result `res` of the function call must have
   428|         0|            0|            0|  0.00%|    either the same dimensions as `a` or one less dimension.  If `res`
   429|         0|            0|            0|  0.00%|    has one less dimension than `a`, a dimension is inserted before
   430|         0|            0|            0|  0.00%|    `axis`.  The call to `func` is then repeated for each axis in `axes`,
   431|         0|            0|            0|  0.00%|    with `res` as the first argument.
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|    Parameters
   434|         0|            0|            0|  0.00%|    ----------
   435|         0|            0|            0|  0.00%|    func : function
   436|         0|            0|            0|  0.00%|        This function must take two arguments, `func(a, axis)`.
   437|         0|            0|            0|  0.00%|    a : array_like
   438|         0|            0|            0|  0.00%|        Input array.
   439|         0|            0|            0|  0.00%|    axes : array_like
   440|         0|            0|            0|  0.00%|        Axes over which `func` is applied; the elements must be integers.
   441|         0|            0|            0|  0.00%|
   442|         0|            0|            0|  0.00%|    Returns
   443|         0|            0|            0|  0.00%|    -------
   444|         0|            0|            0|  0.00%|    apply_over_axis : ndarray
   445|         0|            0|            0|  0.00%|        The output array.  The number of dimensions is the same as `a`,
   446|         0|            0|            0|  0.00%|        but the shape can be different.  This depends on whether `func`
   447|         0|            0|            0|  0.00%|        changes the shape of its output with respect to its input.
   448|         0|            0|            0|  0.00%|
   449|         0|            0|            0|  0.00%|    See Also
   450|         0|            0|            0|  0.00%|    --------
   451|         0|            0|            0|  0.00%|    apply_along_axis :
   452|         0|            0|            0|  0.00%|        Apply a function to 1-D slices of an array along the given axis.
   453|         0|            0|            0|  0.00%|
   454|         0|            0|            0|  0.00%|    Notes
   455|         0|            0|            0|  0.00%|    -----
   456|         0|            0|            0|  0.00%|    This function is equivalent to tuple axis arguments to reorderable ufuncs
   457|         0|            0|            0|  0.00%|    with keepdims=True. Tuple axis arguments to ufuncs have been available since
   458|         0|            0|            0|  0.00%|    version 1.7.0.
   459|         0|            0|            0|  0.00%|
   460|         0|            0|            0|  0.00%|    Examples
   461|         0|            0|            0|  0.00%|    --------
   462|         0|            0|            0|  0.00%|    >>> a = np.arange(24).reshape(2,3,4)
   463|         0|            0|            0|  0.00%|    >>> a
   464|         0|            0|            0|  0.00%|    array([[[ 0,  1,  2,  3],
   465|         0|            0|            0|  0.00%|            [ 4,  5,  6,  7],
   466|         0|            0|            0|  0.00%|            [ 8,  9, 10, 11]],
   467|         0|            0|            0|  0.00%|           [[12, 13, 14, 15],
   468|         0|            0|            0|  0.00%|            [16, 17, 18, 19],
   469|         0|            0|            0|  0.00%|            [20, 21, 22, 23]]])
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|    Sum over axes 0 and 2. The result has same number of dimensions
   472|         0|            0|            0|  0.00%|    as the original array:
   473|         0|            0|            0|  0.00%|
   474|         0|            0|            0|  0.00%|    >>> np.apply_over_axes(np.sum, a, [0,2])
   475|         0|            0|            0|  0.00%|    array([[[ 60],
   476|         0|            0|            0|  0.00%|            [ 92],
   477|         0|            0|            0|  0.00%|            [124]]])
   478|         0|            0|            0|  0.00%|
   479|         0|            0|            0|  0.00%|    Tuple axis arguments to ufuncs are equivalent:
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|    >>> np.sum(a, axis=(0,2), keepdims=True)
   482|         0|            0|            0|  0.00%|    array([[[ 60],
   483|         0|            0|            0|  0.00%|            [ 92],
   484|         0|            0|            0|  0.00%|            [124]]])
   485|         0|            0|            0|  0.00%|
   486|         0|            0|            0|  0.00%|    """
   487|         0|            0|            0|  0.00%|    val = asarray(a)
   488|         0|            0|            0|  0.00%|    N = a.ndim
   489|         0|            0|            0|  0.00%|    if array(axes).ndim == 0:
   490|         0|            0|            0|  0.00%|        axes = (axes,)
   491|         0|            0|            0|  0.00%|    for axis in axes:
   492|         0|            0|            0|  0.00%|        if axis < 0:
   493|         0|            0|            0|  0.00%|            axis = N + axis
   494|         0|            0|            0|  0.00%|        args = (val, axis)
   495|         0|            0|            0|  0.00%|        res = func(*args)
   496|         0|            0|            0|  0.00%|        if res.ndim == val.ndim:
   497|         0|            0|            0|  0.00%|            val = res
   498|         0|            0|            0|  0.00%|        else:
   499|         0|            0|            0|  0.00%|            res = expand_dims(res, axis)
   500|         0|            0|            0|  0.00%|            if res.ndim == val.ndim:
   501|         0|            0|            0|  0.00%|                val = res
   502|         0|            0|            0|  0.00%|            else:
   503|         0|            0|            0|  0.00%|                raise ValueError("function is not returning "
   504|         0|            0|            0|  0.00%|                                 "an array of the correct shape")
   505|         0|            0|            0|  0.00%|    return val
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|
   508|         0|            0|            0|  0.00%|def _expand_dims_dispatcher(a, axis):
   509|         0|            0|            0|  0.00%|    return (a,)
   510|         0|            0|            0|  0.00%|
   511|         0|            0|            0|  0.00%|
   512|         0|            0|            0|  0.00%|@array_function_dispatch(_expand_dims_dispatcher)
   513|         0|            0|            0|  0.00%|def expand_dims(a, axis):
   514|         0|            0|            0|  0.00%|    """
   515|         0|            0|            0|  0.00%|    Expand the shape of an array.
   516|         0|            0|            0|  0.00%|
   517|         0|            0|            0|  0.00%|    Insert a new axis that will appear at the `axis` position in the expanded
   518|         0|            0|            0|  0.00%|    array shape.
   519|         0|            0|            0|  0.00%|
   520|         0|            0|            0|  0.00%|    Parameters
   521|         0|            0|            0|  0.00%|    ----------
   522|         0|            0|            0|  0.00%|    a : array_like
   523|         0|            0|            0|  0.00%|        Input array.
   524|         0|            0|            0|  0.00%|    axis : int or tuple of ints
   525|         0|            0|            0|  0.00%|        Position in the expanded axes where the new axis (or axes) is placed.
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|        .. deprecated:: 1.13.0
   528|         0|            0|            0|  0.00%|            Passing an axis where ``axis > a.ndim`` will be treated as
   529|         0|            0|            0|  0.00%|            ``axis == a.ndim``, and passing ``axis < -a.ndim - 1`` will
   530|         0|            0|            0|  0.00%|            be treated as ``axis == 0``. This behavior is deprecated.
   531|         0|            0|            0|  0.00%|
   532|         0|            0|            0|  0.00%|        .. versionchanged:: 1.18.0
   533|         0|            0|            0|  0.00%|            A tuple of axes is now supported.  Out of range axes as
   534|         0|            0|            0|  0.00%|            described above are now forbidden and raise an `AxisError`.
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|    Returns
   537|         0|            0|            0|  0.00%|    -------
   538|         0|            0|            0|  0.00%|    result : ndarray
   539|         0|            0|            0|  0.00%|        View of `a` with the number of dimensions increased.
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|    See Also
   542|         0|            0|            0|  0.00%|    --------
   543|         0|            0|            0|  0.00%|    squeeze : The inverse operation, removing singleton dimensions
   544|         0|            0|            0|  0.00%|    reshape : Insert, remove, and combine dimensions, and resize existing ones
   545|         0|            0|            0|  0.00%|    doc.indexing, atleast_1d, atleast_2d, atleast_3d
   546|         0|            0|            0|  0.00%|
   547|         0|            0|            0|  0.00%|    Examples
   548|         0|            0|            0|  0.00%|    --------
   549|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2])
   550|         0|            0|            0|  0.00%|    >>> x.shape
   551|         0|            0|            0|  0.00%|    (2,)
   552|         0|            0|            0|  0.00%|
   553|         0|            0|            0|  0.00%|    The following is equivalent to ``x[np.newaxis, :]`` or ``x[np.newaxis]``:
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|    >>> y = np.expand_dims(x, axis=0)
   556|         0|            0|            0|  0.00%|    >>> y
   557|         0|            0|            0|  0.00%|    array([[1, 2]])
   558|         0|            0|            0|  0.00%|    >>> y.shape
   559|         0|            0|            0|  0.00%|    (1, 2)
   560|         0|            0|            0|  0.00%|
   561|         0|            0|            0|  0.00%|    The following is equivalent to ``x[:, np.newaxis]``:
   562|         0|            0|            0|  0.00%|
   563|         0|            0|            0|  0.00%|    >>> y = np.expand_dims(x, axis=1)
   564|         0|            0|            0|  0.00%|    >>> y
   565|         0|            0|            0|  0.00%|    array([[1],
   566|         0|            0|            0|  0.00%|           [2]])
   567|         0|            0|            0|  0.00%|    >>> y.shape
   568|         0|            0|            0|  0.00%|    (2, 1)
   569|         0|            0|            0|  0.00%|
   570|         0|            0|            0|  0.00%|    ``axis`` may also be a tuple:
   571|         0|            0|            0|  0.00%|
   572|         0|            0|            0|  0.00%|    >>> y = np.expand_dims(x, axis=(0, 1))
   573|         0|            0|            0|  0.00%|    >>> y
   574|         0|            0|            0|  0.00%|    array([[[1, 2]]])
   575|         0|            0|            0|  0.00%|
   576|         0|            0|            0|  0.00%|    >>> y = np.expand_dims(x, axis=(2, 0))
   577|         0|            0|            0|  0.00%|    >>> y
   578|         0|            0|            0|  0.00%|    array([[[1],
   579|         0|            0|            0|  0.00%|            [2]]])
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    Note that some examples may use ``None`` instead of ``np.newaxis``.  These
   582|         0|            0|            0|  0.00%|    are the same objects:
   583|         0|            0|            0|  0.00%|
   584|         0|            0|            0|  0.00%|    >>> np.newaxis is None
   585|         0|            0|            0|  0.00%|    True
   586|         0|            0|            0|  0.00%|
   587|         0|            0|            0|  0.00%|    """
   588|         0|            0|            0|  0.00%|    if isinstance(a, matrix):
   589|         0|            0|            0|  0.00%|        a = asarray(a)
   590|         0|            0|            0|  0.00%|    else:
   591|         0|            0|            0|  0.00%|        a = asanyarray(a)
   592|         0|            0|            0|  0.00%|
   593|         0|            0|            0|  0.00%|    if type(axis) not in (tuple, list):
   594|         0|            0|            0|  0.00%|        axis = (axis,)
   595|         0|            0|            0|  0.00%|
   596|         0|            0|            0|  0.00%|    out_ndim = len(axis) + a.ndim
   597|         0|            0|            0|  0.00%|    axis = normalize_axis_tuple(axis, out_ndim)
   598|         0|            0|            0|  0.00%|
   599|         0|            0|            0|  0.00%|    shape_it = iter(a.shape)
   600|         0|            0|            0|  0.00%|    shape = [1 if ax in axis else next(shape_it) for ax in range(out_ndim)]
   601|         0|            0|            0|  0.00%|
   602|         0|            0|            0|  0.00%|    return a.reshape(shape)
   603|         0|            0|            0|  0.00%|
   604|         0|            0|            0|  0.00%|
   605|         0|            0|            0|  0.00%|row_stack = vstack
   606|         0|            0|            0|  0.00%|
   607|         0|            0|            0|  0.00%|
   608|         0|            0|            0|  0.00%|def _column_stack_dispatcher(tup):
   609|         0|            0|            0|  0.00%|    return _arrays_for_stack_dispatcher(tup)
   610|         0|            0|            0|  0.00%|
   611|         0|            0|            0|  0.00%|
   612|         0|            0|            0|  0.00%|@array_function_dispatch(_column_stack_dispatcher)
   613|         0|            0|            0|  0.00%|def column_stack(tup):
   614|         0|            0|            0|  0.00%|    """
   615|         0|            0|            0|  0.00%|    Stack 1-D arrays as columns into a 2-D array.
   616|         0|            0|            0|  0.00%|
   617|         0|            0|            0|  0.00%|    Take a sequence of 1-D arrays and stack them as columns
   618|         0|            0|            0|  0.00%|    to make a single 2-D array. 2-D arrays are stacked as-is,
   619|         0|            0|            0|  0.00%|    just like with `hstack`.  1-D arrays are turned into 2-D columns
   620|         0|            0|            0|  0.00%|    first.
   621|         0|            0|            0|  0.00%|
   622|         0|            0|            0|  0.00%|    Parameters
   623|         0|            0|            0|  0.00%|    ----------
   624|         0|            0|            0|  0.00%|    tup : sequence of 1-D or 2-D arrays.
   625|         0|            0|            0|  0.00%|        Arrays to stack. All of them must have the same first dimension.
   626|         0|            0|            0|  0.00%|
   627|         0|            0|            0|  0.00%|    Returns
   628|         0|            0|            0|  0.00%|    -------
   629|         0|            0|            0|  0.00%|    stacked : 2-D array
   630|         0|            0|            0|  0.00%|        The array formed by stacking the given arrays.
   631|         0|            0|            0|  0.00%|
   632|         0|            0|            0|  0.00%|    See Also
   633|         0|            0|            0|  0.00%|    --------
   634|         0|            0|            0|  0.00%|    stack, hstack, vstack, concatenate
   635|         0|            0|            0|  0.00%|
   636|         0|            0|            0|  0.00%|    Examples
   637|         0|            0|            0|  0.00%|    --------
   638|         0|            0|            0|  0.00%|    >>> a = np.array((1,2,3))
   639|         0|            0|            0|  0.00%|    >>> b = np.array((2,3,4))
   640|         0|            0|            0|  0.00%|    >>> np.column_stack((a,b))
   641|         0|            0|            0|  0.00%|    array([[1, 2],
   642|         0|            0|            0|  0.00%|           [2, 3],
   643|         0|            0|            0|  0.00%|           [3, 4]])
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|    """
   646|         0|            0|            0|  0.00%|    if not overrides.ARRAY_FUNCTION_ENABLED:
   647|         0|            0|            0|  0.00%|        # raise warning if necessary
   648|         0|            0|            0|  0.00%|        _arrays_for_stack_dispatcher(tup, stacklevel=2)
   649|         0|            0|            0|  0.00%|
   650|         0|            0|            0|  0.00%|    arrays = []
   651|         0|            0|            0|  0.00%|    for v in tup:
   652|         0|            0|            0|  0.00%|        arr = array(v, copy=False, subok=True)
   653|         0|            0|            0|  0.00%|        if arr.ndim < 2:
   654|         0|            0|            0|  0.00%|            arr = array(arr, copy=False, subok=True, ndmin=2).T
   655|         0|            0|            0|  0.00%|        arrays.append(arr)
   656|         0|            0|            0|  0.00%|    return _nx.concatenate(arrays, 1)
   657|         0|            0|            0|  0.00%|
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|def _dstack_dispatcher(tup):
   660|         0|            0|            0|  0.00%|    return _arrays_for_stack_dispatcher(tup)
   661|         0|            0|            0|  0.00%|
   662|         0|            0|            0|  0.00%|
   663|         0|            0|            0|  0.00%|@array_function_dispatch(_dstack_dispatcher)
   664|         0|            0|            0|  0.00%|def dstack(tup):
   665|         0|            0|            0|  0.00%|    """
   666|         0|            0|            0|  0.00%|    Stack arrays in sequence depth wise (along third axis).
   667|         0|            0|            0|  0.00%|
   668|         0|            0|            0|  0.00%|    This is equivalent to concatenation along the third axis after 2-D arrays
   669|         0|            0|            0|  0.00%|    of shape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape
   670|         0|            0|            0|  0.00%|    `(N,)` have been reshaped to `(1,N,1)`. Rebuilds arrays divided by
   671|         0|            0|            0|  0.00%|    `dsplit`.
   672|         0|            0|            0|  0.00%|
   673|         0|            0|            0|  0.00%|    This function makes most sense for arrays with up to 3 dimensions. For
   674|         0|            0|            0|  0.00%|    instance, for pixel-data with a height (first axis), width (second axis),
   675|         0|            0|            0|  0.00%|    and r/g/b channels (third axis). The functions `concatenate`, `stack` and
   676|         0|            0|            0|  0.00%|    `block` provide more general stacking and concatenation operations.
   677|         0|            0|            0|  0.00%|
   678|         0|            0|            0|  0.00%|    Parameters
   679|         0|            0|            0|  0.00%|    ----------
   680|         0|            0|            0|  0.00%|    tup : sequence of arrays
   681|         0|            0|            0|  0.00%|        The arrays must have the same shape along all but the third axis.
   682|         0|            0|            0|  0.00%|        1-D or 2-D arrays must have the same shape.
   683|         0|            0|            0|  0.00%|
   684|         0|            0|            0|  0.00%|    Returns
   685|         0|            0|            0|  0.00%|    -------
   686|         0|            0|            0|  0.00%|    stacked : ndarray
   687|         0|            0|            0|  0.00%|        The array formed by stacking the given arrays, will be at least 3-D.
   688|         0|            0|            0|  0.00%|
   689|         0|            0|            0|  0.00%|    See Also
   690|         0|            0|            0|  0.00%|    --------
   691|         0|            0|            0|  0.00%|    concatenate : Join a sequence of arrays along an existing axis.
   692|         0|            0|            0|  0.00%|    stack : Join a sequence of arrays along a new axis.
   693|         0|            0|            0|  0.00%|    block : Assemble an nd-array from nested lists of blocks.
   694|         0|            0|            0|  0.00%|    vstack : Stack arrays in sequence vertically (row wise).
   695|         0|            0|            0|  0.00%|    hstack : Stack arrays in sequence horizontally (column wise).
   696|         0|            0|            0|  0.00%|    column_stack : Stack 1-D arrays as columns into a 2-D array.
   697|         0|            0|            0|  0.00%|    dsplit : Split array along third axis.
   698|         0|            0|            0|  0.00%|
   699|         0|            0|            0|  0.00%|    Examples
   700|         0|            0|            0|  0.00%|    --------
   701|         0|            0|            0|  0.00%|    >>> a = np.array((1,2,3))
   702|         0|            0|            0|  0.00%|    >>> b = np.array((2,3,4))
   703|         0|            0|            0|  0.00%|    >>> np.dstack((a,b))
   704|         0|            0|            0|  0.00%|    array([[[1, 2],
   705|         0|            0|            0|  0.00%|            [2, 3],
   706|         0|            0|            0|  0.00%|            [3, 4]]])
   707|         0|            0|            0|  0.00%|
   708|         0|            0|            0|  0.00%|    >>> a = np.array([[1],[2],[3]])
   709|         0|            0|            0|  0.00%|    >>> b = np.array([[2],[3],[4]])
   710|         0|            0|            0|  0.00%|    >>> np.dstack((a,b))
   711|         0|            0|            0|  0.00%|    array([[[1, 2]],
   712|         0|            0|            0|  0.00%|           [[2, 3]],
   713|         0|            0|            0|  0.00%|           [[3, 4]]])
   714|         0|            0|            0|  0.00%|
   715|         0|            0|            0|  0.00%|    """
   716|         0|            0|            0|  0.00%|    if not overrides.ARRAY_FUNCTION_ENABLED:
   717|         0|            0|            0|  0.00%|        # raise warning if necessary
   718|         0|            0|            0|  0.00%|        _arrays_for_stack_dispatcher(tup, stacklevel=2)
   719|         0|            0|            0|  0.00%|
   720|         0|            0|            0|  0.00%|    arrs = atleast_3d(*tup)
   721|         0|            0|            0|  0.00%|    if not isinstance(arrs, list):
   722|         0|            0|            0|  0.00%|        arrs = [arrs]
   723|         0|            0|            0|  0.00%|    return _nx.concatenate(arrs, 2)
   724|         0|            0|            0|  0.00%|
   725|         0|            0|            0|  0.00%|
   726|         0|            0|            0|  0.00%|def _replace_zero_by_x_arrays(sub_arys):
   727|         0|            0|            0|  0.00%|    for i in range(len(sub_arys)):
   728|         0|            0|            0|  0.00%|        if _nx.ndim(sub_arys[i]) == 0:
   729|         0|            0|            0|  0.00%|            sub_arys[i] = _nx.empty(0, dtype=sub_arys[i].dtype)
   730|         0|            0|            0|  0.00%|        elif _nx.sometrue(_nx.equal(_nx.shape(sub_arys[i]), 0)):
   731|         0|            0|            0|  0.00%|            sub_arys[i] = _nx.empty(0, dtype=sub_arys[i].dtype)
   732|         0|            0|            0|  0.00%|    return sub_arys
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|def _array_split_dispatcher(ary, indices_or_sections, axis=None):
   736|         0|            0|            0|  0.00%|    return (ary, indices_or_sections)
   737|         0|            0|            0|  0.00%|
   738|         0|            0|            0|  0.00%|
   739|         0|            0|            0|  0.00%|@array_function_dispatch(_array_split_dispatcher)
   740|         0|            0|            0|  0.00%|def array_split(ary, indices_or_sections, axis=0):
   741|         0|            0|            0|  0.00%|    """
   742|         0|            0|            0|  0.00%|    Split an array into multiple sub-arrays.
   743|         0|            0|            0|  0.00%|
   744|         0|            0|            0|  0.00%|    Please refer to the ``split`` documentation.  The only difference
   745|         0|            0|            0|  0.00%|    between these functions is that ``array_split`` allows
   746|         0|            0|            0|  0.00%|    `indices_or_sections` to be an integer that does *not* equally
   747|         0|            0|            0|  0.00%|    divide the axis. For an array of length l that should be split
   748|         0|            0|            0|  0.00%|    into n sections, it returns l % n sub-arrays of size l//n + 1
   749|         0|            0|            0|  0.00%|    and the rest of size l//n.
   750|         0|            0|            0|  0.00%|
   751|         0|            0|            0|  0.00%|    See Also
   752|         0|            0|            0|  0.00%|    --------
   753|         0|            0|            0|  0.00%|    split : Split array into multiple sub-arrays of equal size.
   754|         0|            0|            0|  0.00%|
   755|         0|            0|            0|  0.00%|    Examples
   756|         0|            0|            0|  0.00%|    --------
   757|         0|            0|            0|  0.00%|    >>> x = np.arange(8.0)
   758|         0|            0|            0|  0.00%|    >>> np.array_split(x, 3)
   759|         0|            0|            0|  0.00%|    [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]
   760|         0|            0|            0|  0.00%|
   761|         0|            0|            0|  0.00%|    >>> x = np.arange(9)
   762|         0|            0|            0|  0.00%|    >>> np.array_split(x, 4)
   763|         0|            0|            0|  0.00%|    [array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]
   764|         0|            0|            0|  0.00%|
   765|         0|            0|            0|  0.00%|    """
   766|         0|            0|            0|  0.00%|    try:
   767|         0|            0|            0|  0.00%|        Ntotal = ary.shape[axis]
   768|         0|            0|            0|  0.00%|    except AttributeError:
   769|         0|            0|            0|  0.00%|        Ntotal = len(ary)
   770|         0|            0|            0|  0.00%|    try:
   771|         0|            0|            0|  0.00%|        # handle array case.
   772|         0|            0|            0|  0.00%|        Nsections = len(indices_or_sections) + 1
   773|         0|            0|            0|  0.00%|        div_points = [0] + list(indices_or_sections) + [Ntotal]
   774|         0|            0|            0|  0.00%|    except TypeError:
   775|         0|            0|            0|  0.00%|        # indices_or_sections is a scalar, not an array.
   776|         0|            0|            0|  0.00%|        Nsections = int(indices_or_sections)
   777|         0|            0|            0|  0.00%|        if Nsections <= 0:
   778|         0|            0|            0|  0.00%|            raise ValueError('number sections must be larger than 0.')
   779|         0|            0|            0|  0.00%|        Neach_section, extras = divmod(Ntotal, Nsections)
   780|         0|            0|            0|  0.00%|        section_sizes = ([0] +
   781|         0|            0|            0|  0.00%|                         extras * [Neach_section+1] +
   782|         0|            0|            0|  0.00%|                         (Nsections-extras) * [Neach_section])
   783|         0|            0|            0|  0.00%|        div_points = _nx.array(section_sizes, dtype=_nx.intp).cumsum()
   784|         0|            0|            0|  0.00%|
   785|         0|            0|            0|  0.00%|    sub_arys = []
   786|         0|            0|            0|  0.00%|    sary = _nx.swapaxes(ary, axis, 0)
   787|         0|            0|            0|  0.00%|    for i in range(Nsections):
   788|         0|            0|            0|  0.00%|        st = div_points[i]
   789|         0|            0|            0|  0.00%|        end = div_points[i + 1]
   790|         0|            0|            0|  0.00%|        sub_arys.append(_nx.swapaxes(sary[st:end], axis, 0))
   791|         0|            0|            0|  0.00%|
   792|         0|            0|            0|  0.00%|    return sub_arys
   793|         0|            0|            0|  0.00%|
   794|         0|            0|            0|  0.00%|
   795|         0|            0|            0|  0.00%|def _split_dispatcher(ary, indices_or_sections, axis=None):
   796|         0|            0|            0|  0.00%|    return (ary, indices_or_sections)
   797|         0|            0|            0|  0.00%|
   798|         0|            0|            0|  0.00%|
   799|         0|            0|            0|  0.00%|@array_function_dispatch(_split_dispatcher)
   800|         0|            0|            0|  0.00%|def split(ary, indices_or_sections, axis=0):
   801|         0|            0|            0|  0.00%|    """
   802|         0|            0|            0|  0.00%|    Split an array into multiple sub-arrays as views into `ary`.
   803|         0|            0|            0|  0.00%|
   804|         0|            0|            0|  0.00%|    Parameters
   805|         0|            0|            0|  0.00%|    ----------
   806|         0|            0|            0|  0.00%|    ary : ndarray
   807|         0|            0|            0|  0.00%|        Array to be divided into sub-arrays.
   808|         0|            0|            0|  0.00%|    indices_or_sections : int or 1-D array
   809|         0|            0|            0|  0.00%|        If `indices_or_sections` is an integer, N, the array will be divided
   810|         0|            0|            0|  0.00%|        into N equal arrays along `axis`.  If such a split is not possible,
   811|         0|            0|            0|  0.00%|        an error is raised.
   812|         0|            0|            0|  0.00%|
   813|         0|            0|            0|  0.00%|        If `indices_or_sections` is a 1-D array of sorted integers, the entries
   814|         0|            0|            0|  0.00%|        indicate where along `axis` the array is split.  For example,
   815|         0|            0|            0|  0.00%|        ``[2, 3]`` would, for ``axis=0``, result in
   816|         0|            0|            0|  0.00%|
   817|         0|            0|            0|  0.00%|          - ary[:2]
   818|         0|            0|            0|  0.00%|          - ary[2:3]
   819|         0|            0|            0|  0.00%|          - ary[3:]
   820|         0|            0|            0|  0.00%|
   821|         0|            0|            0|  0.00%|        If an index exceeds the dimension of the array along `axis`,
   822|         0|            0|            0|  0.00%|        an empty sub-array is returned correspondingly.
   823|         0|            0|            0|  0.00%|    axis : int, optional
   824|         0|            0|            0|  0.00%|        The axis along which to split, default is 0.
   825|         0|            0|            0|  0.00%|
   826|         0|            0|            0|  0.00%|    Returns
   827|         0|            0|            0|  0.00%|    -------
   828|         0|            0|            0|  0.00%|    sub-arrays : list of ndarrays
   829|         0|            0|            0|  0.00%|        A list of sub-arrays as views into `ary`.
   830|         0|            0|            0|  0.00%|
   831|         0|            0|            0|  0.00%|    Raises
   832|         0|            0|            0|  0.00%|    ------
   833|         0|            0|            0|  0.00%|    ValueError
   834|         0|            0|            0|  0.00%|        If `indices_or_sections` is given as an integer, but
   835|         0|            0|            0|  0.00%|        a split does not result in equal division.
   836|         0|            0|            0|  0.00%|
   837|         0|            0|            0|  0.00%|    See Also
   838|         0|            0|            0|  0.00%|    --------
   839|         0|            0|            0|  0.00%|    array_split : Split an array into multiple sub-arrays of equal or
   840|         0|            0|            0|  0.00%|                  near-equal size.  Does not raise an exception if
   841|         0|            0|            0|  0.00%|                  an equal division cannot be made.
   842|         0|            0|            0|  0.00%|    hsplit : Split array into multiple sub-arrays horizontally (column-wise).
   843|         0|            0|            0|  0.00%|    vsplit : Split array into multiple sub-arrays vertically (row wise).
   844|         0|            0|            0|  0.00%|    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).
   845|         0|            0|            0|  0.00%|    concatenate : Join a sequence of arrays along an existing axis.
   846|         0|            0|            0|  0.00%|    stack : Join a sequence of arrays along a new axis.
   847|         0|            0|            0|  0.00%|    hstack : Stack arrays in sequence horizontally (column wise).
   848|         0|            0|            0|  0.00%|    vstack : Stack arrays in sequence vertically (row wise).
   849|         0|            0|            0|  0.00%|    dstack : Stack arrays in sequence depth wise (along third dimension).
   850|         0|            0|            0|  0.00%|
   851|         0|            0|            0|  0.00%|    Examples
   852|         0|            0|            0|  0.00%|    --------
   853|         0|            0|            0|  0.00%|    >>> x = np.arange(9.0)
   854|         0|            0|            0|  0.00%|    >>> np.split(x, 3)
   855|         0|            0|            0|  0.00%|    [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.,  8.])]
   856|         0|            0|            0|  0.00%|
   857|         0|            0|            0|  0.00%|    >>> x = np.arange(8.0)
   858|         0|            0|            0|  0.00%|    >>> np.split(x, [3, 5, 6, 10])
   859|         0|            0|            0|  0.00%|    [array([0.,  1.,  2.]),
   860|         0|            0|            0|  0.00%|     array([3.,  4.]),
   861|         0|            0|            0|  0.00%|     array([5.]),
   862|         0|            0|            0|  0.00%|     array([6.,  7.]),
   863|         0|            0|            0|  0.00%|     array([], dtype=float64)]
   864|         0|            0|            0|  0.00%|
   865|         0|            0|            0|  0.00%|    """
   866|         0|            0|            0|  0.00%|    try:
   867|         0|            0|            0|  0.00%|        len(indices_or_sections)
   868|         0|            0|            0|  0.00%|    except TypeError:
   869|         0|            0|            0|  0.00%|        sections = indices_or_sections
   870|         0|            0|            0|  0.00%|        N = ary.shape[axis]
   871|         0|            0|            0|  0.00%|        if N % sections:
   872|         0|            0|            0|  0.00%|            raise ValueError(
   873|         0|            0|            0|  0.00%|                'array split does not result in an equal division') from None
   874|         0|            0|            0|  0.00%|    return array_split(ary, indices_or_sections, axis)
   875|         0|            0|            0|  0.00%|
   876|         0|            0|            0|  0.00%|
   877|         0|            0|            0|  0.00%|def _hvdsplit_dispatcher(ary, indices_or_sections):
   878|         0|            0|            0|  0.00%|    return (ary, indices_or_sections)
   879|         0|            0|            0|  0.00%|
   880|         0|            0|            0|  0.00%|
   881|         0|            0|            0|  0.00%|@array_function_dispatch(_hvdsplit_dispatcher)
   882|         0|            0|            0|  0.00%|def hsplit(ary, indices_or_sections):
   883|         0|            0|            0|  0.00%|    """
   884|         0|            0|            0|  0.00%|    Split an array into multiple sub-arrays horizontally (column-wise).
   885|         0|            0|            0|  0.00%|
   886|         0|            0|            0|  0.00%|    Please refer to the `split` documentation.  `hsplit` is equivalent
   887|         0|            0|            0|  0.00%|    to `split` with ``axis=1``, the array is always split along the second
   888|         0|            0|            0|  0.00%|    axis regardless of the array dimension.
   889|         0|            0|            0|  0.00%|
   890|         0|            0|            0|  0.00%|    See Also
   891|         0|            0|            0|  0.00%|    --------
   892|         0|            0|            0|  0.00%|    split : Split an array into multiple sub-arrays of equal size.
   893|         0|            0|            0|  0.00%|
   894|         0|            0|            0|  0.00%|    Examples
   895|         0|            0|            0|  0.00%|    --------
   896|         0|            0|            0|  0.00%|    >>> x = np.arange(16.0).reshape(4, 4)
   897|         0|            0|            0|  0.00%|    >>> x
   898|         0|            0|            0|  0.00%|    array([[ 0.,   1.,   2.,   3.],
   899|         0|            0|            0|  0.00%|           [ 4.,   5.,   6.,   7.],
   900|         0|            0|            0|  0.00%|           [ 8.,   9.,  10.,  11.],
   901|         0|            0|            0|  0.00%|           [12.,  13.,  14.,  15.]])
   902|         0|            0|            0|  0.00%|    >>> np.hsplit(x, 2)
   903|         0|            0|            0|  0.00%|    [array([[  0.,   1.],
   904|         0|            0|            0|  0.00%|           [  4.,   5.],
   905|         0|            0|            0|  0.00%|           [  8.,   9.],
   906|         0|            0|            0|  0.00%|           [12.,  13.]]),
   907|         0|            0|            0|  0.00%|     array([[  2.,   3.],
   908|         0|            0|            0|  0.00%|           [  6.,   7.],
   909|         0|            0|            0|  0.00%|           [10.,  11.],
   910|         0|            0|            0|  0.00%|           [14.,  15.]])]
   911|         0|            0|            0|  0.00%|    >>> np.hsplit(x, np.array([3, 6]))
   912|         0|            0|            0|  0.00%|    [array([[ 0.,   1.,   2.],
   913|         0|            0|            0|  0.00%|           [ 4.,   5.,   6.],
   914|         0|            0|            0|  0.00%|           [ 8.,   9.,  10.],
   915|         0|            0|            0|  0.00%|           [12.,  13.,  14.]]),
   916|         0|            0|            0|  0.00%|     array([[ 3.],
   917|         0|            0|            0|  0.00%|           [ 7.],
   918|         0|            0|            0|  0.00%|           [11.],
   919|         0|            0|            0|  0.00%|           [15.]]),
   920|         0|            0|            0|  0.00%|     array([], shape=(4, 0), dtype=float64)]
   921|         0|            0|            0|  0.00%|
   922|         0|            0|            0|  0.00%|    With a higher dimensional array the split is still along the second axis.
   923|         0|            0|            0|  0.00%|
   924|         0|            0|            0|  0.00%|    >>> x = np.arange(8.0).reshape(2, 2, 2)
   925|         0|            0|            0|  0.00%|    >>> x
   926|         0|            0|            0|  0.00%|    array([[[0.,  1.],
   927|         0|            0|            0|  0.00%|            [2.,  3.]],
   928|         0|            0|            0|  0.00%|           [[4.,  5.],
   929|         0|            0|            0|  0.00%|            [6.,  7.]]])
   930|         0|            0|            0|  0.00%|    >>> np.hsplit(x, 2)
   931|         0|            0|            0|  0.00%|    [array([[[0.,  1.]],
   932|         0|            0|            0|  0.00%|           [[4.,  5.]]]),
   933|         0|            0|            0|  0.00%|     array([[[2.,  3.]],
   934|         0|            0|            0|  0.00%|           [[6.,  7.]]])]
   935|         0|            0|            0|  0.00%|
   936|         0|            0|            0|  0.00%|    """
   937|         0|            0|            0|  0.00%|    if _nx.ndim(ary) == 0:
   938|         0|            0|            0|  0.00%|        raise ValueError('hsplit only works on arrays of 1 or more dimensions')
   939|         0|            0|            0|  0.00%|    if ary.ndim > 1:
   940|         0|            0|            0|  0.00%|        return split(ary, indices_or_sections, 1)
   941|         0|            0|            0|  0.00%|    else:
   942|         0|            0|            0|  0.00%|        return split(ary, indices_or_sections, 0)
   943|         0|            0|            0|  0.00%|
   944|         0|            0|            0|  0.00%|
   945|         0|            0|            0|  0.00%|@array_function_dispatch(_hvdsplit_dispatcher)
   946|         0|            0|            0|  0.00%|def vsplit(ary, indices_or_sections):
   947|         0|            0|            0|  0.00%|    """
   948|         0|            0|            0|  0.00%|    Split an array into multiple sub-arrays vertically (row-wise).
   949|         0|            0|            0|  0.00%|
   950|         0|            0|            0|  0.00%|    Please refer to the ``split`` documentation.  ``vsplit`` is equivalent
   951|         0|            0|            0|  0.00%|    to ``split`` with `axis=0` (default), the array is always split along the
   952|         0|            0|            0|  0.00%|    first axis regardless of the array dimension.
   953|         0|            0|            0|  0.00%|
   954|         0|            0|            0|  0.00%|    See Also
   955|         0|            0|            0|  0.00%|    --------
   956|         0|            0|            0|  0.00%|    split : Split an array into multiple sub-arrays of equal size.
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|    Examples
   959|         0|            0|            0|  0.00%|    --------
   960|         0|            0|            0|  0.00%|    >>> x = np.arange(16.0).reshape(4, 4)
   961|         0|            0|            0|  0.00%|    >>> x
   962|         0|            0|            0|  0.00%|    array([[ 0.,   1.,   2.,   3.],
   963|         0|            0|            0|  0.00%|           [ 4.,   5.,   6.,   7.],
   964|         0|            0|            0|  0.00%|           [ 8.,   9.,  10.,  11.],
   965|         0|            0|            0|  0.00%|           [12.,  13.,  14.,  15.]])
   966|         0|            0|            0|  0.00%|    >>> np.vsplit(x, 2)
   967|         0|            0|            0|  0.00%|    [array([[0., 1., 2., 3.],
   968|         0|            0|            0|  0.00%|           [4., 5., 6., 7.]]), array([[ 8.,  9., 10., 11.],
   969|         0|            0|            0|  0.00%|           [12., 13., 14., 15.]])]
   970|         0|            0|            0|  0.00%|    >>> np.vsplit(x, np.array([3, 6]))
   971|         0|            0|            0|  0.00%|    [array([[ 0.,  1.,  2.,  3.],
   972|         0|            0|            0|  0.00%|           [ 4.,  5.,  6.,  7.],
   973|         0|            0|            0|  0.00%|           [ 8.,  9., 10., 11.]]), array([[12., 13., 14., 15.]]), array([], shape=(0, 4), dtype=float64)]
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|    With a higher dimensional array the split is still along the first axis.
   976|         0|            0|            0|  0.00%|
   977|         0|            0|            0|  0.00%|    >>> x = np.arange(8.0).reshape(2, 2, 2)
   978|         0|            0|            0|  0.00%|    >>> x
   979|         0|            0|            0|  0.00%|    array([[[0.,  1.],
   980|         0|            0|            0|  0.00%|            [2.,  3.]],
   981|         0|            0|            0|  0.00%|           [[4.,  5.],
   982|         0|            0|            0|  0.00%|            [6.,  7.]]])
   983|         0|            0|            0|  0.00%|    >>> np.vsplit(x, 2)
   984|         0|            0|            0|  0.00%|    [array([[[0., 1.],
   985|         0|            0|            0|  0.00%|            [2., 3.]]]), array([[[4., 5.],
   986|         0|            0|            0|  0.00%|            [6., 7.]]])]
   987|         0|            0|            0|  0.00%|
   988|         0|            0|            0|  0.00%|    """
   989|         0|            0|            0|  0.00%|    if _nx.ndim(ary) < 2:
   990|         0|            0|            0|  0.00%|        raise ValueError('vsplit only works on arrays of 2 or more dimensions')
   991|         0|            0|            0|  0.00%|    return split(ary, indices_or_sections, 0)
   992|         0|            0|            0|  0.00%|
   993|         0|            0|            0|  0.00%|
   994|         0|            0|            0|  0.00%|@array_function_dispatch(_hvdsplit_dispatcher)
   995|         0|            0|            0|  0.00%|def dsplit(ary, indices_or_sections):
   996|         0|            0|            0|  0.00%|    """
   997|         0|            0|            0|  0.00%|    Split array into multiple sub-arrays along the 3rd axis (depth).
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|    Please refer to the `split` documentation.  `dsplit` is equivalent
  1000|         0|            0|            0|  0.00%|    to `split` with ``axis=2``, the array is always split along the third
  1001|         0|            0|            0|  0.00%|    axis provided the array dimension is greater than or equal to 3.
  1002|         0|            0|            0|  0.00%|
  1003|         0|            0|            0|  0.00%|    See Also
  1004|         0|            0|            0|  0.00%|    --------
  1005|         0|            0|            0|  0.00%|    split : Split an array into multiple sub-arrays of equal size.
  1006|         0|            0|            0|  0.00%|
  1007|         0|            0|            0|  0.00%|    Examples
  1008|         0|            0|            0|  0.00%|    --------
  1009|         0|            0|            0|  0.00%|    >>> x = np.arange(16.0).reshape(2, 2, 4)
  1010|         0|            0|            0|  0.00%|    >>> x
  1011|         0|            0|            0|  0.00%|    array([[[ 0.,   1.,   2.,   3.],
  1012|         0|            0|            0|  0.00%|            [ 4.,   5.,   6.,   7.]],
  1013|         0|            0|            0|  0.00%|           [[ 8.,   9.,  10.,  11.],
  1014|         0|            0|            0|  0.00%|            [12.,  13.,  14.,  15.]]])
  1015|         0|            0|            0|  0.00%|    >>> np.dsplit(x, 2)
  1016|         0|            0|            0|  0.00%|    [array([[[ 0.,  1.],
  1017|         0|            0|            0|  0.00%|            [ 4.,  5.]],
  1018|         0|            0|            0|  0.00%|           [[ 8.,  9.],
  1019|         0|            0|            0|  0.00%|            [12., 13.]]]), array([[[ 2.,  3.],
  1020|         0|            0|            0|  0.00%|            [ 6.,  7.]],
  1021|         0|            0|            0|  0.00%|           [[10., 11.],
  1022|         0|            0|            0|  0.00%|            [14., 15.]]])]
  1023|         0|            0|            0|  0.00%|    >>> np.dsplit(x, np.array([3, 6]))
  1024|         0|            0|            0|  0.00%|    [array([[[ 0.,   1.,   2.],
  1025|         0|            0|            0|  0.00%|            [ 4.,   5.,   6.]],
  1026|         0|            0|            0|  0.00%|           [[ 8.,   9.,  10.],
  1027|         0|            0|            0|  0.00%|            [12.,  13.,  14.]]]),
  1028|         0|            0|            0|  0.00%|     array([[[ 3.],
  1029|         0|            0|            0|  0.00%|            [ 7.]],
  1030|         0|            0|            0|  0.00%|           [[11.],
  1031|         0|            0|            0|  0.00%|            [15.]]]),
  1032|         0|            0|            0|  0.00%|    array([], shape=(2, 2, 0), dtype=float64)]
  1033|         0|            0|            0|  0.00%|    """
  1034|         0|            0|            0|  0.00%|    if _nx.ndim(ary) < 3:
  1035|         0|            0|            0|  0.00%|        raise ValueError('dsplit only works on arrays of 3 or more dimensions')
  1036|         0|            0|            0|  0.00%|    return split(ary, indices_or_sections, 2)
  1037|         0|            0|            0|  0.00%|
  1038|         0|            0|            0|  0.00%|def get_array_prepare(*args):
  1039|         0|            0|            0|  0.00%|    """Find the wrapper for the array with the highest priority.
  1040|         0|            0|            0|  0.00%|
  1041|         0|            0|            0|  0.00%|    In case of ties, leftmost wins. If no wrapper is found, return None
  1042|         0|            0|            0|  0.00%|    """
  1043|         0|            0|            0|  0.00%|    wrappers = sorted((getattr(x, '__array_priority__', 0), -i,
  1044|         0|            0|            0|  0.00%|                 x.__array_prepare__) for i, x in enumerate(args)
  1045|         0|            0|            0|  0.00%|                                   if hasattr(x, '__array_prepare__'))
  1046|         0|            0|            0|  0.00%|    if wrappers:
  1047|         0|            0|            0|  0.00%|        return wrappers[-1][-1]
  1048|         0|            0|            0|  0.00%|    return None
  1049|         0|            0|            0|  0.00%|
  1050|         0|            0|            0|  0.00%|def get_array_wrap(*args):
  1051|         0|            0|            0|  0.00%|    """Find the wrapper for the array with the highest priority.
  1052|         0|            0|            0|  0.00%|
  1053|         0|            0|            0|  0.00%|    In case of ties, leftmost wins. If no wrapper is found, return None
  1054|         0|            0|            0|  0.00%|    """
  1055|         0|            0|            0|  0.00%|    wrappers = sorted((getattr(x, '__array_priority__', 0), -i,
  1056|         0|            0|            0|  0.00%|                 x.__array_wrap__) for i, x in enumerate(args)
  1057|         0|            0|            0|  0.00%|                                   if hasattr(x, '__array_wrap__'))
  1058|         0|            0|            0|  0.00%|    if wrappers:
  1059|         0|            0|            0|  0.00%|        return wrappers[-1][-1]
  1060|         0|            0|            0|  0.00%|    return None
  1061|         0|            0|            0|  0.00%|
  1062|         0|            0|            0|  0.00%|
  1063|         0|            0|            0|  0.00%|def _kron_dispatcher(a, b):
  1064|         0|            0|            0|  0.00%|    return (a, b)
  1065|         0|            0|            0|  0.00%|
  1066|         0|            0|            0|  0.00%|
  1067|         0|            0|            0|  0.00%|@array_function_dispatch(_kron_dispatcher)
  1068|         0|            0|            0|  0.00%|def kron(a, b):
  1069|         0|            0|            0|  0.00%|    """
  1070|         0|            0|            0|  0.00%|    Kronecker product of two arrays.
  1071|         0|            0|            0|  0.00%|
  1072|         0|            0|            0|  0.00%|    Computes the Kronecker product, a composite array made of blocks of the
  1073|         0|            0|            0|  0.00%|    second array scaled by the first.
  1074|         0|            0|            0|  0.00%|
  1075|         0|            0|            0|  0.00%|    Parameters
  1076|         0|            0|            0|  0.00%|    ----------
  1077|         0|            0|            0|  0.00%|    a, b : array_like
  1078|         0|            0|            0|  0.00%|
  1079|         0|            0|            0|  0.00%|    Returns
  1080|         0|            0|            0|  0.00%|    -------
  1081|         0|            0|            0|  0.00%|    out : ndarray
  1082|         0|            0|            0|  0.00%|
  1083|         0|            0|            0|  0.00%|    See Also
  1084|         0|            0|            0|  0.00%|    --------
  1085|         0|            0|            0|  0.00%|    outer : The outer product
  1086|         0|            0|            0|  0.00%|
  1087|         0|            0|            0|  0.00%|    Notes
  1088|         0|            0|            0|  0.00%|    -----
  1089|         0|            0|            0|  0.00%|    The function assumes that the number of dimensions of `a` and `b`
  1090|         0|            0|            0|  0.00%|    are the same, if necessary prepending the smallest with ones.
  1091|         0|            0|            0|  0.00%|    If `a.shape = (r0,r1,..,rN)` and `b.shape = (s0,s1,...,sN)`,
  1092|         0|            0|            0|  0.00%|    the Kronecker product has shape `(r0*s0, r1*s1, ..., rN*SN)`.
  1093|         0|            0|            0|  0.00%|    The elements are products of elements from `a` and `b`, organized
  1094|         0|            0|            0|  0.00%|    explicitly by::
  1095|         0|            0|            0|  0.00%|
  1096|         0|            0|            0|  0.00%|        kron(a,b)[k0,k1,...,kN] = a[i0,i1,...,iN] * b[j0,j1,...,jN]
  1097|         0|            0|            0|  0.00%|
  1098|         0|            0|            0|  0.00%|    where::
  1099|         0|            0|            0|  0.00%|
  1100|         0|            0|            0|  0.00%|        kt = it * st + jt,  t = 0,...,N
  1101|         0|            0|            0|  0.00%|
  1102|         0|            0|            0|  0.00%|    In the common 2-D case (N=1), the block structure can be visualized::
  1103|         0|            0|            0|  0.00%|
  1104|         0|            0|            0|  0.00%|        [[ a[0,0]*b,   a[0,1]*b,  ... , a[0,-1]*b  ],
  1105|         0|            0|            0|  0.00%|         [  ...                              ...   ],
  1106|         0|            0|            0|  0.00%|         [ a[-1,0]*b,  a[-1,1]*b, ... , a[-1,-1]*b ]]
  1107|         0|            0|            0|  0.00%|
  1108|         0|            0|            0|  0.00%|
  1109|         0|            0|            0|  0.00%|    Examples
  1110|         0|            0|            0|  0.00%|    --------
  1111|         0|            0|            0|  0.00%|    >>> np.kron([1,10,100], [5,6,7])
  1112|         0|            0|            0|  0.00%|    array([  5,   6,   7, ..., 500, 600, 700])
  1113|         0|            0|            0|  0.00%|    >>> np.kron([5,6,7], [1,10,100])
  1114|         0|            0|            0|  0.00%|    array([  5,  50, 500, ...,   7,  70, 700])
  1115|         0|            0|            0|  0.00%|
  1116|         0|            0|            0|  0.00%|    >>> np.kron(np.eye(2), np.ones((2,2)))
  1117|         0|            0|            0|  0.00%|    array([[1.,  1.,  0.,  0.],
  1118|         0|            0|            0|  0.00%|           [1.,  1.,  0.,  0.],
  1119|         0|            0|            0|  0.00%|           [0.,  0.,  1.,  1.],
  1120|         0|            0|            0|  0.00%|           [0.,  0.,  1.,  1.]])
  1121|         0|            0|            0|  0.00%|
  1122|         0|            0|            0|  0.00%|    >>> a = np.arange(100).reshape((2,5,2,5))
  1123|         0|            0|            0|  0.00%|    >>> b = np.arange(24).reshape((2,3,4))
  1124|         0|            0|            0|  0.00%|    >>> c = np.kron(a,b)
  1125|         0|            0|            0|  0.00%|    >>> c.shape
  1126|         0|            0|            0|  0.00%|    (2, 10, 6, 20)
  1127|         0|            0|            0|  0.00%|    >>> I = (1,3,0,2)
  1128|         0|            0|            0|  0.00%|    >>> J = (0,2,1)
  1129|         0|            0|            0|  0.00%|    >>> J1 = (0,) + J             # extend to ndim=4
  1130|         0|            0|            0|  0.00%|    >>> S1 = (1,) + b.shape
  1131|         0|            0|            0|  0.00%|    >>> K = tuple(np.array(I) * np.array(S1) + np.array(J1))
  1132|         0|            0|            0|  0.00%|    >>> c[K] == a[I]*b[J]
  1133|         0|            0|            0|  0.00%|    True
  1134|         0|            0|            0|  0.00%|
  1135|         0|            0|            0|  0.00%|    """
  1136|         0|            0|            0|  0.00%|    b = asanyarray(b)
  1137|         0|            0|            0|  0.00%|    a = array(a, copy=False, subok=True, ndmin=b.ndim)
  1138|         0|            0|            0|  0.00%|    ndb, nda = b.ndim, a.ndim
  1139|         0|            0|            0|  0.00%|    if (nda == 0 or ndb == 0):
  1140|         0|            0|            0|  0.00%|        return _nx.multiply(a, b)
  1141|         0|            0|            0|  0.00%|    as_ = a.shape
  1142|         0|            0|            0|  0.00%|    bs = b.shape
  1143|         0|            0|            0|  0.00%|    if not a.flags.contiguous:
  1144|         0|            0|            0|  0.00%|        a = reshape(a, as_)
  1145|         0|            0|            0|  0.00%|    if not b.flags.contiguous:
  1146|         0|            0|            0|  0.00%|        b = reshape(b, bs)
  1147|         0|            0|            0|  0.00%|    nd = ndb
  1148|         0|            0|            0|  0.00%|    if (ndb != nda):
  1149|         0|            0|            0|  0.00%|        if (ndb > nda):
  1150|         0|            0|            0|  0.00%|            as_ = (1,)*(ndb-nda) + as_
  1151|         0|            0|            0|  0.00%|        else:
  1152|         0|            0|            0|  0.00%|            bs = (1,)*(nda-ndb) + bs
  1153|         0|            0|            0|  0.00%|            nd = nda
  1154|         0|            0|            0|  0.00%|    result = outer(a, b).reshape(as_+bs)
  1155|         0|            0|            0|  0.00%|    axis = nd-1
  1156|         0|            0|            0|  0.00%|    for _ in range(nd):
  1157|         0|            0|            0|  0.00%|        result = concatenate(result, axis=axis)
  1158|         0|            0|            0|  0.00%|    wrapper = get_array_prepare(a, b)
  1159|         0|            0|            0|  0.00%|    if wrapper is not None:
  1160|         0|            0|            0|  0.00%|        result = wrapper(result)
  1161|         0|            0|            0|  0.00%|    wrapper = get_array_wrap(a, b)
  1162|         0|            0|            0|  0.00%|    if wrapper is not None:
  1163|         0|            0|            0|  0.00%|        result = wrapper(result)
  1164|         0|            0|            0|  0.00%|    return result
  1165|         0|            0|            0|  0.00%|
  1166|         0|            0|            0|  0.00%|
  1167|         0|            0|            0|  0.00%|def _tile_dispatcher(A, reps):
  1168|         0|            0|            0|  0.00%|    return (A, reps)
  1169|         0|            0|            0|  0.00%|
  1170|         0|            0|            0|  0.00%|
  1171|         0|            0|            0|  0.00%|@array_function_dispatch(_tile_dispatcher)
  1172|         0|            0|            0|  0.00%|def tile(A, reps):
  1173|         0|            0|            0|  0.00%|    """
  1174|         0|            0|            0|  0.00%|    Construct an array by repeating A the number of times given by reps.
  1175|         0|            0|            0|  0.00%|
  1176|         0|            0|            0|  0.00%|    If `reps` has length ``d``, the result will have dimension of
  1177|         0|            0|            0|  0.00%|    ``max(d, A.ndim)``.
  1178|         0|            0|            0|  0.00%|
  1179|         0|            0|            0|  0.00%|    If ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new
  1180|         0|            0|            0|  0.00%|    axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication,
  1181|         0|            0|            0|  0.00%|    or shape (1, 1, 3) for 3-D replication. If this is not the desired
  1182|         0|            0|            0|  0.00%|    behavior, promote `A` to d-dimensions manually before calling this
  1183|         0|            0|            0|  0.00%|    function.
  1184|         0|            0|            0|  0.00%|
  1185|         0|            0|            0|  0.00%|    If ``A.ndim > d``, `reps` is promoted to `A`.ndim by pre-pending 1's to it.
  1186|         0|            0|            0|  0.00%|    Thus for an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as
  1187|         0|            0|            0|  0.00%|    (1, 1, 2, 2).
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|    Note : Although tile may be used for broadcasting, it is strongly
  1190|         0|            0|            0|  0.00%|    recommended to use numpy's broadcasting operations and functions.
  1191|         0|            0|            0|  0.00%|
  1192|         0|            0|            0|  0.00%|    Parameters
  1193|         0|            0|            0|  0.00%|    ----------
  1194|         0|            0|            0|  0.00%|    A : array_like
  1195|         0|            0|            0|  0.00%|        The input array.
  1196|         0|            0|            0|  0.00%|    reps : array_like
  1197|         0|            0|            0|  0.00%|        The number of repetitions of `A` along each axis.
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|    Returns
  1200|         0|            0|            0|  0.00%|    -------
  1201|         0|            0|            0|  0.00%|    c : ndarray
  1202|         0|            0|            0|  0.00%|        The tiled output array.
  1203|         0|            0|            0|  0.00%|
  1204|         0|            0|            0|  0.00%|    See Also
  1205|         0|            0|            0|  0.00%|    --------
  1206|         0|            0|            0|  0.00%|    repeat : Repeat elements of an array.
  1207|         0|            0|            0|  0.00%|    broadcast_to : Broadcast an array to a new shape
  1208|         0|            0|            0|  0.00%|
  1209|         0|            0|            0|  0.00%|    Examples
  1210|         0|            0|            0|  0.00%|    --------
  1211|         0|            0|            0|  0.00%|    >>> a = np.array([0, 1, 2])
  1212|         0|            0|            0|  0.00%|    >>> np.tile(a, 2)
  1213|         0|            0|            0|  0.00%|    array([0, 1, 2, 0, 1, 2])
  1214|         0|            0|            0|  0.00%|    >>> np.tile(a, (2, 2))
  1215|         0|            0|            0|  0.00%|    array([[0, 1, 2, 0, 1, 2],
  1216|         0|            0|            0|  0.00%|           [0, 1, 2, 0, 1, 2]])
  1217|         0|            0|            0|  0.00%|    >>> np.tile(a, (2, 1, 2))
  1218|         0|            0|            0|  0.00%|    array([[[0, 1, 2, 0, 1, 2]],
  1219|         0|            0|            0|  0.00%|           [[0, 1, 2, 0, 1, 2]]])
  1220|         0|            0|            0|  0.00%|
  1221|         0|            0|            0|  0.00%|    >>> b = np.array([[1, 2], [3, 4]])
  1222|         0|            0|            0|  0.00%|    >>> np.tile(b, 2)
  1223|         0|            0|            0|  0.00%|    array([[1, 2, 1, 2],
  1224|         0|            0|            0|  0.00%|           [3, 4, 3, 4]])
  1225|         0|            0|            0|  0.00%|    >>> np.tile(b, (2, 1))
  1226|         0|            0|            0|  0.00%|    array([[1, 2],
  1227|         0|            0|            0|  0.00%|           [3, 4],
  1228|         0|            0|            0|  0.00%|           [1, 2],
  1229|         0|            0|            0|  0.00%|           [3, 4]])
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|    >>> c = np.array([1,2,3,4])
  1232|         0|            0|            0|  0.00%|    >>> np.tile(c,(4,1))
  1233|         0|            0|            0|  0.00%|    array([[1, 2, 3, 4],
  1234|         0|            0|            0|  0.00%|           [1, 2, 3, 4],
  1235|         0|            0|            0|  0.00%|           [1, 2, 3, 4],
  1236|         0|            0|            0|  0.00%|           [1, 2, 3, 4]])
  1237|         0|            0|            0|  0.00%|    """
  1238|         0|            0|            0|  0.00%|    try:
  1239|         0|            0|            0|  0.00%|        tup = tuple(reps)
  1240|         0|            0|            0|  0.00%|    except TypeError:
  1241|         0|            0|            0|  0.00%|        tup = (reps,)
  1242|         0|            0|            0|  0.00%|    d = len(tup)
  1243|         0|            0|            0|  0.00%|    if all(x == 1 for x in tup) and isinstance(A, _nx.ndarray):
  1244|         0|            0|            0|  0.00%|        # Fixes the problem that the function does not make a copy if A is a
  1245|         0|            0|            0|  0.00%|        # numpy array and the repetitions are 1 in all dimensions
  1246|         0|            0|            0|  0.00%|        return _nx.array(A, copy=True, subok=True, ndmin=d)
  1247|         0|            0|            0|  0.00%|    else:
  1248|         0|            0|            0|  0.00%|        # Note that no copy of zero-sized arrays is made. However since they
  1249|         0|            0|            0|  0.00%|        # have no data there is no risk of an inadvertent overwrite.
  1250|         0|            0|            0|  0.00%|        c = _nx.array(A, copy=False, subok=True, ndmin=d)
  1251|         0|            0|            0|  0.00%|    if (d < c.ndim):
  1252|         0|            0|            0|  0.00%|        tup = (1,)*(c.ndim-d) + tup
  1253|         0|            0|            0|  0.00%|    shape_out = tuple(s*t for s, t in zip(c.shape, tup))
  1254|         0|            0|            0|  0.00%|    n = c.size
  1255|         0|            0|            0|  0.00%|    if n > 0:
  1256|         0|            0|            0|  0.00%|        for dim_in, nrep in zip(c.shape, tup):
  1257|         0|            0|            0|  0.00%|            if nrep != 1:
  1258|         0|            0|            0|  0.00%|                c = c.reshape(-1, n).repeat(nrep, 0)
  1259|         0|            0|            0|  0.00%|            n //= dim_in
  1260|         0|            0|            0|  0.00%|    return c.reshape(shape_out)
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py
File duration: 0.0178671s (2.08%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# coding=utf-8
     2|         0|            0|            0|  0.00%|# Copyright 2020 The HuggingFace Inc. team.
     3|         0|            0|            0|  0.00%|#
     4|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     5|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     6|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     7|         0|            0|            0|  0.00%|#
     8|         0|            0|            0|  0.00%|#     http://www.apache.org/licenses/LICENSE-2.0
     9|         0|            0|            0|  0.00%|#
    10|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    11|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    12|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    14|         0|            0|            0|  0.00%|# limitations under the License.
    15|         0|            0|            0|  0.00%|"""
    16|         0|            0|            0|  0.00%| Tokenization classes for fast tokenizers (provided by HuggingFace's tokenizers library). For slow (python) tokenizers
    17|         0|            0|            0|  0.00%| see tokenization_utils.py
    18|         0|            0|            0|  0.00%|"""
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|import json
    21|         0|            0|            0|  0.00%|import os
    22|         0|            0|            0|  0.00%|from collections import defaultdict
    23|         0|            0|            0|  0.00%|from typing import Any, Dict, List, Optional, Tuple, Union
    24|         0|            0|            0|  0.00%|
    25|         0|            0|            0|  0.00%|from tokenizers import Encoding as EncodingFast
    26|         0|            0|            0|  0.00%|from tokenizers import Tokenizer as TokenizerFast
    27|         0|            0|            0|  0.00%|from tokenizers.decoders import Decoder as DecoderFast
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|from .convert_slow_tokenizer import convert_slow_tokenizer
    30|         0|            0|            0|  0.00%|from .file_utils import PaddingStrategy, add_end_docstrings
    31|         0|            0|            0|  0.00%|from .tokenization_utils import PreTrainedTokenizer
    32|         0|            0|            0|  0.00%|from .tokenization_utils_base import (
    33|         0|            0|            0|  0.00%|    INIT_TOKENIZER_DOCSTRING,
    34|         0|            0|            0|  0.00%|    AddedToken,
    35|         0|            0|            0|  0.00%|    BatchEncoding,
    36|         0|            0|            0|  0.00%|    PreTokenizedInput,
    37|         0|            0|            0|  0.00%|    PreTokenizedInputPair,
    38|         0|            0|            0|  0.00%|    PreTrainedTokenizerBase,
    39|         0|            0|            0|  0.00%|    TextInput,
    40|         0|            0|            0|  0.00%|    TextInputPair,
    41|         0|            0|            0|  0.00%|    TruncationStrategy,
    42|         0|            0|            0|  0.00%|)
    43|         0|            0|            0|  0.00%|from .utils import logging
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|
    46|         0|            0|            0|  0.00%|logger = logging.get_logger(__name__)
    47|         0|            0|            0|  0.00%|
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|# Fast tokenizers (provided by HuggingFace tokenizer's library) can be saved in a single file
    50|         0|            0|            0|  0.00%|TOKENIZER_FILE = "tokenizer.json"
    51|         0|            0|            0|  0.00%|SPECIAL_TOKENS_MAP_FILE = "special_tokens_map.json"
    52|         0|            0|            0|  0.00%|TOKENIZER_CONFIG_FILE = "tokenizer_config.json"
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|# Slow tokenizers have an additional added tokens files
    55|         0|            0|            0|  0.00%|ADDED_TOKENS_FILE = "added_tokens.json"
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|INIT_TOKENIZER_DOCSTRING += """
    58|         0|            0|            0|  0.00%|        tokenizer_object (:class:`tokenizers.Tokenizer`):
    59|         0|            0|            0|  0.00%|            A :class:`tokenizers.Tokenizer` object from 🤗 tokenizers to instantiate from. See :doc:`Using tokenizers
    60|         0|            0|            0|  0.00%|            from 🤗 tokenizers <../fast_tokenizers>` for more information.
    61|         0|            0|            0|  0.00%|"""
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|@add_end_docstrings(INIT_TOKENIZER_DOCSTRING)
    65|         0|            0|            0|  0.00%|class PreTrainedTokenizerFast(PreTrainedTokenizerBase):
    66|         0|            0|            0|  0.00%|    """
    67|         0|            0|            0|  0.00%|    Base class for all fast tokenizers (wrapping HuggingFace tokenizers library).
    68|         0|            0|            0|  0.00%|
    69|         0|            0|            0|  0.00%|    Inherits from :class:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase`.
    70|         0|            0|            0|  0.00%|
    71|         0|            0|            0|  0.00%|    Handles all the shared methods for tokenization and special tokens, as well as methods for
    72|         0|            0|            0|  0.00%|    downloading/caching/loading pretrained tokenizers, as well as adding tokens to the vocabulary.
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    This class also contains the added tokens in a unified way on top of all tokenizers so we don't have to handle the
    75|         0|            0|            0|  0.00%|    specific vocabulary augmentation methods of the various underlying dictionary structures (BPE, sentencepiece...).
    76|         0|            0|            0|  0.00%|    """
    77|         0|            0|            0|  0.00%|
    78|         0|            0|            0|  0.00%|    slow_tokenizer_class: PreTrainedTokenizer = None
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|    def __init__(self, *args, **kwargs):
    81|         0|            0|            0|  0.00%|        tokenizer_object = kwargs.pop("tokenizer_object", None)
    82|         0|            0|            0|  0.00%|        slow_tokenizer = kwargs.pop("__slow_tokenizer", None)
    83|         0|            0|            0|  0.00%|        fast_tokenizer_file = kwargs.pop("tokenizer_file", None)
    84|         0|            0|            0|  0.00%|        from_slow = kwargs.pop("from_slow", False)
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|        if from_slow and slow_tokenizer is None and self.slow_tokenizer_class is None:
    87|         0|            0|            0|  0.00%|            raise ValueError(
    88|         0|            0|            0|  0.00%|                "Cannot instantiate this tokenizer from a slow version. If it's based on sentencepiece, make sure you "
    89|         0|            0|            0|  0.00%|                "have sentencepiece installed."
    90|         0|            0|            0|  0.00%|            )
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|        if tokenizer_object is not None:
    93|         0|            0|            0|  0.00%|            fast_tokenizer = tokenizer_object
    94|         0|            0|            0|  0.00%|        elif fast_tokenizer_file is not None and not from_slow:
    95|         0|            0|            0|  0.00%|            # We have a serialization from tokenizers which let us directly build the backend
    96|         0|            0|            0|  0.00%|            fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)
    97|         0|            0|            0|  0.00%|        elif slow_tokenizer is not None:
    98|         0|            0|            0|  0.00%|            # We need to convert a slow tokenizer to build the backend
    99|         0|            0|            0|  0.00%|            fast_tokenizer = convert_slow_tokenizer(slow_tokenizer)
   100|         0|            0|            0|  0.00%|        elif self.slow_tokenizer_class is not None:
   101|         0|            0|            0|  0.00%|            # We need to create and convert a slow tokenizer to build the backend
   102|         0|            0|            0|  0.00%|            slow_tokenizer = self.slow_tokenizer_class(*args, **kwargs)
   103|         0|            0|            0|  0.00%|            fast_tokenizer = convert_slow_tokenizer(slow_tokenizer)
   104|         0|            0|            0|  0.00%|        else:
   105|         0|            0|            0|  0.00%|            raise ValueError(
   106|         0|            0|            0|  0.00%|                "Couldn't instantiate the backend tokenizer from one of: \n"
   107|         0|            0|            0|  0.00%|                "(1) a `tokenizers` library serialization file, \n"
   108|         0|            0|            0|  0.00%|                "(2) a slow tokenizer instance to convert or \n"
   109|         0|            0|            0|  0.00%|                "(3) an equivalent slow tokenizer class to instantiate and convert. \n"
   110|         0|            0|            0|  0.00%|                "You need to have sentencepiece installed to convert a slow tokenizer to a fast one."
   111|         0|            0|            0|  0.00%|            )
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|        self._tokenizer = fast_tokenizer
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|        if slow_tokenizer is not None:
   116|         0|            0|            0|  0.00%|            kwargs.update(slow_tokenizer.init_kwargs)
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|        self._decode_use_source_tokenizer = False
   119|         0|            0|            0|  0.00%|
   120|         0|            0|            0|  0.00%|        # We call this after having initialized the backend tokenizer because we update it.
   121|         0|            0|            0|  0.00%|        super().__init__(**kwargs)
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    @property
   124|         0|            0|            0|  0.00%|    def is_fast(self) -> bool:
   125|         0|            0|            0|  0.00%|        return True
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    @property
   128|         0|            0|            0|  0.00%|    def vocab_size(self) -> int:
   129|         0|            0|            0|  0.00%|        """
   130|         0|            0|            0|  0.00%|        :obj:`int`: Size of the base vocabulary (without the added tokens).
   131|         0|            0|            0|  0.00%|        """
   132|         0|            0|            0|  0.00%|        return self._tokenizer.get_vocab_size(with_added_tokens=False)
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    def get_vocab(self) -> Dict[str, int]:
   135|         0|            0|            0|  0.00%|        return self._tokenizer.get_vocab(with_added_tokens=True)
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|    @property
   138|         0|            0|            0|  0.00%|    def vocab(self) -> Dict[str, int]:
   139|         0|            0|            0|  0.00%|        return self.get_vocab()
   140|         0|            0|            0|  0.00%|
   141|         0|            0|            0|  0.00%|    def get_added_vocab(self) -> Dict[str, int]:
   142|         0|            0|            0|  0.00%|        """
   143|         0|            0|            0|  0.00%|        Returns the added tokens in the vocabulary as a dictionary of token to index.
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|        Returns:
   146|         0|            0|            0|  0.00%|            :obj:`Dict[str, int]`: The added tokens.
   147|         0|            0|            0|  0.00%|        """
   148|         0|            0|            0|  0.00%|        base_vocab = self._tokenizer.get_vocab(with_added_tokens=False)
   149|         0|            0|            0|  0.00%|        full_vocab = self._tokenizer.get_vocab(with_added_tokens=True)
   150|         0|            0|            0|  0.00%|        added_vocab = dict((tok, index) for tok, index in full_vocab.items() if tok not in base_vocab)
   151|         0|            0|            0|  0.00%|        return added_vocab
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    def __len__(self) -> int:
   154|         0|            0|            0|  0.00%|        """
   155|         0|            0|            0|  0.00%|        Size of the full vocabulary with the added tokens.
   156|         0|            0|            0|  0.00%|        """
   157|         0|            0|            0|  0.00%|        return self._tokenizer.get_vocab_size(with_added_tokens=True)
   158|         0|            0|            0|  0.00%|
   159|      1000|   0.00106788|  1.06788e-06|  0.12%|    @property
   160|         0|            0|            0|  0.00%|    def backend_tokenizer(self) -> TokenizerFast:
   161|         0|            0|            0|  0.00%|        """
   162|         0|            0|            0|  0.00%|        :obj:`tokenizers.implementations.BaseTokenizer`: The Rust tokenizer used as a backend.
   163|         0|            0|            0|  0.00%|        """
   164|      1000|   0.00132442|  1.32442e-06|  0.15%|        return self._tokenizer
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|    @property
   167|         0|            0|            0|  0.00%|    def decoder(self) -> DecoderFast:
   168|         0|            0|            0|  0.00%|        """
   169|         0|            0|            0|  0.00%|        :obj:`tokenizers.decoders.Decoder`: The Rust decoder for this tokenizer.
   170|         0|            0|            0|  0.00%|        """
   171|         0|            0|            0|  0.00%|        return self._tokenizer._tokenizer.decoder
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    def _convert_encoding(
   174|         0|            0|            0|  0.00%|        self,
   175|         0|            0|            0|  0.00%|        encoding: EncodingFast,
   176|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
   177|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
   178|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
   179|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
   180|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
   181|         0|            0|            0|  0.00%|        return_length: bool = False,
   182|         0|            0|            0|  0.00%|        verbose: bool = True,
   183|         0|            0|            0|  0.00%|    ) -> Tuple[Dict[str, Any], List[EncodingFast]]:
   184|         0|            0|            0|  0.00%|        """
   185|         0|            0|            0|  0.00%|        Convert the encoding representation (from low-level HuggingFace tokenizer output) to a python Dict and a list
   186|         0|            0|            0|  0.00%|        of encodings, take care of building a batch from overflowing tokens.
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|        Overflowing tokens are converted to additional examples (like batches) so the output values of the dict are
   189|         0|            0|            0|  0.00%|        lists (overflows) of lists (tokens).
   190|         0|            0|            0|  0.00%|
   191|         0|            0|            0|  0.00%|        Output shape: (overflows, sequence length)
   192|         0|            0|            0|  0.00%|        """
   193|         0|            0|            0|  0.00%|        if return_token_type_ids is None:
   194|         0|            0|            0|  0.00%|            return_token_type_ids = "token_type_ids" in self.model_input_names
   195|         0|            0|            0|  0.00%|        if return_attention_mask is None:
   196|         0|            0|            0|  0.00%|            return_attention_mask = "attention_mask" in self.model_input_names
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|        if return_overflowing_tokens and encoding.overflowing is not None:
   199|         0|            0|            0|  0.00%|            encodings = [encoding] + encoding.overflowing
   200|         0|            0|            0|  0.00%|        else:
   201|         0|            0|            0|  0.00%|            encodings = [encoding]
   202|         0|            0|            0|  0.00%|
   203|         0|            0|            0|  0.00%|        encoding_dict = defaultdict(list)
   204|         0|            0|            0|  0.00%|        for e in encodings:
   205|         0|            0|            0|  0.00%|            encoding_dict["input_ids"].append(e.ids)
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|            if return_token_type_ids:
   208|         0|            0|            0|  0.00%|                encoding_dict["token_type_ids"].append(e.type_ids)
   209|         0|            0|            0|  0.00%|            if return_attention_mask:
   210|         0|            0|            0|  0.00%|                encoding_dict["attention_mask"].append(e.attention_mask)
   211|         0|            0|            0|  0.00%|            if return_special_tokens_mask:
   212|         0|            0|            0|  0.00%|                encoding_dict["special_tokens_mask"].append(e.special_tokens_mask)
   213|         0|            0|            0|  0.00%|            if return_offsets_mapping:
   214|         0|            0|            0|  0.00%|                encoding_dict["offset_mapping"].append(e.offsets)
   215|         0|            0|            0|  0.00%|            if return_length:
   216|         0|            0|            0|  0.00%|                encoding_dict["length"].append(len(e.ids))
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|        return encoding_dict, encodings
   219|         0|            0|            0|  0.00%|
   220|         0|            0|            0|  0.00%|    def convert_tokens_to_ids(self, tokens: Union[str, List[str]]) -> Union[int, List[int]]:
   221|         0|            0|            0|  0.00%|        """
   222|         0|            0|            0|  0.00%|        Converts a token string (or a sequence of tokens) in a single integer id (or a sequence of ids), using the
   223|         0|            0|            0|  0.00%|        vocabulary.
   224|         0|            0|            0|  0.00%|
   225|         0|            0|            0|  0.00%|        Args:
   226|         0|            0|            0|  0.00%|            tokens (:obj:`str` or :obj:`List[str]`): One or several token(s) to convert to token id(s).
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|        Returns:
   229|         0|            0|            0|  0.00%|            :obj:`int` or :obj:`List[int]`: The token id or list of token ids.
   230|         0|            0|            0|  0.00%|        """
   231|         0|            0|            0|  0.00%|        if tokens is None:
   232|         0|            0|            0|  0.00%|            return None
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|        if isinstance(tokens, str):
   235|         0|            0|            0|  0.00%|            return self._convert_token_to_id_with_added_voc(tokens)
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|        ids = []
   238|         0|            0|            0|  0.00%|        for token in tokens:
   239|         0|            0|            0|  0.00%|            ids.append(self._convert_token_to_id_with_added_voc(token))
   240|         0|            0|            0|  0.00%|        return ids
   241|         0|            0|            0|  0.00%|
   242|         0|            0|            0|  0.00%|    def _convert_token_to_id_with_added_voc(self, token: str) -> int:
   243|         0|            0|            0|  0.00%|        index = self._tokenizer.token_to_id(token)
   244|         0|            0|            0|  0.00%|        if index is None:
   245|         0|            0|            0|  0.00%|            return self.unk_token_id
   246|         0|            0|            0|  0.00%|        return index
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|    def _convert_id_to_token(self, index: int) -> Optional[str]:
   249|         0|            0|            0|  0.00%|        return self._tokenizer.id_to_token(int(index))
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|    def _add_tokens(self, new_tokens: List[Union[str, AddedToken]], special_tokens=False) -> int:
   252|         0|            0|            0|  0.00%|        if special_tokens:
   253|         0|            0|            0|  0.00%|            return self._tokenizer.add_special_tokens(new_tokens)
   254|         0|            0|            0|  0.00%|
   255|         0|            0|            0|  0.00%|        return self._tokenizer.add_tokens(new_tokens)
   256|         0|            0|            0|  0.00%|
   257|         0|            0|            0|  0.00%|    def num_special_tokens_to_add(self, pair: bool = False) -> int:
   258|         0|            0|            0|  0.00%|        """
   259|         0|            0|            0|  0.00%|        Returns the number of added tokens when encoding a sequence with special tokens.
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|        .. note::
   262|         0|            0|            0|  0.00%|            This encodes a dummy input and checks the number of added tokens, and is therefore not efficient. Do not
   263|         0|            0|            0|  0.00%|            put this inside your training loop.
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|        Args:
   266|         0|            0|            0|  0.00%|            pair (:obj:`bool`, `optional`, defaults to :obj:`False`):
   267|         0|            0|            0|  0.00%|                Whether the number of added tokens should be computed in the case of a sequence pair or a single
   268|         0|            0|            0|  0.00%|                sequence.
   269|         0|            0|            0|  0.00%|
   270|         0|            0|            0|  0.00%|        Returns:
   271|         0|            0|            0|  0.00%|            :obj:`int`: Number of special tokens added to sequences.
   272|         0|            0|            0|  0.00%|        """
   273|         0|            0|            0|  0.00%|        return self._tokenizer.num_special_tokens_to_add(pair)
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    def convert_ids_to_tokens(
   276|         0|            0|            0|  0.00%|        self, ids: Union[int, List[int]], skip_special_tokens: bool = False
   277|         0|            0|            0|  0.00%|    ) -> Union[str, List[str]]:
   278|         0|            0|            0|  0.00%|        """
   279|         0|            0|            0|  0.00%|        Converts a single index or a sequence of indices in a token or a sequence of tokens, using the vocabulary and
   280|         0|            0|            0|  0.00%|        added tokens.
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|        Args:
   283|         0|            0|            0|  0.00%|            ids (:obj:`int` or :obj:`List[int]`):
   284|         0|            0|            0|  0.00%|                The token id (or token ids) to convert to tokens.
   285|         0|            0|            0|  0.00%|            skip_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
   286|         0|            0|            0|  0.00%|                Whether or not to remove special tokens in the decoding.
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|        Returns:
   289|         0|            0|            0|  0.00%|            :obj:`str` or :obj:`List[str]`: The decoded token(s).
   290|         0|            0|            0|  0.00%|        """
   291|         0|            0|            0|  0.00%|        if isinstance(ids, int):
   292|         0|            0|            0|  0.00%|            return self._tokenizer.id_to_token(ids)
   293|         0|            0|            0|  0.00%|        tokens = []
   294|         0|            0|            0|  0.00%|        for index in ids:
   295|         0|            0|            0|  0.00%|            index = int(index)
   296|         0|            0|            0|  0.00%|            if skip_special_tokens and index in self.all_special_ids:
   297|         0|            0|            0|  0.00%|                continue
   298|         0|            0|            0|  0.00%|            tokens.append(self._tokenizer.id_to_token(index))
   299|         0|            0|            0|  0.00%|        return tokens
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|    def tokenize(self, text: str, pair: Optional[str] = None, add_special_tokens: bool = False, **kwargs) -> List[str]:
   302|         0|            0|            0|  0.00%|        return self.encode_plus(text=text, text_pair=pair, add_special_tokens=add_special_tokens, **kwargs).tokens()
   303|         0|            0|            0|  0.00%|
   304|         0|            0|            0|  0.00%|    def set_truncation_and_padding(
   305|         0|            0|            0|  0.00%|        self,
   306|         0|            0|            0|  0.00%|        padding_strategy: PaddingStrategy,
   307|         0|            0|            0|  0.00%|        truncation_strategy: TruncationStrategy,
   308|         0|            0|            0|  0.00%|        max_length: int,
   309|         0|            0|            0|  0.00%|        stride: int,
   310|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int],
   311|         0|            0|            0|  0.00%|    ):
   312|         0|            0|            0|  0.00%|        """
   313|         0|            0|            0|  0.00%|        Define the truncation and the padding strategies for fast tokenizers (provided by HuggingFace tokenizers
   314|         0|            0|            0|  0.00%|        library) and restore the tokenizer settings afterwards.
   315|         0|            0|            0|  0.00%|
   316|         0|            0|            0|  0.00%|        The provided tokenizer has no padding / truncation strategy before the managed section. If your tokenizer set a
   317|         0|            0|            0|  0.00%|        padding / truncation strategy before, then it will be reset to no padding / truncation when exiting the managed
   318|         0|            0|            0|  0.00%|        section.
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|        Args:
   321|         0|            0|            0|  0.00%|            padding_strategy (:class:`~transformers.file_utils.PaddingStrategy`):
   322|         0|            0|            0|  0.00%|                The kind of padding that will be applied to the input
   323|         0|            0|            0|  0.00%|            truncation_strategy (:class:`~transformers.tokenization_utils_base.TruncationStrategy`):
   324|         0|            0|            0|  0.00%|                The kind of truncation that will be applied to the input
   325|         0|            0|            0|  0.00%|            max_length (:obj:`int`):
   326|         0|            0|            0|  0.00%|                The maximum size of a sequence.
   327|         0|            0|            0|  0.00%|            stride (:obj:`int`):
   328|         0|            0|            0|  0.00%|                The stride to use when handling overflow.
   329|         0|            0|            0|  0.00%|            pad_to_multiple_of (:obj:`int`, `optional`):
   330|         0|            0|            0|  0.00%|                If set will pad the sequence to a multiple of the provided value. This is especially useful to enable
   331|         0|            0|            0|  0.00%|                the use of Tensor Cores on NVIDIA hardware with compute capability >= 7.5 (Volta).
   332|         0|            0|            0|  0.00%|        """
   333|         0|            0|            0|  0.00%|        # Set truncation and padding on the backend tokenizer
   334|         0|            0|            0|  0.00%|        if truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE:
   335|         0|            0|            0|  0.00%|            self._tokenizer.enable_truncation(max_length, stride=stride, strategy=truncation_strategy.value)
   336|         0|            0|            0|  0.00%|        else:
   337|         0|            0|            0|  0.00%|            self._tokenizer.no_truncation()
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|        if padding_strategy != PaddingStrategy.DO_NOT_PAD:
   340|         0|            0|            0|  0.00%|            self._tokenizer.enable_padding(
   341|         0|            0|            0|  0.00%|                length=max_length if padding_strategy == PaddingStrategy.MAX_LENGTH else None,
   342|         0|            0|            0|  0.00%|                direction=self.padding_side,
   343|         0|            0|            0|  0.00%|                pad_id=self.pad_token_id,
   344|         0|            0|            0|  0.00%|                pad_type_id=self.pad_token_type_id,
   345|         0|            0|            0|  0.00%|                pad_token=self.pad_token,
   346|         0|            0|            0|  0.00%|                pad_to_multiple_of=pad_to_multiple_of,
   347|         0|            0|            0|  0.00%|            )
   348|         0|            0|            0|  0.00%|        else:
   349|         0|            0|            0|  0.00%|            self._tokenizer.no_padding()
   350|         0|            0|            0|  0.00%|
   351|         0|            0|            0|  0.00%|    def _batch_encode_plus(
   352|         0|            0|            0|  0.00%|        self,
   353|         0|            0|            0|  0.00%|        batch_text_or_text_pairs: Union[
   354|         0|            0|            0|  0.00%|            List[TextInput], List[TextInputPair], List[PreTokenizedInput], List[PreTokenizedInputPair]
   355|         0|            0|            0|  0.00%|        ],
   356|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
   357|         0|            0|            0|  0.00%|        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
   358|         0|            0|            0|  0.00%|        truncation_strategy: TruncationStrategy = TruncationStrategy.DO_NOT_TRUNCATE,
   359|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
   360|         0|            0|            0|  0.00%|        stride: int = 0,
   361|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
   362|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
   363|         0|            0|            0|  0.00%|        return_tensors: Optional[str] = None,
   364|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
   365|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
   366|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
   367|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
   368|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
   369|         0|            0|            0|  0.00%|        return_length: bool = False,
   370|         0|            0|            0|  0.00%|        verbose: bool = True,
   371|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
   372|         0|            0|            0|  0.00%|
   373|         0|            0|            0|  0.00%|        if not isinstance(batch_text_or_text_pairs, list):
   374|         0|            0|            0|  0.00%|            raise TypeError(f"batch_text_or_text_pairs has to be a list (got {type(batch_text_or_text_pairs)})")
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|        # Set the truncation and padding strategy and restore the initial configuration
   377|         0|            0|            0|  0.00%|        self.set_truncation_and_padding(
   378|         0|            0|            0|  0.00%|            padding_strategy=padding_strategy,
   379|         0|            0|            0|  0.00%|            truncation_strategy=truncation_strategy,
   380|         0|            0|            0|  0.00%|            max_length=max_length,
   381|         0|            0|            0|  0.00%|            stride=stride,
   382|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
   383|         0|            0|            0|  0.00%|        )
   384|         0|            0|            0|  0.00%|
   385|         0|            0|            0|  0.00%|        encodings = self._tokenizer.encode_batch(
   386|         0|            0|            0|  0.00%|            batch_text_or_text_pairs,
   387|         0|            0|            0|  0.00%|            add_special_tokens=add_special_tokens,
   388|         0|            0|            0|  0.00%|            is_pretokenized=is_split_into_words,
   389|         0|            0|            0|  0.00%|        )
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|        # Convert encoding to dict
   392|         0|            0|            0|  0.00%|        # `Tokens` has type: Tuple[
   393|         0|            0|            0|  0.00%|        #                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],
   394|         0|            0|            0|  0.00%|        #                       List[EncodingFast]
   395|         0|            0|            0|  0.00%|        #                    ]
   396|         0|            0|            0|  0.00%|        # with nested dimensions corresponding to batch, overflows, sequence length
   397|         0|            0|            0|  0.00%|        tokens_and_encodings = [
   398|         0|            0|            0|  0.00%|            self._convert_encoding(
   399|         0|            0|            0|  0.00%|                encoding=encoding,
   400|         0|            0|            0|  0.00%|                return_token_type_ids=return_token_type_ids,
   401|         0|            0|            0|  0.00%|                return_attention_mask=return_attention_mask,
   402|         0|            0|            0|  0.00%|                return_overflowing_tokens=return_overflowing_tokens,
   403|         0|            0|            0|  0.00%|                return_special_tokens_mask=return_special_tokens_mask,
   404|         0|            0|            0|  0.00%|                return_offsets_mapping=return_offsets_mapping,
   405|         0|            0|            0|  0.00%|                return_length=return_length,
   406|         0|            0|            0|  0.00%|                verbose=verbose,
   407|         0|            0|            0|  0.00%|            )
   408|         0|            0|            0|  0.00%|            for encoding in encodings
   409|         0|            0|            0|  0.00%|        ]
   410|         0|            0|            0|  0.00%|
   411|         0|            0|            0|  0.00%|        # Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension
   412|         0|            0|            0|  0.00%|        # From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)
   413|         0|            0|            0|  0.00%|        # (we say ~ because the number of overflow varies with the example in the batch)
   414|         0|            0|            0|  0.00%|        #
   415|         0|            0|            0|  0.00%|        # To match each overflowing sample with the original sample in the batch
   416|         0|            0|            0|  0.00%|        # we add an overflow_to_sample_mapping array (see below)
   417|         0|            0|            0|  0.00%|        sanitized_tokens = {}
   418|         0|            0|            0|  0.00%|        for key in tokens_and_encodings[0][0].keys():
   419|         0|            0|            0|  0.00%|            stack = [e for item, _ in tokens_and_encodings for e in item[key]]
   420|         0|            0|            0|  0.00%|            sanitized_tokens[key] = stack
   421|         0|            0|            0|  0.00%|        sanitized_encodings = [e for _, item in tokens_and_encodings for e in item]
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|        # If returning overflowing tokens, we need to return a mapping
   424|         0|            0|            0|  0.00%|        # from the batch idx to the original sample
   425|         0|            0|            0|  0.00%|        if return_overflowing_tokens:
   426|         0|            0|            0|  0.00%|            overflow_to_sample_mapping = []
   427|         0|            0|            0|  0.00%|            for i, (toks, _) in enumerate(tokens_and_encodings):
   428|         0|            0|            0|  0.00%|                overflow_to_sample_mapping += [i] * len(toks["input_ids"])
   429|         0|            0|            0|  0.00%|            sanitized_tokens["overflow_to_sample_mapping"] = overflow_to_sample_mapping
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|        for input_ids in sanitized_tokens["input_ids"]:
   432|         0|            0|            0|  0.00%|            self._eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)
   433|         0|            0|            0|  0.00%|        return BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type=return_tensors)
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|    def _encode_plus(
   436|         0|            0|            0|  0.00%|        self,
   437|         0|            0|            0|  0.00%|        text: Union[TextInput, PreTokenizedInput],
   438|         0|            0|            0|  0.00%|        text_pair: Optional[Union[TextInput, PreTokenizedInput]] = None,
   439|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
   440|         0|            0|            0|  0.00%|        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
   441|         0|            0|            0|  0.00%|        truncation_strategy: TruncationStrategy = TruncationStrategy.DO_NOT_TRUNCATE,
   442|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
   443|         0|            0|            0|  0.00%|        stride: int = 0,
   444|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
   445|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
   446|         0|            0|            0|  0.00%|        return_tensors: Optional[bool] = None,
   447|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
   448|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
   449|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
   450|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
   451|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
   452|         0|            0|            0|  0.00%|        return_length: bool = False,
   453|         0|            0|            0|  0.00%|        verbose: bool = True,
   454|         0|            0|            0|  0.00%|        **kwargs
   455|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
   456|         0|            0|            0|  0.00%|
   457|         0|            0|            0|  0.00%|        batched_input = [(text, text_pair)] if text_pair else [text]
   458|         0|            0|            0|  0.00%|        batched_output = self._batch_encode_plus(
   459|         0|            0|            0|  0.00%|            batched_input,
   460|         0|            0|            0|  0.00%|            is_split_into_words=is_split_into_words,
   461|         0|            0|            0|  0.00%|            add_special_tokens=add_special_tokens,
   462|         0|            0|            0|  0.00%|            padding_strategy=padding_strategy,
   463|         0|            0|            0|  0.00%|            truncation_strategy=truncation_strategy,
   464|         0|            0|            0|  0.00%|            max_length=max_length,
   465|         0|            0|            0|  0.00%|            stride=stride,
   466|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
   467|         0|            0|            0|  0.00%|            return_tensors=return_tensors,
   468|         0|            0|            0|  0.00%|            return_token_type_ids=return_token_type_ids,
   469|         0|            0|            0|  0.00%|            return_attention_mask=return_attention_mask,
   470|         0|            0|            0|  0.00%|            return_overflowing_tokens=return_overflowing_tokens,
   471|         0|            0|            0|  0.00%|            return_special_tokens_mask=return_special_tokens_mask,
   472|         0|            0|            0|  0.00%|            return_offsets_mapping=return_offsets_mapping,
   473|         0|            0|            0|  0.00%|            return_length=return_length,
   474|         0|            0|            0|  0.00%|            verbose=verbose,
   475|         0|            0|            0|  0.00%|            **kwargs,
   476|         0|            0|            0|  0.00%|        )
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|        # Return tensor is None, then we can remove the leading batch axis
   479|         0|            0|            0|  0.00%|        # Overflowing tokens are returned as a batch of output so we keep them in this case
   480|         0|            0|            0|  0.00%|        if return_tensors is None and not return_overflowing_tokens:
   481|         0|            0|            0|  0.00%|            batched_output = BatchEncoding(
   482|         0|            0|            0|  0.00%|                {
   483|         0|            0|            0|  0.00%|                    key: value[0] if len(value) > 0 and isinstance(value[0], list) else value
   484|         0|            0|            0|  0.00%|                    for key, value in batched_output.items()
   485|         0|            0|            0|  0.00%|                },
   486|         0|            0|            0|  0.00%|                batched_output.encodings,
   487|         0|            0|            0|  0.00%|            )
   488|         0|            0|            0|  0.00%|
   489|         0|            0|            0|  0.00%|        self._eventual_warn_about_too_long_sequence(batched_output["input_ids"], max_length, verbose)
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|        return batched_output
   492|         0|            0|            0|  0.00%|
   493|      1000|   0.00121212|  1.21212e-06|  0.14%|    def convert_tokens_to_string(self, tokens: List[str]) -> str:
   494|      1000|    0.0142627|  1.42627e-05|  1.66%|        return self.backend_tokenizer.decoder.decode(tokens)
(call)|      1000|   0.00239229|  2.39229e-06|  0.28%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py:159 backend_tokenizer
   495|         0|            0|            0|  0.00%|
   496|         0|            0|            0|  0.00%|    def _decode(
   497|         0|            0|            0|  0.00%|        self,
   498|         0|            0|            0|  0.00%|        token_ids: Union[int, List[int]],
   499|         0|            0|            0|  0.00%|        skip_special_tokens: bool = False,
   500|         0|            0|            0|  0.00%|        clean_up_tokenization_spaces: bool = True,
   501|         0|            0|            0|  0.00%|        **kwargs
   502|         0|            0|            0|  0.00%|    ) -> str:
   503|         0|            0|            0|  0.00%|        self._decode_use_source_tokenizer = kwargs.pop("use_source_tokenizer", False)
   504|         0|            0|            0|  0.00%|
   505|         0|            0|            0|  0.00%|        if isinstance(token_ids, int):
   506|         0|            0|            0|  0.00%|            token_ids = [token_ids]
   507|         0|            0|            0|  0.00%|        text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
   508|         0|            0|            0|  0.00%|
   509|         0|            0|            0|  0.00%|        if clean_up_tokenization_spaces:
   510|         0|            0|            0|  0.00%|            clean_text = self.clean_up_tokenization(text)
   511|         0|            0|            0|  0.00%|            return clean_text
   512|         0|            0|            0|  0.00%|        else:
   513|         0|            0|            0|  0.00%|            return text
   514|         0|            0|            0|  0.00%|
   515|         0|            0|            0|  0.00%|    def _save_pretrained(
   516|         0|            0|            0|  0.00%|        self,
   517|         0|            0|            0|  0.00%|        save_directory: Union[str, os.PathLike],
   518|         0|            0|            0|  0.00%|        file_names: Tuple[str],
   519|         0|            0|            0|  0.00%|        legacy_format: Optional[bool] = None,
   520|         0|            0|            0|  0.00%|        filename_prefix: Optional[str] = None,
   521|         0|            0|            0|  0.00%|    ) -> Tuple[str]:
   522|         0|            0|            0|  0.00%|        """
   523|         0|            0|            0|  0.00%|        Save a tokenizer using the slow-tokenizer/legacy format: vocabulary + added tokens as well as in a unique JSON
   524|         0|            0|            0|  0.00%|        file containing {config + vocab + added-tokens}.
   525|         0|            0|            0|  0.00%|        """
   526|         0|            0|            0|  0.00%|        save_directory = str(save_directory)
   527|         0|            0|            0|  0.00%|
   528|         0|            0|            0|  0.00%|        if self.slow_tokenizer_class is None and legacy_format is True:
   529|         0|            0|            0|  0.00%|            raise ValueError(
   530|         0|            0|            0|  0.00%|                "Your tokenizer does not have a legacy version defined and therefore cannot register this version. You "
   531|         0|            0|            0|  0.00%|                "might consider leaving the legacy_format at `None` or setting it to `False`."
   532|         0|            0|            0|  0.00%|            )
   533|         0|            0|            0|  0.00%|
   534|         0|            0|            0|  0.00%|        save_slow = (legacy_format is None or legacy_format is True) and self.slow_tokenizer_class is not None
   535|         0|            0|            0|  0.00%|        save_fast = legacy_format is None or legacy_format is False
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|        if save_slow:
   538|         0|            0|            0|  0.00%|            added_tokens_file = os.path.join(
   539|         0|            0|            0|  0.00%|                save_directory, (filename_prefix + "-" if filename_prefix else "") + ADDED_TOKENS_FILE
   540|         0|            0|            0|  0.00%|            )
   541|         0|            0|            0|  0.00%|            added_vocab = self.get_added_vocab()
   542|         0|            0|            0|  0.00%|            if added_vocab:
   543|         0|            0|            0|  0.00%|                with open(added_tokens_file, "w", encoding="utf-8") as f:
   544|         0|            0|            0|  0.00%|                    out_str = json.dumps(added_vocab, ensure_ascii=False)
   545|         0|            0|            0|  0.00%|                    f.write(out_str)
   546|         0|            0|            0|  0.00%|
   547|         0|            0|            0|  0.00%|            vocab_files = self.save_vocabulary(save_directory, filename_prefix=filename_prefix)
   548|         0|            0|            0|  0.00%|            file_names = file_names + vocab_files + (added_tokens_file,)
   549|         0|            0|            0|  0.00%|
   550|         0|            0|            0|  0.00%|        if save_fast:
   551|         0|            0|            0|  0.00%|            tokenizer_file = os.path.join(
   552|         0|            0|            0|  0.00%|                save_directory, (filename_prefix + "-" if filename_prefix else "") + TOKENIZER_FILE
   553|         0|            0|            0|  0.00%|            )
   554|         0|            0|            0|  0.00%|            self.backend_tokenizer.save(tokenizer_file)
   555|         0|            0|            0|  0.00%|            file_names = file_names + (tokenizer_file,)
   556|         0|            0|            0|  0.00%|
   557|         0|            0|            0|  0.00%|        return file_names
File: <__array_function__ internals>_5
File duration: 0.0158188s (1.84%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|      1000|   0.00189209|  1.89209e-06|  0.22%|
     3|         0|            0|            0|  0.00%|
     4|      1000|   0.00580215|  5.80215e-06|  0.68%|
(call)|      1000|   0.00313497|  3.13497e-06|  0.37%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2907 _prod_dispatcher
     5|      2000|   0.00676703|  3.38352e-06|  0.79%|
(call)|      1000|     0.049428|   4.9428e-05|  5.76%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2912 prod
     6|      1000|   0.00135756|  1.35756e-06|  0.16%|
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py
File duration: 0.00531673s (0.62%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Functions in the ``as*array`` family that promote array-likes into arrays.
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|`require` fits this category despite its name not matching this pattern.
     5|         0|            0|            0|  0.00%|"""
     6|         0|            0|            0|  0.00%|from .overrides import (
     7|         0|            0|            0|  0.00%|    array_function_dispatch,
     8|         0|            0|            0|  0.00%|    set_array_function_like_doc,
     9|         0|            0|            0|  0.00%|    set_module,
    10|         0|            0|            0|  0.00%|)
    11|         0|            0|            0|  0.00%|from .multiarray import array
    12|         0|            0|            0|  0.00%|
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|__all__ = [
    15|         0|            0|            0|  0.00%|    "asarray", "asanyarray", "ascontiguousarray", "asfortranarray", "require",
    16|         0|            0|            0|  0.00%|]
    17|         0|            0|            0|  0.00%|
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|def _asarray_dispatcher(a, dtype=None, order=None, *, like=None):
    20|         0|            0|            0|  0.00%|    return (like,)
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|
    23|         4|  2.57492e-05|   6.4373e-06|  0.00%|@set_array_function_like_doc
    24|         0|            0|            0|  0.00%|@set_module('numpy')
    25|         0|            0|            0|  0.00%|def asarray(a, dtype=None, order=None, *, like=None):
    26|         0|            0|            0|  0.00%|    """Convert the input to an array.
    27|         0|            0|            0|  0.00%|
    28|         0|            0|            0|  0.00%|    Parameters
    29|         0|            0|            0|  0.00%|    ----------
    30|         0|            0|            0|  0.00%|    a : array_like
    31|         0|            0|            0|  0.00%|        Input data, in any form that can be converted to an array.  This
    32|         0|            0|            0|  0.00%|        includes lists, lists of tuples, tuples, tuples of tuples, tuples
    33|         0|            0|            0|  0.00%|        of lists and ndarrays.
    34|         0|            0|            0|  0.00%|    dtype : data-type, optional
    35|         0|            0|            0|  0.00%|        By default, the data-type is inferred from the input data.
    36|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', 'K'}, optional
    37|         0|            0|            0|  0.00%|        Memory layout.  'A' and 'K' depend on the order of input array a.
    38|         0|            0|            0|  0.00%|        'C' row-major (C-style),
    39|         0|            0|            0|  0.00%|        'F' column-major (Fortran-style) memory representation.
    40|         0|            0|            0|  0.00%|        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise
    41|         0|            0|            0|  0.00%|        'K' (keep) preserve input order
    42|         0|            0|            0|  0.00%|        Defaults to 'C'.
    43|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
    46|         0|            0|            0|  0.00%|
    47|         0|            0|            0|  0.00%|    Returns
    48|         0|            0|            0|  0.00%|    -------
    49|         0|            0|            0|  0.00%|    out : ndarray
    50|         0|            0|            0|  0.00%|        Array interpretation of `a`.  No copy is performed if the input
    51|         0|            0|            0|  0.00%|        is already an ndarray with matching dtype and order.  If `a` is a
    52|         0|            0|            0|  0.00%|        subclass of ndarray, a base class ndarray is returned.
    53|         0|            0|            0|  0.00%|
    54|         0|            0|            0|  0.00%|    See Also
    55|         0|            0|            0|  0.00%|    --------
    56|         0|            0|            0|  0.00%|    asanyarray : Similar function which passes through subclasses.
    57|         0|            0|            0|  0.00%|    ascontiguousarray : Convert input to a contiguous array.
    58|         0|            0|            0|  0.00%|    asfarray : Convert input to a floating point ndarray.
    59|         0|            0|            0|  0.00%|    asfortranarray : Convert input to an ndarray with column-major
    60|         0|            0|            0|  0.00%|                     memory order.
    61|         0|            0|            0|  0.00%|    asarray_chkfinite : Similar function which checks input for NaNs and Infs.
    62|         0|            0|            0|  0.00%|    fromiter : Create an array from an iterator.
    63|         0|            0|            0|  0.00%|    fromfunction : Construct an array by executing a function on grid
    64|         0|            0|            0|  0.00%|                   positions.
    65|         0|            0|            0|  0.00%|
    66|         0|            0|            0|  0.00%|    Examples
    67|         0|            0|            0|  0.00%|    --------
    68|         0|            0|            0|  0.00%|    Convert a list into an array:
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|    >>> a = [1, 2]
    71|         0|            0|            0|  0.00%|    >>> np.asarray(a)
    72|         0|            0|            0|  0.00%|    array([1, 2])
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    Existing arrays are not copied:
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|    >>> a = np.array([1, 2])
    77|         0|            0|            0|  0.00%|    >>> np.asarray(a) is a
    78|         0|            0|            0|  0.00%|    True
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|    If `dtype` is set, array is copied only if dtype does not match:
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|    >>> a = np.array([1, 2], dtype=np.float32)
    83|         0|            0|            0|  0.00%|    >>> np.asarray(a, dtype=np.float32) is a
    84|         0|            0|            0|  0.00%|    True
    85|         0|            0|            0|  0.00%|    >>> np.asarray(a, dtype=np.float64) is a
    86|         0|            0|            0|  0.00%|    False
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|    Contrary to `asanyarray`, ndarray subclasses are not passed through:
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|    >>> issubclass(np.recarray, np.ndarray)
    91|         0|            0|            0|  0.00%|    True
    92|         0|            0|            0|  0.00%|    >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
    93|         0|            0|            0|  0.00%|    >>> np.asarray(a) is a
    94|         0|            0|            0|  0.00%|    False
    95|         0|            0|            0|  0.00%|    >>> np.asanyarray(a) is a
    96|         0|            0|            0|  0.00%|    True
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|    """
    99|         4|  1.04904e-05|   2.6226e-06|  0.00%|    if like is not None:
   100|         0|            0|            0|  0.00%|        return _asarray_with_like(a, dtype=dtype, order=order, like=like)
   101|         0|            0|            0|  0.00%|
   102|         4|  2.67029e-05|  6.67572e-06|  0.00%|    return array(a, dtype, copy=False, order=order)
   103|         0|            0|            0|  0.00%|
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|_asarray_with_like = array_function_dispatch(
   106|         0|            0|            0|  0.00%|    _asarray_dispatcher
   107|         0|            0|            0|  0.00%|)(asarray)
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|
   110|      1003|   0.00164866|  1.64373e-06|  0.19%|@set_array_function_like_doc
   111|         0|            0|            0|  0.00%|@set_module('numpy')
   112|         0|            0|            0|  0.00%|def asanyarray(a, dtype=None, order=None, *, like=None):
   113|         0|            0|            0|  0.00%|    """Convert the input to an ndarray, but pass ndarray subclasses through.
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|    Parameters
   116|         0|            0|            0|  0.00%|    ----------
   117|         0|            0|            0|  0.00%|    a : array_like
   118|         0|            0|            0|  0.00%|        Input data, in any form that can be converted to an array.  This
   119|         0|            0|            0|  0.00%|        includes scalars, lists, lists of tuples, tuples, tuples of tuples,
   120|         0|            0|            0|  0.00%|        tuples of lists, and ndarrays.
   121|         0|            0|            0|  0.00%|    dtype : data-type, optional
   122|         0|            0|            0|  0.00%|        By default, the data-type is inferred from the input data.
   123|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', 'K'}, optional
   124|         0|            0|            0|  0.00%|        Memory layout.  'A' and 'K' depend on the order of input array a.
   125|         0|            0|            0|  0.00%|        'C' row-major (C-style),
   126|         0|            0|            0|  0.00%|        'F' column-major (Fortran-style) memory representation.
   127|         0|            0|            0|  0.00%|        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise
   128|         0|            0|            0|  0.00%|        'K' (keep) preserve input order
   129|         0|            0|            0|  0.00%|        Defaults to 'C'.
   130|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    Returns
   135|         0|            0|            0|  0.00%|    -------
   136|         0|            0|            0|  0.00%|    out : ndarray or an ndarray subclass
   137|         0|            0|            0|  0.00%|        Array interpretation of `a`.  If `a` is an ndarray or a subclass
   138|         0|            0|            0|  0.00%|        of ndarray, it is returned as-is and no copy is performed.
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|    See Also
   141|         0|            0|            0|  0.00%|    --------
   142|         0|            0|            0|  0.00%|    asarray : Similar function which always returns ndarrays.
   143|         0|            0|            0|  0.00%|    ascontiguousarray : Convert input to a contiguous array.
   144|         0|            0|            0|  0.00%|    asfarray : Convert input to a floating point ndarray.
   145|         0|            0|            0|  0.00%|    asfortranarray : Convert input to an ndarray with column-major
   146|         0|            0|            0|  0.00%|                     memory order.
   147|         0|            0|            0|  0.00%|    asarray_chkfinite : Similar function which checks input for NaNs and
   148|         0|            0|            0|  0.00%|                        Infs.
   149|         0|            0|            0|  0.00%|    fromiter : Create an array from an iterator.
   150|         0|            0|            0|  0.00%|    fromfunction : Construct an array by executing a function on grid
   151|         0|            0|            0|  0.00%|                   positions.
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    Examples
   154|         0|            0|            0|  0.00%|    --------
   155|         0|            0|            0|  0.00%|    Convert a list into an array:
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|    >>> a = [1, 2]
   158|         0|            0|            0|  0.00%|    >>> np.asanyarray(a)
   159|         0|            0|            0|  0.00%|    array([1, 2])
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|    Instances of `ndarray` subclasses are passed through as-is:
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
   164|         0|            0|            0|  0.00%|    >>> np.asanyarray(a) is a
   165|         0|            0|            0|  0.00%|    True
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|    """
   168|      1003|   0.00167441|  1.66941e-06|  0.20%|    if like is not None:
   169|         0|            0|            0|  0.00%|        return _asanyarray_with_like(a, dtype=dtype, order=order, like=like)
   170|         0|            0|            0|  0.00%|
   171|      1003|   0.00193071|  1.92494e-06|  0.23%|    return array(a, dtype, copy=False, order=order, subok=True)
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|_asanyarray_with_like = array_function_dispatch(
   175|         0|            0|            0|  0.00%|    _asarray_dispatcher
   176|         0|            0|            0|  0.00%|)(asanyarray)
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|
   179|         0|            0|            0|  0.00%|def _asarray_contiguous_fortran_dispatcher(a, dtype=None, *, like=None):
   180|         0|            0|            0|  0.00%|    return (like,)
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|@set_array_function_like_doc
   184|         0|            0|            0|  0.00%|@set_module('numpy')
   185|         0|            0|            0|  0.00%|def ascontiguousarray(a, dtype=None, *, like=None):
   186|         0|            0|            0|  0.00%|    """
   187|         0|            0|            0|  0.00%|    Return a contiguous array (ndim >= 1) in memory (C order).
   188|         0|            0|            0|  0.00%|
   189|         0|            0|            0|  0.00%|    Parameters
   190|         0|            0|            0|  0.00%|    ----------
   191|         0|            0|            0|  0.00%|    a : array_like
   192|         0|            0|            0|  0.00%|        Input array.
   193|         0|            0|            0|  0.00%|    dtype : str or dtype object, optional
   194|         0|            0|            0|  0.00%|        Data-type of returned array.
   195|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    Returns
   200|         0|            0|            0|  0.00%|    -------
   201|         0|            0|            0|  0.00%|    out : ndarray
   202|         0|            0|            0|  0.00%|        Contiguous array of same shape and content as `a`, with type `dtype`
   203|         0|            0|            0|  0.00%|        if specified.
   204|         0|            0|            0|  0.00%|
   205|         0|            0|            0|  0.00%|    See Also
   206|         0|            0|            0|  0.00%|    --------
   207|         0|            0|            0|  0.00%|    asfortranarray : Convert input to an ndarray with column-major
   208|         0|            0|            0|  0.00%|                     memory order.
   209|         0|            0|            0|  0.00%|    require : Return an ndarray that satisfies requirements.
   210|         0|            0|            0|  0.00%|    ndarray.flags : Information about the memory layout of the array.
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|    Examples
   213|         0|            0|            0|  0.00%|    --------
   214|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2,3)
   215|         0|            0|            0|  0.00%|    >>> np.ascontiguousarray(x, dtype=np.float32)
   216|         0|            0|            0|  0.00%|    array([[0., 1., 2.],
   217|         0|            0|            0|  0.00%|           [3., 4., 5.]], dtype=float32)
   218|         0|            0|            0|  0.00%|    >>> x.flags['C_CONTIGUOUS']
   219|         0|            0|            0|  0.00%|    True
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|    Note: This function returns an array with at least one-dimension (1-d)
   222|         0|            0|            0|  0.00%|    so it will not preserve 0-d arrays.
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    """
   225|         0|            0|            0|  0.00%|    if like is not None:
   226|         0|            0|            0|  0.00%|        return _ascontiguousarray_with_like(a, dtype=dtype, like=like)
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|    return array(a, dtype, copy=False, order='C', ndmin=1)
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|_ascontiguousarray_with_like = array_function_dispatch(
   232|         0|            0|            0|  0.00%|    _asarray_contiguous_fortran_dispatcher
   233|         0|            0|            0|  0.00%|)(ascontiguousarray)
   234|         0|            0|            0|  0.00%|
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|@set_array_function_like_doc
   237|         0|            0|            0|  0.00%|@set_module('numpy')
   238|         0|            0|            0|  0.00%|def asfortranarray(a, dtype=None, *, like=None):
   239|         0|            0|            0|  0.00%|    """
   240|         0|            0|            0|  0.00%|    Return an array (ndim >= 1) laid out in Fortran order in memory.
   241|         0|            0|            0|  0.00%|
   242|         0|            0|            0|  0.00%|    Parameters
   243|         0|            0|            0|  0.00%|    ----------
   244|         0|            0|            0|  0.00%|    a : array_like
   245|         0|            0|            0|  0.00%|        Input array.
   246|         0|            0|            0|  0.00%|    dtype : str or dtype object, optional
   247|         0|            0|            0|  0.00%|        By default, the data-type is inferred from the input data.
   248|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   251|         0|            0|            0|  0.00%|
   252|         0|            0|            0|  0.00%|    Returns
   253|         0|            0|            0|  0.00%|    -------
   254|         0|            0|            0|  0.00%|    out : ndarray
   255|         0|            0|            0|  0.00%|        The input `a` in Fortran, or column-major, order.
   256|         0|            0|            0|  0.00%|
   257|         0|            0|            0|  0.00%|    See Also
   258|         0|            0|            0|  0.00%|    --------
   259|         0|            0|            0|  0.00%|    ascontiguousarray : Convert input to a contiguous (C order) array.
   260|         0|            0|            0|  0.00%|    asanyarray : Convert input to an ndarray with either row or
   261|         0|            0|            0|  0.00%|        column-major memory order.
   262|         0|            0|            0|  0.00%|    require : Return an ndarray that satisfies requirements.
   263|         0|            0|            0|  0.00%|    ndarray.flags : Information about the memory layout of the array.
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|    Examples
   266|         0|            0|            0|  0.00%|    --------
   267|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2,3)
   268|         0|            0|            0|  0.00%|    >>> y = np.asfortranarray(x)
   269|         0|            0|            0|  0.00%|    >>> x.flags['F_CONTIGUOUS']
   270|         0|            0|            0|  0.00%|    False
   271|         0|            0|            0|  0.00%|    >>> y.flags['F_CONTIGUOUS']
   272|         0|            0|            0|  0.00%|    True
   273|         0|            0|            0|  0.00%|
   274|         0|            0|            0|  0.00%|    Note: This function returns an array with at least one-dimension (1-d)
   275|         0|            0|            0|  0.00%|    so it will not preserve 0-d arrays.
   276|         0|            0|            0|  0.00%|
   277|         0|            0|            0|  0.00%|    """
   278|         0|            0|            0|  0.00%|    if like is not None:
   279|         0|            0|            0|  0.00%|        return _asfortranarray_with_like(a, dtype=dtype, like=like)
   280|         0|            0|            0|  0.00%|
   281|         0|            0|            0|  0.00%|    return array(a, dtype, copy=False, order='F', ndmin=1)
   282|         0|            0|            0|  0.00%|
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|_asfortranarray_with_like = array_function_dispatch(
   285|         0|            0|            0|  0.00%|    _asarray_contiguous_fortran_dispatcher
   286|         0|            0|            0|  0.00%|)(asfortranarray)
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|
   289|         0|            0|            0|  0.00%|def _require_dispatcher(a, dtype=None, requirements=None, *, like=None):
   290|         0|            0|            0|  0.00%|    return (like,)
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|
   293|         0|            0|            0|  0.00%|@set_array_function_like_doc
   294|         0|            0|            0|  0.00%|@set_module('numpy')
   295|         0|            0|            0|  0.00%|def require(a, dtype=None, requirements=None, *, like=None):
   296|         0|            0|            0|  0.00%|    """
   297|         0|            0|            0|  0.00%|    Return an ndarray of the provided type that satisfies requirements.
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|    This function is useful to be sure that an array with the correct flags
   300|         0|            0|            0|  0.00%|    is returned for passing to compiled code (perhaps through ctypes).
   301|         0|            0|            0|  0.00%|
   302|         0|            0|            0|  0.00%|    Parameters
   303|         0|            0|            0|  0.00%|    ----------
   304|         0|            0|            0|  0.00%|    a : array_like
   305|         0|            0|            0|  0.00%|       The object to be converted to a type-and-requirement-satisfying array.
   306|         0|            0|            0|  0.00%|    dtype : data-type
   307|         0|            0|            0|  0.00%|       The required data-type. If None preserve the current dtype. If your
   308|         0|            0|            0|  0.00%|       application requires the data to be in native byteorder, include
   309|         0|            0|            0|  0.00%|       a byteorder specification as a part of the dtype specification.
   310|         0|            0|            0|  0.00%|    requirements : str or list of str
   311|         0|            0|            0|  0.00%|       The requirements list can be any of the following
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|       * 'F_CONTIGUOUS' ('F') - ensure a Fortran-contiguous array
   314|         0|            0|            0|  0.00%|       * 'C_CONTIGUOUS' ('C') - ensure a C-contiguous array
   315|         0|            0|            0|  0.00%|       * 'ALIGNED' ('A')      - ensure a data-type aligned array
   316|         0|            0|            0|  0.00%|       * 'WRITEABLE' ('W')    - ensure a writable array
   317|         0|            0|            0|  0.00%|       * 'OWNDATA' ('O')      - ensure an array that owns its own data
   318|         0|            0|            0|  0.00%|       * 'ENSUREARRAY', ('E') - ensure a base array, instead of a subclass
   319|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   322|         0|            0|            0|  0.00%|
   323|         0|            0|            0|  0.00%|    Returns
   324|         0|            0|            0|  0.00%|    -------
   325|         0|            0|            0|  0.00%|    out : ndarray
   326|         0|            0|            0|  0.00%|        Array with specified requirements and type if given.
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    See Also
   329|         0|            0|            0|  0.00%|    --------
   330|         0|            0|            0|  0.00%|    asarray : Convert input to an ndarray.
   331|         0|            0|            0|  0.00%|    asanyarray : Convert to an ndarray, but pass through ndarray subclasses.
   332|         0|            0|            0|  0.00%|    ascontiguousarray : Convert input to a contiguous array.
   333|         0|            0|            0|  0.00%|    asfortranarray : Convert input to an ndarray with column-major
   334|         0|            0|            0|  0.00%|                     memory order.
   335|         0|            0|            0|  0.00%|    ndarray.flags : Information about the memory layout of the array.
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    Notes
   338|         0|            0|            0|  0.00%|    -----
   339|         0|            0|            0|  0.00%|    The returned array will be guaranteed to have the listed requirements
   340|         0|            0|            0|  0.00%|    by making a copy if needed.
   341|         0|            0|            0|  0.00%|
   342|         0|            0|            0|  0.00%|    Examples
   343|         0|            0|            0|  0.00%|    --------
   344|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2,3)
   345|         0|            0|            0|  0.00%|    >>> x.flags
   346|         0|            0|            0|  0.00%|      C_CONTIGUOUS : True
   347|         0|            0|            0|  0.00%|      F_CONTIGUOUS : False
   348|         0|            0|            0|  0.00%|      OWNDATA : False
   349|         0|            0|            0|  0.00%|      WRITEABLE : True
   350|         0|            0|            0|  0.00%|      ALIGNED : True
   351|         0|            0|            0|  0.00%|      WRITEBACKIFCOPY : False
   352|         0|            0|            0|  0.00%|      UPDATEIFCOPY : False
   353|         0|            0|            0|  0.00%|
   354|         0|            0|            0|  0.00%|    >>> y = np.require(x, dtype=np.float32, requirements=['A', 'O', 'W', 'F'])
   355|         0|            0|            0|  0.00%|    >>> y.flags
   356|         0|            0|            0|  0.00%|      C_CONTIGUOUS : False
   357|         0|            0|            0|  0.00%|      F_CONTIGUOUS : True
   358|         0|            0|            0|  0.00%|      OWNDATA : True
   359|         0|            0|            0|  0.00%|      WRITEABLE : True
   360|         0|            0|            0|  0.00%|      ALIGNED : True
   361|         0|            0|            0|  0.00%|      WRITEBACKIFCOPY : False
   362|         0|            0|            0|  0.00%|      UPDATEIFCOPY : False
   363|         0|            0|            0|  0.00%|
   364|         0|            0|            0|  0.00%|    """
   365|         0|            0|            0|  0.00%|    if like is not None:
   366|         0|            0|            0|  0.00%|        return _require_with_like(
   367|         0|            0|            0|  0.00%|            a,
   368|         0|            0|            0|  0.00%|            dtype=dtype,
   369|         0|            0|            0|  0.00%|            requirements=requirements,
   370|         0|            0|            0|  0.00%|            like=like,
   371|         0|            0|            0|  0.00%|        )
   372|         0|            0|            0|  0.00%|
   373|         0|            0|            0|  0.00%|    possible_flags = {'C': 'C', 'C_CONTIGUOUS': 'C', 'CONTIGUOUS': 'C',
   374|         0|            0|            0|  0.00%|                      'F': 'F', 'F_CONTIGUOUS': 'F', 'FORTRAN': 'F',
   375|         0|            0|            0|  0.00%|                      'A': 'A', 'ALIGNED': 'A',
   376|         0|            0|            0|  0.00%|                      'W': 'W', 'WRITEABLE': 'W',
   377|         0|            0|            0|  0.00%|                      'O': 'O', 'OWNDATA': 'O',
   378|         0|            0|            0|  0.00%|                      'E': 'E', 'ENSUREARRAY': 'E'}
   379|         0|            0|            0|  0.00%|    if not requirements:
   380|         0|            0|            0|  0.00%|        return asanyarray(a, dtype=dtype)
   381|         0|            0|            0|  0.00%|    else:
   382|         0|            0|            0|  0.00%|        requirements = {possible_flags[x.upper()] for x in requirements}
   383|         0|            0|            0|  0.00%|
   384|         0|            0|            0|  0.00%|    if 'E' in requirements:
   385|         0|            0|            0|  0.00%|        requirements.remove('E')
   386|         0|            0|            0|  0.00%|        subok = False
   387|         0|            0|            0|  0.00%|    else:
   388|         0|            0|            0|  0.00%|        subok = True
   389|         0|            0|            0|  0.00%|
   390|         0|            0|            0|  0.00%|    order = 'A'
   391|         0|            0|            0|  0.00%|    if requirements >= {'C', 'F'}:
   392|         0|            0|            0|  0.00%|        raise ValueError('Cannot specify both "C" and "F" order')
   393|         0|            0|            0|  0.00%|    elif 'F' in requirements:
   394|         0|            0|            0|  0.00%|        order = 'F'
   395|         0|            0|            0|  0.00%|        requirements.remove('F')
   396|         0|            0|            0|  0.00%|    elif 'C' in requirements:
   397|         0|            0|            0|  0.00%|        order = 'C'
   398|         0|            0|            0|  0.00%|        requirements.remove('C')
   399|         0|            0|            0|  0.00%|
   400|         0|            0|            0|  0.00%|    arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)
   401|         0|            0|            0|  0.00%|
   402|         0|            0|            0|  0.00%|    for prop in requirements:
   403|         0|            0|            0|  0.00%|        if not arr.flags[prop]:
   404|         0|            0|            0|  0.00%|            arr = arr.copy(order)
   405|         0|            0|            0|  0.00%|            break
   406|         0|            0|            0|  0.00%|    return arr
   407|         0|            0|            0|  0.00%|
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|_require_with_like = array_function_dispatch(
   410|         0|            0|            0|  0.00%|    _require_dispatcher
   411|         0|            0|            0|  0.00%|)(require)
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py
File duration: 0.00490165s (0.57%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|# coding=utf-8
     2|         0|            0|            0|  0.00%|# Copyright 2020 The HuggingFace Inc. team.
     3|         0|            0|            0|  0.00%|#
     4|         0|            0|            0|  0.00%|# Licensed under the Apache License, Version 2.0 (the "License");
     5|         0|            0|            0|  0.00%|# you may not use this file except in compliance with the License.
     6|         0|            0|            0|  0.00%|# You may obtain a copy of the License at
     7|         0|            0|            0|  0.00%|#
     8|         0|            0|            0|  0.00%|#     http://www.apache.org/licenses/LICENSE-2.0
     9|         0|            0|            0|  0.00%|#
    10|         0|            0|            0|  0.00%|# Unless required by applicable law or agreed to in writing, software
    11|         0|            0|            0|  0.00%|# distributed under the License is distributed on an "AS IS" BASIS,
    12|         0|            0|            0|  0.00%|# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    13|         0|            0|            0|  0.00%|# See the License for the specific language governing permissions and
    14|         0|            0|            0|  0.00%|# limitations under the License.
    15|         0|            0|            0|  0.00%|"""
    16|         0|            0|            0|  0.00%|Base classes common to both the slow and the fast tokenization classes: PreTrainedTokenizerBase (host all the user
    17|         0|            0|            0|  0.00%|fronting encoding methods) Special token mixing (host the special tokens logic) and BatchEncoding (wrap the dictionary
    18|         0|            0|            0|  0.00%|of output with special method for the Fast tokenizers)
    19|         0|            0|            0|  0.00%|"""
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|import copy
    22|         0|            0|            0|  0.00%|import json
    23|         0|            0|            0|  0.00%|import os
    24|         0|            0|            0|  0.00%|import warnings
    25|         0|            0|            0|  0.00%|from collections import OrderedDict, UserDict
    26|         0|            0|            0|  0.00%|from contextlib import contextmanager
    27|         0|            0|            0|  0.00%|from dataclasses import dataclass, field
    28|         0|            0|            0|  0.00%|from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Sequence, Tuple, Union
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|import numpy as np
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|import requests
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|from .file_utils import (
    35|         0|            0|            0|  0.00%|    ExplicitEnum,
    36|         0|            0|            0|  0.00%|    PaddingStrategy,
    37|         0|            0|            0|  0.00%|    PushToHubMixin,
    38|         0|            0|            0|  0.00%|    TensorType,
    39|         0|            0|            0|  0.00%|    _is_jax,
    40|         0|            0|            0|  0.00%|    _is_numpy,
    41|         0|            0|            0|  0.00%|    _is_tensorflow,
    42|         0|            0|            0|  0.00%|    _is_torch,
    43|         0|            0|            0|  0.00%|    _is_torch_device,
    44|         0|            0|            0|  0.00%|    add_end_docstrings,
    45|         0|            0|            0|  0.00%|    cached_path,
    46|         0|            0|            0|  0.00%|    hf_bucket_url,
    47|         0|            0|            0|  0.00%|    is_flax_available,
    48|         0|            0|            0|  0.00%|    is_offline_mode,
    49|         0|            0|            0|  0.00%|    is_remote_url,
    50|         0|            0|            0|  0.00%|    is_tf_available,
    51|         0|            0|            0|  0.00%|    is_tokenizers_available,
    52|         0|            0|            0|  0.00%|    is_torch_available,
    53|         0|            0|            0|  0.00%|    to_py_obj,
    54|         0|            0|            0|  0.00%|    torch_required,
    55|         0|            0|            0|  0.00%|)
    56|         0|            0|            0|  0.00%|from .utils import logging
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|if TYPE_CHECKING:
    60|         0|            0|            0|  0.00%|    if is_torch_available():
    61|         0|            0|            0|  0.00%|        import torch
    62|         0|            0|            0|  0.00%|    if is_tf_available():
    63|         0|            0|            0|  0.00%|        import tensorflow as tf
    64|         0|            0|            0|  0.00%|    if is_flax_available():
    65|         0|            0|            0|  0.00%|        import jax.numpy as jnp  # noqa: F401
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|if is_tokenizers_available():
    69|         0|            0|            0|  0.00%|    from tokenizers import AddedToken
    70|         0|            0|            0|  0.00%|    from tokenizers import Encoding as EncodingFast
    71|         0|            0|            0|  0.00%|else:
    72|         0|            0|            0|  0.00%|
    73|         0|            0|            0|  0.00%|    @dataclass(frozen=True, eq=True)
    74|         0|            0|            0|  0.00%|    class AddedToken:
    75|         0|            0|            0|  0.00%|        """
    76|         0|            0|            0|  0.00%|        AddedToken represents a token to be added to a Tokenizer An AddedToken can have special options defining the
    77|         0|            0|            0|  0.00%|        way it should behave.
    78|         0|            0|            0|  0.00%|        """
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|        content: str = field(default_factory=str)
    81|         0|            0|            0|  0.00%|        single_word: bool = False
    82|         0|            0|            0|  0.00%|        lstrip: bool = False
    83|         0|            0|            0|  0.00%|        rstrip: bool = False
    84|         0|            0|            0|  0.00%|        normalized: bool = True
    85|         0|            0|            0|  0.00%|
    86|         0|            0|            0|  0.00%|        def __getstate__(self):
    87|         0|            0|            0|  0.00%|            return self.__dict__
    88|         0|            0|            0|  0.00%|
    89|         0|            0|            0|  0.00%|    @dataclass
    90|         0|            0|            0|  0.00%|    class EncodingFast:
    91|         0|            0|            0|  0.00%|        """This is dummy class because without the `tokenizers` library we don't have these objects anyway"""
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|        pass
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|
    96|         0|            0|            0|  0.00%|logger = logging.get_logger(__name__)
    97|         0|            0|            0|  0.00%|
    98|         0|            0|            0|  0.00%|VERY_LARGE_INTEGER = int(1e30)  # This is used to set the max input length for a model with infinite size input
    99|         0|            0|            0|  0.00%|LARGE_INTEGER = int(1e20)  # This is used when we need something big but slightly smaller than VERY_LARGE_INTEGER
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|# Define type aliases and NamedTuples
   102|         0|            0|            0|  0.00%|TextInput = str
   103|         0|            0|            0|  0.00%|PreTokenizedInput = List[str]
   104|         0|            0|            0|  0.00%|EncodedInput = List[int]
   105|         0|            0|            0|  0.00%|TextInputPair = Tuple[str, str]
   106|         0|            0|            0|  0.00%|PreTokenizedInputPair = Tuple[List[str], List[str]]
   107|         0|            0|            0|  0.00%|EncodedInputPair = Tuple[List[int], List[int]]
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|# Slow tokenizers used to be saved in three separated files
   111|         0|            0|            0|  0.00%|SPECIAL_TOKENS_MAP_FILE = "special_tokens_map.json"
   112|         0|            0|            0|  0.00%|ADDED_TOKENS_FILE = "added_tokens.json"
   113|         0|            0|            0|  0.00%|TOKENIZER_CONFIG_FILE = "tokenizer_config.json"
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|# Fast tokenizers (provided by HuggingFace tokenizer's library) can be saved in a single file
   116|         0|            0|            0|  0.00%|FULL_TOKENIZER_FILE = "tokenizer.json"
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|class TruncationStrategy(ExplicitEnum):
   120|         0|            0|            0|  0.00%|    """
   121|         0|            0|            0|  0.00%|    Possible values for the ``truncation`` argument in :meth:`PreTrainedTokenizerBase.__call__`. Useful for
   122|         0|            0|            0|  0.00%|    tab-completion in an IDE.
   123|         0|            0|            0|  0.00%|    """
   124|         0|            0|            0|  0.00%|
   125|         0|            0|            0|  0.00%|    ONLY_FIRST = "only_first"
   126|         0|            0|            0|  0.00%|    ONLY_SECOND = "only_second"
   127|         0|            0|            0|  0.00%|    LONGEST_FIRST = "longest_first"
   128|         0|            0|            0|  0.00%|    DO_NOT_TRUNCATE = "do_not_truncate"
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|class CharSpan(NamedTuple):
   132|         0|            0|            0|  0.00%|    """
   133|         0|            0|            0|  0.00%|    Character span in the original string.
   134|         0|            0|            0|  0.00%|
   135|         0|            0|            0|  0.00%|    Args:
   136|         0|            0|            0|  0.00%|        start (:obj:`int`): Index of the first character in the original string.
   137|         0|            0|            0|  0.00%|        end (:obj:`int`): Index of the character following the last character in the original string.
   138|         0|            0|            0|  0.00%|    """
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|    start: int
   141|         0|            0|            0|  0.00%|    end: int
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|class TokenSpan(NamedTuple):
   145|         0|            0|            0|  0.00%|    """
   146|         0|            0|            0|  0.00%|    Token span in an encoded string (list of tokens).
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    Args:
   149|         0|            0|            0|  0.00%|        start (:obj:`int`): Index of the first token in the span.
   150|         0|            0|            0|  0.00%|        end (:obj:`int`): Index of the token following the last token in the span.
   151|         0|            0|            0|  0.00%|    """
   152|         0|            0|            0|  0.00%|
   153|         0|            0|            0|  0.00%|    start: int
   154|         0|            0|            0|  0.00%|    end: int
   155|         0|            0|            0|  0.00%|
   156|         0|            0|            0|  0.00%|
   157|         0|            0|            0|  0.00%|class BatchEncoding(UserDict):
   158|         0|            0|            0|  0.00%|    """
   159|         0|            0|            0|  0.00%|    Holds the output of the :meth:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode_plus` and
   160|         0|            0|            0|  0.00%|    :meth:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode` methods (tokens,
   161|         0|            0|            0|  0.00%|    attention_masks, etc).
   162|         0|            0|            0|  0.00%|
   163|         0|            0|            0|  0.00%|    This class is derived from a python dictionary and can be used as a dictionary. In addition, this class exposes
   164|         0|            0|            0|  0.00%|    utility methods to map from word/character space to token space.
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|    Args:
   167|         0|            0|            0|  0.00%|        data (:obj:`dict`):
   168|         0|            0|            0|  0.00%|            Dictionary of lists/arrays/tensors returned by the encode/batch_encode methods ('input_ids',
   169|         0|            0|            0|  0.00%|            'attention_mask', etc.).
   170|         0|            0|            0|  0.00%|        encoding (:obj:`tokenizers.Encoding` or :obj:`Sequence[tokenizers.Encoding]`, `optional`):
   171|         0|            0|            0|  0.00%|            If the tokenizer is a fast tokenizer which outputs additional information like mapping from word/character
   172|         0|            0|            0|  0.00%|            space to token space the :obj:`tokenizers.Encoding` instance or list of instance (for batches) hold this
   173|         0|            0|            0|  0.00%|            information.
   174|         0|            0|            0|  0.00%|        tensor_type (:obj:`Union[None, str, TensorType]`, `optional`):
   175|         0|            0|            0|  0.00%|            You can give a tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy Tensors at
   176|         0|            0|            0|  0.00%|            initialization.
   177|         0|            0|            0|  0.00%|        prepend_batch_axis (:obj:`bool`, `optional`, defaults to :obj:`False`):
   178|         0|            0|            0|  0.00%|            Whether or not to add a batch axis when converting to tensors (see :obj:`tensor_type` above).
   179|         0|            0|            0|  0.00%|        n_sequences (:obj:`Optional[int]`, `optional`):
   180|         0|            0|            0|  0.00%|            You can give a tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy Tensors at
   181|         0|            0|            0|  0.00%|            initialization.
   182|         0|            0|            0|  0.00%|    """
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|    def __init__(
   185|         0|            0|            0|  0.00%|        self,
   186|         0|            0|            0|  0.00%|        data: Optional[Dict[str, Any]] = None,
   187|         0|            0|            0|  0.00%|        encoding: Optional[Union[EncodingFast, Sequence[EncodingFast]]] = None,
   188|         0|            0|            0|  0.00%|        tensor_type: Union[None, str, TensorType] = None,
   189|         0|            0|            0|  0.00%|        prepend_batch_axis: bool = False,
   190|         0|            0|            0|  0.00%|        n_sequences: Optional[int] = None,
   191|         0|            0|            0|  0.00%|    ):
   192|         0|            0|            0|  0.00%|        super().__init__(data)
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|        if isinstance(encoding, EncodingFast):
   195|         0|            0|            0|  0.00%|            encoding = [encoding]
   196|         0|            0|            0|  0.00%|
   197|         0|            0|            0|  0.00%|        self._encodings = encoding
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|        if n_sequences is None and encoding is not None and len(encoding):
   200|         0|            0|            0|  0.00%|            n_sequences = encoding[0].n_sequences
   201|         0|            0|            0|  0.00%|
   202|         0|            0|            0|  0.00%|        self._n_sequences = n_sequences
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|        self.convert_to_tensors(tensor_type=tensor_type, prepend_batch_axis=prepend_batch_axis)
   205|         0|            0|            0|  0.00%|
   206|         0|            0|            0|  0.00%|    @property
   207|         0|            0|            0|  0.00%|    def n_sequences(self) -> Optional[int]:
   208|         0|            0|            0|  0.00%|        """
   209|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: The number of sequences used to generate each sample from the batch encoded in this
   210|         0|            0|            0|  0.00%|        :class:`~transformers.BatchEncoding`. Currently can be one of :obj:`None` (unknown), :obj:`1` (a single
   211|         0|            0|            0|  0.00%|        sentence) or :obj:`2` (a pair of sentences)
   212|         0|            0|            0|  0.00%|        """
   213|         0|            0|            0|  0.00%|        return self._n_sequences
   214|         0|            0|            0|  0.00%|
   215|         0|            0|            0|  0.00%|    @property
   216|         0|            0|            0|  0.00%|    def is_fast(self) -> bool:
   217|         0|            0|            0|  0.00%|        """
   218|         0|            0|            0|  0.00%|        :obj:`bool`: Indicate whether this :class:`~transformers.BatchEncoding` was generated from the result of a
   219|         0|            0|            0|  0.00%|        :class:`~transformers.PreTrainedTokenizerFast` or not.
   220|         0|            0|            0|  0.00%|        """
   221|         0|            0|            0|  0.00%|        return self._encodings is not None
   222|         0|            0|            0|  0.00%|
   223|         0|            0|            0|  0.00%|    def __getitem__(self, item: Union[int, str]) -> Union[Any, EncodingFast]:
   224|         0|            0|            0|  0.00%|        """
   225|         0|            0|            0|  0.00%|        If the key is a string, returns the value of the dict associated to :obj:`key` ('input_ids', 'attention_mask',
   226|         0|            0|            0|  0.00%|        etc.).
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|        If the key is an integer, get the :obj:`tokenizers.Encoding` for batch item with index :obj:`key`.
   229|         0|            0|            0|  0.00%|        """
   230|         0|            0|            0|  0.00%|        if isinstance(item, str):
   231|         0|            0|            0|  0.00%|            return self.data[item]
   232|         0|            0|            0|  0.00%|        elif self._encodings is not None:
   233|         0|            0|            0|  0.00%|            return self._encodings[item]
   234|         0|            0|            0|  0.00%|        else:
   235|         0|            0|            0|  0.00%|            raise KeyError(
   236|         0|            0|            0|  0.00%|                "Indexing with integers (to access backend Encoding for a given batch index) "
   237|         0|            0|            0|  0.00%|                "is not available when using Python based tokenizers"
   238|         0|            0|            0|  0.00%|            )
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|    def __getattr__(self, item: str):
   241|         0|            0|            0|  0.00%|        try:
   242|         0|            0|            0|  0.00%|            return self.data[item]
   243|         0|            0|            0|  0.00%|        except KeyError:
   244|         0|            0|            0|  0.00%|            raise AttributeError
   245|         0|            0|            0|  0.00%|
   246|         0|            0|            0|  0.00%|    def __getstate__(self):
   247|         0|            0|            0|  0.00%|        return {"data": self.data, "encodings": self._encodings}
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|    def __setstate__(self, state):
   250|         0|            0|            0|  0.00%|        if "data" in state:
   251|         0|            0|            0|  0.00%|            self.data = state["data"]
   252|         0|            0|            0|  0.00%|
   253|         0|            0|            0|  0.00%|        if "encodings" in state:
   254|         0|            0|            0|  0.00%|            self._encodings = state["encodings"]
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|    def keys(self):
   257|         0|            0|            0|  0.00%|        return self.data.keys()
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    def values(self):
   260|         0|            0|            0|  0.00%|        return self.data.values()
   261|         0|            0|            0|  0.00%|
   262|         0|            0|            0|  0.00%|    def items(self):
   263|         0|            0|            0|  0.00%|        return self.data.items()
   264|         0|            0|            0|  0.00%|
   265|         0|            0|            0|  0.00%|    # After this point:
   266|         0|            0|            0|  0.00%|    # Extended properties and methods only available for fast (Rust-based) tokenizers
   267|         0|            0|            0|  0.00%|    # provided by HuggingFace tokenizers library.
   268|         0|            0|            0|  0.00%|
   269|         0|            0|            0|  0.00%|    @property
   270|         0|            0|            0|  0.00%|    def encodings(self) -> Optional[List[EncodingFast]]:
   271|         0|            0|            0|  0.00%|        """
   272|         0|            0|            0|  0.00%|        :obj:`Optional[List[tokenizers.Encoding]]`: The list all encodings from the tokenization process. Returns
   273|         0|            0|            0|  0.00%|        :obj:`None` if the input was tokenized through Python (i.e., not a fast) tokenizer.
   274|         0|            0|            0|  0.00%|        """
   275|         0|            0|            0|  0.00%|        return self._encodings
   276|         0|            0|            0|  0.00%|
   277|         0|            0|            0|  0.00%|    def tokens(self, batch_index: int = 0) -> List[str]:
   278|         0|            0|            0|  0.00%|        """
   279|         0|            0|            0|  0.00%|        Return the list of tokens (sub-parts of the input strings after word/subword splitting and before conversion to
   280|         0|            0|            0|  0.00%|        integer indices) at a given batch index (only works for the output of a fast tokenizer).
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|        Args:
   283|         0|            0|            0|  0.00%|            batch_index (:obj:`int`, `optional`, defaults to 0): The index to access in the batch.
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|        Returns:
   286|         0|            0|            0|  0.00%|            :obj:`List[str]`: The list of tokens at that index.
   287|         0|            0|            0|  0.00%|        """
   288|         0|            0|            0|  0.00%|        if not self._encodings:
   289|         0|            0|            0|  0.00%|            raise ValueError("tokens() is not available when using Python-based tokenizers")
   290|         0|            0|            0|  0.00%|        return self._encodings[batch_index].tokens
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|    def sequence_ids(self, batch_index: int = 0) -> List[Optional[int]]:
   293|         0|            0|            0|  0.00%|        """
   294|         0|            0|            0|  0.00%|        Return a list mapping the tokens to the id of their original sentences:
   295|         0|            0|            0|  0.00%|
   296|         0|            0|            0|  0.00%|            - :obj:`None` for special tokens added around or between sequences,
   297|         0|            0|            0|  0.00%|            - :obj:`0` for tokens corresponding to words in the first sequence,
   298|         0|            0|            0|  0.00%|            - :obj:`1` for tokens corresponding to words in the second sequence when a pair of sequences was jointly
   299|         0|            0|            0|  0.00%|              encoded.
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|        Args:
   302|         0|            0|            0|  0.00%|            batch_index (:obj:`int`, `optional`, defaults to 0): The index to access in the batch.
   303|         0|            0|            0|  0.00%|
   304|         0|            0|            0|  0.00%|        Returns:
   305|         0|            0|            0|  0.00%|            :obj:`List[Optional[int]]`: A list indicating the sequence id corresponding to each token. Special tokens
   306|         0|            0|            0|  0.00%|            added by the tokenizer are mapped to :obj:`None` and other tokens are mapped to the index of their
   307|         0|            0|            0|  0.00%|            corresponding sequence.
   308|         0|            0|            0|  0.00%|        """
   309|         0|            0|            0|  0.00%|        if not self._encodings:
   310|         0|            0|            0|  0.00%|            raise ValueError("sequence_ids() is not available when using Python-based tokenizers")
   311|         0|            0|            0|  0.00%|        return self._encodings[batch_index].sequence_ids
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|    def words(self, batch_index: int = 0) -> List[Optional[int]]:
   314|         0|            0|            0|  0.00%|        """
   315|         0|            0|            0|  0.00%|        Return a list mapping the tokens to their actual word in the initial sentence for a fast tokenizer.
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|        Args:
   318|         0|            0|            0|  0.00%|            batch_index (:obj:`int`, `optional`, defaults to 0): The index to access in the batch.
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|        Returns:
   321|         0|            0|            0|  0.00%|            :obj:`List[Optional[int]]`: A list indicating the word corresponding to each token. Special tokens added by
   322|         0|            0|            0|  0.00%|            the tokenizer are mapped to :obj:`None` and other tokens are mapped to the index of their corresponding
   323|         0|            0|            0|  0.00%|            word (several tokens will be mapped to the same word index if they are parts of that word).
   324|         0|            0|            0|  0.00%|        """
   325|         0|            0|            0|  0.00%|        if not self._encodings:
   326|         0|            0|            0|  0.00%|            raise ValueError("words() is not available when using Python-based tokenizers")
   327|         0|            0|            0|  0.00%|        warnings.warn(
   328|         0|            0|            0|  0.00%|            "`BatchEncoding.words()` property is deprecated and should be replaced with the identical, "
   329|         0|            0|            0|  0.00%|            "but more self-explanatory `BatchEncoding.word_ids()` property.",
   330|         0|            0|            0|  0.00%|            FutureWarning,
   331|         0|            0|            0|  0.00%|        )
   332|         0|            0|            0|  0.00%|        return self.word_ids(batch_index)
   333|         0|            0|            0|  0.00%|
   334|         0|            0|            0|  0.00%|    def word_ids(self, batch_index: int = 0) -> List[Optional[int]]:
   335|         0|            0|            0|  0.00%|        """
   336|         0|            0|            0|  0.00%|        Return a list mapping the tokens to their actual word in the initial sentence for a fast tokenizer.
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|        Args:
   339|         0|            0|            0|  0.00%|            batch_index (:obj:`int`, `optional`, defaults to 0): The index to access in the batch.
   340|         0|            0|            0|  0.00%|
   341|         0|            0|            0|  0.00%|        Returns:
   342|         0|            0|            0|  0.00%|            :obj:`List[Optional[int]]`: A list indicating the word corresponding to each token. Special tokens added by
   343|         0|            0|            0|  0.00%|            the tokenizer are mapped to :obj:`None` and other tokens are mapped to the index of their corresponding
   344|         0|            0|            0|  0.00%|            word (several tokens will be mapped to the same word index if they are parts of that word).
   345|         0|            0|            0|  0.00%|        """
   346|         0|            0|            0|  0.00%|        if not self._encodings:
   347|         0|            0|            0|  0.00%|            raise ValueError("word_ids() is not available when using Python-based tokenizers")
   348|         0|            0|            0|  0.00%|        return self._encodings[batch_index].word_ids
   349|         0|            0|            0|  0.00%|
   350|         0|            0|            0|  0.00%|    def token_to_sequence(self, batch_or_token_index: int, token_index: Optional[int] = None) -> int:
   351|         0|            0|            0|  0.00%|        """
   352|         0|            0|            0|  0.00%|        Get the index of the sequence represented by the given token. In the general use case, this method returns
   353|         0|            0|            0|  0.00%|        :obj:`0` for a single sequence or the first sequence of a pair, and :obj:`1` for the second sequence of a pair
   354|         0|            0|            0|  0.00%|
   355|         0|            0|            0|  0.00%|        Can be called as:
   356|         0|            0|            0|  0.00%|
   357|         0|            0|            0|  0.00%|        - ``self.token_to_sequence(token_index)`` if batch size is 1
   358|         0|            0|            0|  0.00%|        - ``self.token_to_sequence(batch_index, token_index)`` if batch size is greater than 1
   359|         0|            0|            0|  0.00%|
   360|         0|            0|            0|  0.00%|        This method is particularly suited when the input sequences are provided as pre-tokenized sequences (i.e.,
   361|         0|            0|            0|  0.00%|        words are defined by the user). In this case it allows to easily associate encoded tokens with provided
   362|         0|            0|            0|  0.00%|        tokenized words.
   363|         0|            0|            0|  0.00%|
   364|         0|            0|            0|  0.00%|        Args:
   365|         0|            0|            0|  0.00%|            batch_or_token_index (:obj:`int`):
   366|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprises one sequence, this can be the index of
   367|         0|            0|            0|  0.00%|                the token in the sequence.
   368|         0|            0|            0|  0.00%|            token_index (:obj:`int`, `optional`):
   369|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the token in the
   370|         0|            0|            0|  0.00%|                sequence.
   371|         0|            0|            0|  0.00%|
   372|         0|            0|            0|  0.00%|        Returns:
   373|         0|            0|            0|  0.00%|            :obj:`int`: Index of the word in the input sequence.
   374|         0|            0|            0|  0.00%|        """
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|        if not self._encodings:
   377|         0|            0|            0|  0.00%|            raise ValueError("token_to_sequence() is not available when using Python based tokenizers")
   378|         0|            0|            0|  0.00%|        if token_index is not None:
   379|         0|            0|            0|  0.00%|            batch_index = batch_or_token_index
   380|         0|            0|            0|  0.00%|        else:
   381|         0|            0|            0|  0.00%|            batch_index = 0
   382|         0|            0|            0|  0.00%|            token_index = batch_or_token_index
   383|         0|            0|            0|  0.00%|        if batch_index < 0:
   384|         0|            0|            0|  0.00%|            batch_index = self._batch_size + batch_index
   385|         0|            0|            0|  0.00%|        if token_index < 0:
   386|         0|            0|            0|  0.00%|            token_index = self._seq_len + token_index
   387|         0|            0|            0|  0.00%|        return self._encodings[batch_index].token_to_sequence(token_index)
   388|         0|            0|            0|  0.00%|
   389|         0|            0|            0|  0.00%|    def token_to_word(self, batch_or_token_index: int, token_index: Optional[int] = None) -> int:
   390|         0|            0|            0|  0.00%|        """
   391|         0|            0|            0|  0.00%|        Get the index of the word corresponding (i.e. comprising) to an encoded token in a sequence of the batch.
   392|         0|            0|            0|  0.00%|
   393|         0|            0|            0|  0.00%|        Can be called as:
   394|         0|            0|            0|  0.00%|
   395|         0|            0|            0|  0.00%|        - ``self.token_to_word(token_index)`` if batch size is 1
   396|         0|            0|            0|  0.00%|        - ``self.token_to_word(batch_index, token_index)`` if batch size is greater than 1
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|        This method is particularly suited when the input sequences are provided as pre-tokenized sequences (i.e.,
   399|         0|            0|            0|  0.00%|        words are defined by the user). In this case it allows to easily associate encoded tokens with provided
   400|         0|            0|            0|  0.00%|        tokenized words.
   401|         0|            0|            0|  0.00%|
   402|         0|            0|            0|  0.00%|        Args:
   403|         0|            0|            0|  0.00%|            batch_or_token_index (:obj:`int`):
   404|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprise one sequence, this can be the index of
   405|         0|            0|            0|  0.00%|                the token in the sequence.
   406|         0|            0|            0|  0.00%|            token_index (:obj:`int`, `optional`):
   407|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the token in the
   408|         0|            0|            0|  0.00%|                sequence.
   409|         0|            0|            0|  0.00%|
   410|         0|            0|            0|  0.00%|        Returns:
   411|         0|            0|            0|  0.00%|            :obj:`int`: Index of the word in the input sequence.
   412|         0|            0|            0|  0.00%|        """
   413|         0|            0|            0|  0.00%|
   414|         0|            0|            0|  0.00%|        if not self._encodings:
   415|         0|            0|            0|  0.00%|            raise ValueError("token_to_word() is not available when using Python based tokenizers")
   416|         0|            0|            0|  0.00%|        if token_index is not None:
   417|         0|            0|            0|  0.00%|            batch_index = batch_or_token_index
   418|         0|            0|            0|  0.00%|        else:
   419|         0|            0|            0|  0.00%|            batch_index = 0
   420|         0|            0|            0|  0.00%|            token_index = batch_or_token_index
   421|         0|            0|            0|  0.00%|        if batch_index < 0:
   422|         0|            0|            0|  0.00%|            batch_index = self._batch_size + batch_index
   423|         0|            0|            0|  0.00%|        if token_index < 0:
   424|         0|            0|            0|  0.00%|            token_index = self._seq_len + token_index
   425|         0|            0|            0|  0.00%|        return self._encodings[batch_index].token_to_word(token_index)
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|    def word_to_tokens(
   428|         0|            0|            0|  0.00%|        self, batch_or_word_index: int, word_index: Optional[int] = None, sequence_index: int = 0
   429|         0|            0|            0|  0.00%|    ) -> Optional[TokenSpan]:
   430|         0|            0|            0|  0.00%|        """
   431|         0|            0|            0|  0.00%|        Get the encoded token span corresponding to a word in a sequence of the batch.
   432|         0|            0|            0|  0.00%|
   433|         0|            0|            0|  0.00%|        Token spans are returned as a :class:`~transformers.tokenization_utils_base.TokenSpan` with:
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|        - **start** -- Index of the first token.
   436|         0|            0|            0|  0.00%|        - **end** -- Index of the token following the last token.
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|        Can be called as:
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|        - ``self.word_to_tokens(word_index, sequence_index: int = 0)`` if batch size is 1
   441|         0|            0|            0|  0.00%|        - ``self.word_to_tokens(batch_index, word_index, sequence_index: int = 0)`` if batch size is greater or equal
   442|         0|            0|            0|  0.00%|          to 1
   443|         0|            0|            0|  0.00%|
   444|         0|            0|            0|  0.00%|        This method is particularly suited when the input sequences are provided as pre-tokenized sequences (i.e. words
   445|         0|            0|            0|  0.00%|        are defined by the user). In this case it allows to easily associate encoded tokens with provided tokenized
   446|         0|            0|            0|  0.00%|        words.
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|        Args:
   449|         0|            0|            0|  0.00%|            batch_or_word_index (:obj:`int`):
   450|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprises one sequence, this can be the index of
   451|         0|            0|            0|  0.00%|                the word in the sequence.
   452|         0|            0|            0|  0.00%|            word_index (:obj:`int`, `optional`):
   453|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the word in the
   454|         0|            0|            0|  0.00%|                sequence.
   455|         0|            0|            0|  0.00%|            sequence_index (:obj:`int`, `optional`, defaults to 0):
   456|         0|            0|            0|  0.00%|                If pair of sequences are encoded in the batch this can be used to specify which sequence in the pair (0
   457|         0|            0|            0|  0.00%|                or 1) the provided word index belongs to.
   458|         0|            0|            0|  0.00%|
   459|         0|            0|            0|  0.00%|        Returns:
   460|         0|            0|            0|  0.00%|            Optional :class:`~transformers.tokenization_utils_base.TokenSpan` Span of tokens in the encoded sequence.
   461|         0|            0|            0|  0.00%|            Returns :obj:`None` if no tokens correspond to the word.
   462|         0|            0|            0|  0.00%|        """
   463|         0|            0|            0|  0.00%|
   464|         0|            0|            0|  0.00%|        if not self._encodings:
   465|         0|            0|            0|  0.00%|            raise ValueError("word_to_tokens() is not available when using Python based tokenizers")
   466|         0|            0|            0|  0.00%|        if word_index is not None:
   467|         0|            0|            0|  0.00%|            batch_index = batch_or_word_index
   468|         0|            0|            0|  0.00%|        else:
   469|         0|            0|            0|  0.00%|            batch_index = 0
   470|         0|            0|            0|  0.00%|            word_index = batch_or_word_index
   471|         0|            0|            0|  0.00%|        if batch_index < 0:
   472|         0|            0|            0|  0.00%|            batch_index = self._batch_size + batch_index
   473|         0|            0|            0|  0.00%|        if word_index < 0:
   474|         0|            0|            0|  0.00%|            word_index = self._seq_len + word_index
   475|         0|            0|            0|  0.00%|        span = self._encodings[batch_index].word_to_tokens(word_index, sequence_index)
   476|         0|            0|            0|  0.00%|        return TokenSpan(*span) if span is not None else None
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|    def token_to_chars(self, batch_or_token_index: int, token_index: Optional[int] = None) -> CharSpan:
   479|         0|            0|            0|  0.00%|        """
   480|         0|            0|            0|  0.00%|        Get the character span corresponding to an encoded token in a sequence of the batch.
   481|         0|            0|            0|  0.00%|
   482|         0|            0|            0|  0.00%|        Character spans are returned as a :class:`~transformers.tokenization_utils_base.CharSpan` with:
   483|         0|            0|            0|  0.00%|
   484|         0|            0|            0|  0.00%|        - **start** -- Index of the first character in the original string associated to the token.
   485|         0|            0|            0|  0.00%|        - **end** -- Index of the character following the last character in the original string associated to the
   486|         0|            0|            0|  0.00%|          token.
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|        Can be called as:
   489|         0|            0|            0|  0.00%|
   490|         0|            0|            0|  0.00%|        - ``self.token_to_chars(token_index)`` if batch size is 1
   491|         0|            0|            0|  0.00%|        - ``self.token_to_chars(batch_index, token_index)`` if batch size is greater or equal to 1
   492|         0|            0|            0|  0.00%|
   493|         0|            0|            0|  0.00%|        Args:
   494|         0|            0|            0|  0.00%|            batch_or_token_index (:obj:`int`):
   495|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprise one sequence, this can be the index of
   496|         0|            0|            0|  0.00%|                the token in the sequence.
   497|         0|            0|            0|  0.00%|            token_index (:obj:`int`, `optional`):
   498|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the token or tokens in
   499|         0|            0|            0|  0.00%|                the sequence.
   500|         0|            0|            0|  0.00%|
   501|         0|            0|            0|  0.00%|        Returns:
   502|         0|            0|            0|  0.00%|            :class:`~transformers.tokenization_utils_base.CharSpan`: Span of characters in the original string.
   503|         0|            0|            0|  0.00%|        """
   504|         0|            0|            0|  0.00%|
   505|         0|            0|            0|  0.00%|        if not self._encodings:
   506|         0|            0|            0|  0.00%|            raise ValueError("token_to_chars() is not available when using Python based tokenizers")
   507|         0|            0|            0|  0.00%|        if token_index is not None:
   508|         0|            0|            0|  0.00%|            batch_index = batch_or_token_index
   509|         0|            0|            0|  0.00%|        else:
   510|         0|            0|            0|  0.00%|            batch_index = 0
   511|         0|            0|            0|  0.00%|            token_index = batch_or_token_index
   512|         0|            0|            0|  0.00%|        return CharSpan(*(self._encodings[batch_index].token_to_chars(token_index)))
   513|         0|            0|            0|  0.00%|
   514|         0|            0|            0|  0.00%|    def char_to_token(
   515|         0|            0|            0|  0.00%|        self, batch_or_char_index: int, char_index: Optional[int] = None, sequence_index: int = 0
   516|         0|            0|            0|  0.00%|    ) -> int:
   517|         0|            0|            0|  0.00%|        """
   518|         0|            0|            0|  0.00%|        Get the index of the token in the encoded output comprising a character in the original string for a sequence
   519|         0|            0|            0|  0.00%|        of the batch.
   520|         0|            0|            0|  0.00%|
   521|         0|            0|            0|  0.00%|        Can be called as:
   522|         0|            0|            0|  0.00%|
   523|         0|            0|            0|  0.00%|        - ``self.char_to_token(char_index)`` if batch size is 1
   524|         0|            0|            0|  0.00%|        - ``self.char_to_token(batch_index, char_index)`` if batch size is greater or equal to 1
   525|         0|            0|            0|  0.00%|
   526|         0|            0|            0|  0.00%|        This method is particularly suited when the input sequences are provided as pre-tokenized sequences (i.e. words
   527|         0|            0|            0|  0.00%|        are defined by the user). In this case it allows to easily associate encoded tokens with provided tokenized
   528|         0|            0|            0|  0.00%|        words.
   529|         0|            0|            0|  0.00%|
   530|         0|            0|            0|  0.00%|        Args:
   531|         0|            0|            0|  0.00%|            batch_or_char_index (:obj:`int`):
   532|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprise one sequence, this can be the index of
   533|         0|            0|            0|  0.00%|                the word in the sequence
   534|         0|            0|            0|  0.00%|            char_index (:obj:`int`, `optional`):
   535|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the word in the
   536|         0|            0|            0|  0.00%|                sequence.
   537|         0|            0|            0|  0.00%|            sequence_index (:obj:`int`, `optional`, defaults to 0):
   538|         0|            0|            0|  0.00%|                If pair of sequences are encoded in the batch this can be used to specify which sequence in the pair (0
   539|         0|            0|            0|  0.00%|                or 1) the provided character index belongs to.
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|
   542|         0|            0|            0|  0.00%|        Returns:
   543|         0|            0|            0|  0.00%|            :obj:`int`: Index of the token.
   544|         0|            0|            0|  0.00%|        """
   545|         0|            0|            0|  0.00%|
   546|         0|            0|            0|  0.00%|        if not self._encodings:
   547|         0|            0|            0|  0.00%|            raise ValueError("char_to_token() is not available when using Python based tokenizers")
   548|         0|            0|            0|  0.00%|        if char_index is not None:
   549|         0|            0|            0|  0.00%|            batch_index = batch_or_char_index
   550|         0|            0|            0|  0.00%|        else:
   551|         0|            0|            0|  0.00%|            batch_index = 0
   552|         0|            0|            0|  0.00%|            char_index = batch_or_char_index
   553|         0|            0|            0|  0.00%|        return self._encodings[batch_index].char_to_token(char_index, sequence_index)
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|    def word_to_chars(
   556|         0|            0|            0|  0.00%|        self, batch_or_word_index: int, word_index: Optional[int] = None, sequence_index: int = 0
   557|         0|            0|            0|  0.00%|    ) -> CharSpan:
   558|         0|            0|            0|  0.00%|        """
   559|         0|            0|            0|  0.00%|        Get the character span in the original string corresponding to given word in a sequence of the batch.
   560|         0|            0|            0|  0.00%|
   561|         0|            0|            0|  0.00%|        Character spans are returned as a CharSpan NamedTuple with:
   562|         0|            0|            0|  0.00%|
   563|         0|            0|            0|  0.00%|        - start: index of the first character in the original string
   564|         0|            0|            0|  0.00%|        - end: index of the character following the last character in the original string
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|        Can be called as:
   567|         0|            0|            0|  0.00%|
   568|         0|            0|            0|  0.00%|        - ``self.word_to_chars(word_index)`` if batch size is 1
   569|         0|            0|            0|  0.00%|        - ``self.word_to_chars(batch_index, word_index)`` if batch size is greater or equal to 1
   570|         0|            0|            0|  0.00%|
   571|         0|            0|            0|  0.00%|        Args:
   572|         0|            0|            0|  0.00%|            batch_or_word_index (:obj:`int`):
   573|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprise one sequence, this can be the index of
   574|         0|            0|            0|  0.00%|                the word in the sequence
   575|         0|            0|            0|  0.00%|            word_index (:obj:`int`, `optional`):
   576|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the word in the
   577|         0|            0|            0|  0.00%|                sequence.
   578|         0|            0|            0|  0.00%|            sequence_index (:obj:`int`, `optional`, defaults to 0):
   579|         0|            0|            0|  0.00%|                If pair of sequences are encoded in the batch this can be used to specify which sequence in the pair (0
   580|         0|            0|            0|  0.00%|                or 1) the provided word index belongs to.
   581|         0|            0|            0|  0.00%|
   582|         0|            0|            0|  0.00%|        Returns:
   583|         0|            0|            0|  0.00%|            :obj:`CharSpan` or :obj:`List[CharSpan]`: Span(s) of the associated character or characters in the string.
   584|         0|            0|            0|  0.00%|            CharSpan are NamedTuple with:
   585|         0|            0|            0|  0.00%|
   586|         0|            0|            0|  0.00%|                - start: index of the first character associated to the token in the original string
   587|         0|            0|            0|  0.00%|                - end: index of the character following the last character associated to the token in the original
   588|         0|            0|            0|  0.00%|                  string
   589|         0|            0|            0|  0.00%|        """
   590|         0|            0|            0|  0.00%|
   591|         0|            0|            0|  0.00%|        if not self._encodings:
   592|         0|            0|            0|  0.00%|            raise ValueError("word_to_chars() is not available when using Python based tokenizers")
   593|         0|            0|            0|  0.00%|        if word_index is not None:
   594|         0|            0|            0|  0.00%|            batch_index = batch_or_word_index
   595|         0|            0|            0|  0.00%|        else:
   596|         0|            0|            0|  0.00%|            batch_index = 0
   597|         0|            0|            0|  0.00%|            word_index = batch_or_word_index
   598|         0|            0|            0|  0.00%|        return CharSpan(*(self._encodings[batch_index].word_to_chars(word_index, sequence_index)))
   599|         0|            0|            0|  0.00%|
   600|         0|            0|            0|  0.00%|    def char_to_word(self, batch_or_char_index: int, char_index: Optional[int] = None, sequence_index: int = 0) -> int:
   601|         0|            0|            0|  0.00%|        """
   602|         0|            0|            0|  0.00%|        Get the word in the original string corresponding to a character in the original string of a sequence of the
   603|         0|            0|            0|  0.00%|        batch.
   604|         0|            0|            0|  0.00%|
   605|         0|            0|            0|  0.00%|        Can be called as:
   606|         0|            0|            0|  0.00%|
   607|         0|            0|            0|  0.00%|        - ``self.char_to_word(char_index)`` if batch size is 1
   608|         0|            0|            0|  0.00%|        - ``self.char_to_word(batch_index, char_index)`` if batch size is greater than 1
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|        This method is particularly suited when the input sequences are provided as pre-tokenized sequences (i.e. words
   611|         0|            0|            0|  0.00%|        are defined by the user). In this case it allows to easily associate encoded tokens with provided tokenized
   612|         0|            0|            0|  0.00%|        words.
   613|         0|            0|            0|  0.00%|
   614|         0|            0|            0|  0.00%|        Args:
   615|         0|            0|            0|  0.00%|            batch_or_char_index (:obj:`int`):
   616|         0|            0|            0|  0.00%|                Index of the sequence in the batch. If the batch only comprise one sequence, this can be the index of
   617|         0|            0|            0|  0.00%|                the character in the original string.
   618|         0|            0|            0|  0.00%|            char_index (:obj:`int`, `optional`):
   619|         0|            0|            0|  0.00%|                If a batch index is provided in `batch_or_token_index`, this can be the index of the character in the
   620|         0|            0|            0|  0.00%|                original string.
   621|         0|            0|            0|  0.00%|            sequence_index (:obj:`int`, `optional`, defaults to 0):
   622|         0|            0|            0|  0.00%|                If pair of sequences are encoded in the batch this can be used to specify which sequence in the pair (0
   623|         0|            0|            0|  0.00%|                or 1) the provided character index belongs to.
   624|         0|            0|            0|  0.00%|
   625|         0|            0|            0|  0.00%|
   626|         0|            0|            0|  0.00%|        Returns:
   627|         0|            0|            0|  0.00%|            :obj:`int` or :obj:`List[int]`: Index or indices of the associated encoded token(s).
   628|         0|            0|            0|  0.00%|        """
   629|         0|            0|            0|  0.00%|
   630|         0|            0|            0|  0.00%|        if not self._encodings:
   631|         0|            0|            0|  0.00%|            raise ValueError("char_to_word() is not available when using Python based tokenizers")
   632|         0|            0|            0|  0.00%|        if char_index is not None:
   633|         0|            0|            0|  0.00%|            batch_index = batch_or_char_index
   634|         0|            0|            0|  0.00%|        else:
   635|         0|            0|            0|  0.00%|            batch_index = 0
   636|         0|            0|            0|  0.00%|            char_index = batch_or_char_index
   637|         0|            0|            0|  0.00%|        return self._encodings[batch_index].char_to_word(char_index, sequence_index)
   638|         0|            0|            0|  0.00%|
   639|         0|            0|            0|  0.00%|    def convert_to_tensors(
   640|         0|            0|            0|  0.00%|        self, tensor_type: Optional[Union[str, TensorType]] = None, prepend_batch_axis: bool = False
   641|         0|            0|            0|  0.00%|    ):
   642|         0|            0|            0|  0.00%|        """
   643|         0|            0|            0|  0.00%|        Convert the inner content to tensors.
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|        Args:
   646|         0|            0|            0|  0.00%|            tensor_type (:obj:`str` or :class:`~transformers.file_utils.TensorType`, `optional`):
   647|         0|            0|            0|  0.00%|                The type of tensors to use. If :obj:`str`, should be one of the values of the enum
   648|         0|            0|            0|  0.00%|                :class:`~transformers.file_utils.TensorType`. If :obj:`None`, no modification is done.
   649|         0|            0|            0|  0.00%|            prepend_batch_axis (:obj:`int`, `optional`, defaults to :obj:`False`):
   650|         0|            0|            0|  0.00%|                Whether or not to add the batch dimension during the conversion.
   651|         0|            0|            0|  0.00%|        """
   652|         0|            0|            0|  0.00%|        if tensor_type is None:
   653|         0|            0|            0|  0.00%|            return self
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|        # Convert to TensorType
   656|         0|            0|            0|  0.00%|        if not isinstance(tensor_type, TensorType):
   657|         0|            0|            0|  0.00%|            tensor_type = TensorType(tensor_type)
   658|         0|            0|            0|  0.00%|
   659|         0|            0|            0|  0.00%|        # Get a function reference for the correct framework
   660|         0|            0|            0|  0.00%|        if tensor_type == TensorType.TENSORFLOW:
   661|         0|            0|            0|  0.00%|            if not is_tf_available():
   662|         0|            0|            0|  0.00%|                raise ImportError(
   663|         0|            0|            0|  0.00%|                    "Unable to convert output to TensorFlow tensors format, TensorFlow is not installed."
   664|         0|            0|            0|  0.00%|                )
   665|         0|            0|            0|  0.00%|            import tensorflow as tf
   666|         0|            0|            0|  0.00%|
   667|         0|            0|            0|  0.00%|            as_tensor = tf.constant
   668|         0|            0|            0|  0.00%|            is_tensor = tf.is_tensor
   669|         0|            0|            0|  0.00%|        elif tensor_type == TensorType.PYTORCH:
   670|         0|            0|            0|  0.00%|            if not is_torch_available():
   671|         0|            0|            0|  0.00%|                raise ImportError("Unable to convert output to PyTorch tensors format, PyTorch is not installed.")
   672|         0|            0|            0|  0.00%|            import torch
   673|         0|            0|            0|  0.00%|
   674|         0|            0|            0|  0.00%|            as_tensor = torch.tensor
   675|         0|            0|            0|  0.00%|            is_tensor = torch.is_tensor
   676|         0|            0|            0|  0.00%|        elif tensor_type == TensorType.JAX:
   677|         0|            0|            0|  0.00%|            if not is_flax_available():
   678|         0|            0|            0|  0.00%|                raise ImportError("Unable to convert output to JAX tensors format, JAX is not installed.")
   679|         0|            0|            0|  0.00%|            import jax.numpy as jnp  # noqa: F811
   680|         0|            0|            0|  0.00%|
   681|         0|            0|            0|  0.00%|            as_tensor = jnp.array
   682|         0|            0|            0|  0.00%|            is_tensor = _is_jax
   683|         0|            0|            0|  0.00%|        else:
   684|         0|            0|            0|  0.00%|            as_tensor = np.asarray
   685|         0|            0|            0|  0.00%|            is_tensor = _is_numpy
   686|         0|            0|            0|  0.00%|        # (mfuntowicz: This code is unreachable)
   687|         0|            0|            0|  0.00%|        # else:
   688|         0|            0|            0|  0.00%|        #     raise ImportError(
   689|         0|            0|            0|  0.00%|        #         f"Unable to convert output to tensors format {tensor_type}"
   690|         0|            0|            0|  0.00%|        #     )
   691|         0|            0|            0|  0.00%|
   692|         0|            0|            0|  0.00%|        # Do the tensor conversion in batch
   693|         0|            0|            0|  0.00%|        for key, value in self.items():
   694|         0|            0|            0|  0.00%|            try:
   695|         0|            0|            0|  0.00%|                if prepend_batch_axis:
   696|         0|            0|            0|  0.00%|                    value = [value]
   697|         0|            0|            0|  0.00%|
   698|         0|            0|            0|  0.00%|                if not is_tensor(value):
   699|         0|            0|            0|  0.00%|                    tensor = as_tensor(value)
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|                    # Removing this for now in favor of controlling the shape with `prepend_batch_axis`
   702|         0|            0|            0|  0.00%|                    # # at-least2d
   703|         0|            0|            0|  0.00%|                    # if tensor.ndim > 2:
   704|         0|            0|            0|  0.00%|                    #     tensor = tensor.squeeze(0)
   705|         0|            0|            0|  0.00%|                    # elif tensor.ndim < 2:
   706|         0|            0|            0|  0.00%|                    #     tensor = tensor[None, :]
   707|         0|            0|            0|  0.00%|
   708|         0|            0|            0|  0.00%|                    self[key] = tensor
   709|         0|            0|            0|  0.00%|            except:  # noqa E722
   710|         0|            0|            0|  0.00%|                if key == "overflowing_tokens":
   711|         0|            0|            0|  0.00%|                    raise ValueError(
   712|         0|            0|            0|  0.00%|                        "Unable to create tensor returning overflowing tokens of different lengths. "
   713|         0|            0|            0|  0.00%|                        "Please see if a fast version of this tokenizer is available to have this feature available."
   714|         0|            0|            0|  0.00%|                    )
   715|         0|            0|            0|  0.00%|                raise ValueError(
   716|         0|            0|            0|  0.00%|                    "Unable to create tensor, you should probably activate truncation and/or padding "
   717|         0|            0|            0|  0.00%|                    "with 'padding=True' 'truncation=True' to have batched tensors with the same length."
   718|         0|            0|            0|  0.00%|                )
   719|         0|            0|            0|  0.00%|
   720|         0|            0|            0|  0.00%|        return self
   721|         0|            0|            0|  0.00%|
   722|         0|            0|            0|  0.00%|    @torch_required
   723|         0|            0|            0|  0.00%|    def to(self, device: Union[str, "torch.device"]) -> "BatchEncoding":
   724|         0|            0|            0|  0.00%|        """
   725|         0|            0|            0|  0.00%|        Send all values to device by calling :obj:`v.to(device)` (PyTorch only).
   726|         0|            0|            0|  0.00%|
   727|         0|            0|            0|  0.00%|        Args:
   728|         0|            0|            0|  0.00%|            device (:obj:`str` or :obj:`torch.device`): The device to put the tensors on.
   729|         0|            0|            0|  0.00%|
   730|         0|            0|            0|  0.00%|        Returns:
   731|         0|            0|            0|  0.00%|            :class:`~transformers.BatchEncoding`: The same instance after modification.
   732|         0|            0|            0|  0.00%|        """
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|        # This check catches things like APEX blindly calling "to" on all inputs to a module
   735|         0|            0|            0|  0.00%|        # Otherwise it passes the casts down and casts the LongTensor containing the token idxs
   736|         0|            0|            0|  0.00%|        # into a HalfTensor
   737|         0|            0|            0|  0.00%|        if isinstance(device, str) or _is_torch_device(device) or isinstance(device, int):
   738|         0|            0|            0|  0.00%|            self.data = {k: v.to(device=device) for k, v in self.data.items()}
   739|         0|            0|            0|  0.00%|        else:
   740|         0|            0|            0|  0.00%|            logger.warning(f"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.")
   741|         0|            0|            0|  0.00%|        return self
   742|         0|            0|            0|  0.00%|
   743|         0|            0|            0|  0.00%|
   744|         0|            0|            0|  0.00%|class SpecialTokensMixin:
   745|         0|            0|            0|  0.00%|    """
   746|         0|            0|            0|  0.00%|    A mixin derived by :class:`~transformers.PreTrainedTokenizer` and :class:`~transformers.PreTrainedTokenizerFast` to
   747|         0|            0|            0|  0.00%|    handle specific behaviors related to special tokens. In particular, this class hold the attributes which can be
   748|         0|            0|            0|  0.00%|    used to directly access these special tokens in a model-independent manner and allow to set and update the special
   749|         0|            0|            0|  0.00%|    tokens.
   750|         0|            0|            0|  0.00%|
   751|         0|            0|            0|  0.00%|    Args:
   752|         0|            0|            0|  0.00%|        bos_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   753|         0|            0|            0|  0.00%|            A special token representing the beginning of a sentence.
   754|         0|            0|            0|  0.00%|        eos_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   755|         0|            0|            0|  0.00%|            A special token representing the end of a sentence.
   756|         0|            0|            0|  0.00%|        unk_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   757|         0|            0|            0|  0.00%|            A special token representing an out-of-vocabulary token.
   758|         0|            0|            0|  0.00%|        sep_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   759|         0|            0|            0|  0.00%|            A special token separating two different sentences in the same input (used by BERT for instance).
   760|         0|            0|            0|  0.00%|        pad_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   761|         0|            0|            0|  0.00%|            A special token used to make arrays of tokens the same size for batching purpose. Will then be ignored by
   762|         0|            0|            0|  0.00%|            attention mechanisms or loss computation.
   763|         0|            0|            0|  0.00%|        cls_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   764|         0|            0|            0|  0.00%|            A special token representing the class of the input (used by BERT for instance).
   765|         0|            0|            0|  0.00%|        mask_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   766|         0|            0|            0|  0.00%|            A special token representing a masked token (used by masked-language modeling pretraining objectives, like
   767|         0|            0|            0|  0.00%|            BERT).
   768|         0|            0|            0|  0.00%|        additional_special_tokens (tuple or list of :obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
   769|         0|            0|            0|  0.00%|            A tuple or a list of additional special tokens.
   770|         0|            0|            0|  0.00%|    """
   771|         0|            0|            0|  0.00%|
   772|         0|            0|            0|  0.00%|    SPECIAL_TOKENS_ATTRIBUTES = [
   773|         0|            0|            0|  0.00%|        "bos_token",
   774|         0|            0|            0|  0.00%|        "eos_token",
   775|         0|            0|            0|  0.00%|        "unk_token",
   776|         0|            0|            0|  0.00%|        "sep_token",
   777|         0|            0|            0|  0.00%|        "pad_token",
   778|         0|            0|            0|  0.00%|        "cls_token",
   779|         0|            0|            0|  0.00%|        "mask_token",
   780|         0|            0|            0|  0.00%|        "additional_special_tokens",
   781|         0|            0|            0|  0.00%|    ]
   782|         0|            0|            0|  0.00%|
   783|         0|            0|            0|  0.00%|    def __init__(self, verbose=True, **kwargs):
   784|         0|            0|            0|  0.00%|        self._bos_token = None
   785|         0|            0|            0|  0.00%|        self._eos_token = None
   786|         0|            0|            0|  0.00%|        self._unk_token = None
   787|         0|            0|            0|  0.00%|        self._sep_token = None
   788|         0|            0|            0|  0.00%|        self._pad_token = None
   789|         0|            0|            0|  0.00%|        self._cls_token = None
   790|         0|            0|            0|  0.00%|        self._mask_token = None
   791|         0|            0|            0|  0.00%|        self._pad_token_type_id = 0
   792|         0|            0|            0|  0.00%|        self._additional_special_tokens = []
   793|         0|            0|            0|  0.00%|        self.verbose = verbose
   794|         0|            0|            0|  0.00%|
   795|         0|            0|            0|  0.00%|        # We directly set the hidden value to allow initialization with special tokens
   796|         0|            0|            0|  0.00%|        # which are not yet in the vocabulary. Necessary for serialization/de-serialization
   797|         0|            0|            0|  0.00%|        # TODO clean this up at some point (probably by switching to fast tokenizers)
   798|         0|            0|            0|  0.00%|        for key, value in kwargs.items():
   799|         0|            0|            0|  0.00%|            if value is None:
   800|         0|            0|            0|  0.00%|                continue
   801|         0|            0|            0|  0.00%|            if key in self.SPECIAL_TOKENS_ATTRIBUTES:
   802|         0|            0|            0|  0.00%|                if key == "additional_special_tokens":
   803|         0|            0|            0|  0.00%|                    assert isinstance(value, (list, tuple)), f"Value {value} is not a list or tuple"
   804|         0|            0|            0|  0.00%|                    assert all(
   805|         0|            0|            0|  0.00%|                        isinstance(t, (str, AddedToken)) for t in value
   806|         0|            0|            0|  0.00%|                    ), "One of the tokens is not a string or an AddedToken"
   807|         0|            0|            0|  0.00%|                    setattr(self, key, value)
   808|         0|            0|            0|  0.00%|                elif isinstance(value, (str, AddedToken)):
   809|         0|            0|            0|  0.00%|                    setattr(self, key, value)
   810|         0|            0|            0|  0.00%|                else:
   811|         0|            0|            0|  0.00%|                    raise TypeError(f"special token {key} has to be either str or AddedToken but got: {type(value)}")
   812|         0|            0|            0|  0.00%|
   813|         0|            0|            0|  0.00%|    def sanitize_special_tokens(self) -> int:
   814|         0|            0|            0|  0.00%|        """
   815|         0|            0|            0|  0.00%|        Make sure that all the special tokens attributes of the tokenizer (:obj:`tokenizer.mask_token`,
   816|         0|            0|            0|  0.00%|        :obj:`tokenizer.cls_token`, etc.) are in the vocabulary.
   817|         0|            0|            0|  0.00%|
   818|         0|            0|            0|  0.00%|        Add the missing ones to the vocabulary if needed.
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|        Return:
   821|         0|            0|            0|  0.00%|            :obj:`int`: The number of tokens added in the vocabulary during the operation.
   822|         0|            0|            0|  0.00%|        """
   823|         0|            0|            0|  0.00%|        return self.add_tokens(self.all_special_tokens_extended, special_tokens=True)
   824|         0|            0|            0|  0.00%|
   825|         0|            0|            0|  0.00%|    def add_special_tokens(self, special_tokens_dict: Dict[str, Union[str, AddedToken]]) -> int:
   826|         0|            0|            0|  0.00%|        """
   827|         0|            0|            0|  0.00%|        Add a dictionary of special tokens (eos, pad, cls, etc.) to the encoder and link them to class attributes. If
   828|         0|            0|            0|  0.00%|        special tokens are NOT in the vocabulary, they are added to it (indexed starting from the last index of the
   829|         0|            0|            0|  0.00%|        current vocabulary).
   830|         0|            0|            0|  0.00%|
   831|         0|            0|            0|  0.00%|        .. Note::
   832|         0|            0|            0|  0.00%|            When adding new tokens to the vocabulary, you should make sure to also resize the token embedding matrix of
   833|         0|            0|            0|  0.00%|            the model so that its embedding matrix matches the tokenizer.
   834|         0|            0|            0|  0.00%|
   835|         0|            0|            0|  0.00%|            In order to do that, please use the :meth:`~transformers.PreTrainedModel.resize_token_embeddings` method.
   836|         0|            0|            0|  0.00%|
   837|         0|            0|            0|  0.00%|        Using :obj:`add_special_tokens` will ensure your special tokens can be used in several ways:
   838|         0|            0|            0|  0.00%|
   839|         0|            0|            0|  0.00%|        - Special tokens are carefully handled by the tokenizer (they are never split).
   840|         0|            0|            0|  0.00%|        - You can easily refer to special tokens using tokenizer class attributes like :obj:`tokenizer.cls_token`. This
   841|         0|            0|            0|  0.00%|          makes it easy to develop model-agnostic training and fine-tuning scripts.
   842|         0|            0|            0|  0.00%|
   843|         0|            0|            0|  0.00%|        When possible, special tokens are already registered for provided pretrained models (for instance
   844|         0|            0|            0|  0.00%|        :class:`~transformers.BertTokenizer` :obj:`cls_token` is already registered to be :obj`'[CLS]'` and XLM's one
   845|         0|            0|            0|  0.00%|        is also registered to be :obj:`'</s>'`).
   846|         0|            0|            0|  0.00%|
   847|         0|            0|            0|  0.00%|        Args:
   848|         0|            0|            0|  0.00%|            special_tokens_dict (dictionary `str` to `str` or :obj:`tokenizers.AddedToken`):
   849|         0|            0|            0|  0.00%|                Keys should be in the list of predefined special attributes: [``bos_token``, ``eos_token``,
   850|         0|            0|            0|  0.00%|                ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``,
   851|         0|            0|            0|  0.00%|                ``additional_special_tokens``].
   852|         0|            0|            0|  0.00%|
   853|         0|            0|            0|  0.00%|                Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer
   854|         0|            0|            0|  0.00%|                assign the index of the ``unk_token`` to them).
   855|         0|            0|            0|  0.00%|
   856|         0|            0|            0|  0.00%|        Returns:
   857|         0|            0|            0|  0.00%|            :obj:`int`: Number of tokens added to the vocabulary.
   858|         0|            0|            0|  0.00%|
   859|         0|            0|            0|  0.00%|        Examples::
   860|         0|            0|            0|  0.00%|
   861|         0|            0|            0|  0.00%|            # Let's see how to add a new classification token to GPT-2
   862|         0|            0|            0|  0.00%|            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
   863|         0|            0|            0|  0.00%|            model = GPT2Model.from_pretrained('gpt2')
   864|         0|            0|            0|  0.00%|
   865|         0|            0|            0|  0.00%|            special_tokens_dict = {'cls_token': '<CLS>'}
   866|         0|            0|            0|  0.00%|
   867|         0|            0|            0|  0.00%|            num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)
   868|         0|            0|            0|  0.00%|            print('We have added', num_added_toks, 'tokens')
   869|         0|            0|            0|  0.00%|            # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.
   870|         0|            0|            0|  0.00%|            model.resize_token_embeddings(len(tokenizer))
   871|         0|            0|            0|  0.00%|
   872|         0|            0|            0|  0.00%|            assert tokenizer.cls_token == '<CLS>'
   873|         0|            0|            0|  0.00%|        """
   874|         0|            0|            0|  0.00%|        if not special_tokens_dict:
   875|         0|            0|            0|  0.00%|            return 0
   876|         0|            0|            0|  0.00%|
   877|         0|            0|            0|  0.00%|        added_tokens = 0
   878|         0|            0|            0|  0.00%|        for key, value in special_tokens_dict.items():
   879|         0|            0|            0|  0.00%|            assert key in self.SPECIAL_TOKENS_ATTRIBUTES, f"Key {key} is not a special token"
   880|         0|            0|            0|  0.00%|
   881|         0|            0|            0|  0.00%|            if self.verbose:
   882|         0|            0|            0|  0.00%|                logger.info(f"Assigning {value} to the {key} key of the tokenizer")
   883|         0|            0|            0|  0.00%|            setattr(self, key, value)
   884|         0|            0|            0|  0.00%|
   885|         0|            0|            0|  0.00%|            if key == "additional_special_tokens":
   886|         0|            0|            0|  0.00%|                assert isinstance(value, (list, tuple)) and all(
   887|         0|            0|            0|  0.00%|                    isinstance(t, (str, AddedToken)) for t in value
   888|         0|            0|            0|  0.00%|                ), f"Tokens {value} for key {key} should all be str or AddedToken instances"
   889|         0|            0|            0|  0.00%|                added_tokens += self.add_tokens(value, special_tokens=True)
   890|         0|            0|            0|  0.00%|            else:
   891|         0|            0|            0|  0.00%|                assert isinstance(
   892|         0|            0|            0|  0.00%|                    value, (str, AddedToken)
   893|         0|            0|            0|  0.00%|                ), f"Token {value} for key {key} should be a str or an AddedToken instance"
   894|         0|            0|            0|  0.00%|                added_tokens += self.add_tokens([value], special_tokens=True)
   895|         0|            0|            0|  0.00%|
   896|         0|            0|            0|  0.00%|        return added_tokens
   897|         0|            0|            0|  0.00%|
   898|         0|            0|            0|  0.00%|    def add_tokens(
   899|         0|            0|            0|  0.00%|        self, new_tokens: Union[str, AddedToken, List[Union[str, AddedToken]]], special_tokens: bool = False
   900|         0|            0|            0|  0.00%|    ) -> int:
   901|         0|            0|            0|  0.00%|        """
   902|         0|            0|            0|  0.00%|        Add a list of new tokens to the tokenizer class. If the new tokens are not in the vocabulary, they are added to
   903|         0|            0|            0|  0.00%|        it with indices starting from length of the current vocabulary.
   904|         0|            0|            0|  0.00%|
   905|         0|            0|            0|  0.00%|        .. Note::
   906|         0|            0|            0|  0.00%|            When adding new tokens to the vocabulary, you should make sure to also resize the token embedding matrix of
   907|         0|            0|            0|  0.00%|            the model so that its embedding matrix matches the tokenizer.
   908|         0|            0|            0|  0.00%|
   909|         0|            0|            0|  0.00%|            In order to do that, please use the :meth:`~transformers.PreTrainedModel.resize_token_embeddings` method.
   910|         0|            0|            0|  0.00%|
   911|         0|            0|            0|  0.00%|        Args:
   912|         0|            0|            0|  0.00%|            new_tokens (:obj:`str`, :obj:`tokenizers.AddedToken` or a list of `str` or :obj:`tokenizers.AddedToken`):
   913|         0|            0|            0|  0.00%|                Tokens are only added if they are not already in the vocabulary. :obj:`tokenizers.AddedToken` wraps a
   914|         0|            0|            0|  0.00%|                string token to let you personalize its behavior: whether this token should only match against a single
   915|         0|            0|            0|  0.00%|                word, whether this token should strip all potential whitespaces on the left side, whether this token
   916|         0|            0|            0|  0.00%|                should strip all potential whitespaces on the right side, etc.
   917|         0|            0|            0|  0.00%|            special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
   918|         0|            0|            0|  0.00%|                Can be used to specify if the token is a special token. This mostly change the normalization behavior
   919|         0|            0|            0|  0.00%|                (special tokens like CLS or [MASK] are usually not lower-cased for instance).
   920|         0|            0|            0|  0.00%|
   921|         0|            0|            0|  0.00%|                See details for :obj:`tokenizers.AddedToken` in HuggingFace tokenizers library.
   922|         0|            0|            0|  0.00%|
   923|         0|            0|            0|  0.00%|        Returns:
   924|         0|            0|            0|  0.00%|            :obj:`int`: Number of tokens added to the vocabulary.
   925|         0|            0|            0|  0.00%|
   926|         0|            0|            0|  0.00%|        Examples::
   927|         0|            0|            0|  0.00%|
   928|         0|            0|            0|  0.00%|            # Let's see how to increase the vocabulary of Bert model and tokenizer
   929|         0|            0|            0|  0.00%|            tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')
   930|         0|            0|            0|  0.00%|            model = BertModel.from_pretrained('bert-base-uncased')
   931|         0|            0|            0|  0.00%|
   932|         0|            0|            0|  0.00%|            num_added_toks = tokenizer.add_tokens(['new_tok1', 'my_new-tok2'])
   933|         0|            0|            0|  0.00%|            print('We have added', num_added_toks, 'tokens')
   934|         0|            0|            0|  0.00%|             # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.
   935|         0|            0|            0|  0.00%|            model.resize_token_embeddings(len(tokenizer))
   936|         0|            0|            0|  0.00%|        """
   937|         0|            0|            0|  0.00%|        if not new_tokens:
   938|         0|            0|            0|  0.00%|            return 0
   939|         0|            0|            0|  0.00%|
   940|         0|            0|            0|  0.00%|        if not isinstance(new_tokens, (list, tuple)):
   941|         0|            0|            0|  0.00%|            new_tokens = [new_tokens]
   942|         0|            0|            0|  0.00%|
   943|         0|            0|            0|  0.00%|        return self._add_tokens(new_tokens, special_tokens=special_tokens)
   944|         0|            0|            0|  0.00%|
   945|         0|            0|            0|  0.00%|    def _add_tokens(self, new_tokens: Union[List[str], List[AddedToken]], special_tokens: bool = False) -> int:
   946|         0|            0|            0|  0.00%|        raise NotImplementedError
   947|         0|            0|            0|  0.00%|
   948|         0|            0|            0|  0.00%|    @property
   949|         0|            0|            0|  0.00%|    def bos_token(self) -> str:
   950|         0|            0|            0|  0.00%|        """
   951|         0|            0|            0|  0.00%|        :obj:`str`: Beginning of sentence token. Log an error if used while not having been set.
   952|         0|            0|            0|  0.00%|        """
   953|         0|            0|            0|  0.00%|        if self._bos_token is None and self.verbose:
   954|         0|            0|            0|  0.00%|            logger.error("Using bos_token, but it is not set yet.")
   955|         0|            0|            0|  0.00%|            return None
   956|         0|            0|            0|  0.00%|        return str(self._bos_token)
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|    @property
   959|         0|            0|            0|  0.00%|    def eos_token(self) -> str:
   960|         0|            0|            0|  0.00%|        """
   961|         0|            0|            0|  0.00%|        :obj:`str`: End of sentence token. Log an error if used while not having been set.
   962|         0|            0|            0|  0.00%|        """
   963|         0|            0|            0|  0.00%|        if self._eos_token is None and self.verbose:
   964|         0|            0|            0|  0.00%|            logger.error("Using eos_token, but it is not set yet.")
   965|         0|            0|            0|  0.00%|            return None
   966|         0|            0|            0|  0.00%|        return str(self._eos_token)
   967|         0|            0|            0|  0.00%|
   968|         0|            0|            0|  0.00%|    @property
   969|         0|            0|            0|  0.00%|    def unk_token(self) -> str:
   970|         0|            0|            0|  0.00%|        """
   971|         0|            0|            0|  0.00%|        :obj:`str`: Unknown token. Log an error if used while not having been set.
   972|         0|            0|            0|  0.00%|        """
   973|         0|            0|            0|  0.00%|        if self._unk_token is None and self.verbose:
   974|         0|            0|            0|  0.00%|            logger.error("Using unk_token, but it is not set yet.")
   975|         0|            0|            0|  0.00%|            return None
   976|         0|            0|            0|  0.00%|        return str(self._unk_token)
   977|         0|            0|            0|  0.00%|
   978|         0|            0|            0|  0.00%|    @property
   979|         0|            0|            0|  0.00%|    def sep_token(self) -> str:
   980|         0|            0|            0|  0.00%|        """
   981|         0|            0|            0|  0.00%|        :obj:`str`: Separation token, to separate context and query in an input sequence. Log an error if used while
   982|         0|            0|            0|  0.00%|        not having been set.
   983|         0|            0|            0|  0.00%|        """
   984|         0|            0|            0|  0.00%|        if self._sep_token is None and self.verbose:
   985|         0|            0|            0|  0.00%|            logger.error("Using sep_token, but it is not set yet.")
   986|         0|            0|            0|  0.00%|            return None
   987|         0|            0|            0|  0.00%|        return str(self._sep_token)
   988|         0|            0|            0|  0.00%|
   989|         0|            0|            0|  0.00%|    @property
   990|         0|            0|            0|  0.00%|    def pad_token(self) -> str:
   991|         0|            0|            0|  0.00%|        """
   992|         0|            0|            0|  0.00%|        :obj:`str`: Padding token. Log an error if used while not having been set.
   993|         0|            0|            0|  0.00%|        """
   994|         0|            0|            0|  0.00%|        if self._pad_token is None and self.verbose:
   995|         0|            0|            0|  0.00%|            logger.error("Using pad_token, but it is not set yet.")
   996|         0|            0|            0|  0.00%|            return None
   997|         0|            0|            0|  0.00%|        return str(self._pad_token)
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|    @property
  1000|         0|            0|            0|  0.00%|    def cls_token(self) -> str:
  1001|         0|            0|            0|  0.00%|        """
  1002|         0|            0|            0|  0.00%|        :obj:`str`: Classification token, to extract a summary of an input sequence leveraging self-attention along the
  1003|         0|            0|            0|  0.00%|        full depth of the model. Log an error if used while not having been set.
  1004|         0|            0|            0|  0.00%|        """
  1005|         0|            0|            0|  0.00%|        if self._cls_token is None and self.verbose:
  1006|         0|            0|            0|  0.00%|            logger.error("Using cls_token, but it is not set yet.")
  1007|         0|            0|            0|  0.00%|            return None
  1008|         0|            0|            0|  0.00%|        return str(self._cls_token)
  1009|         0|            0|            0|  0.00%|
  1010|      1000|   0.00126982|  1.26982e-06|  0.15%|    @property
  1011|         0|            0|            0|  0.00%|    def mask_token(self) -> str:
  1012|         0|            0|            0|  0.00%|        """
  1013|         0|            0|            0|  0.00%|        :obj:`str`: Mask token, to use when training a model with masked-language modeling. Log an error if used while
  1014|         0|            0|            0|  0.00%|        not having been set.
  1015|         0|            0|            0|  0.00%|        """
  1016|      1000|   0.00160813|  1.60813e-06|  0.19%|        if self._mask_token is None and self.verbose:
  1017|         0|            0|            0|  0.00%|            logger.error("Using mask_token, but it is not set yet.")
  1018|         0|            0|            0|  0.00%|            return None
  1019|      1000|    0.0020237|   2.0237e-06|  0.24%|        return str(self._mask_token)
  1020|         0|            0|            0|  0.00%|
  1021|         0|            0|            0|  0.00%|    @property
  1022|         0|            0|            0|  0.00%|    def additional_special_tokens(self) -> List[str]:
  1023|         0|            0|            0|  0.00%|        """
  1024|         0|            0|            0|  0.00%|        :obj:`List[str]`: All the additional special tokens you may want to use. Log an error if used while not having
  1025|         0|            0|            0|  0.00%|        been set.
  1026|         0|            0|            0|  0.00%|        """
  1027|         0|            0|            0|  0.00%|        if self._additional_special_tokens is None and self.verbose:
  1028|         0|            0|            0|  0.00%|            logger.error("Using additional_special_tokens, but it is not set yet.")
  1029|         0|            0|            0|  0.00%|            return None
  1030|         0|            0|            0|  0.00%|        return [str(tok) for tok in self._additional_special_tokens]
  1031|         0|            0|            0|  0.00%|
  1032|         0|            0|            0|  0.00%|    @bos_token.setter
  1033|         0|            0|            0|  0.00%|    def bos_token(self, value):
  1034|         0|            0|            0|  0.00%|        self._bos_token = value
  1035|         0|            0|            0|  0.00%|
  1036|         0|            0|            0|  0.00%|    @eos_token.setter
  1037|         0|            0|            0|  0.00%|    def eos_token(self, value):
  1038|         0|            0|            0|  0.00%|        self._eos_token = value
  1039|         0|            0|            0|  0.00%|
  1040|         0|            0|            0|  0.00%|    @unk_token.setter
  1041|         0|            0|            0|  0.00%|    def unk_token(self, value):
  1042|         0|            0|            0|  0.00%|        self._unk_token = value
  1043|         0|            0|            0|  0.00%|
  1044|         0|            0|            0|  0.00%|    @sep_token.setter
  1045|         0|            0|            0|  0.00%|    def sep_token(self, value):
  1046|         0|            0|            0|  0.00%|        self._sep_token = value
  1047|         0|            0|            0|  0.00%|
  1048|         0|            0|            0|  0.00%|    @pad_token.setter
  1049|         0|            0|            0|  0.00%|    def pad_token(self, value):
  1050|         0|            0|            0|  0.00%|        self._pad_token = value
  1051|         0|            0|            0|  0.00%|
  1052|         0|            0|            0|  0.00%|    @cls_token.setter
  1053|         0|            0|            0|  0.00%|    def cls_token(self, value):
  1054|         0|            0|            0|  0.00%|        self._cls_token = value
  1055|         0|            0|            0|  0.00%|
  1056|         0|            0|            0|  0.00%|    @mask_token.setter
  1057|         0|            0|            0|  0.00%|    def mask_token(self, value):
  1058|         0|            0|            0|  0.00%|        self._mask_token = value
  1059|         0|            0|            0|  0.00%|
  1060|         0|            0|            0|  0.00%|    @additional_special_tokens.setter
  1061|         0|            0|            0|  0.00%|    def additional_special_tokens(self, value):
  1062|         0|            0|            0|  0.00%|        self._additional_special_tokens = value
  1063|         0|            0|            0|  0.00%|
  1064|         0|            0|            0|  0.00%|    @property
  1065|         0|            0|            0|  0.00%|    def bos_token_id(self) -> Optional[int]:
  1066|         0|            0|            0|  0.00%|        """
  1067|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the beginning of sentence token in the vocabulary. Returns :obj:`None` if the token
  1068|         0|            0|            0|  0.00%|        has not been set.
  1069|         0|            0|            0|  0.00%|        """
  1070|         0|            0|            0|  0.00%|        if self._bos_token is None:
  1071|         0|            0|            0|  0.00%|            return None
  1072|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.bos_token)
  1073|         0|            0|            0|  0.00%|
  1074|         0|            0|            0|  0.00%|    @property
  1075|         0|            0|            0|  0.00%|    def eos_token_id(self) -> Optional[int]:
  1076|         0|            0|            0|  0.00%|        """
  1077|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the end of sentence token in the vocabulary. Returns :obj:`None` if the token has
  1078|         0|            0|            0|  0.00%|        not been set.
  1079|         0|            0|            0|  0.00%|        """
  1080|         0|            0|            0|  0.00%|        if self._eos_token is None:
  1081|         0|            0|            0|  0.00%|            return None
  1082|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.eos_token)
  1083|         0|            0|            0|  0.00%|
  1084|         0|            0|            0|  0.00%|    @property
  1085|         0|            0|            0|  0.00%|    def unk_token_id(self) -> Optional[int]:
  1086|         0|            0|            0|  0.00%|        """
  1087|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the unknown token in the vocabulary. Returns :obj:`None` if the token has not been
  1088|         0|            0|            0|  0.00%|        set.
  1089|         0|            0|            0|  0.00%|        """
  1090|         0|            0|            0|  0.00%|        if self._unk_token is None:
  1091|         0|            0|            0|  0.00%|            return None
  1092|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.unk_token)
  1093|         0|            0|            0|  0.00%|
  1094|         0|            0|            0|  0.00%|    @property
  1095|         0|            0|            0|  0.00%|    def sep_token_id(self) -> Optional[int]:
  1096|         0|            0|            0|  0.00%|        """
  1097|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the separation token in the vocabulary, to separate context and query in an input
  1098|         0|            0|            0|  0.00%|        sequence. Returns :obj:`None` if the token has not been set.
  1099|         0|            0|            0|  0.00%|        """
  1100|         0|            0|            0|  0.00%|        if self._sep_token is None:
  1101|         0|            0|            0|  0.00%|            return None
  1102|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.sep_token)
  1103|         0|            0|            0|  0.00%|
  1104|         0|            0|            0|  0.00%|    @property
  1105|         0|            0|            0|  0.00%|    def pad_token_id(self) -> Optional[int]:
  1106|         0|            0|            0|  0.00%|        """
  1107|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the padding token in the vocabulary. Returns :obj:`None` if the token has not been
  1108|         0|            0|            0|  0.00%|        set.
  1109|         0|            0|            0|  0.00%|        """
  1110|         0|            0|            0|  0.00%|        if self._pad_token is None:
  1111|         0|            0|            0|  0.00%|            return None
  1112|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.pad_token)
  1113|         0|            0|            0|  0.00%|
  1114|         0|            0|            0|  0.00%|    @property
  1115|         0|            0|            0|  0.00%|    def pad_token_type_id(self) -> int:
  1116|         0|            0|            0|  0.00%|        """
  1117|         0|            0|            0|  0.00%|        :obj:`int`: Id of the padding token type in the vocabulary.
  1118|         0|            0|            0|  0.00%|        """
  1119|         0|            0|            0|  0.00%|        return self._pad_token_type_id
  1120|         0|            0|            0|  0.00%|
  1121|         0|            0|            0|  0.00%|    @property
  1122|         0|            0|            0|  0.00%|    def cls_token_id(self) -> Optional[int]:
  1123|         0|            0|            0|  0.00%|        """
  1124|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the classification token in the vocabulary, to extract a summary of an input
  1125|         0|            0|            0|  0.00%|        sequence leveraging self-attention along the full depth of the model.
  1126|         0|            0|            0|  0.00%|
  1127|         0|            0|            0|  0.00%|        Returns :obj:`None` if the token has not been set.
  1128|         0|            0|            0|  0.00%|        """
  1129|         0|            0|            0|  0.00%|        if self._cls_token is None:
  1130|         0|            0|            0|  0.00%|            return None
  1131|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.cls_token)
  1132|         0|            0|            0|  0.00%|
  1133|         0|            0|            0|  0.00%|    @property
  1134|         0|            0|            0|  0.00%|    def mask_token_id(self) -> Optional[int]:
  1135|         0|            0|            0|  0.00%|        """
  1136|         0|            0|            0|  0.00%|        :obj:`Optional[int]`: Id of the mask token in the vocabulary, used when training a model with masked-language
  1137|         0|            0|            0|  0.00%|        modeling. Returns :obj:`None` if the token has not been set.
  1138|         0|            0|            0|  0.00%|        """
  1139|         0|            0|            0|  0.00%|        if self._mask_token is None:
  1140|         0|            0|            0|  0.00%|            return None
  1141|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.mask_token)
  1142|         0|            0|            0|  0.00%|
  1143|         0|            0|            0|  0.00%|    @property
  1144|         0|            0|            0|  0.00%|    def additional_special_tokens_ids(self) -> List[int]:
  1145|         0|            0|            0|  0.00%|        """
  1146|         0|            0|            0|  0.00%|        :obj:`List[int]`: Ids of all the additional special tokens in the vocabulary. Log an error if used while not
  1147|         0|            0|            0|  0.00%|        having been set.
  1148|         0|            0|            0|  0.00%|        """
  1149|         0|            0|            0|  0.00%|        return self.convert_tokens_to_ids(self.additional_special_tokens)
  1150|         0|            0|            0|  0.00%|
  1151|         0|            0|            0|  0.00%|    @bos_token_id.setter
  1152|         0|            0|            0|  0.00%|    def bos_token_id(self, value):
  1153|         0|            0|            0|  0.00%|        self._bos_token = self.convert_tokens_to_ids(value)
  1154|         0|            0|            0|  0.00%|
  1155|         0|            0|            0|  0.00%|    @eos_token_id.setter
  1156|         0|            0|            0|  0.00%|    def eos_token_id(self, value):
  1157|         0|            0|            0|  0.00%|        self._eos_token = self.convert_tokens_to_ids(value)
  1158|         0|            0|            0|  0.00%|
  1159|         0|            0|            0|  0.00%|    @unk_token_id.setter
  1160|         0|            0|            0|  0.00%|    def unk_token_id(self, value):
  1161|         0|            0|            0|  0.00%|        self._unk_token = self.convert_tokens_to_ids(value)
  1162|         0|            0|            0|  0.00%|
  1163|         0|            0|            0|  0.00%|    @sep_token_id.setter
  1164|         0|            0|            0|  0.00%|    def sep_token_id(self, value):
  1165|         0|            0|            0|  0.00%|        self._sep_token = self.convert_tokens_to_ids(value)
  1166|         0|            0|            0|  0.00%|
  1167|         0|            0|            0|  0.00%|    @pad_token_id.setter
  1168|         0|            0|            0|  0.00%|    def pad_token_id(self, value):
  1169|         0|            0|            0|  0.00%|        self._pad_token = self.convert_tokens_to_ids(value)
  1170|         0|            0|            0|  0.00%|
  1171|         0|            0|            0|  0.00%|    @cls_token_id.setter
  1172|         0|            0|            0|  0.00%|    def cls_token_id(self, value):
  1173|         0|            0|            0|  0.00%|        self._cls_token = self.convert_tokens_to_ids(value)
  1174|         0|            0|            0|  0.00%|
  1175|         0|            0|            0|  0.00%|    @mask_token_id.setter
  1176|         0|            0|            0|  0.00%|    def mask_token_id(self, value):
  1177|         0|            0|            0|  0.00%|        self._mask_token = self.convert_tokens_to_ids(value)
  1178|         0|            0|            0|  0.00%|
  1179|         0|            0|            0|  0.00%|    @additional_special_tokens_ids.setter
  1180|         0|            0|            0|  0.00%|    def additional_special_tokens_ids(self, values):
  1181|         0|            0|            0|  0.00%|        self._additional_special_tokens = [self.convert_tokens_to_ids(value) for value in values]
  1182|         0|            0|            0|  0.00%|
  1183|         0|            0|            0|  0.00%|    @property
  1184|         0|            0|            0|  0.00%|    def special_tokens_map(self) -> Dict[str, Union[str, List[str]]]:
  1185|         0|            0|            0|  0.00%|        """
  1186|         0|            0|            0|  0.00%|        :obj:`Dict[str, Union[str, List[str]]]`: A dictionary mapping special token class attributes (:obj:`cls_token`,
  1187|         0|            0|            0|  0.00%|        :obj:`unk_token`, etc.) to their values (:obj:`'<unk>'`, :obj:`'<cls>'`, etc.).
  1188|         0|            0|            0|  0.00%|
  1189|         0|            0|            0|  0.00%|        Convert potential tokens of :obj:`tokenizers.AddedToken` type to string.
  1190|         0|            0|            0|  0.00%|        """
  1191|         0|            0|            0|  0.00%|        set_attr = {}
  1192|         0|            0|            0|  0.00%|        for attr in self.SPECIAL_TOKENS_ATTRIBUTES:
  1193|         0|            0|            0|  0.00%|            attr_value = getattr(self, "_" + attr)
  1194|         0|            0|            0|  0.00%|            if attr_value:
  1195|         0|            0|            0|  0.00%|                set_attr[attr] = str(attr_value)
  1196|         0|            0|            0|  0.00%|        return set_attr
  1197|         0|            0|            0|  0.00%|
  1198|         0|            0|            0|  0.00%|    @property
  1199|         0|            0|            0|  0.00%|    def special_tokens_map_extended(self) -> Dict[str, Union[str, AddedToken, List[Union[str, AddedToken]]]]:
  1200|         0|            0|            0|  0.00%|        """
  1201|         0|            0|            0|  0.00%|        :obj:`Dict[str, Union[str, tokenizers.AddedToken, List[Union[str, tokenizers.AddedToken]]]]`: A dictionary
  1202|         0|            0|            0|  0.00%|        mapping special token class attributes (:obj:`cls_token`, :obj:`unk_token`, etc.) to their values
  1203|         0|            0|            0|  0.00%|        (:obj:`'<unk>'`, :obj:`'<cls>'`, etc.).
  1204|         0|            0|            0|  0.00%|
  1205|         0|            0|            0|  0.00%|        Don't convert tokens of :obj:`tokenizers.AddedToken` type to string so they can be used to control more finely
  1206|         0|            0|            0|  0.00%|        how special tokens are tokenized.
  1207|         0|            0|            0|  0.00%|        """
  1208|         0|            0|            0|  0.00%|        set_attr = {}
  1209|         0|            0|            0|  0.00%|        for attr in self.SPECIAL_TOKENS_ATTRIBUTES:
  1210|         0|            0|            0|  0.00%|            attr_value = getattr(self, "_" + attr)
  1211|         0|            0|            0|  0.00%|            if attr_value:
  1212|         0|            0|            0|  0.00%|                set_attr[attr] = attr_value
  1213|         0|            0|            0|  0.00%|        return set_attr
  1214|         0|            0|            0|  0.00%|
  1215|         0|            0|            0|  0.00%|    @property
  1216|         0|            0|            0|  0.00%|    def all_special_tokens(self) -> List[str]:
  1217|         0|            0|            0|  0.00%|        """
  1218|         0|            0|            0|  0.00%|        :obj:`List[str]`: All the special tokens (:obj:`'<unk>'`, :obj:`'<cls>'`, etc.) mapped to class attributes.
  1219|         0|            0|            0|  0.00%|
  1220|         0|            0|            0|  0.00%|        Convert tokens of :obj:`tokenizers.AddedToken` type to string.
  1221|         0|            0|            0|  0.00%|        """
  1222|         0|            0|            0|  0.00%|        all_toks = [str(s) for s in self.all_special_tokens_extended]
  1223|         0|            0|            0|  0.00%|        return all_toks
  1224|         0|            0|            0|  0.00%|
  1225|         0|            0|            0|  0.00%|    @property
  1226|         0|            0|            0|  0.00%|    def all_special_tokens_extended(self) -> List[Union[str, AddedToken]]:
  1227|         0|            0|            0|  0.00%|        """
  1228|         0|            0|            0|  0.00%|        :obj:`List[Union[str, tokenizers.AddedToken]]`: All the special tokens (:obj:`'<unk>'`, :obj:`'<cls>'`, etc.)
  1229|         0|            0|            0|  0.00%|        mapped to class attributes.
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|        Don't convert tokens of :obj:`tokenizers.AddedToken` type to string so they can be used to control more finely
  1232|         0|            0|            0|  0.00%|        how special tokens are tokenized.
  1233|         0|            0|            0|  0.00%|        """
  1234|         0|            0|            0|  0.00%|        all_toks = []
  1235|         0|            0|            0|  0.00%|        set_attr = self.special_tokens_map_extended
  1236|         0|            0|            0|  0.00%|        for attr_value in set_attr.values():
  1237|         0|            0|            0|  0.00%|            all_toks = all_toks + (list(attr_value) if isinstance(attr_value, (list, tuple)) else [attr_value])
  1238|         0|            0|            0|  0.00%|        all_toks = list(OrderedDict.fromkeys(all_toks))
  1239|         0|            0|            0|  0.00%|        return all_toks
  1240|         0|            0|            0|  0.00%|
  1241|         0|            0|            0|  0.00%|    @property
  1242|         0|            0|            0|  0.00%|    def all_special_ids(self) -> List[int]:
  1243|         0|            0|            0|  0.00%|        """
  1244|         0|            0|            0|  0.00%|        :obj:`List[int]`: List the ids of the special tokens(:obj:`'<unk>'`, :obj:`'<cls>'`, etc.) mapped to class
  1245|         0|            0|            0|  0.00%|        attributes.
  1246|         0|            0|            0|  0.00%|        """
  1247|         0|            0|            0|  0.00%|        all_toks = self.all_special_tokens
  1248|         0|            0|            0|  0.00%|        all_ids = self.convert_tokens_to_ids(all_toks)
  1249|         0|            0|            0|  0.00%|        return all_ids
  1250|         0|            0|            0|  0.00%|
  1251|         0|            0|            0|  0.00%|
  1252|         0|            0|            0|  0.00%|ENCODE_KWARGS_DOCSTRING = r"""
  1253|         0|            0|            0|  0.00%|            add_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`True`):
  1254|         0|            0|            0|  0.00%|                Whether or not to encode the sequences with the special tokens relative to their model.
  1255|         0|            0|            0|  0.00%|            padding (:obj:`bool`, :obj:`str` or :class:`~transformers.file_utils.PaddingStrategy`, `optional`, defaults to :obj:`False`):
  1256|         0|            0|            0|  0.00%|                Activates and controls padding. Accepts the following values:
  1257|         0|            0|            0|  0.00%|
  1258|         0|            0|            0|  0.00%|                * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a
  1259|         0|            0|            0|  0.00%|                  single sequence if provided).
  1260|         0|            0|            0|  0.00%|                * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the
  1261|         0|            0|            0|  0.00%|                  maximum acceptable input length for the model if that argument is not provided.
  1262|         0|            0|            0|  0.00%|                * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of
  1263|         0|            0|            0|  0.00%|                  different lengths).
  1264|         0|            0|            0|  0.00%|            truncation (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.TruncationStrategy`, `optional`, defaults to :obj:`False`):
  1265|         0|            0|            0|  0.00%|                Activates and controls truncation. Accepts the following values:
  1266|         0|            0|            0|  0.00%|
  1267|         0|            0|            0|  0.00%|                * :obj:`True` or :obj:`'longest_first'`: Truncate to a maximum length specified with the argument
  1268|         0|            0|            0|  0.00%|                  :obj:`max_length` or to the maximum acceptable input length for the model if that argument is not
  1269|         0|            0|            0|  0.00%|                  provided. This will truncate token by token, removing a token from the longest sequence in the pair
  1270|         0|            0|            0|  0.00%|                  if a pair of sequences (or a batch of pairs) is provided.
  1271|         0|            0|            0|  0.00%|                * :obj:`'only_first'`: Truncate to a maximum length specified with the argument :obj:`max_length` or to
  1272|         0|            0|            0|  0.00%|                  the maximum acceptable input length for the model if that argument is not provided. This will only
  1273|         0|            0|            0|  0.00%|                  truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.
  1274|         0|            0|            0|  0.00%|                * :obj:`'only_second'`: Truncate to a maximum length specified with the argument :obj:`max_length` or
  1275|         0|            0|            0|  0.00%|                  to the maximum acceptable input length for the model if that argument is not provided. This will only
  1276|         0|            0|            0|  0.00%|                  truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.
  1277|         0|            0|            0|  0.00%|                * :obj:`False` or :obj:`'do_not_truncate'` (default): No truncation (i.e., can output batch with
  1278|         0|            0|            0|  0.00%|                  sequence lengths greater than the model maximum admissible input size).
  1279|         0|            0|            0|  0.00%|            max_length (:obj:`int`, `optional`):
  1280|         0|            0|            0|  0.00%|                Controls the maximum length to use by one of the truncation/padding parameters.
  1281|         0|            0|            0|  0.00%|
  1282|         0|            0|            0|  0.00%|                If left unset or set to :obj:`None`, this will use the predefined model maximum length if a maximum
  1283|         0|            0|            0|  0.00%|                length is required by one of the truncation/padding parameters. If the model has no specific maximum
  1284|         0|            0|            0|  0.00%|                input length (like XLNet) truncation/padding to a maximum length will be deactivated.
  1285|         0|            0|            0|  0.00%|            stride (:obj:`int`, `optional`, defaults to 0):
  1286|         0|            0|            0|  0.00%|                If set to a number along with :obj:`max_length`, the overflowing tokens returned when
  1287|         0|            0|            0|  0.00%|                :obj:`return_overflowing_tokens=True` will contain some tokens from the end of the truncated sequence
  1288|         0|            0|            0|  0.00%|                returned to provide some overlap between truncated and overflowing sequences. The value of this
  1289|         0|            0|            0|  0.00%|                argument defines the number of overlapping tokens.
  1290|         0|            0|            0|  0.00%|            is_split_into_words (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1291|         0|            0|            0|  0.00%|                Whether or not the input is already pre-tokenized (e.g., split into words). If set to :obj:`True`, the
  1292|         0|            0|            0|  0.00%|                tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)
  1293|         0|            0|            0|  0.00%|                which it will tokenize. This is useful for NER or token classification.
  1294|         0|            0|            0|  0.00%|            pad_to_multiple_of (:obj:`int`, `optional`):
  1295|         0|            0|            0|  0.00%|                If set will pad the sequence to a multiple of the provided value. This is especially useful to enable
  1296|         0|            0|            0|  0.00%|                the use of Tensor Cores on NVIDIA hardware with compute capability >= 7.5 (Volta).
  1297|         0|            0|            0|  0.00%|            return_tensors (:obj:`str` or :class:`~transformers.file_utils.TensorType`, `optional`):
  1298|         0|            0|            0|  0.00%|                If set, will return tensors instead of list of python integers. Acceptable values are:
  1299|         0|            0|            0|  0.00%|
  1300|         0|            0|            0|  0.00%|                * :obj:`'tf'`: Return TensorFlow :obj:`tf.constant` objects.
  1301|         0|            0|            0|  0.00%|                * :obj:`'pt'`: Return PyTorch :obj:`torch.Tensor` objects.
  1302|         0|            0|            0|  0.00%|                * :obj:`'np'`: Return Numpy :obj:`np.ndarray` objects.
  1303|         0|            0|            0|  0.00%|"""
  1304|         0|            0|            0|  0.00%|
  1305|         0|            0|            0|  0.00%|ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING = r"""
  1306|         0|            0|            0|  0.00%|            return_token_type_ids (:obj:`bool`, `optional`):
  1307|         0|            0|            0|  0.00%|                Whether to return token type IDs. If left to the default, will return the token type IDs according to
  1308|         0|            0|            0|  0.00%|                the specific tokenizer's default, defined by the :obj:`return_outputs` attribute.
  1309|         0|            0|            0|  0.00%|
  1310|         0|            0|            0|  0.00%|                `What are token type IDs? <../glossary.html#token-type-ids>`__
  1311|         0|            0|            0|  0.00%|            return_attention_mask (:obj:`bool`, `optional`):
  1312|         0|            0|            0|  0.00%|                Whether to return the attention mask. If left to the default, will return the attention mask according
  1313|         0|            0|            0|  0.00%|                to the specific tokenizer's default, defined by the :obj:`return_outputs` attribute.
  1314|         0|            0|            0|  0.00%|
  1315|         0|            0|            0|  0.00%|                `What are attention masks? <../glossary.html#attention-mask>`__
  1316|         0|            0|            0|  0.00%|            return_overflowing_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1317|         0|            0|            0|  0.00%|                Whether or not to return overflowing token sequences.
  1318|         0|            0|            0|  0.00%|            return_special_tokens_mask (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1319|         0|            0|            0|  0.00%|                Whether or not to return special tokens mask information.
  1320|         0|            0|            0|  0.00%|            return_offsets_mapping (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1321|         0|            0|            0|  0.00%|                Whether or not to return :obj:`(char_start, char_end)` for each token.
  1322|         0|            0|            0|  0.00%|
  1323|         0|            0|            0|  0.00%|                This is only available on fast tokenizers inheriting from
  1324|         0|            0|            0|  0.00%|                :class:`~transformers.PreTrainedTokenizerFast`, if using Python's tokenizer, this method will raise
  1325|         0|            0|            0|  0.00%|                :obj:`NotImplementedError`.
  1326|         0|            0|            0|  0.00%|            return_length  (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1327|         0|            0|            0|  0.00%|                Whether or not to return the lengths of the encoded inputs.
  1328|         0|            0|            0|  0.00%|            verbose (:obj:`bool`, `optional`, defaults to :obj:`True`):
  1329|         0|            0|            0|  0.00%|                Whether or not to print more information and warnings.
  1330|         0|            0|            0|  0.00%|            **kwargs: passed to the :obj:`self.tokenize()` method
  1331|         0|            0|            0|  0.00%|
  1332|         0|            0|            0|  0.00%|        Return:
  1333|         0|            0|            0|  0.00%|            :class:`~transformers.BatchEncoding`: A :class:`~transformers.BatchEncoding` with the following fields:
  1334|         0|            0|            0|  0.00%|
  1335|         0|            0|            0|  0.00%|            - **input_ids** -- List of token ids to be fed to a model.
  1336|         0|            0|            0|  0.00%|
  1337|         0|            0|            0|  0.00%|              `What are input IDs? <../glossary.html#input-ids>`__
  1338|         0|            0|            0|  0.00%|
  1339|         0|            0|            0|  0.00%|            - **token_type_ids** -- List of token type ids to be fed to a model (when :obj:`return_token_type_ids=True`
  1340|         0|            0|            0|  0.00%|              or if `"token_type_ids"` is in :obj:`self.model_input_names`).
  1341|         0|            0|            0|  0.00%|
  1342|         0|            0|            0|  0.00%|              `What are token type IDs? <../glossary.html#token-type-ids>`__
  1343|         0|            0|            0|  0.00%|
  1344|         0|            0|            0|  0.00%|            - **attention_mask** -- List of indices specifying which tokens should be attended to by the model (when
  1345|         0|            0|            0|  0.00%|              :obj:`return_attention_mask=True` or if `"attention_mask"` is in :obj:`self.model_input_names`).
  1346|         0|            0|            0|  0.00%|
  1347|         0|            0|            0|  0.00%|              `What are attention masks? <../glossary.html#attention-mask>`__
  1348|         0|            0|            0|  0.00%|
  1349|         0|            0|            0|  0.00%|            - **overflowing_tokens** -- List of overflowing tokens sequences (when a :obj:`max_length` is specified and
  1350|         0|            0|            0|  0.00%|              :obj:`return_overflowing_tokens=True`).
  1351|         0|            0|            0|  0.00%|            - **num_truncated_tokens** -- Number of tokens truncated (when a :obj:`max_length` is specified and
  1352|         0|            0|            0|  0.00%|              :obj:`return_overflowing_tokens=True`).
  1353|         0|            0|            0|  0.00%|            - **special_tokens_mask** -- List of 0s and 1s, with 1 specifying added special tokens and 0 specifying
  1354|         0|            0|            0|  0.00%|              regular sequence tokens (when :obj:`add_special_tokens=True` and :obj:`return_special_tokens_mask=True`).
  1355|         0|            0|            0|  0.00%|            - **length** -- The length of the inputs (when :obj:`return_length=True`)
  1356|         0|            0|            0|  0.00%|"""
  1357|         0|            0|            0|  0.00%|
  1358|         0|            0|            0|  0.00%|INIT_TOKENIZER_DOCSTRING = r"""
  1359|         0|            0|            0|  0.00%|    Class attributes (overridden by derived classes)
  1360|         0|            0|            0|  0.00%|
  1361|         0|            0|            0|  0.00%|        - **vocab_files_names** (:obj:`Dict[str, str]`) -- A dictionary with, as keys, the ``__init__`` keyword name of
  1362|         0|            0|            0|  0.00%|          each vocabulary file required by the model, and as associated values, the filename for saving the associated
  1363|         0|            0|            0|  0.00%|          file (string).
  1364|         0|            0|            0|  0.00%|        - **pretrained_vocab_files_map** (:obj:`Dict[str, Dict[str, str]]`) -- A dictionary of dictionaries, with the
  1365|         0|            0|            0|  0.00%|          high-level keys being the ``__init__`` keyword name of each vocabulary file required by the model, the
  1366|         0|            0|            0|  0.00%|          low-level being the :obj:`short-cut-names` of the pretrained models with, as associated values, the
  1367|         0|            0|            0|  0.00%|          :obj:`url` to the associated pretrained vocabulary file.
  1368|         0|            0|            0|  0.00%|        - **max_model_input_sizes** (:obj:`Dict[str, Optinal[int]]`) -- A dictionary with, as keys, the
  1369|         0|            0|            0|  0.00%|          :obj:`short-cut-names` of the pretrained models, and as associated values, the maximum length of the sequence
  1370|         0|            0|            0|  0.00%|          inputs of this model, or :obj:`None` if the model has no maximum input size.
  1371|         0|            0|            0|  0.00%|        - **pretrained_init_configuration** (:obj:`Dict[str, Dict[str, Any]]`) -- A dictionary with, as keys, the
  1372|         0|            0|            0|  0.00%|          :obj:`short-cut-names` of the pretrained models, and as associated values, a dictionary of specific arguments
  1373|         0|            0|            0|  0.00%|          to pass to the ``__init__`` method of the tokenizer class for this pretrained model when loading the
  1374|         0|            0|            0|  0.00%|          tokenizer with the :meth:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase.from_pretrained`
  1375|         0|            0|            0|  0.00%|          method.
  1376|         0|            0|            0|  0.00%|        - **model_input_names** (:obj:`List[str]`) -- A list of inputs expected in the forward pass of the model.
  1377|         0|            0|            0|  0.00%|        - **padding_side** (:obj:`str`) -- The default value for the side on which the model should have padding
  1378|         0|            0|            0|  0.00%|          applied. Should be :obj:`'right'` or :obj:`'left'`.
  1379|         0|            0|            0|  0.00%|
  1380|         0|            0|            0|  0.00%|    Args:
  1381|         0|            0|            0|  0.00%|        model_max_length (:obj:`int`, `optional`):
  1382|         0|            0|            0|  0.00%|            The maximum length (in number of tokens) for the inputs to the transformer model. When the tokenizer is
  1383|         0|            0|            0|  0.00%|            loaded with :meth:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase.from_pretrained`, this
  1384|         0|            0|            0|  0.00%|            will be set to the value stored for the associated model in ``max_model_input_sizes`` (see above). If no
  1385|         0|            0|            0|  0.00%|            value is provided, will default to VERY_LARGE_INTEGER (:obj:`int(1e30)`).
  1386|         0|            0|            0|  0.00%|        padding_side: (:obj:`str`, `optional`):
  1387|         0|            0|            0|  0.00%|            The side on which the model should have padding applied. Should be selected between ['right', 'left'].
  1388|         0|            0|            0|  0.00%|            Default value is picked from the class attribute of the same name.
  1389|         0|            0|            0|  0.00%|        model_input_names (:obj:`List[string]`, `optional`):
  1390|         0|            0|            0|  0.00%|            The list of inputs accepted by the forward pass of the model (like :obj:`"token_type_ids"` or
  1391|         0|            0|            0|  0.00%|            :obj:`"attention_mask"`). Default value is picked from the class attribute of the same name.
  1392|         0|            0|            0|  0.00%|        bos_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1393|         0|            0|            0|  0.00%|            A special token representing the beginning of a sentence. Will be associated to ``self.bos_token`` and
  1394|         0|            0|            0|  0.00%|            ``self.bos_token_id``.
  1395|         0|            0|            0|  0.00%|        eos_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1396|         0|            0|            0|  0.00%|            A special token representing the end of a sentence. Will be associated to ``self.eos_token`` and
  1397|         0|            0|            0|  0.00%|            ``self.eos_token_id``.
  1398|         0|            0|            0|  0.00%|        unk_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1399|         0|            0|            0|  0.00%|            A special token representing an out-of-vocabulary token. Will be associated to ``self.unk_token`` and
  1400|         0|            0|            0|  0.00%|            ``self.unk_token_id``.
  1401|         0|            0|            0|  0.00%|        sep_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1402|         0|            0|            0|  0.00%|            A special token separating two different sentences in the same input (used by BERT for instance). Will be
  1403|         0|            0|            0|  0.00%|            associated to ``self.sep_token`` and ``self.sep_token_id``.
  1404|         0|            0|            0|  0.00%|        pad_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1405|         0|            0|            0|  0.00%|            A special token used to make arrays of tokens the same size for batching purpose. Will then be ignored by
  1406|         0|            0|            0|  0.00%|            attention mechanisms or loss computation. Will be associated to ``self.pad_token`` and
  1407|         0|            0|            0|  0.00%|            ``self.pad_token_id``.
  1408|         0|            0|            0|  0.00%|        cls_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1409|         0|            0|            0|  0.00%|            A special token representing the class of the input (used by BERT for instance). Will be associated to
  1410|         0|            0|            0|  0.00%|            ``self.cls_token`` and ``self.cls_token_id``.
  1411|         0|            0|            0|  0.00%|        mask_token (:obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1412|         0|            0|            0|  0.00%|            A special token representing a masked token (used by masked-language modeling pretraining objectives, like
  1413|         0|            0|            0|  0.00%|            BERT). Will be associated to ``self.mask_token`` and ``self.mask_token_id``.
  1414|         0|            0|            0|  0.00%|        additional_special_tokens (tuple or list of :obj:`str` or :obj:`tokenizers.AddedToken`, `optional`):
  1415|         0|            0|            0|  0.00%|            A tuple or a list of additional special tokens. Add them here to ensure they won't be split by the
  1416|         0|            0|            0|  0.00%|            tokenization process. Will be associated to ``self.additional_special_tokens`` and
  1417|         0|            0|            0|  0.00%|            ``self.additional_special_tokens_ids``.
  1418|         0|            0|            0|  0.00%|"""
  1419|         0|            0|            0|  0.00%|
  1420|         0|            0|            0|  0.00%|
  1421|         0|            0|            0|  0.00%|@add_end_docstrings(INIT_TOKENIZER_DOCSTRING)
  1422|         0|            0|            0|  0.00%|class PreTrainedTokenizerBase(SpecialTokensMixin, PushToHubMixin):
  1423|         0|            0|            0|  0.00%|    """
  1424|         0|            0|            0|  0.00%|    Base class for :class:`~transformers.PreTrainedTokenizer` and :class:`~transformers.PreTrainedTokenizerFast`.
  1425|         0|            0|            0|  0.00%|
  1426|         0|            0|            0|  0.00%|    Handles shared (mostly boiler plate) methods for those two classes.
  1427|         0|            0|            0|  0.00%|    """
  1428|         0|            0|            0|  0.00%|
  1429|         0|            0|            0|  0.00%|    vocab_files_names: Dict[str, str] = {}
  1430|         0|            0|            0|  0.00%|    pretrained_vocab_files_map: Dict[str, Dict[str, str]] = {}
  1431|         0|            0|            0|  0.00%|    pretrained_init_configuration: Dict[str, Dict[str, Any]] = {}
  1432|         0|            0|            0|  0.00%|    max_model_input_sizes: Dict[str, Optional[int]] = {}
  1433|         0|            0|            0|  0.00%|
  1434|         0|            0|            0|  0.00%|    # first name has to correspond to main model input name
  1435|         0|            0|            0|  0.00%|    # to make sure `tokenizer.pad(...)` works correctly
  1436|         0|            0|            0|  0.00%|    model_input_names: List[str] = ["input_ids", "token_type_ids", "attention_mask"]
  1437|         0|            0|            0|  0.00%|    padding_side: str = "right"
  1438|         0|            0|            0|  0.00%|    slow_tokenizer_class = None
  1439|         0|            0|            0|  0.00%|
  1440|         0|            0|            0|  0.00%|    def __init__(self, **kwargs):
  1441|         0|            0|            0|  0.00%|        # inputs and kwargs for saving and re-loading (see ``from_pretrained`` and ``save_pretrained``)
  1442|         0|            0|            0|  0.00%|        self.init_inputs = ()
  1443|         0|            0|            0|  0.00%|        self.init_kwargs = copy.deepcopy(kwargs)
  1444|         0|            0|            0|  0.00%|        self.name_or_path = kwargs.pop("name_or_path", "")
  1445|         0|            0|            0|  0.00%|
  1446|         0|            0|            0|  0.00%|        # For backward compatibility we fallback to set model_max_length from max_len if provided
  1447|         0|            0|            0|  0.00%|        model_max_length = kwargs.pop("model_max_length", kwargs.pop("max_len", None))
  1448|         0|            0|            0|  0.00%|        self.model_max_length = model_max_length if model_max_length is not None else VERY_LARGE_INTEGER
  1449|         0|            0|            0|  0.00%|
  1450|         0|            0|            0|  0.00%|        # Padding side is right by default and overridden in subclasses. If specified in the kwargs, it is changed.
  1451|         0|            0|            0|  0.00%|        self.padding_side = kwargs.pop("padding_side", self.padding_side)
  1452|         0|            0|            0|  0.00%|        assert self.padding_side in [
  1453|         0|            0|            0|  0.00%|            "right",
  1454|         0|            0|            0|  0.00%|            "left",
  1455|         0|            0|            0|  0.00%|        ], f"Padding side should be selected between 'right' and 'left', current value: {self.padding_side}"
  1456|         0|            0|            0|  0.00%|        self.model_input_names = kwargs.pop("model_input_names", self.model_input_names)
  1457|         0|            0|            0|  0.00%|
  1458|         0|            0|            0|  0.00%|        self.deprecation_warnings = (
  1459|         0|            0|            0|  0.00%|            {}
  1460|         0|            0|            0|  0.00%|        )  # Use to store when we have already noticed a deprecation warning (avoid overlogging).
  1461|         0|            0|            0|  0.00%|
  1462|         0|            0|            0|  0.00%|        super().__init__(**kwargs)
  1463|         0|            0|            0|  0.00%|
  1464|         0|            0|            0|  0.00%|    @property
  1465|         0|            0|            0|  0.00%|    def max_len_single_sentence(self) -> int:
  1466|         0|            0|            0|  0.00%|        """
  1467|         0|            0|            0|  0.00%|        :obj:`int`: The maximum length of a sentence that can be fed to the model.
  1468|         0|            0|            0|  0.00%|        """
  1469|         0|            0|            0|  0.00%|        return self.model_max_length - self.num_special_tokens_to_add(pair=False)
  1470|         0|            0|            0|  0.00%|
  1471|         0|            0|            0|  0.00%|    @property
  1472|         0|            0|            0|  0.00%|    def max_len_sentences_pair(self) -> int:
  1473|         0|            0|            0|  0.00%|        """
  1474|         0|            0|            0|  0.00%|        :obj:`int`: The maximum combined length of a pair of sentences that can be fed to the model.
  1475|         0|            0|            0|  0.00%|        """
  1476|         0|            0|            0|  0.00%|        return self.model_max_length - self.num_special_tokens_to_add(pair=True)
  1477|         0|            0|            0|  0.00%|
  1478|         0|            0|            0|  0.00%|    @max_len_single_sentence.setter
  1479|         0|            0|            0|  0.00%|    def max_len_single_sentence(self, value) -> int:
  1480|         0|            0|            0|  0.00%|        # For backward compatibility, allow to try to setup 'max_len_single_sentence'.
  1481|         0|            0|            0|  0.00%|        if value == self.model_max_length - self.num_special_tokens_to_add(pair=False) and self.verbose:
  1482|         0|            0|            0|  0.00%|            if not self.deprecation_warnings.get("max_len_single_sentence", False):
  1483|         0|            0|            0|  0.00%|                logger.warning(
  1484|         0|            0|            0|  0.00%|                    "Setting 'max_len_single_sentence' is now deprecated. " "This value is automatically set up."
  1485|         0|            0|            0|  0.00%|                )
  1486|         0|            0|            0|  0.00%|            self.deprecation_warnings["max_len_single_sentence"] = True
  1487|         0|            0|            0|  0.00%|        else:
  1488|         0|            0|            0|  0.00%|            raise ValueError(
  1489|         0|            0|            0|  0.00%|                "Setting 'max_len_single_sentence' is now deprecated. " "This value is automatically set up."
  1490|         0|            0|            0|  0.00%|            )
  1491|         0|            0|            0|  0.00%|
  1492|         0|            0|            0|  0.00%|    @max_len_sentences_pair.setter
  1493|         0|            0|            0|  0.00%|    def max_len_sentences_pair(self, value) -> int:
  1494|         0|            0|            0|  0.00%|        # For backward compatibility, allow to try to setup 'max_len_sentences_pair'.
  1495|         0|            0|            0|  0.00%|        if value == self.model_max_length - self.num_special_tokens_to_add(pair=True) and self.verbose:
  1496|         0|            0|            0|  0.00%|            if not self.deprecation_warnings.get("max_len_sentences_pair", False):
  1497|         0|            0|            0|  0.00%|                logger.warning(
  1498|         0|            0|            0|  0.00%|                    "Setting 'max_len_sentences_pair' is now deprecated. " "This value is automatically set up."
  1499|         0|            0|            0|  0.00%|                )
  1500|         0|            0|            0|  0.00%|            self.deprecation_warnings["max_len_sentences_pair"] = True
  1501|         0|            0|            0|  0.00%|        else:
  1502|         0|            0|            0|  0.00%|            raise ValueError(
  1503|         0|            0|            0|  0.00%|                "Setting 'max_len_sentences_pair' is now deprecated. " "This value is automatically set up."
  1504|         0|            0|            0|  0.00%|            )
  1505|         0|            0|            0|  0.00%|
  1506|         0|            0|            0|  0.00%|    def __repr__(self) -> str:
  1507|         0|            0|            0|  0.00%|        return (
  1508|         0|            0|            0|  0.00%|            f"{'PreTrainedTokenizerFast' if self.is_fast else 'PreTrainedTokenizer'}(name_or_path='{self.name_or_path}', "
  1509|         0|            0|            0|  0.00%|            f"vocab_size={self.vocab_size}, model_max_len={self.model_max_length}, is_fast={self.is_fast}, "
  1510|         0|            0|            0|  0.00%|            f"padding_side='{self.padding_side}', special_tokens={self.special_tokens_map_extended})"
  1511|         0|            0|            0|  0.00%|        )
  1512|         0|            0|            0|  0.00%|
  1513|         0|            0|            0|  0.00%|    def get_vocab(self) -> Dict[str, int]:
  1514|         0|            0|            0|  0.00%|        """
  1515|         0|            0|            0|  0.00%|        Returns the vocabulary as a dictionary of token to index.
  1516|         0|            0|            0|  0.00%|
  1517|         0|            0|            0|  0.00%|        :obj:`tokenizer.get_vocab()[token]` is equivalent to :obj:`tokenizer.convert_tokens_to_ids(token)` when
  1518|         0|            0|            0|  0.00%|        :obj:`token` is in the vocab.
  1519|         0|            0|            0|  0.00%|
  1520|         0|            0|            0|  0.00%|        Returns:
  1521|         0|            0|            0|  0.00%|            :obj:`Dict[str, int]`: The vocabulary.
  1522|         0|            0|            0|  0.00%|        """
  1523|         0|            0|            0|  0.00%|        raise NotImplementedError()
  1524|         0|            0|            0|  0.00%|
  1525|         0|            0|            0|  0.00%|    @classmethod
  1526|         0|            0|            0|  0.00%|    def from_pretrained(cls, pretrained_model_name_or_path: Union[str, os.PathLike], *init_inputs, **kwargs):
  1527|         0|            0|            0|  0.00%|        r"""
  1528|         0|            0|            0|  0.00%|        Instantiate a :class:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase` (or a derived class) from
  1529|         0|            0|            0|  0.00%|        a predefined tokenizer.
  1530|         0|            0|            0|  0.00%|
  1531|         0|            0|            0|  0.00%|        Args:
  1532|         0|            0|            0|  0.00%|            pretrained_model_name_or_path (:obj:`str` or :obj:`os.PathLike`):
  1533|         0|            0|            0|  0.00%|                Can be either:
  1534|         0|            0|            0|  0.00%|
  1535|         0|            0|            0|  0.00%|                - A string, the `model id` of a predefined tokenizer hosted inside a model repo on huggingface.co.
  1536|         0|            0|            0|  0.00%|                  Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under a
  1537|         0|            0|            0|  0.00%|                  user or organization name, like ``dbmdz/bert-base-german-cased``.
  1538|         0|            0|            0|  0.00%|                - A path to a `directory` containing vocabulary files required by the tokenizer, for instance saved
  1539|         0|            0|            0|  0.00%|                  using the :meth:`~transformers.tokenization_utils_base.PreTrainedTokenizerBase.save_pretrained`
  1540|         0|            0|            0|  0.00%|                  method, e.g., ``./my_model_directory/``.
  1541|         0|            0|            0|  0.00%|                - (**Deprecated**, not applicable to all derived classes) A path or url to a single saved vocabulary
  1542|         0|            0|            0|  0.00%|                  file (if and only if the tokenizer only requires a single vocabulary file like Bert or XLNet), e.g.,
  1543|         0|            0|            0|  0.00%|                  ``./my_model_directory/vocab.txt``.
  1544|         0|            0|            0|  0.00%|            cache_dir (:obj:`str` or :obj:`os.PathLike`, `optional`):
  1545|         0|            0|            0|  0.00%|                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the
  1546|         0|            0|            0|  0.00%|                standard cache should not be used.
  1547|         0|            0|            0|  0.00%|            force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1548|         0|            0|            0|  0.00%|                Whether or not to force the (re-)download the vocabulary files and override the cached versions if they
  1549|         0|            0|            0|  0.00%|                exist.
  1550|         0|            0|            0|  0.00%|            resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):
  1551|         0|            0|            0|  0.00%|                Whether or not to delete incompletely received files. Attempt to resume the download if such a file
  1552|         0|            0|            0|  0.00%|                exists.
  1553|         0|            0|            0|  0.00%|            proxies (:obj:`Dict[str, str], `optional`):
  1554|         0|            0|            0|  0.00%|                A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',
  1555|         0|            0|            0|  0.00%|                'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.
  1556|         0|            0|            0|  0.00%|            use_auth_token (:obj:`str` or `bool`, `optional`):
  1557|         0|            0|            0|  0.00%|                The token to use as HTTP bearer authorization for remote files. If :obj:`True`, will use the token
  1558|         0|            0|            0|  0.00%|                generated when running :obj:`transformers-cli login` (stored in :obj:`~/.huggingface`).
  1559|         0|            0|            0|  0.00%|            revision(:obj:`str`, `optional`, defaults to :obj:`"main"`):
  1560|         0|            0|            0|  0.00%|                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
  1561|         0|            0|            0|  0.00%|                git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any
  1562|         0|            0|            0|  0.00%|                identifier allowed by git.
  1563|         0|            0|            0|  0.00%|            subfolder (:obj:`str`, `optional`):
  1564|         0|            0|            0|  0.00%|                In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
  1565|         0|            0|            0|  0.00%|                facebook/rag-token-base), specify it here.
  1566|         0|            0|            0|  0.00%|            inputs (additional positional arguments, `optional`):
  1567|         0|            0|            0|  0.00%|                Will be passed along to the Tokenizer ``__init__`` method.
  1568|         0|            0|            0|  0.00%|            kwargs (additional keyword arguments, `optional`):
  1569|         0|            0|            0|  0.00%|                Will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like
  1570|         0|            0|            0|  0.00%|                ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``,
  1571|         0|            0|            0|  0.00%|                ``mask_token``, ``additional_special_tokens``. See parameters in the ``__init__`` for more details.
  1572|         0|            0|            0|  0.00%|
  1573|         0|            0|            0|  0.00%|        .. note::
  1574|         0|            0|            0|  0.00%|
  1575|         0|            0|            0|  0.00%|            Passing :obj:`use_auth_token=True` is required when you want to use a private model.
  1576|         0|            0|            0|  0.00%|
  1577|         0|            0|            0|  0.00%|        Examples::
  1578|         0|            0|            0|  0.00%|
  1579|         0|            0|            0|  0.00%|            # We can't instantiate directly the base class `PreTrainedTokenizerBase` so let's show our examples on a derived class: BertTokenizer
  1580|         0|            0|            0|  0.00%|            # Download vocabulary from huggingface.co and cache.
  1581|         0|            0|            0|  0.00%|            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
  1582|         0|            0|            0|  0.00%|
  1583|         0|            0|            0|  0.00%|            # Download vocabulary from huggingface.co (user-uploaded) and cache.
  1584|         0|            0|            0|  0.00%|            tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')
  1585|         0|            0|            0|  0.00%|
  1586|         0|            0|            0|  0.00%|            # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)
  1587|         0|            0|            0|  0.00%|            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/')
  1588|         0|            0|            0|  0.00%|
  1589|         0|            0|            0|  0.00%|            # If the tokenizer uses a single vocabulary file, you can point directly to this file
  1590|         0|            0|            0|  0.00%|            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/my_vocab.txt')
  1591|         0|            0|            0|  0.00%|
  1592|         0|            0|            0|  0.00%|            # You can link tokens to special vocabulary when instantiating
  1593|         0|            0|            0|  0.00%|            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', unk_token='<unk>')
  1594|         0|            0|            0|  0.00%|            # You should be sure '<unk>' is in the vocabulary when doing that.
  1595|         0|            0|            0|  0.00%|            # Otherwise use tokenizer.add_special_tokens({'unk_token': '<unk>'}) instead)
  1596|         0|            0|            0|  0.00%|            assert tokenizer.unk_token == '<unk>'
  1597|         0|            0|            0|  0.00%|
  1598|         0|            0|            0|  0.00%|        """
  1599|         0|            0|            0|  0.00%|        cache_dir = kwargs.pop("cache_dir", None)
  1600|         0|            0|            0|  0.00%|        force_download = kwargs.pop("force_download", False)
  1601|         0|            0|            0|  0.00%|        resume_download = kwargs.pop("resume_download", False)
  1602|         0|            0|            0|  0.00%|        proxies = kwargs.pop("proxies", None)
  1603|         0|            0|            0|  0.00%|        local_files_only = kwargs.pop("local_files_only", False)
  1604|         0|            0|            0|  0.00%|        use_auth_token = kwargs.pop("use_auth_token", None)
  1605|         0|            0|            0|  0.00%|        revision = kwargs.pop("revision", None)
  1606|         0|            0|            0|  0.00%|        subfolder = kwargs.pop("subfolder", None)
  1607|         0|            0|            0|  0.00%|        from_pipeline = kwargs.pop("_from_pipeline", None)
  1608|         0|            0|            0|  0.00%|        from_auto_class = kwargs.pop("_from_auto", False)
  1609|         0|            0|            0|  0.00%|
  1610|         0|            0|            0|  0.00%|        user_agent = {"file_type": "tokenizer", "from_auto_class": from_auto_class, "is_fast": "Fast" in cls.__name__}
  1611|         0|            0|            0|  0.00%|        if from_pipeline is not None:
  1612|         0|            0|            0|  0.00%|            user_agent["using_pipeline"] = from_pipeline
  1613|         0|            0|            0|  0.00%|
  1614|         0|            0|            0|  0.00%|        if is_offline_mode() and not local_files_only:
  1615|         0|            0|            0|  0.00%|            logger.info("Offline mode: forcing local_files_only=True")
  1616|         0|            0|            0|  0.00%|            local_files_only = True
  1617|         0|            0|            0|  0.00%|
  1618|         0|            0|            0|  0.00%|        pretrained_model_name_or_path = str(pretrained_model_name_or_path)
  1619|         0|            0|            0|  0.00%|        vocab_files = {}
  1620|         0|            0|            0|  0.00%|        init_configuration = {}
  1621|         0|            0|            0|  0.00%|
  1622|         0|            0|            0|  0.00%|        if os.path.isfile(pretrained_model_name_or_path) or is_remote_url(pretrained_model_name_or_path):
  1623|         0|            0|            0|  0.00%|            if len(cls.vocab_files_names) > 1:
  1624|         0|            0|            0|  0.00%|                raise ValueError(
  1625|         0|            0|            0|  0.00%|                    f"Calling {cls.__name__}.from_pretrained() with the path to a single file or url is not "
  1626|         0|            0|            0|  0.00%|                    "supported for this tokenizer. Use a model identifier or the path to a directory instead."
  1627|         0|            0|            0|  0.00%|                )
  1628|         0|            0|            0|  0.00%|            warnings.warn(
  1629|         0|            0|            0|  0.00%|                f"Calling {cls.__name__}.from_pretrained() with the path to a single file or url is deprecated and "
  1630|         0|            0|            0|  0.00%|                "won't be possible anymore in v5. Use a model identifier or the path to a directory instead.",
  1631|         0|            0|            0|  0.00%|                FutureWarning,
  1632|         0|            0|            0|  0.00%|            )
  1633|         0|            0|            0|  0.00%|            file_id = list(cls.vocab_files_names.keys())[0]
  1634|         0|            0|            0|  0.00%|            vocab_files[file_id] = pretrained_model_name_or_path
  1635|         0|            0|            0|  0.00%|        else:
  1636|         0|            0|            0|  0.00%|            # At this point pretrained_model_name_or_path is either a directory or a model identifier name
  1637|         0|            0|            0|  0.00%|            additional_files_names = {
  1638|         0|            0|            0|  0.00%|                "added_tokens_file": ADDED_TOKENS_FILE,
  1639|         0|            0|            0|  0.00%|                "special_tokens_map_file": SPECIAL_TOKENS_MAP_FILE,
  1640|         0|            0|            0|  0.00%|                "tokenizer_config_file": TOKENIZER_CONFIG_FILE,
  1641|         0|            0|            0|  0.00%|                "tokenizer_file": FULL_TOKENIZER_FILE,
  1642|         0|            0|            0|  0.00%|            }
  1643|         0|            0|            0|  0.00%|            # Look for the tokenizer files
  1644|         0|            0|            0|  0.00%|            for file_id, file_name in {**cls.vocab_files_names, **additional_files_names}.items():
  1645|         0|            0|            0|  0.00%|                if os.path.isdir(pretrained_model_name_or_path):
  1646|         0|            0|            0|  0.00%|                    if subfolder is not None:
  1647|         0|            0|            0|  0.00%|                        full_file_name = os.path.join(pretrained_model_name_or_path, subfolder, file_name)
  1648|         0|            0|            0|  0.00%|                    else:
  1649|         0|            0|            0|  0.00%|                        full_file_name = os.path.join(pretrained_model_name_or_path, file_name)
  1650|         0|            0|            0|  0.00%|                    if not os.path.exists(full_file_name):
  1651|         0|            0|            0|  0.00%|                        logger.info(f"Didn't find file {full_file_name}. We won't load it.")
  1652|         0|            0|            0|  0.00%|                        full_file_name = None
  1653|         0|            0|            0|  0.00%|                else:
  1654|         0|            0|            0|  0.00%|                    full_file_name = hf_bucket_url(
  1655|         0|            0|            0|  0.00%|                        pretrained_model_name_or_path,
  1656|         0|            0|            0|  0.00%|                        filename=file_name,
  1657|         0|            0|            0|  0.00%|                        subfolder=subfolder,
  1658|         0|            0|            0|  0.00%|                        revision=revision,
  1659|         0|            0|            0|  0.00%|                        mirror=None,
  1660|         0|            0|            0|  0.00%|                    )
  1661|         0|            0|            0|  0.00%|
  1662|         0|            0|            0|  0.00%|                vocab_files[file_id] = full_file_name
  1663|         0|            0|            0|  0.00%|
  1664|         0|            0|            0|  0.00%|        # Get files from url, cache, or disk depending on the case
  1665|         0|            0|            0|  0.00%|        resolved_vocab_files = {}
  1666|         0|            0|            0|  0.00%|        unresolved_files = []
  1667|         0|            0|            0|  0.00%|        for file_id, file_path in vocab_files.items():
  1668|         0|            0|            0|  0.00%|            if file_path is None:
  1669|         0|            0|            0|  0.00%|                resolved_vocab_files[file_id] = None
  1670|         0|            0|            0|  0.00%|            else:
  1671|         0|            0|            0|  0.00%|                try:
  1672|         0|            0|            0|  0.00%|                    resolved_vocab_files[file_id] = cached_path(
  1673|         0|            0|            0|  0.00%|                        file_path,
  1674|         0|            0|            0|  0.00%|                        cache_dir=cache_dir,
  1675|         0|            0|            0|  0.00%|                        force_download=force_download,
  1676|         0|            0|            0|  0.00%|                        proxies=proxies,
  1677|         0|            0|            0|  0.00%|                        resume_download=resume_download,
  1678|         0|            0|            0|  0.00%|                        local_files_only=local_files_only,
  1679|         0|            0|            0|  0.00%|                        use_auth_token=use_auth_token,
  1680|         0|            0|            0|  0.00%|                        user_agent=user_agent,
  1681|         0|            0|            0|  0.00%|                    )
  1682|         0|            0|            0|  0.00%|
  1683|         0|            0|            0|  0.00%|                except FileNotFoundError as error:
  1684|         0|            0|            0|  0.00%|                    if local_files_only:
  1685|         0|            0|            0|  0.00%|                        unresolved_files.append(file_id)
  1686|         0|            0|            0|  0.00%|                    else:
  1687|         0|            0|            0|  0.00%|                        raise error
  1688|         0|            0|            0|  0.00%|
  1689|         0|            0|            0|  0.00%|                except requests.exceptions.HTTPError as err:
  1690|         0|            0|            0|  0.00%|                    if "404 Client Error" in str(err):
  1691|         0|            0|            0|  0.00%|                        logger.debug(err)
  1692|         0|            0|            0|  0.00%|                        resolved_vocab_files[file_id] = None
  1693|         0|            0|            0|  0.00%|                    else:
  1694|         0|            0|            0|  0.00%|                        raise err
  1695|         0|            0|            0|  0.00%|
  1696|         0|            0|            0|  0.00%|        if len(unresolved_files) > 0:
  1697|         0|            0|            0|  0.00%|            logger.info(
  1698|         0|            0|            0|  0.00%|                f"Can't load following files from cache: {unresolved_files} and cannot check if these "
  1699|         0|            0|            0|  0.00%|                "files are necessary for the tokenizer to operate."
  1700|         0|            0|            0|  0.00%|            )
  1701|         0|            0|            0|  0.00%|
  1702|         0|            0|            0|  0.00%|        if all(full_file_name is None for full_file_name in resolved_vocab_files.values()):
  1703|         0|            0|            0|  0.00%|            msg = (
  1704|         0|            0|            0|  0.00%|                f"Can't load tokenizer for '{pretrained_model_name_or_path}'. Make sure that:\n\n"
  1705|         0|            0|            0|  0.00%|                f"- '{pretrained_model_name_or_path}' is a correct model identifier listed on 'https://huggingface.co/models'\n\n"
  1706|         0|            0|            0|  0.00%|                f"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing relevant tokenizer files\n\n"
  1707|         0|            0|            0|  0.00%|            )
  1708|         0|            0|            0|  0.00%|            raise EnvironmentError(msg)
  1709|         0|            0|            0|  0.00%|
  1710|         0|            0|            0|  0.00%|        for file_id, file_path in vocab_files.items():
  1711|         0|            0|            0|  0.00%|            if file_id not in resolved_vocab_files:
  1712|         0|            0|            0|  0.00%|                continue
  1713|         0|            0|            0|  0.00%|
  1714|         0|            0|            0|  0.00%|            if file_path == resolved_vocab_files[file_id]:
  1715|         0|            0|            0|  0.00%|                logger.info(f"loading file {file_path}")
  1716|         0|            0|            0|  0.00%|            else:
  1717|         0|            0|            0|  0.00%|                logger.info(f"loading file {file_path} from cache at {resolved_vocab_files[file_id]}")
  1718|         0|            0|            0|  0.00%|
  1719|         0|            0|            0|  0.00%|        return cls._from_pretrained(
  1720|         0|            0|            0|  0.00%|            resolved_vocab_files, pretrained_model_name_or_path, init_configuration, *init_inputs, **kwargs
  1721|         0|            0|            0|  0.00%|        )
  1722|         0|            0|            0|  0.00%|
  1723|         0|            0|            0|  0.00%|    @classmethod
  1724|         0|            0|            0|  0.00%|    def _from_pretrained(
  1725|         0|            0|            0|  0.00%|        cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, *init_inputs, **kwargs
  1726|         0|            0|            0|  0.00%|    ):
  1727|         0|            0|            0|  0.00%|        # We instantiate fast tokenizers based on a slow tokenizer if we don't have access to the tokenizer.json
  1728|         0|            0|            0|  0.00%|        # file or if `from_slow` is set to True.
  1729|         0|            0|            0|  0.00%|        from_slow = kwargs.get("from_slow", False)
  1730|         0|            0|            0|  0.00%|        has_tokenizer_file = resolved_vocab_files.get("tokenizer_file", None) is not None
  1731|         0|            0|            0|  0.00%|        if (from_slow or not has_tokenizer_file) and cls.slow_tokenizer_class is not None:
  1732|         0|            0|            0|  0.00%|            slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(
  1733|         0|            0|            0|  0.00%|                copy.deepcopy(resolved_vocab_files),
  1734|         0|            0|            0|  0.00%|                pretrained_model_name_or_path,
  1735|         0|            0|            0|  0.00%|                copy.deepcopy(init_configuration),
  1736|         0|            0|            0|  0.00%|                *init_inputs,
  1737|         0|            0|            0|  0.00%|                **(copy.deepcopy(kwargs)),
  1738|         0|            0|            0|  0.00%|            )
  1739|         0|            0|            0|  0.00%|        else:
  1740|         0|            0|            0|  0.00%|            slow_tokenizer = None
  1741|         0|            0|            0|  0.00%|
  1742|         0|            0|            0|  0.00%|        # Prepare tokenizer initialization kwargs
  1743|         0|            0|            0|  0.00%|        # Did we saved some inputs and kwargs to reload ?
  1744|         0|            0|            0|  0.00%|        tokenizer_config_file = resolved_vocab_files.pop("tokenizer_config_file", None)
  1745|         0|            0|            0|  0.00%|        if tokenizer_config_file is not None:
  1746|         0|            0|            0|  0.00%|            with open(tokenizer_config_file, encoding="utf-8") as tokenizer_config_handle:
  1747|         0|            0|            0|  0.00%|                init_kwargs = json.load(tokenizer_config_handle)
  1748|         0|            0|            0|  0.00%|            saved_init_inputs = init_kwargs.pop("init_inputs", ())
  1749|         0|            0|            0|  0.00%|            if not init_inputs:
  1750|         0|            0|            0|  0.00%|                init_inputs = saved_init_inputs
  1751|         0|            0|            0|  0.00%|        else:
  1752|         0|            0|            0|  0.00%|            init_kwargs = init_configuration
  1753|         0|            0|            0|  0.00%|
  1754|         0|            0|            0|  0.00%|        # Update with newly provided kwargs
  1755|         0|            0|            0|  0.00%|        init_kwargs.update(kwargs)
  1756|         0|            0|            0|  0.00%|
  1757|         0|            0|            0|  0.00%|        # Convert AddedTokens serialized as dict to class instances
  1758|         0|            0|            0|  0.00%|        def convert_added_tokens(obj: Union[AddedToken, Any]):
  1759|         0|            0|            0|  0.00%|            if isinstance(obj, dict) and "__type" in obj and obj["__type"] == "AddedToken":
  1760|         0|            0|            0|  0.00%|                obj.pop("__type")
  1761|         0|            0|            0|  0.00%|                return AddedToken(**obj)
  1762|         0|            0|            0|  0.00%|            elif isinstance(obj, (list, tuple)):
  1763|         0|            0|            0|  0.00%|                return list(convert_added_tokens(o) for o in obj)
  1764|         0|            0|            0|  0.00%|            elif isinstance(obj, dict):
  1765|         0|            0|            0|  0.00%|                return {k: convert_added_tokens(v) for k, v in obj.items()}
  1766|         0|            0|            0|  0.00%|            return obj
  1767|         0|            0|            0|  0.00%|
  1768|         0|            0|            0|  0.00%|        init_kwargs = convert_added_tokens(init_kwargs)
  1769|         0|            0|            0|  0.00%|
  1770|         0|            0|            0|  0.00%|        # Set max length if needed
  1771|         0|            0|            0|  0.00%|        if pretrained_model_name_or_path in cls.max_model_input_sizes:
  1772|         0|            0|            0|  0.00%|            # if we're using a pretrained model, ensure the tokenizer
  1773|         0|            0|            0|  0.00%|            # wont index sequences longer than the number of positional embeddings
  1774|         0|            0|            0|  0.00%|            model_max_length = cls.max_model_input_sizes[pretrained_model_name_or_path]
  1775|         0|            0|            0|  0.00%|            if model_max_length is not None and isinstance(model_max_length, (int, float)):
  1776|         0|            0|            0|  0.00%|                init_kwargs["model_max_length"] = min(init_kwargs.get("model_max_length", int(1e30)), model_max_length)
  1777|         0|            0|            0|  0.00%|
  1778|         0|            0|            0|  0.00%|        # Merge resolved_vocab_files arguments in init_kwargs.
  1779|         0|            0|            0|  0.00%|        added_tokens_file = resolved_vocab_files.pop("added_tokens_file", None)
  1780|         0|            0|            0|  0.00%|        for args_name, file_path in resolved_vocab_files.items():
  1781|         0|            0|            0|  0.00%|            if args_name not in init_kwargs:
  1782|         0|            0|            0|  0.00%|                init_kwargs[args_name] = file_path
  1783|         0|            0|            0|  0.00%|
  1784|         0|            0|            0|  0.00%|        if slow_tokenizer is not None:
  1785|         0|            0|            0|  0.00%|            init_kwargs["__slow_tokenizer"] = slow_tokenizer
  1786|         0|            0|            0|  0.00%|
  1787|         0|            0|            0|  0.00%|        init_kwargs["name_or_path"] = pretrained_model_name_or_path
  1788|         0|            0|            0|  0.00%|
  1789|         0|            0|            0|  0.00%|        # Instantiate tokenizer.
  1790|         0|            0|            0|  0.00%|        try:
  1791|         0|            0|            0|  0.00%|            tokenizer = cls(*init_inputs, **init_kwargs)
  1792|         0|            0|            0|  0.00%|        except OSError:
  1793|         0|            0|            0|  0.00%|            raise OSError(
  1794|         0|            0|            0|  0.00%|                "Unable to load vocabulary from file. "
  1795|         0|            0|            0|  0.00%|                "Please check that the provided vocabulary is accessible and not corrupted."
  1796|         0|            0|            0|  0.00%|            )
  1797|         0|            0|            0|  0.00%|
  1798|         0|            0|            0|  0.00%|        # Save inputs and kwargs for saving and re-loading with ``save_pretrained``
  1799|         0|            0|            0|  0.00%|        # Removed: Now done at the base class level
  1800|         0|            0|            0|  0.00%|        # tokenizer.init_inputs = init_inputs
  1801|         0|            0|            0|  0.00%|        # tokenizer.init_kwargs = init_kwargs
  1802|         0|            0|            0|  0.00%|
  1803|         0|            0|            0|  0.00%|        # If there is a complementary special token map, load it
  1804|         0|            0|            0|  0.00%|        special_tokens_map_file = resolved_vocab_files.pop("special_tokens_map_file", None)
  1805|         0|            0|            0|  0.00%|        if special_tokens_map_file is not None:
  1806|         0|            0|            0|  0.00%|            with open(special_tokens_map_file, encoding="utf-8") as special_tokens_map_handle:
  1807|         0|            0|            0|  0.00%|                special_tokens_map = json.load(special_tokens_map_handle)
  1808|         0|            0|            0|  0.00%|            for key, value in special_tokens_map.items():
  1809|         0|            0|            0|  0.00%|                if isinstance(value, dict):
  1810|         0|            0|            0|  0.00%|                    value = AddedToken(**value)
  1811|         0|            0|            0|  0.00%|                elif isinstance(value, list):
  1812|         0|            0|            0|  0.00%|                    value = [AddedToken(**token) if isinstance(token, dict) else token for token in value]
  1813|         0|            0|            0|  0.00%|                setattr(tokenizer, key, value)
  1814|         0|            0|            0|  0.00%|
  1815|         0|            0|            0|  0.00%|        # Add supplementary tokens.
  1816|         0|            0|            0|  0.00%|        special_tokens = tokenizer.all_special_tokens
  1817|         0|            0|            0|  0.00%|        if added_tokens_file is not None:
  1818|         0|            0|            0|  0.00%|            with open(added_tokens_file, encoding="utf-8") as added_tokens_handle:
  1819|         0|            0|            0|  0.00%|                added_tok_encoder = json.load(added_tokens_handle)
  1820|         0|            0|            0|  0.00%|
  1821|         0|            0|            0|  0.00%|            # Sort added tokens by index
  1822|         0|            0|            0|  0.00%|            added_tok_encoder_sorted = list(sorted(added_tok_encoder.items(), key=lambda x: x[1]))
  1823|         0|            0|            0|  0.00%|
  1824|         0|            0|            0|  0.00%|            for token, index in added_tok_encoder_sorted:
  1825|         0|            0|            0|  0.00%|                if has_tokenizer_file and index != len(tokenizer) and tokenizer.convert_tokens_to_ids(token) != index:
  1826|         0|            0|            0|  0.00%|                    # Tokenizer fast: added token needs to either be in the vocabulary with the proper index or the
  1827|         0|            0|            0|  0.00%|                    # index is the current length of the tokenizer (not in vocabulary)
  1828|         0|            0|            0|  0.00%|                    raise ValueError(
  1829|         0|            0|            0|  0.00%|                        f"Wrong index found for {token}: should be {tokenizer.convert_tokens_to_ids(token)} but found "
  1830|         0|            0|            0|  0.00%|                        f"{index}."
  1831|         0|            0|            0|  0.00%|                    )
  1832|         0|            0|            0|  0.00%|                elif not has_tokenizer_file and index != len(tokenizer):
  1833|         0|            0|            0|  0.00%|                    # Tokenizer slow: added token cannot already be in the vocabulary so its index needs to be the
  1834|         0|            0|            0|  0.00%|                    # current length of the tokenizer.
  1835|         0|            0|            0|  0.00%|                    raise ValueError(
  1836|         0|            0|            0|  0.00%|                        f"Non-consecutive added token '{token}' found. "
  1837|         0|            0|            0|  0.00%|                        f"Should have index {len(tokenizer)} but has index {index} in saved vocabulary."
  1838|         0|            0|            0|  0.00%|                    )
  1839|         0|            0|            0|  0.00%|
  1840|         0|            0|            0|  0.00%|                # Safe to call on a tokenizer fast even if token already there.
  1841|         0|            0|            0|  0.00%|                tokenizer.add_tokens(token, special_tokens=bool(token in special_tokens))
  1842|         0|            0|            0|  0.00%|
  1843|         0|            0|            0|  0.00%|        # Check all our special tokens are registered as "no split" token (we don't cut them) and are in the vocab
  1844|         0|            0|            0|  0.00%|        added_tokens = tokenizer.sanitize_special_tokens()
  1845|         0|            0|            0|  0.00%|        if added_tokens:
  1846|         0|            0|            0|  0.00%|            logger.warning(
  1847|         0|            0|            0|  0.00%|                "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained."
  1848|         0|            0|            0|  0.00%|            )
  1849|         0|            0|            0|  0.00%|
  1850|         0|            0|            0|  0.00%|        return tokenizer
  1851|         0|            0|            0|  0.00%|
  1852|         0|            0|            0|  0.00%|    def save_pretrained(
  1853|         0|            0|            0|  0.00%|        self,
  1854|         0|            0|            0|  0.00%|        save_directory: Union[str, os.PathLike],
  1855|         0|            0|            0|  0.00%|        legacy_format: Optional[bool] = None,
  1856|         0|            0|            0|  0.00%|        filename_prefix: Optional[str] = None,
  1857|         0|            0|            0|  0.00%|        push_to_hub: bool = False,
  1858|         0|            0|            0|  0.00%|        **kwargs,
  1859|         0|            0|            0|  0.00%|    ) -> Tuple[str]:
  1860|         0|            0|            0|  0.00%|        """
  1861|         0|            0|            0|  0.00%|        Save the full tokenizer state.
  1862|         0|            0|            0|  0.00%|
  1863|         0|            0|            0|  0.00%|
  1864|         0|            0|            0|  0.00%|        This method make sure the full tokenizer can then be re-loaded using the
  1865|         0|            0|            0|  0.00%|        :meth:`~transformers.tokenization_utils_base.PreTrainedTokenizer.from_pretrained` class method..
  1866|         0|            0|            0|  0.00%|
  1867|         0|            0|            0|  0.00%|        .. Warning::
  1868|         0|            0|            0|  0.00%|           This won't save modifications you may have applied to the tokenizer after the instantiation (for instance,
  1869|         0|            0|            0|  0.00%|           modifying :obj:`tokenizer.do_lower_case` after creation).
  1870|         0|            0|            0|  0.00%|
  1871|         0|            0|            0|  0.00%|        Args:
  1872|         0|            0|            0|  0.00%|            save_directory (:obj:`str` or :obj:`os.PathLike`): The path to a directory where the tokenizer will be saved.
  1873|         0|            0|            0|  0.00%|            legacy_format (:obj:`bool`, `optional`):
  1874|         0|            0|            0|  0.00%|                Only applicable for a fast tokenizer. If unset (default), will save the tokenizer in the unified JSON
  1875|         0|            0|            0|  0.00%|                format as well as in legacy format if it exists, i.e. with tokenizer specific vocabulary and a separate
  1876|         0|            0|            0|  0.00%|                added_tokens files.
  1877|         0|            0|            0|  0.00%|
  1878|         0|            0|            0|  0.00%|                If :obj:`False`, will only save the tokenizer in the unified JSON format. This format is incompatible
  1879|         0|            0|            0|  0.00%|                with "slow" tokenizers (not powered by the `tokenizers` library), so the tokenizer will not be able to
  1880|         0|            0|            0|  0.00%|                be loaded in the corresponding "slow" tokenizer.
  1881|         0|            0|            0|  0.00%|
  1882|         0|            0|            0|  0.00%|                If :obj:`True`, will save the tokenizer in legacy format. If the "slow" tokenizer doesn't exits, a
  1883|         0|            0|            0|  0.00%|                value error is raised.
  1884|         0|            0|            0|  0.00%|            filename_prefix: (:obj:`str`, `optional`):
  1885|         0|            0|            0|  0.00%|                A prefix to add to the names of the files saved by the tokenizer.
  1886|         0|            0|            0|  0.00%|
  1887|         0|            0|            0|  0.00%|        Returns:
  1888|         0|            0|            0|  0.00%|            A tuple of :obj:`str`: The files saved.
  1889|         0|            0|            0|  0.00%|        """
  1890|         0|            0|            0|  0.00%|        if os.path.isfile(save_directory):
  1891|         0|            0|            0|  0.00%|            logger.error(f"Provided path ({save_directory}) should be a directory, not a file")
  1892|         0|            0|            0|  0.00%|            return
  1893|         0|            0|            0|  0.00%|        os.makedirs(save_directory, exist_ok=True)
  1894|         0|            0|            0|  0.00%|
  1895|         0|            0|            0|  0.00%|        special_tokens_map_file = os.path.join(
  1896|         0|            0|            0|  0.00%|            save_directory, (filename_prefix + "-" if filename_prefix else "") + SPECIAL_TOKENS_MAP_FILE
  1897|         0|            0|            0|  0.00%|        )
  1898|         0|            0|            0|  0.00%|        tokenizer_config_file = os.path.join(
  1899|         0|            0|            0|  0.00%|            save_directory, (filename_prefix + "-" if filename_prefix else "") + TOKENIZER_CONFIG_FILE
  1900|         0|            0|            0|  0.00%|        )
  1901|         0|            0|            0|  0.00%|
  1902|         0|            0|            0|  0.00%|        tokenizer_config = copy.deepcopy(self.init_kwargs)
  1903|         0|            0|            0|  0.00%|        if len(self.init_inputs) > 0:
  1904|         0|            0|            0|  0.00%|            tokenizer_config["init_inputs"] = copy.deepcopy(self.init_inputs)
  1905|         0|            0|            0|  0.00%|        for file_id in self.vocab_files_names.keys():
  1906|         0|            0|            0|  0.00%|            tokenizer_config.pop(file_id, None)
  1907|         0|            0|            0|  0.00%|
  1908|         0|            0|            0|  0.00%|        # Sanitize AddedTokens
  1909|         0|            0|            0|  0.00%|        def convert_added_tokens(obj: Union[AddedToken, Any], add_type_field=True):
  1910|         0|            0|            0|  0.00%|            if isinstance(obj, AddedToken):
  1911|         0|            0|            0|  0.00%|                out = obj.__getstate__()
  1912|         0|            0|            0|  0.00%|                if add_type_field:
  1913|         0|            0|            0|  0.00%|                    out["__type"] = "AddedToken"
  1914|         0|            0|            0|  0.00%|                return out
  1915|         0|            0|            0|  0.00%|            elif isinstance(obj, (list, tuple)):
  1916|         0|            0|            0|  0.00%|                return list(convert_added_tokens(o, add_type_field=add_type_field) for o in obj)
  1917|         0|            0|            0|  0.00%|            elif isinstance(obj, dict):
  1918|         0|            0|            0|  0.00%|                return {k: convert_added_tokens(v, add_type_field=add_type_field) for k, v in obj.items()}
  1919|         0|            0|            0|  0.00%|            return obj
  1920|         0|            0|            0|  0.00%|
  1921|         0|            0|            0|  0.00%|        # add_type_field=True to allow dicts in the kwargs / differentiate from AddedToken serialization
  1922|         0|            0|            0|  0.00%|        tokenizer_config = convert_added_tokens(tokenizer_config, add_type_field=True)
  1923|         0|            0|            0|  0.00%|        with open(tokenizer_config_file, "w", encoding="utf-8") as f:
  1924|         0|            0|            0|  0.00%|            f.write(json.dumps(tokenizer_config, ensure_ascii=False))
  1925|         0|            0|            0|  0.00%|        logger.info(f"tokenizer config file saved in {tokenizer_config_file}")
  1926|         0|            0|            0|  0.00%|
  1927|         0|            0|            0|  0.00%|        # Sanitize AddedTokens in special_tokens_map
  1928|         0|            0|            0|  0.00%|        write_dict = convert_added_tokens(self.special_tokens_map_extended, add_type_field=False)
  1929|         0|            0|            0|  0.00%|        with open(special_tokens_map_file, "w", encoding="utf-8") as f:
  1930|         0|            0|            0|  0.00%|            f.write(json.dumps(write_dict, ensure_ascii=False))
  1931|         0|            0|            0|  0.00%|        logger.info(f"Special tokens file saved in {special_tokens_map_file}")
  1932|         0|            0|            0|  0.00%|
  1933|         0|            0|            0|  0.00%|        file_names = (tokenizer_config_file, special_tokens_map_file)
  1934|         0|            0|            0|  0.00%|
  1935|         0|            0|            0|  0.00%|        save_files = self._save_pretrained(
  1936|         0|            0|            0|  0.00%|            save_directory=save_directory,
  1937|         0|            0|            0|  0.00%|            file_names=file_names,
  1938|         0|            0|            0|  0.00%|            legacy_format=legacy_format,
  1939|         0|            0|            0|  0.00%|            filename_prefix=filename_prefix,
  1940|         0|            0|            0|  0.00%|        )
  1941|         0|            0|            0|  0.00%|
  1942|         0|            0|            0|  0.00%|        if push_to_hub:
  1943|         0|            0|            0|  0.00%|            # Annoyingly, the return contains files that don't exist.
  1944|         0|            0|            0|  0.00%|            existing_files = [f for f in save_files if os.path.isfile(f)]
  1945|         0|            0|            0|  0.00%|            url = self._push_to_hub(save_files=existing_files, **kwargs)
  1946|         0|            0|            0|  0.00%|            logger.info(f"Tokenizer pushed to the hub in this commit: {url}")
  1947|         0|            0|            0|  0.00%|
  1948|         0|            0|            0|  0.00%|        return save_files
  1949|         0|            0|            0|  0.00%|
  1950|         0|            0|            0|  0.00%|    def _save_pretrained(
  1951|         0|            0|            0|  0.00%|        self,
  1952|         0|            0|            0|  0.00%|        save_directory: Union[str, os.PathLike],
  1953|         0|            0|            0|  0.00%|        file_names: Tuple[str],
  1954|         0|            0|            0|  0.00%|        legacy_format: Optional[bool] = None,
  1955|         0|            0|            0|  0.00%|        filename_prefix: Optional[str] = None,
  1956|         0|            0|            0|  0.00%|    ) -> Tuple[str]:
  1957|         0|            0|            0|  0.00%|        """
  1958|         0|            0|            0|  0.00%|        Save a tokenizer using the slow-tokenizer/legacy format: vocabulary + added tokens.
  1959|         0|            0|            0|  0.00%|
  1960|         0|            0|            0|  0.00%|        Fast tokenizers can also be saved in a unique JSON file containing {config + vocab + added-tokens} using the
  1961|         0|            0|            0|  0.00%|        specific :meth:`~transformers.tokenization_utils_fast.PreTrainedTokenizerFast._save_pretrained`
  1962|         0|            0|            0|  0.00%|        """
  1963|         0|            0|            0|  0.00%|        if legacy_format is False:
  1964|         0|            0|            0|  0.00%|            raise ValueError(
  1965|         0|            0|            0|  0.00%|                "Only fast tokenizers (instances of PreTrainedTokenizerFast) can be saved in non legacy format."
  1966|         0|            0|            0|  0.00%|            )
  1967|         0|            0|            0|  0.00%|
  1968|         0|            0|            0|  0.00%|        save_directory = str(save_directory)
  1969|         0|            0|            0|  0.00%|
  1970|         0|            0|            0|  0.00%|        added_tokens_file = os.path.join(
  1971|         0|            0|            0|  0.00%|            save_directory, (filename_prefix + "-" if filename_prefix else "") + ADDED_TOKENS_FILE
  1972|         0|            0|            0|  0.00%|        )
  1973|         0|            0|            0|  0.00%|        added_vocab = self.get_added_vocab()
  1974|         0|            0|            0|  0.00%|        if added_vocab:
  1975|         0|            0|            0|  0.00%|            with open(added_tokens_file, "w", encoding="utf-8") as f:
  1976|         0|            0|            0|  0.00%|                out_str = json.dumps(added_vocab, ensure_ascii=False)
  1977|         0|            0|            0|  0.00%|                f.write(out_str)
  1978|         0|            0|            0|  0.00%|                logger.info(f"added tokens file saved in {added_tokens_file}")
  1979|         0|            0|            0|  0.00%|
  1980|         0|            0|            0|  0.00%|        vocab_files = self.save_vocabulary(save_directory, filename_prefix=filename_prefix)
  1981|         0|            0|            0|  0.00%|
  1982|         0|            0|            0|  0.00%|        return file_names + vocab_files + (added_tokens_file,)
  1983|         0|            0|            0|  0.00%|
  1984|         0|            0|            0|  0.00%|    def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:
  1985|         0|            0|            0|  0.00%|        """
  1986|         0|            0|            0|  0.00%|        Save only the vocabulary of the tokenizer (vocabulary + added tokens).
  1987|         0|            0|            0|  0.00%|
  1988|         0|            0|            0|  0.00%|        This method won't save the configuration and special token mappings of the tokenizer. Use
  1989|         0|            0|            0|  0.00%|        :meth:`~transformers.PreTrainedTokenizerFast._save_pretrained` to save the whole state of the tokenizer.
  1990|         0|            0|            0|  0.00%|
  1991|         0|            0|            0|  0.00%|        Args:
  1992|         0|            0|            0|  0.00%|            save_directory (:obj:`str`):
  1993|         0|            0|            0|  0.00%|                The directory in which to save the vocabulary.
  1994|         0|            0|            0|  0.00%|            filename_prefix (:obj:`str`, `optional`):
  1995|         0|            0|            0|  0.00%|                An optional prefix to add to the named of the saved files.
  1996|         0|            0|            0|  0.00%|
  1997|         0|            0|            0|  0.00%|        Returns:
  1998|         0|            0|            0|  0.00%|            :obj:`Tuple(str)`: Paths to the files saved.
  1999|         0|            0|            0|  0.00%|        """
  2000|         0|            0|            0|  0.00%|        raise NotImplementedError
  2001|         0|            0|            0|  0.00%|
  2002|         0|            0|            0|  0.00%|    def tokenize(self, text: str, pair: Optional[str] = None, add_special_tokens: bool = False, **kwargs) -> List[str]:
  2003|         0|            0|            0|  0.00%|        """
  2004|         0|            0|            0|  0.00%|        Converts a string in a sequence of tokens, replacing unknown tokens with the :obj:`unk_token`.
  2005|         0|            0|            0|  0.00%|
  2006|         0|            0|            0|  0.00%|        Args:
  2007|         0|            0|            0|  0.00%|            text (:obj:`str`):
  2008|         0|            0|            0|  0.00%|                The sequence to be encoded.
  2009|         0|            0|            0|  0.00%|            pair (:obj:`str`, `optional`):
  2010|         0|            0|            0|  0.00%|                A second sequence to be encoded with the first.
  2011|         0|            0|            0|  0.00%|            add_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
  2012|         0|            0|            0|  0.00%|                Whether or not to add the special tokens associated with the corresponding model.
  2013|         0|            0|            0|  0.00%|            kwargs (additional keyword arguments, `optional`):
  2014|         0|            0|            0|  0.00%|                Will be passed to the underlying model specific encode method. See details in
  2015|         0|            0|            0|  0.00%|                :meth:`~transformers.PreTrainedTokenizerBase.__call__`
  2016|         0|            0|            0|  0.00%|
  2017|         0|            0|            0|  0.00%|        Returns:
  2018|         0|            0|            0|  0.00%|            :obj:`List[str]`: The list of tokens.
  2019|         0|            0|            0|  0.00%|        """
  2020|         0|            0|            0|  0.00%|        raise NotImplementedError
  2021|         0|            0|            0|  0.00%|
  2022|         0|            0|            0|  0.00%|    @add_end_docstrings(
  2023|         0|            0|            0|  0.00%|        ENCODE_KWARGS_DOCSTRING,
  2024|         0|            0|            0|  0.00%|        """
  2025|         0|            0|            0|  0.00%|            **kwargs: Passed along to the `.tokenize()` method.
  2026|         0|            0|            0|  0.00%|        """,
  2027|         0|            0|            0|  0.00%|        """
  2028|         0|            0|            0|  0.00%|        Returns:
  2029|         0|            0|            0|  0.00%|            :obj:`List[int]`, :obj:`torch.Tensor`, :obj:`tf.Tensor` or :obj:`np.ndarray`: The tokenized ids of the
  2030|         0|            0|            0|  0.00%|            text.
  2031|         0|            0|            0|  0.00%|        """,
  2032|         0|            0|            0|  0.00%|    )
  2033|         0|            0|            0|  0.00%|    def encode(
  2034|         0|            0|            0|  0.00%|        self,
  2035|         0|            0|            0|  0.00%|        text: Union[TextInput, PreTokenizedInput, EncodedInput],
  2036|         0|            0|            0|  0.00%|        text_pair: Optional[Union[TextInput, PreTokenizedInput, EncodedInput]] = None,
  2037|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2038|         0|            0|            0|  0.00%|        padding: Union[bool, str, PaddingStrategy] = False,
  2039|         0|            0|            0|  0.00%|        truncation: Union[bool, str, TruncationStrategy] = False,
  2040|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2041|         0|            0|            0|  0.00%|        stride: int = 0,
  2042|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2043|         0|            0|            0|  0.00%|        **kwargs
  2044|         0|            0|            0|  0.00%|    ) -> List[int]:
  2045|         0|            0|            0|  0.00%|        """
  2046|         0|            0|            0|  0.00%|        Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.
  2047|         0|            0|            0|  0.00%|
  2048|         0|            0|            0|  0.00%|        Same as doing ``self.convert_tokens_to_ids(self.tokenize(text))``.
  2049|         0|            0|            0|  0.00%|
  2050|         0|            0|            0|  0.00%|        Args:
  2051|         0|            0|            0|  0.00%|            text (:obj:`str`, :obj:`List[str]` or :obj:`List[int]`):
  2052|         0|            0|            0|  0.00%|                The first sequence to be encoded. This can be a string, a list of strings (tokenized string using the
  2053|         0|            0|            0|  0.00%|                ``tokenize`` method) or a list of integers (tokenized string ids using the ``convert_tokens_to_ids``
  2054|         0|            0|            0|  0.00%|                method).
  2055|         0|            0|            0|  0.00%|            text_pair (:obj:`str`, :obj:`List[str]` or :obj:`List[int]`, `optional`):
  2056|         0|            0|            0|  0.00%|                Optional second sequence to be encoded. This can be a string, a list of strings (tokenized string using
  2057|         0|            0|            0|  0.00%|                the ``tokenize`` method) or a list of integers (tokenized string ids using the
  2058|         0|            0|            0|  0.00%|                ``convert_tokens_to_ids`` method).
  2059|         0|            0|            0|  0.00%|        """
  2060|         0|            0|            0|  0.00%|        encoded_inputs = self.encode_plus(
  2061|         0|            0|            0|  0.00%|            text,
  2062|         0|            0|            0|  0.00%|            text_pair=text_pair,
  2063|         0|            0|            0|  0.00%|            add_special_tokens=add_special_tokens,
  2064|         0|            0|            0|  0.00%|            padding=padding,
  2065|         0|            0|            0|  0.00%|            truncation=truncation,
  2066|         0|            0|            0|  0.00%|            max_length=max_length,
  2067|         0|            0|            0|  0.00%|            stride=stride,
  2068|         0|            0|            0|  0.00%|            return_tensors=return_tensors,
  2069|         0|            0|            0|  0.00%|            **kwargs,
  2070|         0|            0|            0|  0.00%|        )
  2071|         0|            0|            0|  0.00%|
  2072|         0|            0|            0|  0.00%|        return encoded_inputs["input_ids"]
  2073|         0|            0|            0|  0.00%|
  2074|         0|            0|            0|  0.00%|    def num_special_tokens_to_add(self, pair: bool = False) -> int:
  2075|         0|            0|            0|  0.00%|        raise NotImplementedError
  2076|         0|            0|            0|  0.00%|
  2077|         0|            0|            0|  0.00%|    def _get_padding_truncation_strategies(
  2078|         0|            0|            0|  0.00%|        self, padding=False, truncation=False, max_length=None, pad_to_multiple_of=None, verbose=True, **kwargs
  2079|         0|            0|            0|  0.00%|    ):
  2080|         0|            0|            0|  0.00%|        """
  2081|         0|            0|            0|  0.00%|        Find the correct padding/truncation strategy with backward compatibility for old arguments (truncation_strategy
  2082|         0|            0|            0|  0.00%|        and pad_to_max_length) and behaviors.
  2083|         0|            0|            0|  0.00%|        """
  2084|         0|            0|            0|  0.00%|        old_truncation_strategy = kwargs.pop("truncation_strategy", "do_not_truncate")
  2085|         0|            0|            0|  0.00%|        old_pad_to_max_length = kwargs.pop("pad_to_max_length", False)
  2086|         0|            0|            0|  0.00%|
  2087|         0|            0|            0|  0.00%|        # Backward compatibility for previous behavior, maybe we should deprecate it:
  2088|         0|            0|            0|  0.00%|        # If you only set max_length, it activates truncation for max_length
  2089|         0|            0|            0|  0.00%|        if max_length is not None and padding is False and truncation is False:
  2090|         0|            0|            0|  0.00%|            if verbose:
  2091|         0|            0|            0|  0.00%|                if not self.deprecation_warnings.get("Truncation-not-explicitly-activated", False):
  2092|         0|            0|            0|  0.00%|                    logger.warning(
  2093|         0|            0|            0|  0.00%|                        "Truncation was not explicitly activated but `max_length` is provided a specific value, "
  2094|         0|            0|            0|  0.00%|                        "please use `truncation=True` to explicitly truncate examples to max length. "
  2095|         0|            0|            0|  0.00%|                        "Defaulting to 'longest_first' truncation strategy. "
  2096|         0|            0|            0|  0.00%|                        "If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy "
  2097|         0|            0|            0|  0.00%|                        "more precisely by providing a specific strategy to `truncation`."
  2098|         0|            0|            0|  0.00%|                    )
  2099|         0|            0|            0|  0.00%|                self.deprecation_warnings["Truncation-not-explicitly-activated"] = True
  2100|         0|            0|            0|  0.00%|            truncation = "longest_first"
  2101|         0|            0|            0|  0.00%|
  2102|         0|            0|            0|  0.00%|        # Get padding strategy
  2103|         0|            0|            0|  0.00%|        if padding is False and old_pad_to_max_length:
  2104|         0|            0|            0|  0.00%|            if verbose:
  2105|         0|            0|            0|  0.00%|                warnings.warn(
  2106|         0|            0|            0|  0.00%|                    "The `pad_to_max_length` argument is deprecated and will be removed in a future version, "
  2107|         0|            0|            0|  0.00%|                    "use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or "
  2108|         0|            0|            0|  0.00%|                    "use `padding='max_length'` to pad to a max length. In this case, you can give a specific "
  2109|         0|            0|            0|  0.00%|                    "length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the "
  2110|         0|            0|            0|  0.00%|                    "maximal input size of the model (e.g. 512 for Bert).",
  2111|         0|            0|            0|  0.00%|                    FutureWarning,
  2112|         0|            0|            0|  0.00%|                )
  2113|         0|            0|            0|  0.00%|            if max_length is None:
  2114|         0|            0|            0|  0.00%|                padding_strategy = PaddingStrategy.LONGEST
  2115|         0|            0|            0|  0.00%|            else:
  2116|         0|            0|            0|  0.00%|                padding_strategy = PaddingStrategy.MAX_LENGTH
  2117|         0|            0|            0|  0.00%|        elif padding is not False:
  2118|         0|            0|            0|  0.00%|            if padding is True:
  2119|         0|            0|            0|  0.00%|                padding_strategy = PaddingStrategy.LONGEST  # Default to pad to the longest sequence in the batch
  2120|         0|            0|            0|  0.00%|            elif not isinstance(padding, PaddingStrategy):
  2121|         0|            0|            0|  0.00%|                padding_strategy = PaddingStrategy(padding)
  2122|         0|            0|            0|  0.00%|            elif isinstance(padding, PaddingStrategy):
  2123|         0|            0|            0|  0.00%|                padding_strategy = padding
  2124|         0|            0|            0|  0.00%|        else:
  2125|         0|            0|            0|  0.00%|            padding_strategy = PaddingStrategy.DO_NOT_PAD
  2126|         0|            0|            0|  0.00%|
  2127|         0|            0|            0|  0.00%|        # Get truncation strategy
  2128|         0|            0|            0|  0.00%|        if truncation is False and old_truncation_strategy != "do_not_truncate":
  2129|         0|            0|            0|  0.00%|            if verbose:
  2130|         0|            0|            0|  0.00%|                warnings.warn(
  2131|         0|            0|            0|  0.00%|                    "The `truncation_strategy` argument is deprecated and will be removed in a future version, "
  2132|         0|            0|            0|  0.00%|                    "use `truncation=True` to truncate examples to a max length. You can give a specific "
  2133|         0|            0|            0|  0.00%|                    "length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the "
  2134|         0|            0|            0|  0.00%|                    "maximal input size of the model (e.g. 512 for Bert). "
  2135|         0|            0|            0|  0.00%|                    " If you have pairs of inputs, you can give a specific truncation strategy selected among "
  2136|         0|            0|            0|  0.00%|                    "`truncation='only_first'` (will only truncate the first sentence in the pairs) "
  2137|         0|            0|            0|  0.00%|                    "`truncation='only_second'` (will only truncate the second sentence in the pairs) "
  2138|         0|            0|            0|  0.00%|                    "or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).",
  2139|         0|            0|            0|  0.00%|                    FutureWarning,
  2140|         0|            0|            0|  0.00%|                )
  2141|         0|            0|            0|  0.00%|            truncation_strategy = TruncationStrategy(old_truncation_strategy)
  2142|         0|            0|            0|  0.00%|        elif truncation is not False:
  2143|         0|            0|            0|  0.00%|            if truncation is True:
  2144|         0|            0|            0|  0.00%|                truncation_strategy = (
  2145|         0|            0|            0|  0.00%|                    TruncationStrategy.LONGEST_FIRST
  2146|         0|            0|            0|  0.00%|                )  # Default to truncate the longest sequences in pairs of inputs
  2147|         0|            0|            0|  0.00%|            elif not isinstance(truncation, TruncationStrategy):
  2148|         0|            0|            0|  0.00%|                truncation_strategy = TruncationStrategy(truncation)
  2149|         0|            0|            0|  0.00%|            elif isinstance(truncation, TruncationStrategy):
  2150|         0|            0|            0|  0.00%|                truncation_strategy = truncation
  2151|         0|            0|            0|  0.00%|        else:
  2152|         0|            0|            0|  0.00%|            truncation_strategy = TruncationStrategy.DO_NOT_TRUNCATE
  2153|         0|            0|            0|  0.00%|
  2154|         0|            0|            0|  0.00%|        # Set max length if needed
  2155|         0|            0|            0|  0.00%|        if max_length is None:
  2156|         0|            0|            0|  0.00%|            if padding_strategy == PaddingStrategy.MAX_LENGTH:
  2157|         0|            0|            0|  0.00%|                if self.model_max_length > LARGE_INTEGER:
  2158|         0|            0|            0|  0.00%|                    if verbose:
  2159|         0|            0|            0|  0.00%|                        if not self.deprecation_warnings.get("Asking-to-pad-to-max_length", False):
  2160|         0|            0|            0|  0.00%|                            logger.warning(
  2161|         0|            0|            0|  0.00%|                                "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. "
  2162|         0|            0|            0|  0.00%|                                "Default to no padding."
  2163|         0|            0|            0|  0.00%|                            )
  2164|         0|            0|            0|  0.00%|                        self.deprecation_warnings["Asking-to-pad-to-max_length"] = True
  2165|         0|            0|            0|  0.00%|                    padding_strategy = PaddingStrategy.DO_NOT_PAD
  2166|         0|            0|            0|  0.00%|                else:
  2167|         0|            0|            0|  0.00%|                    max_length = self.model_max_length
  2168|         0|            0|            0|  0.00%|
  2169|         0|            0|            0|  0.00%|            if truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE:
  2170|         0|            0|            0|  0.00%|                if self.model_max_length > LARGE_INTEGER:
  2171|         0|            0|            0|  0.00%|                    if verbose:
  2172|         0|            0|            0|  0.00%|                        if not self.deprecation_warnings.get("Asking-to-truncate-to-max_length", False):
  2173|         0|            0|            0|  0.00%|                            logger.warning(
  2174|         0|            0|            0|  0.00%|                                "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. "
  2175|         0|            0|            0|  0.00%|                                "Default to no truncation."
  2176|         0|            0|            0|  0.00%|                            )
  2177|         0|            0|            0|  0.00%|                        self.deprecation_warnings["Asking-to-truncate-to-max_length"] = True
  2178|         0|            0|            0|  0.00%|                    truncation_strategy = TruncationStrategy.DO_NOT_TRUNCATE
  2179|         0|            0|            0|  0.00%|                else:
  2180|         0|            0|            0|  0.00%|                    max_length = self.model_max_length
  2181|         0|            0|            0|  0.00%|
  2182|         0|            0|            0|  0.00%|        # Test if we have a padding token
  2183|         0|            0|            0|  0.00%|        if padding_strategy != PaddingStrategy.DO_NOT_PAD and (not self.pad_token or self.pad_token_id < 0):
  2184|         0|            0|            0|  0.00%|            raise ValueError(
  2185|         0|            0|            0|  0.00%|                "Asking to pad but the tokenizer does not have a padding token. "
  2186|         0|            0|            0|  0.00%|                "Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` "
  2187|         0|            0|            0|  0.00%|                "or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
  2188|         0|            0|            0|  0.00%|            )
  2189|         0|            0|            0|  0.00%|
  2190|         0|            0|            0|  0.00%|        # Check that we will truncate to a multiple of pad_to_multiple_of if both are provided
  2191|         0|            0|            0|  0.00%|        if (
  2192|         0|            0|            0|  0.00%|            truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE
  2193|         0|            0|            0|  0.00%|            and padding_strategy != PaddingStrategy.DO_NOT_PAD
  2194|         0|            0|            0|  0.00%|            and pad_to_multiple_of is not None
  2195|         0|            0|            0|  0.00%|            and max_length is not None
  2196|         0|            0|            0|  0.00%|            and (max_length % pad_to_multiple_of != 0)
  2197|         0|            0|            0|  0.00%|        ):
  2198|         0|            0|            0|  0.00%|            raise ValueError(
  2199|         0|            0|            0|  0.00%|                f"Truncation and padding are both activated but "
  2200|         0|            0|            0|  0.00%|                f"truncation length ({max_length}) is not a multiple of pad_to_multiple_of ({pad_to_multiple_of})."
  2201|         0|            0|            0|  0.00%|            )
  2202|         0|            0|            0|  0.00%|
  2203|         0|            0|            0|  0.00%|        return padding_strategy, truncation_strategy, max_length, kwargs
  2204|         0|            0|            0|  0.00%|
  2205|         0|            0|            0|  0.00%|    @add_end_docstrings(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)
  2206|         0|            0|            0|  0.00%|    def __call__(
  2207|         0|            0|            0|  0.00%|        self,
  2208|         0|            0|            0|  0.00%|        text: Union[TextInput, PreTokenizedInput, List[TextInput], List[PreTokenizedInput]],
  2209|         0|            0|            0|  0.00%|        text_pair: Optional[Union[TextInput, PreTokenizedInput, List[TextInput], List[PreTokenizedInput]]] = None,
  2210|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2211|         0|            0|            0|  0.00%|        padding: Union[bool, str, PaddingStrategy] = False,
  2212|         0|            0|            0|  0.00%|        truncation: Union[bool, str, TruncationStrategy] = False,
  2213|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2214|         0|            0|            0|  0.00%|        stride: int = 0,
  2215|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
  2216|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2217|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2218|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
  2219|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2220|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
  2221|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
  2222|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
  2223|         0|            0|            0|  0.00%|        return_length: bool = False,
  2224|         0|            0|            0|  0.00%|        verbose: bool = True,
  2225|         0|            0|            0|  0.00%|        **kwargs
  2226|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2227|         0|            0|            0|  0.00%|        """
  2228|         0|            0|            0|  0.00%|        Main method to tokenize and prepare for the model one or several sequence(s) or one or several pair(s) of
  2229|         0|            0|            0|  0.00%|        sequences.
  2230|         0|            0|            0|  0.00%|
  2231|         0|            0|            0|  0.00%|        Args:
  2232|         0|            0|            0|  0.00%|            text (:obj:`str`, :obj:`List[str]`, :obj:`List[List[str]]`):
  2233|         0|            0|            0|  0.00%|                The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings
  2234|         0|            0|            0|  0.00%|                (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set
  2235|         0|            0|            0|  0.00%|                :obj:`is_split_into_words=True` (to lift the ambiguity with a batch of sequences).
  2236|         0|            0|            0|  0.00%|            text_pair (:obj:`str`, :obj:`List[str]`, :obj:`List[List[str]]`):
  2237|         0|            0|            0|  0.00%|                The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings
  2238|         0|            0|            0|  0.00%|                (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set
  2239|         0|            0|            0|  0.00%|                :obj:`is_split_into_words=True` (to lift the ambiguity with a batch of sequences).
  2240|         0|            0|            0|  0.00%|        """
  2241|         0|            0|            0|  0.00%|        # Input type checking for clearer error
  2242|         0|            0|            0|  0.00%|        def _is_valid_text_input(t):
  2243|         0|            0|            0|  0.00%|            if isinstance(t, str):
  2244|         0|            0|            0|  0.00%|                # Strings are fine
  2245|         0|            0|            0|  0.00%|                return True
  2246|         0|            0|            0|  0.00%|            elif isinstance(t, (list, tuple)):
  2247|         0|            0|            0|  0.00%|                # List are fine as long as they are...
  2248|         0|            0|            0|  0.00%|                if len(t) == 0:
  2249|         0|            0|            0|  0.00%|                    # ... empty
  2250|         0|            0|            0|  0.00%|                    return True
  2251|         0|            0|            0|  0.00%|                elif isinstance(t[0], str):
  2252|         0|            0|            0|  0.00%|                    # ... list of strings
  2253|         0|            0|            0|  0.00%|                    return True
  2254|         0|            0|            0|  0.00%|                elif isinstance(t[0], (list, tuple)):
  2255|         0|            0|            0|  0.00%|                    # ... list with an empty list or with a list of strings
  2256|         0|            0|            0|  0.00%|                    return len(t[0]) == 0 or isinstance(t[0][0], str)
  2257|         0|            0|            0|  0.00%|                else:
  2258|         0|            0|            0|  0.00%|                    return False
  2259|         0|            0|            0|  0.00%|            else:
  2260|         0|            0|            0|  0.00%|                return False
  2261|         0|            0|            0|  0.00%|
  2262|         0|            0|            0|  0.00%|        if not _is_valid_text_input(text):
  2263|         0|            0|            0|  0.00%|            raise ValueError(
  2264|         0|            0|            0|  0.00%|                "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) "
  2265|         0|            0|            0|  0.00%|                "or `List[List[str]]` (batch of pretokenized examples)."
  2266|         0|            0|            0|  0.00%|            )
  2267|         0|            0|            0|  0.00%|
  2268|         0|            0|            0|  0.00%|        if text_pair is not None and not _is_valid_text_input(text_pair):
  2269|         0|            0|            0|  0.00%|            raise ValueError(
  2270|         0|            0|            0|  0.00%|                "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) "
  2271|         0|            0|            0|  0.00%|                "or `List[List[str]]` (batch of pretokenized examples)."
  2272|         0|            0|            0|  0.00%|            )
  2273|         0|            0|            0|  0.00%|
  2274|         0|            0|            0|  0.00%|        if is_split_into_words:
  2275|         0|            0|            0|  0.00%|            is_batched = isinstance(text, (list, tuple)) and text and isinstance(text[0], (list, tuple))
  2276|         0|            0|            0|  0.00%|        else:
  2277|         0|            0|            0|  0.00%|            is_batched = isinstance(text, (list, tuple))
  2278|         0|            0|            0|  0.00%|
  2279|         0|            0|            0|  0.00%|        if is_batched:
  2280|         0|            0|            0|  0.00%|            if isinstance(text_pair, str):
  2281|         0|            0|            0|  0.00%|                raise TypeError(
  2282|         0|            0|            0|  0.00%|                    "when tokenizing batches of text, `text_pair` must be a list or tuple with the same length as `text`."
  2283|         0|            0|            0|  0.00%|                )
  2284|         0|            0|            0|  0.00%|            if text_pair is not None and len(text) != len(text_pair):
  2285|         0|            0|            0|  0.00%|                raise ValueError(
  2286|         0|            0|            0|  0.00%|                    f"batch length of `text`: {len(text)} does not match batch length of `text_pair`: {len(text_pair)}."
  2287|         0|            0|            0|  0.00%|                )
  2288|         0|            0|            0|  0.00%|            batch_text_or_text_pairs = list(zip(text, text_pair)) if text_pair is not None else text
  2289|         0|            0|            0|  0.00%|            return self.batch_encode_plus(
  2290|         0|            0|            0|  0.00%|                batch_text_or_text_pairs=batch_text_or_text_pairs,
  2291|         0|            0|            0|  0.00%|                add_special_tokens=add_special_tokens,
  2292|         0|            0|            0|  0.00%|                padding=padding,
  2293|         0|            0|            0|  0.00%|                truncation=truncation,
  2294|         0|            0|            0|  0.00%|                max_length=max_length,
  2295|         0|            0|            0|  0.00%|                stride=stride,
  2296|         0|            0|            0|  0.00%|                is_split_into_words=is_split_into_words,
  2297|         0|            0|            0|  0.00%|                pad_to_multiple_of=pad_to_multiple_of,
  2298|         0|            0|            0|  0.00%|                return_tensors=return_tensors,
  2299|         0|            0|            0|  0.00%|                return_token_type_ids=return_token_type_ids,
  2300|         0|            0|            0|  0.00%|                return_attention_mask=return_attention_mask,
  2301|         0|            0|            0|  0.00%|                return_overflowing_tokens=return_overflowing_tokens,
  2302|         0|            0|            0|  0.00%|                return_special_tokens_mask=return_special_tokens_mask,
  2303|         0|            0|            0|  0.00%|                return_offsets_mapping=return_offsets_mapping,
  2304|         0|            0|            0|  0.00%|                return_length=return_length,
  2305|         0|            0|            0|  0.00%|                verbose=verbose,
  2306|         0|            0|            0|  0.00%|                **kwargs,
  2307|         0|            0|            0|  0.00%|            )
  2308|         0|            0|            0|  0.00%|        else:
  2309|         0|            0|            0|  0.00%|            return self.encode_plus(
  2310|         0|            0|            0|  0.00%|                text=text,
  2311|         0|            0|            0|  0.00%|                text_pair=text_pair,
  2312|         0|            0|            0|  0.00%|                add_special_tokens=add_special_tokens,
  2313|         0|            0|            0|  0.00%|                padding=padding,
  2314|         0|            0|            0|  0.00%|                truncation=truncation,
  2315|         0|            0|            0|  0.00%|                max_length=max_length,
  2316|         0|            0|            0|  0.00%|                stride=stride,
  2317|         0|            0|            0|  0.00%|                is_split_into_words=is_split_into_words,
  2318|         0|            0|            0|  0.00%|                pad_to_multiple_of=pad_to_multiple_of,
  2319|         0|            0|            0|  0.00%|                return_tensors=return_tensors,
  2320|         0|            0|            0|  0.00%|                return_token_type_ids=return_token_type_ids,
  2321|         0|            0|            0|  0.00%|                return_attention_mask=return_attention_mask,
  2322|         0|            0|            0|  0.00%|                return_overflowing_tokens=return_overflowing_tokens,
  2323|         0|            0|            0|  0.00%|                return_special_tokens_mask=return_special_tokens_mask,
  2324|         0|            0|            0|  0.00%|                return_offsets_mapping=return_offsets_mapping,
  2325|         0|            0|            0|  0.00%|                return_length=return_length,
  2326|         0|            0|            0|  0.00%|                verbose=verbose,
  2327|         0|            0|            0|  0.00%|                **kwargs,
  2328|         0|            0|            0|  0.00%|            )
  2329|         0|            0|            0|  0.00%|
  2330|         0|            0|            0|  0.00%|    @add_end_docstrings(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)
  2331|         0|            0|            0|  0.00%|    def encode_plus(
  2332|         0|            0|            0|  0.00%|        self,
  2333|         0|            0|            0|  0.00%|        text: Union[TextInput, PreTokenizedInput, EncodedInput],
  2334|         0|            0|            0|  0.00%|        text_pair: Optional[Union[TextInput, PreTokenizedInput, EncodedInput]] = None,
  2335|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2336|         0|            0|            0|  0.00%|        padding: Union[bool, str, PaddingStrategy] = False,
  2337|         0|            0|            0|  0.00%|        truncation: Union[bool, str, TruncationStrategy] = False,
  2338|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2339|         0|            0|            0|  0.00%|        stride: int = 0,
  2340|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
  2341|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2342|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2343|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
  2344|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2345|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
  2346|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
  2347|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
  2348|         0|            0|            0|  0.00%|        return_length: bool = False,
  2349|         0|            0|            0|  0.00%|        verbose: bool = True,
  2350|         0|            0|            0|  0.00%|        **kwargs
  2351|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2352|         0|            0|            0|  0.00%|        """
  2353|         0|            0|            0|  0.00%|        Tokenize and prepare for the model a sequence or a pair of sequences.
  2354|         0|            0|            0|  0.00%|
  2355|         0|            0|            0|  0.00%|        .. warning::
  2356|         0|            0|            0|  0.00%|            This method is deprecated, ``__call__`` should be used instead.
  2357|         0|            0|            0|  0.00%|
  2358|         0|            0|            0|  0.00%|        Args:
  2359|         0|            0|            0|  0.00%|            text (:obj:`str`, :obj:`List[str]` or :obj:`List[int]` (the latter only for not-fast tokenizers)):
  2360|         0|            0|            0|  0.00%|                The first sequence to be encoded. This can be a string, a list of strings (tokenized string using the
  2361|         0|            0|            0|  0.00%|                ``tokenize`` method) or a list of integers (tokenized string ids using the ``convert_tokens_to_ids``
  2362|         0|            0|            0|  0.00%|                method).
  2363|         0|            0|            0|  0.00%|            text_pair (:obj:`str`, :obj:`List[str]` or :obj:`List[int]`, `optional`):
  2364|         0|            0|            0|  0.00%|                Optional second sequence to be encoded. This can be a string, a list of strings (tokenized string using
  2365|         0|            0|            0|  0.00%|                the ``tokenize`` method) or a list of integers (tokenized string ids using the
  2366|         0|            0|            0|  0.00%|                ``convert_tokens_to_ids`` method).
  2367|         0|            0|            0|  0.00%|        """
  2368|         0|            0|            0|  0.00%|
  2369|         0|            0|            0|  0.00%|        # Backward compatibility for 'truncation_strategy', 'pad_to_max_length'
  2370|         0|            0|            0|  0.00%|        padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
  2371|         0|            0|            0|  0.00%|            padding=padding,
  2372|         0|            0|            0|  0.00%|            truncation=truncation,
  2373|         0|            0|            0|  0.00%|            max_length=max_length,
  2374|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
  2375|         0|            0|            0|  0.00%|            verbose=verbose,
  2376|         0|            0|            0|  0.00%|            **kwargs,
  2377|         0|            0|            0|  0.00%|        )
  2378|         0|            0|            0|  0.00%|
  2379|         0|            0|            0|  0.00%|        return self._encode_plus(
  2380|         0|            0|            0|  0.00%|            text=text,
  2381|         0|            0|            0|  0.00%|            text_pair=text_pair,
  2382|         0|            0|            0|  0.00%|            add_special_tokens=add_special_tokens,
  2383|         0|            0|            0|  0.00%|            padding_strategy=padding_strategy,
  2384|         0|            0|            0|  0.00%|            truncation_strategy=truncation_strategy,
  2385|         0|            0|            0|  0.00%|            max_length=max_length,
  2386|         0|            0|            0|  0.00%|            stride=stride,
  2387|         0|            0|            0|  0.00%|            is_split_into_words=is_split_into_words,
  2388|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
  2389|         0|            0|            0|  0.00%|            return_tensors=return_tensors,
  2390|         0|            0|            0|  0.00%|            return_token_type_ids=return_token_type_ids,
  2391|         0|            0|            0|  0.00%|            return_attention_mask=return_attention_mask,
  2392|         0|            0|            0|  0.00%|            return_overflowing_tokens=return_overflowing_tokens,
  2393|         0|            0|            0|  0.00%|            return_special_tokens_mask=return_special_tokens_mask,
  2394|         0|            0|            0|  0.00%|            return_offsets_mapping=return_offsets_mapping,
  2395|         0|            0|            0|  0.00%|            return_length=return_length,
  2396|         0|            0|            0|  0.00%|            verbose=verbose,
  2397|         0|            0|            0|  0.00%|            **kwargs,
  2398|         0|            0|            0|  0.00%|        )
  2399|         0|            0|            0|  0.00%|
  2400|         0|            0|            0|  0.00%|    def _encode_plus(
  2401|         0|            0|            0|  0.00%|        self,
  2402|         0|            0|            0|  0.00%|        text: Union[TextInput, PreTokenizedInput, EncodedInput],
  2403|         0|            0|            0|  0.00%|        text_pair: Optional[Union[TextInput, PreTokenizedInput, EncodedInput]] = None,
  2404|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2405|         0|            0|            0|  0.00%|        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
  2406|         0|            0|            0|  0.00%|        truncation_strategy: TruncationStrategy = TruncationStrategy.DO_NOT_TRUNCATE,
  2407|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2408|         0|            0|            0|  0.00%|        stride: int = 0,
  2409|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
  2410|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2411|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2412|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
  2413|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2414|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
  2415|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
  2416|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
  2417|         0|            0|            0|  0.00%|        return_length: bool = False,
  2418|         0|            0|            0|  0.00%|        verbose: bool = True,
  2419|         0|            0|            0|  0.00%|        **kwargs
  2420|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2421|         0|            0|            0|  0.00%|        raise NotImplementedError
  2422|         0|            0|            0|  0.00%|
  2423|         0|            0|            0|  0.00%|    @add_end_docstrings(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)
  2424|         0|            0|            0|  0.00%|    def batch_encode_plus(
  2425|         0|            0|            0|  0.00%|        self,
  2426|         0|            0|            0|  0.00%|        batch_text_or_text_pairs: Union[
  2427|         0|            0|            0|  0.00%|            List[TextInput],
  2428|         0|            0|            0|  0.00%|            List[TextInputPair],
  2429|         0|            0|            0|  0.00%|            List[PreTokenizedInput],
  2430|         0|            0|            0|  0.00%|            List[PreTokenizedInputPair],
  2431|         0|            0|            0|  0.00%|            List[EncodedInput],
  2432|         0|            0|            0|  0.00%|            List[EncodedInputPair],
  2433|         0|            0|            0|  0.00%|        ],
  2434|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2435|         0|            0|            0|  0.00%|        padding: Union[bool, str, PaddingStrategy] = False,
  2436|         0|            0|            0|  0.00%|        truncation: Union[bool, str, TruncationStrategy] = False,
  2437|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2438|         0|            0|            0|  0.00%|        stride: int = 0,
  2439|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
  2440|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2441|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2442|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
  2443|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2444|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
  2445|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
  2446|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
  2447|         0|            0|            0|  0.00%|        return_length: bool = False,
  2448|         0|            0|            0|  0.00%|        verbose: bool = True,
  2449|         0|            0|            0|  0.00%|        **kwargs
  2450|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2451|         0|            0|            0|  0.00%|        """
  2452|         0|            0|            0|  0.00%|        Tokenize and prepare for the model a list of sequences or a list of pairs of sequences.
  2453|         0|            0|            0|  0.00%|
  2454|         0|            0|            0|  0.00%|        .. warning::
  2455|         0|            0|            0|  0.00%|            This method is deprecated, ``__call__`` should be used instead.
  2456|         0|            0|            0|  0.00%|
  2457|         0|            0|            0|  0.00%|        Args:
  2458|         0|            0|            0|  0.00%|            batch_text_or_text_pairs (:obj:`List[str]`, :obj:`List[Tuple[str, str]]`, :obj:`List[List[str]]`, :obj:`List[Tuple[List[str], List[str]]]`, and for not-fast tokenizers, also :obj:`List[List[int]]`, :obj:`List[Tuple[List[int], List[int]]]`):
  2459|         0|            0|            0|  0.00%|                Batch of sequences or pair of sequences to be encoded. This can be a list of
  2460|         0|            0|            0|  0.00%|                string/string-sequences/int-sequences or a list of pair of string/string-sequences/int-sequence (see
  2461|         0|            0|            0|  0.00%|                details in ``encode_plus``).
  2462|         0|            0|            0|  0.00%|        """
  2463|         0|            0|            0|  0.00%|
  2464|         0|            0|            0|  0.00%|        # Backward compatibility for 'truncation_strategy', 'pad_to_max_length'
  2465|         0|            0|            0|  0.00%|        padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
  2466|         0|            0|            0|  0.00%|            padding=padding,
  2467|         0|            0|            0|  0.00%|            truncation=truncation,
  2468|         0|            0|            0|  0.00%|            max_length=max_length,
  2469|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
  2470|         0|            0|            0|  0.00%|            verbose=verbose,
  2471|         0|            0|            0|  0.00%|            **kwargs,
  2472|         0|            0|            0|  0.00%|        )
  2473|         0|            0|            0|  0.00%|
  2474|         0|            0|            0|  0.00%|        return self._batch_encode_plus(
  2475|         0|            0|            0|  0.00%|            batch_text_or_text_pairs=batch_text_or_text_pairs,
  2476|         0|            0|            0|  0.00%|            add_special_tokens=add_special_tokens,
  2477|         0|            0|            0|  0.00%|            padding_strategy=padding_strategy,
  2478|         0|            0|            0|  0.00%|            truncation_strategy=truncation_strategy,
  2479|         0|            0|            0|  0.00%|            max_length=max_length,
  2480|         0|            0|            0|  0.00%|            stride=stride,
  2481|         0|            0|            0|  0.00%|            is_split_into_words=is_split_into_words,
  2482|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
  2483|         0|            0|            0|  0.00%|            return_tensors=return_tensors,
  2484|         0|            0|            0|  0.00%|            return_token_type_ids=return_token_type_ids,
  2485|         0|            0|            0|  0.00%|            return_attention_mask=return_attention_mask,
  2486|         0|            0|            0|  0.00%|            return_overflowing_tokens=return_overflowing_tokens,
  2487|         0|            0|            0|  0.00%|            return_special_tokens_mask=return_special_tokens_mask,
  2488|         0|            0|            0|  0.00%|            return_offsets_mapping=return_offsets_mapping,
  2489|         0|            0|            0|  0.00%|            return_length=return_length,
  2490|         0|            0|            0|  0.00%|            verbose=verbose,
  2491|         0|            0|            0|  0.00%|            **kwargs,
  2492|         0|            0|            0|  0.00%|        )
  2493|         0|            0|            0|  0.00%|
  2494|         0|            0|            0|  0.00%|    def _batch_encode_plus(
  2495|         0|            0|            0|  0.00%|        self,
  2496|         0|            0|            0|  0.00%|        batch_text_or_text_pairs: Union[
  2497|         0|            0|            0|  0.00%|            List[TextInput],
  2498|         0|            0|            0|  0.00%|            List[TextInputPair],
  2499|         0|            0|            0|  0.00%|            List[PreTokenizedInput],
  2500|         0|            0|            0|  0.00%|            List[PreTokenizedInputPair],
  2501|         0|            0|            0|  0.00%|            List[EncodedInput],
  2502|         0|            0|            0|  0.00%|            List[EncodedInputPair],
  2503|         0|            0|            0|  0.00%|        ],
  2504|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2505|         0|            0|            0|  0.00%|        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
  2506|         0|            0|            0|  0.00%|        truncation_strategy: TruncationStrategy = TruncationStrategy.DO_NOT_TRUNCATE,
  2507|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2508|         0|            0|            0|  0.00%|        stride: int = 0,
  2509|         0|            0|            0|  0.00%|        is_split_into_words: bool = False,
  2510|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2511|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2512|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
  2513|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2514|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
  2515|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
  2516|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
  2517|         0|            0|            0|  0.00%|        return_length: bool = False,
  2518|         0|            0|            0|  0.00%|        verbose: bool = True,
  2519|         0|            0|            0|  0.00%|        **kwargs
  2520|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2521|         0|            0|            0|  0.00%|        raise NotImplementedError
  2522|         0|            0|            0|  0.00%|
  2523|         0|            0|            0|  0.00%|    def pad(
  2524|         0|            0|            0|  0.00%|        self,
  2525|         0|            0|            0|  0.00%|        encoded_inputs: Union[
  2526|         0|            0|            0|  0.00%|            BatchEncoding,
  2527|         0|            0|            0|  0.00%|            List[BatchEncoding],
  2528|         0|            0|            0|  0.00%|            Dict[str, EncodedInput],
  2529|         0|            0|            0|  0.00%|            Dict[str, List[EncodedInput]],
  2530|         0|            0|            0|  0.00%|            List[Dict[str, EncodedInput]],
  2531|         0|            0|            0|  0.00%|        ],
  2532|         0|            0|            0|  0.00%|        padding: Union[bool, str, PaddingStrategy] = True,
  2533|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2534|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2535|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2536|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2537|         0|            0|            0|  0.00%|        verbose: bool = True,
  2538|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2539|         0|            0|            0|  0.00%|        """
  2540|         0|            0|            0|  0.00%|        Pad a single encoded input or a batch of encoded inputs up to predefined length or to the max sequence length
  2541|         0|            0|            0|  0.00%|        in the batch.
  2542|         0|            0|            0|  0.00%|
  2543|         0|            0|            0|  0.00%|        Padding side (left/right) padding token ids are defined at the tokenizer level (with ``self.padding_side``,
  2544|         0|            0|            0|  0.00%|        ``self.pad_token_id`` and ``self.pad_token_type_id``)
  2545|         0|            0|            0|  0.00%|
  2546|         0|            0|            0|  0.00%|        .. note::
  2547|         0|            0|            0|  0.00%|
  2548|         0|            0|            0|  0.00%|            If the ``encoded_inputs`` passed are dictionary of numpy arrays, PyTorch tensors or TensorFlow tensors, the
  2549|         0|            0|            0|  0.00%|            result will use the same type unless you provide a different tensor type with ``return_tensors``. In the
  2550|         0|            0|            0|  0.00%|            case of PyTorch tensors, you will lose the specific device of your tensors however.
  2551|         0|            0|            0|  0.00%|
  2552|         0|            0|            0|  0.00%|        Args:
  2553|         0|            0|            0|  0.00%|            encoded_inputs (:class:`~transformers.BatchEncoding`, list of :class:`~transformers.BatchEncoding`, :obj:`Dict[str, List[int]]`, :obj:`Dict[str, List[List[int]]` or :obj:`List[Dict[str, List[int]]]`):
  2554|         0|            0|            0|  0.00%|                Tokenized inputs. Can represent one input (:class:`~transformers.BatchEncoding` or :obj:`Dict[str,
  2555|         0|            0|            0|  0.00%|                List[int]]`) or a batch of tokenized inputs (list of :class:`~transformers.BatchEncoding`, `Dict[str,
  2556|         0|            0|            0|  0.00%|                List[List[int]]]` or `List[Dict[str, List[int]]]`) so you can use this method during preprocessing as
  2557|         0|            0|            0|  0.00%|                well as in a PyTorch Dataloader collate function.
  2558|         0|            0|            0|  0.00%|
  2559|         0|            0|            0|  0.00%|                Instead of :obj:`List[int]` you can have tensors (numpy arrays, PyTorch tensors or TensorFlow tensors),
  2560|         0|            0|            0|  0.00%|                see the note above for the return type.
  2561|         0|            0|            0|  0.00%|            padding (:obj:`bool`, :obj:`str` or :class:`~transformers.file_utils.PaddingStrategy`, `optional`, defaults to :obj:`True`):
  2562|         0|            0|            0|  0.00%|                 Select a strategy to pad the returned sequences (according to the model's padding side and padding
  2563|         0|            0|            0|  0.00%|                 index) among:
  2564|         0|            0|            0|  0.00%|
  2565|         0|            0|            0|  0.00%|                * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a
  2566|         0|            0|            0|  0.00%|                  single sequence if provided).
  2567|         0|            0|            0|  0.00%|                * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the
  2568|         0|            0|            0|  0.00%|                  maximum acceptable input length for the model if that argument is not provided.
  2569|         0|            0|            0|  0.00%|                * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of
  2570|         0|            0|            0|  0.00%|                  different lengths).
  2571|         0|            0|            0|  0.00%|            max_length (:obj:`int`, `optional`):
  2572|         0|            0|            0|  0.00%|                Maximum length of the returned list and optionally padding length (see above).
  2573|         0|            0|            0|  0.00%|            pad_to_multiple_of (:obj:`int`, `optional`):
  2574|         0|            0|            0|  0.00%|                If set will pad the sequence to a multiple of the provided value.
  2575|         0|            0|            0|  0.00%|
  2576|         0|            0|            0|  0.00%|                This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability
  2577|         0|            0|            0|  0.00%|                >= 7.5 (Volta).
  2578|         0|            0|            0|  0.00%|            return_attention_mask (:obj:`bool`, `optional`):
  2579|         0|            0|            0|  0.00%|                Whether to return the attention mask. If left to the default, will return the attention mask according
  2580|         0|            0|            0|  0.00%|                to the specific tokenizer's default, defined by the :obj:`return_outputs` attribute.
  2581|         0|            0|            0|  0.00%|
  2582|         0|            0|            0|  0.00%|                `What are attention masks? <../glossary.html#attention-mask>`__
  2583|         0|            0|            0|  0.00%|            return_tensors (:obj:`str` or :class:`~transformers.file_utils.TensorType`, `optional`):
  2584|         0|            0|            0|  0.00%|                If set, will return tensors instead of list of python integers. Acceptable values are:
  2585|         0|            0|            0|  0.00%|
  2586|         0|            0|            0|  0.00%|                * :obj:`'tf'`: Return TensorFlow :obj:`tf.constant` objects.
  2587|         0|            0|            0|  0.00%|                * :obj:`'pt'`: Return PyTorch :obj:`torch.Tensor` objects.
  2588|         0|            0|            0|  0.00%|                * :obj:`'np'`: Return Numpy :obj:`np.ndarray` objects.
  2589|         0|            0|            0|  0.00%|            verbose (:obj:`bool`, `optional`, defaults to :obj:`True`):
  2590|         0|            0|            0|  0.00%|                Whether or not to print more information and warnings.
  2591|         0|            0|            0|  0.00%|        """
  2592|         0|            0|            0|  0.00%|        # If we have a list of dicts, let's convert it in a dict of lists
  2593|         0|            0|            0|  0.00%|        # We do this to allow using this method as a collate_fn function in PyTorch Dataloader
  2594|         0|            0|            0|  0.00%|        if isinstance(encoded_inputs, (list, tuple)) and isinstance(encoded_inputs[0], (dict, BatchEncoding)):
  2595|         0|            0|            0|  0.00%|            encoded_inputs = {key: [example[key] for example in encoded_inputs] for key in encoded_inputs[0].keys()}
  2596|         0|            0|            0|  0.00%|
  2597|         0|            0|            0|  0.00%|        # The model's main input name, usually `input_ids`, has be passed for padding
  2598|         0|            0|            0|  0.00%|        if self.model_input_names[0] not in encoded_inputs:
  2599|         0|            0|            0|  0.00%|            raise ValueError(
  2600|         0|            0|            0|  0.00%|                "You should supply an encoding or a list of encodings to this method "
  2601|         0|            0|            0|  0.00%|                f"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}"
  2602|         0|            0|            0|  0.00%|            )
  2603|         0|            0|            0|  0.00%|
  2604|         0|            0|            0|  0.00%|        required_input = encoded_inputs[self.model_input_names[0]]
  2605|         0|            0|            0|  0.00%|
  2606|         0|            0|            0|  0.00%|        if not required_input:
  2607|         0|            0|            0|  0.00%|            if return_attention_mask:
  2608|         0|            0|            0|  0.00%|                encoded_inputs["attention_mask"] = []
  2609|         0|            0|            0|  0.00%|            return encoded_inputs
  2610|         0|            0|            0|  0.00%|
  2611|         0|            0|            0|  0.00%|        # If we have PyTorch/TF/NumPy tensors/arrays as inputs, we cast them as python objects
  2612|         0|            0|            0|  0.00%|        # and rebuild them afterwards if no return_tensors is specified
  2613|         0|            0|            0|  0.00%|        # Note that we lose the specific device the tensor may be on for PyTorch
  2614|         0|            0|            0|  0.00%|
  2615|         0|            0|            0|  0.00%|        first_element = required_input[0]
  2616|         0|            0|            0|  0.00%|        if isinstance(first_element, (list, tuple)):
  2617|         0|            0|            0|  0.00%|            # first_element might be an empty list/tuple in some edge cases so we grab the first non empty element.
  2618|         0|            0|            0|  0.00%|            index = 0
  2619|         0|            0|            0|  0.00%|            while len(required_input[index]) == 0:
  2620|         0|            0|            0|  0.00%|                index += 1
  2621|         0|            0|            0|  0.00%|            if index < len(required_input):
  2622|         0|            0|            0|  0.00%|                first_element = required_input[index][0]
  2623|         0|            0|            0|  0.00%|        # At this state, if `first_element` is still a list/tuple, it's an empty one so there is nothing to do.
  2624|         0|            0|            0|  0.00%|        if not isinstance(first_element, (int, list, tuple)):
  2625|         0|            0|            0|  0.00%|            if is_tf_available() and _is_tensorflow(first_element):
  2626|         0|            0|            0|  0.00%|                return_tensors = "tf" if return_tensors is None else return_tensors
  2627|         0|            0|            0|  0.00%|            elif is_torch_available() and _is_torch(first_element):
  2628|         0|            0|            0|  0.00%|                return_tensors = "pt" if return_tensors is None else return_tensors
  2629|         0|            0|            0|  0.00%|            elif isinstance(first_element, np.ndarray):
  2630|         0|            0|            0|  0.00%|                return_tensors = "np" if return_tensors is None else return_tensors
  2631|         0|            0|            0|  0.00%|            else:
  2632|         0|            0|            0|  0.00%|                raise ValueError(
  2633|         0|            0|            0|  0.00%|                    f"type of {first_element} unknown: {type(first_element)}. "
  2634|         0|            0|            0|  0.00%|                    f"Should be one of a python, numpy, pytorch or tensorflow object."
  2635|         0|            0|            0|  0.00%|                )
  2636|         0|            0|            0|  0.00%|
  2637|         0|            0|            0|  0.00%|            for key, value in encoded_inputs.items():
  2638|         0|            0|            0|  0.00%|                encoded_inputs[key] = to_py_obj(value)
  2639|         0|            0|            0|  0.00%|
  2640|         0|            0|            0|  0.00%|        # Convert padding_strategy in PaddingStrategy
  2641|         0|            0|            0|  0.00%|        padding_strategy, _, max_length, _ = self._get_padding_truncation_strategies(
  2642|         0|            0|            0|  0.00%|            padding=padding, max_length=max_length, verbose=verbose
  2643|         0|            0|            0|  0.00%|        )
  2644|         0|            0|            0|  0.00%|
  2645|         0|            0|            0|  0.00%|        required_input = encoded_inputs[self.model_input_names[0]]
  2646|         0|            0|            0|  0.00%|        if required_input and not isinstance(required_input[0], (list, tuple)):
  2647|         0|            0|            0|  0.00%|            encoded_inputs = self._pad(
  2648|         0|            0|            0|  0.00%|                encoded_inputs,
  2649|         0|            0|            0|  0.00%|                max_length=max_length,
  2650|         0|            0|            0|  0.00%|                padding_strategy=padding_strategy,
  2651|         0|            0|            0|  0.00%|                pad_to_multiple_of=pad_to_multiple_of,
  2652|         0|            0|            0|  0.00%|                return_attention_mask=return_attention_mask,
  2653|         0|            0|            0|  0.00%|            )
  2654|         0|            0|            0|  0.00%|            return BatchEncoding(encoded_inputs, tensor_type=return_tensors)
  2655|         0|            0|            0|  0.00%|
  2656|         0|            0|            0|  0.00%|        batch_size = len(required_input)
  2657|         0|            0|            0|  0.00%|        assert all(
  2658|         0|            0|            0|  0.00%|            len(v) == batch_size for v in encoded_inputs.values()
  2659|         0|            0|            0|  0.00%|        ), "Some items in the output dictionary have a different batch size than others."
  2660|         0|            0|            0|  0.00%|
  2661|         0|            0|            0|  0.00%|        if padding_strategy == PaddingStrategy.LONGEST:
  2662|         0|            0|            0|  0.00%|            max_length = max(len(inputs) for inputs in required_input)
  2663|         0|            0|            0|  0.00%|            padding_strategy = PaddingStrategy.MAX_LENGTH
  2664|         0|            0|            0|  0.00%|
  2665|         0|            0|            0|  0.00%|        batch_outputs = {}
  2666|         0|            0|            0|  0.00%|        for i in range(batch_size):
  2667|         0|            0|            0|  0.00%|            inputs = dict((k, v[i]) for k, v in encoded_inputs.items())
  2668|         0|            0|            0|  0.00%|            outputs = self._pad(
  2669|         0|            0|            0|  0.00%|                inputs,
  2670|         0|            0|            0|  0.00%|                max_length=max_length,
  2671|         0|            0|            0|  0.00%|                padding_strategy=padding_strategy,
  2672|         0|            0|            0|  0.00%|                pad_to_multiple_of=pad_to_multiple_of,
  2673|         0|            0|            0|  0.00%|                return_attention_mask=return_attention_mask,
  2674|         0|            0|            0|  0.00%|            )
  2675|         0|            0|            0|  0.00%|
  2676|         0|            0|            0|  0.00%|            for key, value in outputs.items():
  2677|         0|            0|            0|  0.00%|                if key not in batch_outputs:
  2678|         0|            0|            0|  0.00%|                    batch_outputs[key] = []
  2679|         0|            0|            0|  0.00%|                batch_outputs[key].append(value)
  2680|         0|            0|            0|  0.00%|
  2681|         0|            0|            0|  0.00%|        return BatchEncoding(batch_outputs, tensor_type=return_tensors)
  2682|         0|            0|            0|  0.00%|
  2683|         0|            0|            0|  0.00%|    def create_token_type_ids_from_sequences(
  2684|         0|            0|            0|  0.00%|        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None
  2685|         0|            0|            0|  0.00%|    ) -> List[int]:
  2686|         0|            0|            0|  0.00%|        """
  2687|         0|            0|            0|  0.00%|        Create the token type IDs corresponding to the sequences passed. `What are token type IDs?
  2688|         0|            0|            0|  0.00%|        <../glossary.html#token-type-ids>`__
  2689|         0|            0|            0|  0.00%|
  2690|         0|            0|            0|  0.00%|        Should be overridden in a subclass if the model has a special way of building those.
  2691|         0|            0|            0|  0.00%|
  2692|         0|            0|            0|  0.00%|        Args:
  2693|         0|            0|            0|  0.00%|            token_ids_0 (:obj:`List[int]`): The first tokenized sequence.
  2694|         0|            0|            0|  0.00%|            token_ids_1 (:obj:`List[int]`, `optional`): The second tokenized sequence.
  2695|         0|            0|            0|  0.00%|
  2696|         0|            0|            0|  0.00%|        Returns:
  2697|         0|            0|            0|  0.00%|            :obj:`List[int]`: The token type ids.
  2698|         0|            0|            0|  0.00%|        """
  2699|         0|            0|            0|  0.00%|        if token_ids_1 is None:
  2700|         0|            0|            0|  0.00%|            return len(token_ids_0) * [0]
  2701|         0|            0|            0|  0.00%|        return [0] * len(token_ids_0) + [1] * len(token_ids_1)
  2702|         0|            0|            0|  0.00%|
  2703|         0|            0|            0|  0.00%|    def build_inputs_with_special_tokens(
  2704|         0|            0|            0|  0.00%|        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None
  2705|         0|            0|            0|  0.00%|    ) -> List[int]:
  2706|         0|            0|            0|  0.00%|        """
  2707|         0|            0|            0|  0.00%|        Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
  2708|         0|            0|            0|  0.00%|        adding special tokens.
  2709|         0|            0|            0|  0.00%|
  2710|         0|            0|            0|  0.00%|        This implementation does not add special tokens and this method should be overridden in a subclass.
  2711|         0|            0|            0|  0.00%|
  2712|         0|            0|            0|  0.00%|        Args:
  2713|         0|            0|            0|  0.00%|            token_ids_0 (:obj:`List[int]`): The first tokenized sequence.
  2714|         0|            0|            0|  0.00%|            token_ids_1 (:obj:`List[int]`, `optional`): The second tokenized sequence.
  2715|         0|            0|            0|  0.00%|
  2716|         0|            0|            0|  0.00%|        Returns:
  2717|         0|            0|            0|  0.00%|            :obj:`List[int]`: The model input with special tokens.
  2718|         0|            0|            0|  0.00%|        """
  2719|         0|            0|            0|  0.00%|        if token_ids_1 is None:
  2720|         0|            0|            0|  0.00%|            return token_ids_0
  2721|         0|            0|            0|  0.00%|        return token_ids_0 + token_ids_1
  2722|         0|            0|            0|  0.00%|
  2723|         0|            0|            0|  0.00%|    @add_end_docstrings(ENCODE_KWARGS_DOCSTRING, ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)
  2724|         0|            0|            0|  0.00%|    def prepare_for_model(
  2725|         0|            0|            0|  0.00%|        self,
  2726|         0|            0|            0|  0.00%|        ids: List[int],
  2727|         0|            0|            0|  0.00%|        pair_ids: Optional[List[int]] = None,
  2728|         0|            0|            0|  0.00%|        add_special_tokens: bool = True,
  2729|         0|            0|            0|  0.00%|        padding: Union[bool, str, PaddingStrategy] = False,
  2730|         0|            0|            0|  0.00%|        truncation: Union[bool, str, TruncationStrategy] = False,
  2731|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2732|         0|            0|            0|  0.00%|        stride: int = 0,
  2733|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2734|         0|            0|            0|  0.00%|        return_tensors: Optional[Union[str, TensorType]] = None,
  2735|         0|            0|            0|  0.00%|        return_token_type_ids: Optional[bool] = None,
  2736|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2737|         0|            0|            0|  0.00%|        return_overflowing_tokens: bool = False,
  2738|         0|            0|            0|  0.00%|        return_special_tokens_mask: bool = False,
  2739|         0|            0|            0|  0.00%|        return_offsets_mapping: bool = False,
  2740|         0|            0|            0|  0.00%|        return_length: bool = False,
  2741|         0|            0|            0|  0.00%|        verbose: bool = True,
  2742|         0|            0|            0|  0.00%|        prepend_batch_axis: bool = False,
  2743|         0|            0|            0|  0.00%|        **kwargs
  2744|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  2745|         0|            0|            0|  0.00%|        """
  2746|         0|            0|            0|  0.00%|        Prepares a sequence of input id, or a pair of sequences of inputs ids so that it can be used by the model. It
  2747|         0|            0|            0|  0.00%|        adds special tokens, truncates sequences if overflowing while taking into account the special tokens and
  2748|         0|            0|            0|  0.00%|        manages a moving window (with user defined stride) for overflowing tokens
  2749|         0|            0|            0|  0.00%|
  2750|         0|            0|            0|  0.00%|        Args:
  2751|         0|            0|            0|  0.00%|            ids (:obj:`List[int]`):
  2752|         0|            0|            0|  0.00%|                Tokenized input ids of the first sequence. Can be obtained from a string by chaining the ``tokenize``
  2753|         0|            0|            0|  0.00%|                and ``convert_tokens_to_ids`` methods.
  2754|         0|            0|            0|  0.00%|            pair_ids (:obj:`List[int]`, `optional`):
  2755|         0|            0|            0|  0.00%|                Tokenized input ids of the second sequence. Can be obtained from a string by chaining the ``tokenize``
  2756|         0|            0|            0|  0.00%|                and ``convert_tokens_to_ids`` methods.
  2757|         0|            0|            0|  0.00%|        """
  2758|         0|            0|            0|  0.00%|
  2759|         0|            0|            0|  0.00%|        # Backward compatibility for 'truncation_strategy', 'pad_to_max_length'
  2760|         0|            0|            0|  0.00%|        padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(
  2761|         0|            0|            0|  0.00%|            padding=padding,
  2762|         0|            0|            0|  0.00%|            truncation=truncation,
  2763|         0|            0|            0|  0.00%|            max_length=max_length,
  2764|         0|            0|            0|  0.00%|            pad_to_multiple_of=pad_to_multiple_of,
  2765|         0|            0|            0|  0.00%|            verbose=verbose,
  2766|         0|            0|            0|  0.00%|            **kwargs,
  2767|         0|            0|            0|  0.00%|        )
  2768|         0|            0|            0|  0.00%|
  2769|         0|            0|            0|  0.00%|        pair = bool(pair_ids is not None)
  2770|         0|            0|            0|  0.00%|        len_ids = len(ids)
  2771|         0|            0|            0|  0.00%|        len_pair_ids = len(pair_ids) if pair else 0
  2772|         0|            0|            0|  0.00%|
  2773|         0|            0|            0|  0.00%|        if return_token_type_ids and not add_special_tokens:
  2774|         0|            0|            0|  0.00%|            raise ValueError(
  2775|         0|            0|            0|  0.00%|                "Asking to return token_type_ids while setting add_special_tokens to False "
  2776|         0|            0|            0|  0.00%|                "results in an undefined behavior. Please set add_special_tokens to True or "
  2777|         0|            0|            0|  0.00%|                "set return_token_type_ids to None."
  2778|         0|            0|            0|  0.00%|            )
  2779|         0|            0|            0|  0.00%|
  2780|         0|            0|            0|  0.00%|        # Load from model defaults
  2781|         0|            0|            0|  0.00%|        if return_token_type_ids is None:
  2782|         0|            0|            0|  0.00%|            return_token_type_ids = "token_type_ids" in self.model_input_names
  2783|         0|            0|            0|  0.00%|        if return_attention_mask is None:
  2784|         0|            0|            0|  0.00%|            return_attention_mask = "attention_mask" in self.model_input_names
  2785|         0|            0|            0|  0.00%|
  2786|         0|            0|            0|  0.00%|        encoded_inputs = {}
  2787|         0|            0|            0|  0.00%|
  2788|         0|            0|            0|  0.00%|        # Compute the total size of the returned encodings
  2789|         0|            0|            0|  0.00%|        total_len = len_ids + len_pair_ids + (self.num_special_tokens_to_add(pair=pair) if add_special_tokens else 0)
  2790|         0|            0|            0|  0.00%|
  2791|         0|            0|            0|  0.00%|        # Truncation: Handle max sequence length
  2792|         0|            0|            0|  0.00%|        overflowing_tokens = []
  2793|         0|            0|            0|  0.00%|        if truncation_strategy != TruncationStrategy.DO_NOT_TRUNCATE and max_length and total_len > max_length:
  2794|         0|            0|            0|  0.00%|            ids, pair_ids, overflowing_tokens = self.truncate_sequences(
  2795|         0|            0|            0|  0.00%|                ids,
  2796|         0|            0|            0|  0.00%|                pair_ids=pair_ids,
  2797|         0|            0|            0|  0.00%|                num_tokens_to_remove=total_len - max_length,
  2798|         0|            0|            0|  0.00%|                truncation_strategy=truncation_strategy,
  2799|         0|            0|            0|  0.00%|                stride=stride,
  2800|         0|            0|            0|  0.00%|            )
  2801|         0|            0|            0|  0.00%|
  2802|         0|            0|            0|  0.00%|        if return_overflowing_tokens:
  2803|         0|            0|            0|  0.00%|            encoded_inputs["overflowing_tokens"] = overflowing_tokens
  2804|         0|            0|            0|  0.00%|            encoded_inputs["num_truncated_tokens"] = total_len - max_length
  2805|         0|            0|            0|  0.00%|
  2806|         0|            0|            0|  0.00%|        # Add special tokens
  2807|         0|            0|            0|  0.00%|        if add_special_tokens:
  2808|         0|            0|            0|  0.00%|            sequence = self.build_inputs_with_special_tokens(ids, pair_ids)
  2809|         0|            0|            0|  0.00%|            token_type_ids = self.create_token_type_ids_from_sequences(ids, pair_ids)
  2810|         0|            0|            0|  0.00%|        else:
  2811|         0|            0|            0|  0.00%|            sequence = ids + pair_ids if pair else ids
  2812|         0|            0|            0|  0.00%|            token_type_ids = [0] * len(ids) + ([0] * len(pair_ids) if pair else [])
  2813|         0|            0|            0|  0.00%|
  2814|         0|            0|            0|  0.00%|        # Build output dictionary
  2815|         0|            0|            0|  0.00%|        encoded_inputs["input_ids"] = sequence
  2816|         0|            0|            0|  0.00%|        if return_token_type_ids:
  2817|         0|            0|            0|  0.00%|            encoded_inputs["token_type_ids"] = token_type_ids
  2818|         0|            0|            0|  0.00%|        if return_special_tokens_mask:
  2819|         0|            0|            0|  0.00%|            if add_special_tokens:
  2820|         0|            0|            0|  0.00%|                encoded_inputs["special_tokens_mask"] = self.get_special_tokens_mask(ids, pair_ids)
  2821|         0|            0|            0|  0.00%|            else:
  2822|         0|            0|            0|  0.00%|                encoded_inputs["special_tokens_mask"] = [0] * len(sequence)
  2823|         0|            0|            0|  0.00%|
  2824|         0|            0|            0|  0.00%|        # Check lengths
  2825|         0|            0|            0|  0.00%|        self._eventual_warn_about_too_long_sequence(encoded_inputs["input_ids"], max_length, verbose)
  2826|         0|            0|            0|  0.00%|
  2827|         0|            0|            0|  0.00%|        # Padding
  2828|         0|            0|            0|  0.00%|        if padding_strategy != PaddingStrategy.DO_NOT_PAD or return_attention_mask:
  2829|         0|            0|            0|  0.00%|            encoded_inputs = self.pad(
  2830|         0|            0|            0|  0.00%|                encoded_inputs,
  2831|         0|            0|            0|  0.00%|                max_length=max_length,
  2832|         0|            0|            0|  0.00%|                padding=padding_strategy.value,
  2833|         0|            0|            0|  0.00%|                pad_to_multiple_of=pad_to_multiple_of,
  2834|         0|            0|            0|  0.00%|                return_attention_mask=return_attention_mask,
  2835|         0|            0|            0|  0.00%|            )
  2836|         0|            0|            0|  0.00%|
  2837|         0|            0|            0|  0.00%|        if return_length:
  2838|         0|            0|            0|  0.00%|            encoded_inputs["length"] = len(encoded_inputs["input_ids"])
  2839|         0|            0|            0|  0.00%|
  2840|         0|            0|            0|  0.00%|        batch_outputs = BatchEncoding(
  2841|         0|            0|            0|  0.00%|            encoded_inputs, tensor_type=return_tensors, prepend_batch_axis=prepend_batch_axis
  2842|         0|            0|            0|  0.00%|        )
  2843|         0|            0|            0|  0.00%|
  2844|         0|            0|            0|  0.00%|        return batch_outputs
  2845|         0|            0|            0|  0.00%|
  2846|         0|            0|            0|  0.00%|    def truncate_sequences(
  2847|         0|            0|            0|  0.00%|        self,
  2848|         0|            0|            0|  0.00%|        ids: List[int],
  2849|         0|            0|            0|  0.00%|        pair_ids: Optional[List[int]] = None,
  2850|         0|            0|            0|  0.00%|        num_tokens_to_remove: int = 0,
  2851|         0|            0|            0|  0.00%|        truncation_strategy: Union[str, TruncationStrategy] = "longest_first",
  2852|         0|            0|            0|  0.00%|        stride: int = 0,
  2853|         0|            0|            0|  0.00%|    ) -> Tuple[List[int], List[int], List[int]]:
  2854|         0|            0|            0|  0.00%|        """
  2855|         0|            0|            0|  0.00%|        Truncates a sequence pair in-place following the strategy.
  2856|         0|            0|            0|  0.00%|
  2857|         0|            0|            0|  0.00%|        Args:
  2858|         0|            0|            0|  0.00%|            ids (:obj:`List[int]`):
  2859|         0|            0|            0|  0.00%|                Tokenized input ids of the first sequence. Can be obtained from a string by chaining the ``tokenize``
  2860|         0|            0|            0|  0.00%|                and ``convert_tokens_to_ids`` methods.
  2861|         0|            0|            0|  0.00%|            pair_ids (:obj:`List[int]`, `optional`):
  2862|         0|            0|            0|  0.00%|                Tokenized input ids of the second sequence. Can be obtained from a string by chaining the ``tokenize``
  2863|         0|            0|            0|  0.00%|                and ``convert_tokens_to_ids`` methods.
  2864|         0|            0|            0|  0.00%|            num_tokens_to_remove (:obj:`int`, `optional`, defaults to 0):
  2865|         0|            0|            0|  0.00%|                Number of tokens to remove using the truncation strategy.
  2866|         0|            0|            0|  0.00%|            truncation_strategy (:obj:`str` or :class:`~transformers.tokenization_utils_base.TruncationStrategy`, `optional`, defaults to :obj:`False`):
  2867|         0|            0|            0|  0.00%|                The strategy to follow for truncation. Can be:
  2868|         0|            0|            0|  0.00%|
  2869|         0|            0|            0|  0.00%|                * :obj:`'longest_first'`: Truncate to a maximum length specified with the argument :obj:`max_length` or
  2870|         0|            0|            0|  0.00%|                  to the maximum acceptable input length for the model if that argument is not provided. This will
  2871|         0|            0|            0|  0.00%|                  truncate token by token, removing a token from the longest sequence in the pair if a pair of
  2872|         0|            0|            0|  0.00%|                  sequences (or a batch of pairs) is provided.
  2873|         0|            0|            0|  0.00%|                * :obj:`'only_first'`: Truncate to a maximum length specified with the argument :obj:`max_length` or to
  2874|         0|            0|            0|  0.00%|                  the maximum acceptable input length for the model if that argument is not provided. This will only
  2875|         0|            0|            0|  0.00%|                  truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.
  2876|         0|            0|            0|  0.00%|                * :obj:`'only_second'`: Truncate to a maximum length specified with the argument :obj:`max_length` or
  2877|         0|            0|            0|  0.00%|                  to the maximum acceptable input length for the model if that argument is not provided. This will only
  2878|         0|            0|            0|  0.00%|                  truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.
  2879|         0|            0|            0|  0.00%|                * :obj:`'do_not_truncate'` (default): No truncation (i.e., can output batch with sequence lengths
  2880|         0|            0|            0|  0.00%|                  greater than the model maximum admissible input size).
  2881|         0|            0|            0|  0.00%|            stride (:obj:`int`, `optional`, defaults to 0):
  2882|         0|            0|            0|  0.00%|                If set to a positive number, the overflowing tokens returned will contain some tokens from the main
  2883|         0|            0|            0|  0.00%|                sequence returned. The value of this argument defines the number of additional tokens.
  2884|         0|            0|            0|  0.00%|
  2885|         0|            0|            0|  0.00%|        Returns:
  2886|         0|            0|            0|  0.00%|            :obj:`Tuple[List[int], List[int], List[int]]`: The truncated ``ids``, the truncated ``pair_ids`` and the
  2887|         0|            0|            0|  0.00%|            list of overflowing tokens.
  2888|         0|            0|            0|  0.00%|        """
  2889|         0|            0|            0|  0.00%|        if num_tokens_to_remove <= 0:
  2890|         0|            0|            0|  0.00%|            return ids, pair_ids, []
  2891|         0|            0|            0|  0.00%|
  2892|         0|            0|            0|  0.00%|        if not isinstance(truncation_strategy, TruncationStrategy):
  2893|         0|            0|            0|  0.00%|            truncation_strategy = TruncationStrategy(truncation_strategy)
  2894|         0|            0|            0|  0.00%|
  2895|         0|            0|            0|  0.00%|        overflowing_tokens = []
  2896|         0|            0|            0|  0.00%|        if truncation_strategy == TruncationStrategy.LONGEST_FIRST:
  2897|         0|            0|            0|  0.00%|            for _ in range(num_tokens_to_remove):
  2898|         0|            0|            0|  0.00%|                if pair_ids is None or len(ids) > len(pair_ids):
  2899|         0|            0|            0|  0.00%|                    if not overflowing_tokens:
  2900|         0|            0|            0|  0.00%|                        window_len = min(len(ids), stride + 1)
  2901|         0|            0|            0|  0.00%|                    else:
  2902|         0|            0|            0|  0.00%|                        window_len = 1
  2903|         0|            0|            0|  0.00%|                    overflowing_tokens.extend(ids[-window_len:])
  2904|         0|            0|            0|  0.00%|                    ids = ids[:-1]
  2905|         0|            0|            0|  0.00%|                else:
  2906|         0|            0|            0|  0.00%|                    if not overflowing_tokens:
  2907|         0|            0|            0|  0.00%|                        window_len = min(len(pair_ids), stride + 1)
  2908|         0|            0|            0|  0.00%|                    else:
  2909|         0|            0|            0|  0.00%|                        window_len = 1
  2910|         0|            0|            0|  0.00%|                    overflowing_tokens.extend(pair_ids[-window_len:])
  2911|         0|            0|            0|  0.00%|                    pair_ids = pair_ids[:-1]
  2912|         0|            0|            0|  0.00%|        elif truncation_strategy == TruncationStrategy.ONLY_FIRST:
  2913|         0|            0|            0|  0.00%|            if len(ids) > num_tokens_to_remove:
  2914|         0|            0|            0|  0.00%|                window_len = min(len(ids), stride + num_tokens_to_remove)
  2915|         0|            0|            0|  0.00%|                overflowing_tokens = ids[-window_len:]
  2916|         0|            0|            0|  0.00%|                ids = ids[:-num_tokens_to_remove]
  2917|         0|            0|            0|  0.00%|            else:
  2918|         0|            0|            0|  0.00%|                logger.error(
  2919|         0|            0|            0|  0.00%|                    f"We need to remove {num_tokens_to_remove} to truncate the input"
  2920|         0|            0|            0|  0.00%|                    f"but the first sequence has a length {len(ids)}. "
  2921|         0|            0|            0|  0.00%|                    f"Please select another truncation strategy than {truncation_strategy}, "
  2922|         0|            0|            0|  0.00%|                    f"for instance 'longest_first' or 'only_second'."
  2923|         0|            0|            0|  0.00%|                )
  2924|         0|            0|            0|  0.00%|        elif truncation_strategy == TruncationStrategy.ONLY_SECOND and pair_ids is not None:
  2925|         0|            0|            0|  0.00%|            if len(pair_ids) > num_tokens_to_remove:
  2926|         0|            0|            0|  0.00%|                window_len = min(len(pair_ids), stride + num_tokens_to_remove)
  2927|         0|            0|            0|  0.00%|                overflowing_tokens = pair_ids[-window_len:]
  2928|         0|            0|            0|  0.00%|                pair_ids = pair_ids[:-num_tokens_to_remove]
  2929|         0|            0|            0|  0.00%|            else:
  2930|         0|            0|            0|  0.00%|                logger.error(
  2931|         0|            0|            0|  0.00%|                    f"We need to remove {num_tokens_to_remove} to truncate the input"
  2932|         0|            0|            0|  0.00%|                    f"but the second sequence has a length {len(pair_ids)}. "
  2933|         0|            0|            0|  0.00%|                    f"Please select another truncation strategy than {truncation_strategy}, "
  2934|         0|            0|            0|  0.00%|                    f"for instance 'longest_first' or 'only_first'."
  2935|         0|            0|            0|  0.00%|                )
  2936|         0|            0|            0|  0.00%|
  2937|         0|            0|            0|  0.00%|        return (ids, pair_ids, overflowing_tokens)
  2938|         0|            0|            0|  0.00%|
  2939|         0|            0|            0|  0.00%|    def _pad(
  2940|         0|            0|            0|  0.00%|        self,
  2941|         0|            0|            0|  0.00%|        encoded_inputs: Union[Dict[str, EncodedInput], BatchEncoding],
  2942|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  2943|         0|            0|            0|  0.00%|        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
  2944|         0|            0|            0|  0.00%|        pad_to_multiple_of: Optional[int] = None,
  2945|         0|            0|            0|  0.00%|        return_attention_mask: Optional[bool] = None,
  2946|         0|            0|            0|  0.00%|    ) -> dict:
  2947|         0|            0|            0|  0.00%|        """
  2948|         0|            0|            0|  0.00%|        Pad encoded inputs (on left/right and up to predefined length or max length in the batch)
  2949|         0|            0|            0|  0.00%|
  2950|         0|            0|            0|  0.00%|        Args:
  2951|         0|            0|            0|  0.00%|            encoded_inputs: Dictionary of tokenized inputs (`List[int]`) or batch of tokenized inputs (`List[List[int]]`).
  2952|         0|            0|            0|  0.00%|            max_length: maximum length of the returned list and optionally padding length (see below).
  2953|         0|            0|            0|  0.00%|                Will truncate by taking into account the special tokens.
  2954|         0|            0|            0|  0.00%|            padding_strategy: PaddingStrategy to use for padding.
  2955|         0|            0|            0|  0.00%|
  2956|         0|            0|            0|  0.00%|                - PaddingStrategy.LONGEST Pad to the longest sequence in the batch
  2957|         0|            0|            0|  0.00%|                - PaddingStrategy.MAX_LENGTH: Pad to the max length (default)
  2958|         0|            0|            0|  0.00%|                - PaddingStrategy.DO_NOT_PAD: Do not pad
  2959|         0|            0|            0|  0.00%|                The tokenizer padding sides are defined in self.padding_side:
  2960|         0|            0|            0|  0.00%|
  2961|         0|            0|            0|  0.00%|                    - 'left': pads on the left of the sequences
  2962|         0|            0|            0|  0.00%|                    - 'right': pads on the right of the sequences
  2963|         0|            0|            0|  0.00%|            pad_to_multiple_of: (optional) Integer if set will pad the sequence to a multiple of the provided value.
  2964|         0|            0|            0|  0.00%|                This is especially useful to enable the use of Tensor Core on NVIDIA hardware with compute capability
  2965|         0|            0|            0|  0.00%|                >= 7.5 (Volta).
  2966|         0|            0|            0|  0.00%|            return_attention_mask: (optional) Set to False to avoid returning attention mask (default: set to model specifics)
  2967|         0|            0|            0|  0.00%|        """
  2968|         0|            0|            0|  0.00%|        # Load from model defaults
  2969|         0|            0|            0|  0.00%|        if return_attention_mask is None:
  2970|         0|            0|            0|  0.00%|            return_attention_mask = "attention_mask" in self.model_input_names
  2971|         0|            0|            0|  0.00%|
  2972|         0|            0|            0|  0.00%|        required_input = encoded_inputs[self.model_input_names[0]]
  2973|         0|            0|            0|  0.00%|
  2974|         0|            0|            0|  0.00%|        if padding_strategy == PaddingStrategy.LONGEST:
  2975|         0|            0|            0|  0.00%|            max_length = len(required_input)
  2976|         0|            0|            0|  0.00%|
  2977|         0|            0|            0|  0.00%|        if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):
  2978|         0|            0|            0|  0.00%|            max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of
  2979|         0|            0|            0|  0.00%|
  2980|         0|            0|            0|  0.00%|        needs_to_be_padded = padding_strategy != PaddingStrategy.DO_NOT_PAD and len(required_input) != max_length
  2981|         0|            0|            0|  0.00%|
  2982|         0|            0|            0|  0.00%|        if needs_to_be_padded:
  2983|         0|            0|            0|  0.00%|            difference = max_length - len(required_input)
  2984|         0|            0|            0|  0.00%|            if self.padding_side == "right":
  2985|         0|            0|            0|  0.00%|                if return_attention_mask:
  2986|         0|            0|            0|  0.00%|                    encoded_inputs["attention_mask"] = [1] * len(required_input) + [0] * difference
  2987|         0|            0|            0|  0.00%|                if "token_type_ids" in encoded_inputs:
  2988|         0|            0|            0|  0.00%|                    encoded_inputs["token_type_ids"] = (
  2989|         0|            0|            0|  0.00%|                        encoded_inputs["token_type_ids"] + [self.pad_token_type_id] * difference
  2990|         0|            0|            0|  0.00%|                    )
  2991|         0|            0|            0|  0.00%|                if "special_tokens_mask" in encoded_inputs:
  2992|         0|            0|            0|  0.00%|                    encoded_inputs["special_tokens_mask"] = encoded_inputs["special_tokens_mask"] + [1] * difference
  2993|         0|            0|            0|  0.00%|                encoded_inputs[self.model_input_names[0]] = required_input + [self.pad_token_id] * difference
  2994|         0|            0|            0|  0.00%|            elif self.padding_side == "left":
  2995|         0|            0|            0|  0.00%|                if return_attention_mask:
  2996|         0|            0|            0|  0.00%|                    encoded_inputs["attention_mask"] = [0] * difference + [1] * len(required_input)
  2997|         0|            0|            0|  0.00%|                if "token_type_ids" in encoded_inputs:
  2998|         0|            0|            0|  0.00%|                    encoded_inputs["token_type_ids"] = [self.pad_token_type_id] * difference + encoded_inputs[
  2999|         0|            0|            0|  0.00%|                        "token_type_ids"
  3000|         0|            0|            0|  0.00%|                    ]
  3001|         0|            0|            0|  0.00%|                if "special_tokens_mask" in encoded_inputs:
  3002|         0|            0|            0|  0.00%|                    encoded_inputs["special_tokens_mask"] = [1] * difference + encoded_inputs["special_tokens_mask"]
  3003|         0|            0|            0|  0.00%|                encoded_inputs[self.model_input_names[0]] = [self.pad_token_id] * difference + required_input
  3004|         0|            0|            0|  0.00%|            else:
  3005|         0|            0|            0|  0.00%|                raise ValueError("Invalid padding strategy:" + str(self.padding_side))
  3006|         0|            0|            0|  0.00%|        elif return_attention_mask and "attention_mask" not in encoded_inputs:
  3007|         0|            0|            0|  0.00%|            encoded_inputs["attention_mask"] = [1] * len(required_input)
  3008|         0|            0|            0|  0.00%|
  3009|         0|            0|            0|  0.00%|        return encoded_inputs
  3010|         0|            0|            0|  0.00%|
  3011|         0|            0|            0|  0.00%|    def convert_tokens_to_string(self, tokens: List[str]) -> str:
  3012|         0|            0|            0|  0.00%|        """
  3013|         0|            0|            0|  0.00%|        Converts a sequence of tokens in a single string. The most simple way to do it is ``" ".join(tokens)`` but we
  3014|         0|            0|            0|  0.00%|        often want to remove sub-word tokenization artifacts at the same time.
  3015|         0|            0|            0|  0.00%|
  3016|         0|            0|            0|  0.00%|        Args:
  3017|         0|            0|            0|  0.00%|            tokens (:obj:`List[str]`): The token to join in a string.
  3018|         0|            0|            0|  0.00%|
  3019|         0|            0|            0|  0.00%|        Returns:
  3020|         0|            0|            0|  0.00%|            :obj:`str`: The joined tokens.
  3021|         0|            0|            0|  0.00%|        """
  3022|         0|            0|            0|  0.00%|        raise NotImplementedError
  3023|         0|            0|            0|  0.00%|
  3024|         0|            0|            0|  0.00%|    def batch_decode(
  3025|         0|            0|            0|  0.00%|        self,
  3026|         0|            0|            0|  0.00%|        sequences: Union[List[int], List[List[int]], "np.ndarray", "torch.Tensor", "tf.Tensor"],
  3027|         0|            0|            0|  0.00%|        skip_special_tokens: bool = False,
  3028|         0|            0|            0|  0.00%|        clean_up_tokenization_spaces: bool = True,
  3029|         0|            0|            0|  0.00%|        **kwargs
  3030|         0|            0|            0|  0.00%|    ) -> List[str]:
  3031|         0|            0|            0|  0.00%|        """
  3032|         0|            0|            0|  0.00%|        Convert a list of lists of token ids into a list of strings by calling decode.
  3033|         0|            0|            0|  0.00%|
  3034|         0|            0|            0|  0.00%|        Args:
  3035|         0|            0|            0|  0.00%|            sequences (:obj:`Union[List[int], List[List[int]], np.ndarray, torch.Tensor, tf.Tensor]`):
  3036|         0|            0|            0|  0.00%|                List of tokenized input ids. Can be obtained using the ``__call__`` method.
  3037|         0|            0|            0|  0.00%|            skip_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
  3038|         0|            0|            0|  0.00%|                Whether or not to remove special tokens in the decoding.
  3039|         0|            0|            0|  0.00%|            clean_up_tokenization_spaces (:obj:`bool`, `optional`, defaults to :obj:`True`):
  3040|         0|            0|            0|  0.00%|                Whether or not to clean up the tokenization spaces.
  3041|         0|            0|            0|  0.00%|            kwargs (additional keyword arguments, `optional`):
  3042|         0|            0|            0|  0.00%|                Will be passed to the underlying model specific decode method.
  3043|         0|            0|            0|  0.00%|
  3044|         0|            0|            0|  0.00%|        Returns:
  3045|         0|            0|            0|  0.00%|            :obj:`List[str]`: The list of decoded sentences.
  3046|         0|            0|            0|  0.00%|        """
  3047|         0|            0|            0|  0.00%|        return [
  3048|         0|            0|            0|  0.00%|            self.decode(
  3049|         0|            0|            0|  0.00%|                seq,
  3050|         0|            0|            0|  0.00%|                skip_special_tokens=skip_special_tokens,
  3051|         0|            0|            0|  0.00%|                clean_up_tokenization_spaces=clean_up_tokenization_spaces,
  3052|         0|            0|            0|  0.00%|                **kwargs,
  3053|         0|            0|            0|  0.00%|            )
  3054|         0|            0|            0|  0.00%|            for seq in sequences
  3055|         0|            0|            0|  0.00%|        ]
  3056|         0|            0|            0|  0.00%|
  3057|         0|            0|            0|  0.00%|    def decode(
  3058|         0|            0|            0|  0.00%|        self,
  3059|         0|            0|            0|  0.00%|        token_ids: Union[int, List[int], "np.ndarray", "torch.Tensor", "tf.Tensor"],
  3060|         0|            0|            0|  0.00%|        skip_special_tokens: bool = False,
  3061|         0|            0|            0|  0.00%|        clean_up_tokenization_spaces: bool = True,
  3062|         0|            0|            0|  0.00%|        **kwargs
  3063|         0|            0|            0|  0.00%|    ) -> str:
  3064|         0|            0|            0|  0.00%|        """
  3065|         0|            0|            0|  0.00%|        Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special
  3066|         0|            0|            0|  0.00%|        tokens and clean up tokenization spaces.
  3067|         0|            0|            0|  0.00%|
  3068|         0|            0|            0|  0.00%|        Similar to doing ``self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))``.
  3069|         0|            0|            0|  0.00%|
  3070|         0|            0|            0|  0.00%|        Args:
  3071|         0|            0|            0|  0.00%|            token_ids (:obj:`Union[int, List[int], np.ndarray, torch.Tensor, tf.Tensor]`):
  3072|         0|            0|            0|  0.00%|                List of tokenized input ids. Can be obtained using the ``__call__`` method.
  3073|         0|            0|            0|  0.00%|            skip_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
  3074|         0|            0|            0|  0.00%|                Whether or not to remove special tokens in the decoding.
  3075|         0|            0|            0|  0.00%|            clean_up_tokenization_spaces (:obj:`bool`, `optional`, defaults to :obj:`True`):
  3076|         0|            0|            0|  0.00%|                Whether or not to clean up the tokenization spaces.
  3077|         0|            0|            0|  0.00%|            kwargs (additional keyword arguments, `optional`):
  3078|         0|            0|            0|  0.00%|                Will be passed to the underlying model specific decode method.
  3079|         0|            0|            0|  0.00%|
  3080|         0|            0|            0|  0.00%|        Returns:
  3081|         0|            0|            0|  0.00%|            :obj:`str`: The decoded sentence.
  3082|         0|            0|            0|  0.00%|        """
  3083|         0|            0|            0|  0.00%|        # Convert inputs to python lists
  3084|         0|            0|            0|  0.00%|        token_ids = to_py_obj(token_ids)
  3085|         0|            0|            0|  0.00%|
  3086|         0|            0|            0|  0.00%|        return self._decode(
  3087|         0|            0|            0|  0.00%|            token_ids=token_ids,
  3088|         0|            0|            0|  0.00%|            skip_special_tokens=skip_special_tokens,
  3089|         0|            0|            0|  0.00%|            clean_up_tokenization_spaces=clean_up_tokenization_spaces,
  3090|         0|            0|            0|  0.00%|            **kwargs,
  3091|         0|            0|            0|  0.00%|        )
  3092|         0|            0|            0|  0.00%|
  3093|         0|            0|            0|  0.00%|    def _decode(
  3094|         0|            0|            0|  0.00%|        self,
  3095|         0|            0|            0|  0.00%|        token_ids: Union[int, List[int]],
  3096|         0|            0|            0|  0.00%|        skip_special_tokens: bool = False,
  3097|         0|            0|            0|  0.00%|        clean_up_tokenization_spaces: bool = True,
  3098|         0|            0|            0|  0.00%|        **kwargs
  3099|         0|            0|            0|  0.00%|    ) -> str:
  3100|         0|            0|            0|  0.00%|        raise NotImplementedError
  3101|         0|            0|            0|  0.00%|
  3102|         0|            0|            0|  0.00%|    def get_special_tokens_mask(
  3103|         0|            0|            0|  0.00%|        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False
  3104|         0|            0|            0|  0.00%|    ) -> List[int]:
  3105|         0|            0|            0|  0.00%|        """
  3106|         0|            0|            0|  0.00%|        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding
  3107|         0|            0|            0|  0.00%|        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.
  3108|         0|            0|            0|  0.00%|
  3109|         0|            0|            0|  0.00%|        Args:
  3110|         0|            0|            0|  0.00%|            token_ids_0 (:obj:`List[int]`):
  3111|         0|            0|            0|  0.00%|                List of ids of the first sequence.
  3112|         0|            0|            0|  0.00%|            token_ids_1 (:obj:`List[int]`, `optional`):
  3113|         0|            0|            0|  0.00%|                List of ids of the second sequence.
  3114|         0|            0|            0|  0.00%|            already_has_special_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`):
  3115|         0|            0|            0|  0.00%|                Whether or not the token list is already formatted with special tokens for the model.
  3116|         0|            0|            0|  0.00%|
  3117|         0|            0|            0|  0.00%|        Returns:
  3118|         0|            0|            0|  0.00%|            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.
  3119|         0|            0|            0|  0.00%|        """
  3120|         0|            0|            0|  0.00%|        assert already_has_special_tokens and token_ids_1 is None, (
  3121|         0|            0|            0|  0.00%|            "You cannot use ``already_has_special_tokens=False`` with this tokenizer. "
  3122|         0|            0|            0|  0.00%|            "Please use a slow (full python) tokenizer to activate this argument."
  3123|         0|            0|            0|  0.00%|            "Or set `return_special_tokens_mask=True` when calling the encoding method "
  3124|         0|            0|            0|  0.00%|            "to get the special tokens mask in any tokenizer. "
  3125|         0|            0|            0|  0.00%|        )
  3126|         0|            0|            0|  0.00%|
  3127|         0|            0|            0|  0.00%|        all_special_ids = self.all_special_ids  # cache the property
  3128|         0|            0|            0|  0.00%|
  3129|         0|            0|            0|  0.00%|        special_tokens_mask = [1 if token in all_special_ids else 0 for token in token_ids_0]
  3130|         0|            0|            0|  0.00%|
  3131|         0|            0|            0|  0.00%|        return special_tokens_mask
  3132|         0|            0|            0|  0.00%|
  3133|         0|            0|            0|  0.00%|    @staticmethod
  3134|         0|            0|            0|  0.00%|    def clean_up_tokenization(out_string: str) -> str:
  3135|         0|            0|            0|  0.00%|        """
  3136|         0|            0|            0|  0.00%|        Clean up a list of simple English tokenization artifacts like spaces before punctuations and abbreviated forms.
  3137|         0|            0|            0|  0.00%|
  3138|         0|            0|            0|  0.00%|        Args:
  3139|         0|            0|            0|  0.00%|            out_string (:obj:`str`): The text to clean up.
  3140|         0|            0|            0|  0.00%|
  3141|         0|            0|            0|  0.00%|        Returns:
  3142|         0|            0|            0|  0.00%|            :obj:`str`: The cleaned-up string.
  3143|         0|            0|            0|  0.00%|        """
  3144|         0|            0|            0|  0.00%|        out_string = (
  3145|         0|            0|            0|  0.00%|            out_string.replace(" .", ".")
  3146|         0|            0|            0|  0.00%|            .replace(" ?", "?")
  3147|         0|            0|            0|  0.00%|            .replace(" !", "!")
  3148|         0|            0|            0|  0.00%|            .replace(" ,", ",")
  3149|         0|            0|            0|  0.00%|            .replace(" ' ", "'")
  3150|         0|            0|            0|  0.00%|            .replace(" n't", "n't")
  3151|         0|            0|            0|  0.00%|            .replace(" 'm", "'m")
  3152|         0|            0|            0|  0.00%|            .replace(" 's", "'s")
  3153|         0|            0|            0|  0.00%|            .replace(" 've", "'ve")
  3154|         0|            0|            0|  0.00%|            .replace(" 're", "'re")
  3155|         0|            0|            0|  0.00%|        )
  3156|         0|            0|            0|  0.00%|        return out_string
  3157|         0|            0|            0|  0.00%|
  3158|         0|            0|            0|  0.00%|    def _eventual_warn_about_too_long_sequence(self, ids: List[int], max_length: Optional[int], verbose: bool):
  3159|         0|            0|            0|  0.00%|        """
  3160|         0|            0|            0|  0.00%|        Depending on the input and internal state we might trigger a warning about a sequence that is too long for its
  3161|         0|            0|            0|  0.00%|        corresponding model
  3162|         0|            0|            0|  0.00%|
  3163|         0|            0|            0|  0.00%|        Args:
  3164|         0|            0|            0|  0.00%|            ids (:obj:`List[str]`): The ids produced by the tokenization
  3165|         0|            0|            0|  0.00%|            max_length (:obj:`int`, `optional`): The max_length desired (does not trigger a warning if it is set)
  3166|         0|            0|            0|  0.00%|            verbose (:obj:`bool`): Whether or not to print more information and warnings.
  3167|         0|            0|            0|  0.00%|
  3168|         0|            0|            0|  0.00%|        """
  3169|         0|            0|            0|  0.00%|        if max_length is None and len(ids) > self.model_max_length and verbose:
  3170|         0|            0|            0|  0.00%|            if not self.deprecation_warnings.get("sequence-length-is-longer-than-the-specified-maximum", False):
  3171|         0|            0|            0|  0.00%|                logger.warning(
  3172|         0|            0|            0|  0.00%|                    "Token indices sequence length is longer than the specified maximum sequence length "
  3173|         0|            0|            0|  0.00%|                    f"for this model ({len(ids)} > {self.model_max_length}). Running this sequence through the model "
  3174|         0|            0|            0|  0.00%|                    "will result in indexing errors"
  3175|         0|            0|            0|  0.00%|                )
  3176|         0|            0|            0|  0.00%|            self.deprecation_warnings["sequence-length-is-longer-than-the-specified-maximum"] = True
  3177|         0|            0|            0|  0.00%|
  3178|         0|            0|            0|  0.00%|    @contextmanager
  3179|         0|            0|            0|  0.00%|    def as_target_tokenizer(self):
  3180|         0|            0|            0|  0.00%|        """
  3181|         0|            0|            0|  0.00%|        Temporarily sets the tokenizer for encoding the targets. Useful for tokenizer associated to
  3182|         0|            0|            0|  0.00%|        sequence-to-sequence models that need a slightly different processing for the labels.
  3183|         0|            0|            0|  0.00%|        """
  3184|         0|            0|            0|  0.00%|        yield
  3185|         0|            0|            0|  0.00%|
  3186|         0|            0|            0|  0.00%|    def prepare_seq2seq_batch(
  3187|         0|            0|            0|  0.00%|        self,
  3188|         0|            0|            0|  0.00%|        src_texts: List[str],
  3189|         0|            0|            0|  0.00%|        tgt_texts: Optional[List[str]] = None,
  3190|         0|            0|            0|  0.00%|        max_length: Optional[int] = None,
  3191|         0|            0|            0|  0.00%|        max_target_length: Optional[int] = None,
  3192|         0|            0|            0|  0.00%|        padding: str = "longest",
  3193|         0|            0|            0|  0.00%|        return_tensors: str = None,
  3194|         0|            0|            0|  0.00%|        truncation: bool = True,
  3195|         0|            0|            0|  0.00%|        **kwargs,
  3196|         0|            0|            0|  0.00%|    ) -> BatchEncoding:
  3197|         0|            0|            0|  0.00%|        """
  3198|         0|            0|            0|  0.00%|        Prepare model inputs for translation. For best performance, translate one sentence at a time.
  3199|         0|            0|            0|  0.00%|
  3200|         0|            0|            0|  0.00%|        Arguments:
  3201|         0|            0|            0|  0.00%|            src_texts (:obj:`List[str]`):
  3202|         0|            0|            0|  0.00%|                List of documents to summarize or source language texts.
  3203|         0|            0|            0|  0.00%|            tgt_texts (:obj:`list`, `optional`):
  3204|         0|            0|            0|  0.00%|                List of summaries or target language texts.
  3205|         0|            0|            0|  0.00%|            max_length (:obj:`int`, `optional`):
  3206|         0|            0|            0|  0.00%|                Controls the maximum length for encoder inputs (documents to summarize or source language texts) If
  3207|         0|            0|            0|  0.00%|                left unset or set to :obj:`None`, this will use the predefined model maximum length if a maximum length
  3208|         0|            0|            0|  0.00%|                is required by one of the truncation/padding parameters. If the model has no specific maximum input
  3209|         0|            0|            0|  0.00%|                length (like XLNet) truncation/padding to a maximum length will be deactivated.
  3210|         0|            0|            0|  0.00%|            max_target_length (:obj:`int`, `optional`):
  3211|         0|            0|            0|  0.00%|                Controls the maximum length of decoder inputs (target language texts or summaries) If left unset or set
  3212|         0|            0|            0|  0.00%|                to :obj:`None`, this will use the max_length value.
  3213|         0|            0|            0|  0.00%|            padding (:obj:`bool`, :obj:`str` or :class:`~transformers.file_utils.PaddingStrategy`, `optional`, defaults to :obj:`False`):
  3214|         0|            0|            0|  0.00%|                Activates and controls padding. Accepts the following values:
  3215|         0|            0|            0|  0.00%|
  3216|         0|            0|            0|  0.00%|                * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a
  3217|         0|            0|            0|  0.00%|                  single sequence if provided).
  3218|         0|            0|            0|  0.00%|                * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the
  3219|         0|            0|            0|  0.00%|                  maximum acceptable input length for the model if that argument is not provided.
  3220|         0|            0|            0|  0.00%|                * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of
  3221|         0|            0|            0|  0.00%|                  different lengths).
  3222|         0|            0|            0|  0.00%|            return_tensors (:obj:`str` or :class:`~transformers.file_utils.TensorType`, `optional`):
  3223|         0|            0|            0|  0.00%|                If set, will return tensors instead of list of python integers. Acceptable values are:
  3224|         0|            0|            0|  0.00%|
  3225|         0|            0|            0|  0.00%|                * :obj:`'tf'`: Return TensorFlow :obj:`tf.constant` objects.
  3226|         0|            0|            0|  0.00%|                * :obj:`'pt'`: Return PyTorch :obj:`torch.Tensor` objects.
  3227|         0|            0|            0|  0.00%|                * :obj:`'np'`: Return Numpy :obj:`np.ndarray` objects.
  3228|         0|            0|            0|  0.00%|            truncation (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.TruncationStrategy`, `optional`, defaults to :obj:`True`):
  3229|         0|            0|            0|  0.00%|                Activates and controls truncation. Accepts the following values:
  3230|         0|            0|            0|  0.00%|
  3231|         0|            0|            0|  0.00%|                * :obj:`True` or :obj:`'longest_first'`: Truncate to a maximum length specified with the argument
  3232|         0|            0|            0|  0.00%|                  :obj:`max_length` or to the maximum acceptable input length for the model if that argument is not
  3233|         0|            0|            0|  0.00%|                  provided. This will truncate token by token, removing a token from the longest sequence in the pair
  3234|         0|            0|            0|  0.00%|                  if a pair of sequences (or a batch of pairs) is provided.
  3235|         0|            0|            0|  0.00%|                * :obj:`'only_first'`: Truncate to a maximum length specified with the argument :obj:`max_length` or to
  3236|         0|            0|            0|  0.00%|                  the maximum acceptable input length for the model if that argument is not provided. This will only
  3237|         0|            0|            0|  0.00%|                  truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.
  3238|         0|            0|            0|  0.00%|                * :obj:`'only_second'`: Truncate to a maximum length specified with the argument :obj:`max_length` or
  3239|         0|            0|            0|  0.00%|                  to the maximum acceptable input length for the model if that argument is not provided. This will only
  3240|         0|            0|            0|  0.00%|                  truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.
  3241|         0|            0|            0|  0.00%|                * :obj:`False` or :obj:`'do_not_truncate'` (default): No truncation (i.e., can output batch with
  3242|         0|            0|            0|  0.00%|                  sequence lengths greater than the model maximum admissible input size).
  3243|         0|            0|            0|  0.00%|            **kwargs:
  3244|         0|            0|            0|  0.00%|                Additional keyword arguments passed along to :obj:`self.__call__`.
  3245|         0|            0|            0|  0.00%|
  3246|         0|            0|            0|  0.00%|        Return:
  3247|         0|            0|            0|  0.00%|            :class:`~transformers.BatchEncoding`: A :class:`~transformers.BatchEncoding` with the following fields:
  3248|         0|            0|            0|  0.00%|
  3249|         0|            0|            0|  0.00%|            - **input_ids** -- List of token ids to be fed to the encoder.
  3250|         0|            0|            0|  0.00%|            - **attention_mask** -- List of indices specifying which tokens should be attended to by the model.
  3251|         0|            0|            0|  0.00%|            - **labels** -- List of token ids for tgt_texts.
  3252|         0|            0|            0|  0.00%|
  3253|         0|            0|            0|  0.00%|            The full set of keys ``[input_ids, attention_mask, labels]``, will only be returned if tgt_texts is passed.
  3254|         0|            0|            0|  0.00%|            Otherwise, input_ids, attention_mask will be the only keys.
  3255|         0|            0|            0|  0.00%|        """
  3256|         0|            0|            0|  0.00%|        warnings.warn(
  3257|         0|            0|            0|  0.00%|            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the "
  3258|         0|            0|            0|  0.00%|            "regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` "
  3259|         0|            0|            0|  0.00%|            "context manager to prepare your targets. See the documentation of your specific tokenizer for more "
  3260|         0|            0|            0|  0.00%|            "details",
  3261|         0|            0|            0|  0.00%|            FutureWarning,
  3262|         0|            0|            0|  0.00%|        )
  3263|         0|            0|            0|  0.00%|        # mBART-specific kwargs that should be ignored by other models.
  3264|         0|            0|            0|  0.00%|        kwargs.pop("src_lang", None)
  3265|         0|            0|            0|  0.00%|        kwargs.pop("tgt_lang", None)
  3266|         0|            0|            0|  0.00%|        if max_length is None:
  3267|         0|            0|            0|  0.00%|            max_length = self.model_max_length
  3268|         0|            0|            0|  0.00%|        model_inputs = self(
  3269|         0|            0|            0|  0.00%|            src_texts,
  3270|         0|            0|            0|  0.00%|            add_special_tokens=True,
  3271|         0|            0|            0|  0.00%|            return_tensors=return_tensors,
  3272|         0|            0|            0|  0.00%|            max_length=max_length,
  3273|         0|            0|            0|  0.00%|            padding=padding,
  3274|         0|            0|            0|  0.00%|            truncation=truncation,
  3275|         0|            0|            0|  0.00%|            **kwargs,
  3276|         0|            0|            0|  0.00%|        )
  3277|         0|            0|            0|  0.00%|        if tgt_texts is None:
  3278|         0|            0|            0|  0.00%|            return model_inputs
  3279|         0|            0|            0|  0.00%|        # Process tgt_texts
  3280|         0|            0|            0|  0.00%|        if max_target_length is None:
  3281|         0|            0|            0|  0.00%|            max_target_length = max_length
  3282|         0|            0|            0|  0.00%|        with self.as_target_tokenizer():
  3283|         0|            0|            0|  0.00%|            labels = self(
  3284|         0|            0|            0|  0.00%|                tgt_texts,
  3285|         0|            0|            0|  0.00%|                add_special_tokens=True,
  3286|         0|            0|            0|  0.00%|                return_tensors=return_tensors,
  3287|         0|            0|            0|  0.00%|                padding=padding,
  3288|         0|            0|            0|  0.00%|                max_length=max_target_length,
  3289|         0|            0|            0|  0.00%|                truncation=truncation,
  3290|         0|            0|            0|  0.00%|                **kwargs,
  3291|         0|            0|            0|  0.00%|            )
  3292|         0|            0|            0|  0.00%|        model_inputs["labels"] = labels["input_ids"]
  3293|         0|            0|            0|  0.00%|        return model_inputs
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/index_tricks.py
File duration: 0.00451469s (0.53%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import functools
     2|         0|            0|            0|  0.00%|import sys
     3|         0|            0|            0|  0.00%|import math
     4|         0|            0|            0|  0.00%|import warnings
     5|         0|            0|            0|  0.00%|
     6|         0|            0|            0|  0.00%|import numpy.core.numeric as _nx
     7|         0|            0|            0|  0.00%|from numpy.core.numeric import (
     8|         0|            0|            0|  0.00%|    asarray, ScalarType, array, alltrue, cumprod, arange, ndim
     9|         0|            0|            0|  0.00%|    )
    10|         0|            0|            0|  0.00%|from numpy.core.numerictypes import find_common_type, issubdtype
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|import numpy.matrixlib as matrixlib
    13|         0|            0|            0|  0.00%|from .function_base import diff
    14|         0|            0|            0|  0.00%|from numpy.core.multiarray import ravel_multi_index, unravel_index
    15|         0|            0|            0|  0.00%|from numpy.core.overrides import set_module
    16|         0|            0|            0|  0.00%|from numpy.core import overrides, linspace
    17|         0|            0|            0|  0.00%|from numpy.lib.stride_tricks import as_strided
    18|         0|            0|            0|  0.00%|
    19|         0|            0|            0|  0.00%|
    20|         0|            0|            0|  0.00%|array_function_dispatch = functools.partial(
    21|         0|            0|            0|  0.00%|    overrides.array_function_dispatch, module='numpy')
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|__all__ = [
    25|         0|            0|            0|  0.00%|    'ravel_multi_index', 'unravel_index', 'mgrid', 'ogrid', 'r_', 'c_',
    26|         0|            0|            0|  0.00%|    's_', 'index_exp', 'ix_', 'ndenumerate', 'ndindex', 'fill_diagonal',
    27|         0|            0|            0|  0.00%|    'diag_indices', 'diag_indices_from'
    28|         0|            0|            0|  0.00%|    ]
    29|         0|            0|            0|  0.00%|
    30|         0|            0|            0|  0.00%|
    31|         0|            0|            0|  0.00%|def _ix__dispatcher(*args):
    32|         0|            0|            0|  0.00%|    return args
    33|         0|            0|            0|  0.00%|
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|@array_function_dispatch(_ix__dispatcher)
    36|         0|            0|            0|  0.00%|def ix_(*args):
    37|         0|            0|            0|  0.00%|    """
    38|         0|            0|            0|  0.00%|    Construct an open mesh from multiple sequences.
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|    This function takes N 1-D sequences and returns N outputs with N
    41|         0|            0|            0|  0.00%|    dimensions each, such that the shape is 1 in all but one dimension
    42|         0|            0|            0|  0.00%|    and the dimension with the non-unit shape value cycles through all
    43|         0|            0|            0|  0.00%|    N dimensions.
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|    Using `ix_` one can quickly construct index arrays that will index
    46|         0|            0|            0|  0.00%|    the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array
    47|         0|            0|            0|  0.00%|    ``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|    Parameters
    50|         0|            0|            0|  0.00%|    ----------
    51|         0|            0|            0|  0.00%|    args : 1-D sequences
    52|         0|            0|            0|  0.00%|        Each sequence should be of integer or boolean type.
    53|         0|            0|            0|  0.00%|        Boolean sequences will be interpreted as boolean masks for the
    54|         0|            0|            0|  0.00%|        corresponding dimension (equivalent to passing in
    55|         0|            0|            0|  0.00%|        ``np.nonzero(boolean_sequence)``).
    56|         0|            0|            0|  0.00%|
    57|         0|            0|            0|  0.00%|    Returns
    58|         0|            0|            0|  0.00%|    -------
    59|         0|            0|            0|  0.00%|    out : tuple of ndarrays
    60|         0|            0|            0|  0.00%|        N arrays with N dimensions each, with N the number of input
    61|         0|            0|            0|  0.00%|        sequences. Together these arrays form an open mesh.
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|    See Also
    64|         0|            0|            0|  0.00%|    --------
    65|         0|            0|            0|  0.00%|    ogrid, mgrid, meshgrid
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|    Examples
    68|         0|            0|            0|  0.00%|    --------
    69|         0|            0|            0|  0.00%|    >>> a = np.arange(10).reshape(2, 5)
    70|         0|            0|            0|  0.00%|    >>> a
    71|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3, 4],
    72|         0|            0|            0|  0.00%|           [5, 6, 7, 8, 9]])
    73|         0|            0|            0|  0.00%|    >>> ixgrid = np.ix_([0, 1], [2, 4])
    74|         0|            0|            0|  0.00%|    >>> ixgrid
    75|         0|            0|            0|  0.00%|    (array([[0],
    76|         0|            0|            0|  0.00%|           [1]]), array([[2, 4]]))
    77|         0|            0|            0|  0.00%|    >>> ixgrid[0].shape, ixgrid[1].shape
    78|         0|            0|            0|  0.00%|    ((2, 1), (1, 2))
    79|         0|            0|            0|  0.00%|    >>> a[ixgrid]
    80|         0|            0|            0|  0.00%|    array([[2, 4],
    81|         0|            0|            0|  0.00%|           [7, 9]])
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|    >>> ixgrid = np.ix_([True, True], [2, 4])
    84|         0|            0|            0|  0.00%|    >>> a[ixgrid]
    85|         0|            0|            0|  0.00%|    array([[2, 4],
    86|         0|            0|            0|  0.00%|           [7, 9]])
    87|         0|            0|            0|  0.00%|    >>> ixgrid = np.ix_([True, True], [False, False, True, False, True])
    88|         0|            0|            0|  0.00%|    >>> a[ixgrid]
    89|         0|            0|            0|  0.00%|    array([[2, 4],
    90|         0|            0|            0|  0.00%|           [7, 9]])
    91|         0|            0|            0|  0.00%|
    92|         0|            0|            0|  0.00%|    """
    93|         0|            0|            0|  0.00%|    out = []
    94|         0|            0|            0|  0.00%|    nd = len(args)
    95|         0|            0|            0|  0.00%|    for k, new in enumerate(args):
    96|         0|            0|            0|  0.00%|        if not isinstance(new, _nx.ndarray):
    97|         0|            0|            0|  0.00%|            new = asarray(new)
    98|         0|            0|            0|  0.00%|            if new.size == 0:
    99|         0|            0|            0|  0.00%|                # Explicitly type empty arrays to avoid float default
   100|         0|            0|            0|  0.00%|                new = new.astype(_nx.intp)
   101|         0|            0|            0|  0.00%|        if new.ndim != 1:
   102|         0|            0|            0|  0.00%|            raise ValueError("Cross index must be 1 dimensional")
   103|         0|            0|            0|  0.00%|        if issubdtype(new.dtype, _nx.bool_):
   104|         0|            0|            0|  0.00%|            new, = new.nonzero()
   105|         0|            0|            0|  0.00%|        new = new.reshape((1,)*k + (new.size,) + (1,)*(nd-k-1))
   106|         0|            0|            0|  0.00%|        out.append(new)
   107|         0|            0|            0|  0.00%|    return tuple(out)
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|class nd_grid:
   110|         0|            0|            0|  0.00%|    """
   111|         0|            0|            0|  0.00%|    Construct a multi-dimensional "meshgrid".
   112|         0|            0|            0|  0.00%|
   113|         0|            0|            0|  0.00%|    ``grid = nd_grid()`` creates an instance which will return a mesh-grid
   114|         0|            0|            0|  0.00%|    when indexed.  The dimension and number of the output arrays are equal
   115|         0|            0|            0|  0.00%|    to the number of indexing dimensions.  If the step length is not a
   116|         0|            0|            0|  0.00%|    complex number, then the stop is not inclusive.
   117|         0|            0|            0|  0.00%|
   118|         0|            0|            0|  0.00%|    However, if the step length is a **complex number** (e.g. 5j), then the
   119|         0|            0|            0|  0.00%|    integer part of its magnitude is interpreted as specifying the
   120|         0|            0|            0|  0.00%|    number of points to create between the start and stop values, where
   121|         0|            0|            0|  0.00%|    the stop value **is inclusive**.
   122|         0|            0|            0|  0.00%|
   123|         0|            0|            0|  0.00%|    If instantiated with an argument of ``sparse=True``, the mesh-grid is
   124|         0|            0|            0|  0.00%|    open (or not fleshed out) so that only one-dimension of each returned
   125|         0|            0|            0|  0.00%|    argument is greater than 1.
   126|         0|            0|            0|  0.00%|
   127|         0|            0|            0|  0.00%|    Parameters
   128|         0|            0|            0|  0.00%|    ----------
   129|         0|            0|            0|  0.00%|    sparse : bool, optional
   130|         0|            0|            0|  0.00%|        Whether the grid is sparse or not. Default is False.
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|    Notes
   133|         0|            0|            0|  0.00%|    -----
   134|         0|            0|            0|  0.00%|    Two instances of `nd_grid` are made available in the NumPy namespace,
   135|         0|            0|            0|  0.00%|    `mgrid` and `ogrid`, approximately defined as::
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|        mgrid = nd_grid(sparse=False)
   138|         0|            0|            0|  0.00%|        ogrid = nd_grid(sparse=True)
   139|         0|            0|            0|  0.00%|
   140|         0|            0|            0|  0.00%|    Users should use these pre-defined instances instead of using `nd_grid`
   141|         0|            0|            0|  0.00%|    directly.
   142|         0|            0|            0|  0.00%|    """
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|    def __init__(self, sparse=False):
   145|         0|            0|            0|  0.00%|        self.sparse = sparse
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|    def __getitem__(self, key):
   148|         0|            0|            0|  0.00%|        try:
   149|         0|            0|            0|  0.00%|            size = []
   150|         0|            0|            0|  0.00%|            typ = int
   151|         0|            0|            0|  0.00%|            for k in range(len(key)):
   152|         0|            0|            0|  0.00%|                step = key[k].step
   153|         0|            0|            0|  0.00%|                start = key[k].start
   154|         0|            0|            0|  0.00%|                if start is None:
   155|         0|            0|            0|  0.00%|                    start = 0
   156|         0|            0|            0|  0.00%|                if step is None:
   157|         0|            0|            0|  0.00%|                    step = 1
   158|         0|            0|            0|  0.00%|                if isinstance(step, (_nx.complexfloating, complex)):
   159|         0|            0|            0|  0.00%|                    size.append(int(abs(step)))
   160|         0|            0|            0|  0.00%|                    typ = float
   161|         0|            0|            0|  0.00%|                else:
   162|         0|            0|            0|  0.00%|                    size.append(
   163|         0|            0|            0|  0.00%|                        int(math.ceil((key[k].stop - start)/(step*1.0))))
   164|         0|            0|            0|  0.00%|                if (isinstance(step, (_nx.floating, float)) or
   165|         0|            0|            0|  0.00%|                        isinstance(start, (_nx.floating, float)) or
   166|         0|            0|            0|  0.00%|                        isinstance(key[k].stop, (_nx.floating, float))):
   167|         0|            0|            0|  0.00%|                    typ = float
   168|         0|            0|            0|  0.00%|            if self.sparse:
   169|         0|            0|            0|  0.00%|                nn = [_nx.arange(_x, dtype=_t)
   170|         0|            0|            0|  0.00%|                        for _x, _t in zip(size, (typ,)*len(size))]
   171|         0|            0|            0|  0.00%|            else:
   172|         0|            0|            0|  0.00%|                nn = _nx.indices(size, typ)
   173|         0|            0|            0|  0.00%|            for k in range(len(size)):
   174|         0|            0|            0|  0.00%|                step = key[k].step
   175|         0|            0|            0|  0.00%|                start = key[k].start
   176|         0|            0|            0|  0.00%|                if start is None:
   177|         0|            0|            0|  0.00%|                    start = 0
   178|         0|            0|            0|  0.00%|                if step is None:
   179|         0|            0|            0|  0.00%|                    step = 1
   180|         0|            0|            0|  0.00%|                if isinstance(step, (_nx.complexfloating, complex)):
   181|         0|            0|            0|  0.00%|                    step = int(abs(step))
   182|         0|            0|            0|  0.00%|                    if step != 1:
   183|         0|            0|            0|  0.00%|                        step = (key[k].stop - start)/float(step-1)
   184|         0|            0|            0|  0.00%|                nn[k] = (nn[k]*step+start)
   185|         0|            0|            0|  0.00%|            if self.sparse:
   186|         0|            0|            0|  0.00%|                slobj = [_nx.newaxis]*len(size)
   187|         0|            0|            0|  0.00%|                for k in range(len(size)):
   188|         0|            0|            0|  0.00%|                    slobj[k] = slice(None, None)
   189|         0|            0|            0|  0.00%|                    nn[k] = nn[k][tuple(slobj)]
   190|         0|            0|            0|  0.00%|                    slobj[k] = _nx.newaxis
   191|         0|            0|            0|  0.00%|            return nn
   192|         0|            0|            0|  0.00%|        except (IndexError, TypeError):
   193|         0|            0|            0|  0.00%|            step = key.step
   194|         0|            0|            0|  0.00%|            stop = key.stop
   195|         0|            0|            0|  0.00%|            start = key.start
   196|         0|            0|            0|  0.00%|            if start is None:
   197|         0|            0|            0|  0.00%|                start = 0
   198|         0|            0|            0|  0.00%|            if isinstance(step, (_nx.complexfloating, complex)):
   199|         0|            0|            0|  0.00%|                step = abs(step)
   200|         0|            0|            0|  0.00%|                length = int(step)
   201|         0|            0|            0|  0.00%|                if step != 1:
   202|         0|            0|            0|  0.00%|                    step = (key.stop-start)/float(step-1)
   203|         0|            0|            0|  0.00%|                stop = key.stop + step
   204|         0|            0|            0|  0.00%|                return _nx.arange(0, length, 1, float)*step + start
   205|         0|            0|            0|  0.00%|            else:
   206|         0|            0|            0|  0.00%|                return _nx.arange(start, stop, step)
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|
   209|         0|            0|            0|  0.00%|class MGridClass(nd_grid):
   210|         0|            0|            0|  0.00%|    """
   211|         0|            0|            0|  0.00%|    `nd_grid` instance which returns a dense multi-dimensional "meshgrid".
   212|         0|            0|            0|  0.00%|
   213|         0|            0|            0|  0.00%|    An instance of `numpy.lib.index_tricks.nd_grid` which returns an dense
   214|         0|            0|            0|  0.00%|    (or fleshed out) mesh-grid when indexed, so that each returned argument
   215|         0|            0|            0|  0.00%|    has the same shape.  The dimensions and number of the output arrays are
   216|         0|            0|            0|  0.00%|    equal to the number of indexing dimensions.  If the step length is not a
   217|         0|            0|            0|  0.00%|    complex number, then the stop is not inclusive.
   218|         0|            0|            0|  0.00%|
   219|         0|            0|            0|  0.00%|    However, if the step length is a **complex number** (e.g. 5j), then
   220|         0|            0|            0|  0.00%|    the integer part of its magnitude is interpreted as specifying the
   221|         0|            0|            0|  0.00%|    number of points to create between the start and stop values, where
   222|         0|            0|            0|  0.00%|    the stop value **is inclusive**.
   223|         0|            0|            0|  0.00%|
   224|         0|            0|            0|  0.00%|    Returns
   225|         0|            0|            0|  0.00%|    -------
   226|         0|            0|            0|  0.00%|    mesh-grid `ndarrays` all of the same dimensions
   227|         0|            0|            0|  0.00%|
   228|         0|            0|            0|  0.00%|    See Also
   229|         0|            0|            0|  0.00%|    --------
   230|         0|            0|            0|  0.00%|    numpy.lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects
   231|         0|            0|            0|  0.00%|    ogrid : like mgrid but returns open (not fleshed out) mesh grids
   232|         0|            0|            0|  0.00%|    r_ : array concatenator
   233|         0|            0|            0|  0.00%|
   234|         0|            0|            0|  0.00%|    Examples
   235|         0|            0|            0|  0.00%|    --------
   236|         0|            0|            0|  0.00%|    >>> np.mgrid[0:5,0:5]
   237|         0|            0|            0|  0.00%|    array([[[0, 0, 0, 0, 0],
   238|         0|            0|            0|  0.00%|            [1, 1, 1, 1, 1],
   239|         0|            0|            0|  0.00%|            [2, 2, 2, 2, 2],
   240|         0|            0|            0|  0.00%|            [3, 3, 3, 3, 3],
   241|         0|            0|            0|  0.00%|            [4, 4, 4, 4, 4]],
   242|         0|            0|            0|  0.00%|           [[0, 1, 2, 3, 4],
   243|         0|            0|            0|  0.00%|            [0, 1, 2, 3, 4],
   244|         0|            0|            0|  0.00%|            [0, 1, 2, 3, 4],
   245|         0|            0|            0|  0.00%|            [0, 1, 2, 3, 4],
   246|         0|            0|            0|  0.00%|            [0, 1, 2, 3, 4]]])
   247|         0|            0|            0|  0.00%|    >>> np.mgrid[-1:1:5j]
   248|         0|            0|            0|  0.00%|    array([-1. , -0.5,  0. ,  0.5,  1. ])
   249|         0|            0|            0|  0.00%|
   250|         0|            0|            0|  0.00%|    """
   251|         0|            0|            0|  0.00%|    def __init__(self):
   252|         0|            0|            0|  0.00%|        super(MGridClass, self).__init__(sparse=False)
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|mgrid = MGridClass()
   255|         0|            0|            0|  0.00%|
   256|         0|            0|            0|  0.00%|class OGridClass(nd_grid):
   257|         0|            0|            0|  0.00%|    """
   258|         0|            0|            0|  0.00%|    `nd_grid` instance which returns an open multi-dimensional "meshgrid".
   259|         0|            0|            0|  0.00%|
   260|         0|            0|            0|  0.00%|    An instance of `numpy.lib.index_tricks.nd_grid` which returns an open
   261|         0|            0|            0|  0.00%|    (i.e. not fleshed out) mesh-grid when indexed, so that only one dimension
   262|         0|            0|            0|  0.00%|    of each returned array is greater than 1.  The dimension and number of the
   263|         0|            0|            0|  0.00%|    output arrays are equal to the number of indexing dimensions.  If the step
   264|         0|            0|            0|  0.00%|    length is not a complex number, then the stop is not inclusive.
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|    However, if the step length is a **complex number** (e.g. 5j), then
   267|         0|            0|            0|  0.00%|    the integer part of its magnitude is interpreted as specifying the
   268|         0|            0|            0|  0.00%|    number of points to create between the start and stop values, where
   269|         0|            0|            0|  0.00%|    the stop value **is inclusive**.
   270|         0|            0|            0|  0.00%|
   271|         0|            0|            0|  0.00%|    Returns
   272|         0|            0|            0|  0.00%|    -------
   273|         0|            0|            0|  0.00%|    mesh-grid
   274|         0|            0|            0|  0.00%|        `ndarrays` with only one dimension not equal to 1
   275|         0|            0|            0|  0.00%|
   276|         0|            0|            0|  0.00%|    See Also
   277|         0|            0|            0|  0.00%|    --------
   278|         0|            0|            0|  0.00%|    np.lib.index_tricks.nd_grid : class of `ogrid` and `mgrid` objects
   279|         0|            0|            0|  0.00%|    mgrid : like `ogrid` but returns dense (or fleshed out) mesh grids
   280|         0|            0|            0|  0.00%|    r_ : array concatenator
   281|         0|            0|            0|  0.00%|
   282|         0|            0|            0|  0.00%|    Examples
   283|         0|            0|            0|  0.00%|    --------
   284|         0|            0|            0|  0.00%|    >>> from numpy import ogrid
   285|         0|            0|            0|  0.00%|    >>> ogrid[-1:1:5j]
   286|         0|            0|            0|  0.00%|    array([-1. , -0.5,  0. ,  0.5,  1. ])
   287|         0|            0|            0|  0.00%|    >>> ogrid[0:5,0:5]
   288|         0|            0|            0|  0.00%|    [array([[0],
   289|         0|            0|            0|  0.00%|            [1],
   290|         0|            0|            0|  0.00%|            [2],
   291|         0|            0|            0|  0.00%|            [3],
   292|         0|            0|            0|  0.00%|            [4]]), array([[0, 1, 2, 3, 4]])]
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    """
   295|         0|            0|            0|  0.00%|    def __init__(self):
   296|         0|            0|            0|  0.00%|        super(OGridClass, self).__init__(sparse=True)
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|ogrid = OGridClass()
   299|         0|            0|            0|  0.00%|
   300|         0|            0|            0|  0.00%|
   301|         0|            0|            0|  0.00%|class AxisConcatenator:
   302|         0|            0|            0|  0.00%|    """
   303|         0|            0|            0|  0.00%|    Translates slice objects to concatenation along an axis.
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|    For detailed documentation on usage, see `r_`.
   306|         0|            0|            0|  0.00%|    """
   307|         0|            0|            0|  0.00%|    # allow ma.mr_ to override this
   308|         0|            0|            0|  0.00%|    concatenate = staticmethod(_nx.concatenate)
   309|         0|            0|            0|  0.00%|    makemat = staticmethod(matrixlib.matrix)
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|    def __init__(self, axis=0, matrix=False, ndmin=1, trans1d=-1):
   312|         0|            0|            0|  0.00%|        self.axis = axis
   313|         0|            0|            0|  0.00%|        self.matrix = matrix
   314|         0|            0|            0|  0.00%|        self.trans1d = trans1d
   315|         0|            0|            0|  0.00%|        self.ndmin = ndmin
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|    def __getitem__(self, key):
   318|         0|            0|            0|  0.00%|        # handle matrix builder syntax
   319|         0|            0|            0|  0.00%|        if isinstance(key, str):
   320|         0|            0|            0|  0.00%|            frame = sys._getframe().f_back
   321|         0|            0|            0|  0.00%|            mymat = matrixlib.bmat(key, frame.f_globals, frame.f_locals)
   322|         0|            0|            0|  0.00%|            return mymat
   323|         0|            0|            0|  0.00%|
   324|         0|            0|            0|  0.00%|        if not isinstance(key, tuple):
   325|         0|            0|            0|  0.00%|            key = (key,)
   326|         0|            0|            0|  0.00%|
   327|         0|            0|            0|  0.00%|        # copy attributes, since they can be overridden in the first argument
   328|         0|            0|            0|  0.00%|        trans1d = self.trans1d
   329|         0|            0|            0|  0.00%|        ndmin = self.ndmin
   330|         0|            0|            0|  0.00%|        matrix = self.matrix
   331|         0|            0|            0|  0.00%|        axis = self.axis
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|        objs = []
   334|         0|            0|            0|  0.00%|        scalars = []
   335|         0|            0|            0|  0.00%|        arraytypes = []
   336|         0|            0|            0|  0.00%|        scalartypes = []
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|        for k, item in enumerate(key):
   339|         0|            0|            0|  0.00%|            scalar = False
   340|         0|            0|            0|  0.00%|            if isinstance(item, slice):
   341|         0|            0|            0|  0.00%|                step = item.step
   342|         0|            0|            0|  0.00%|                start = item.start
   343|         0|            0|            0|  0.00%|                stop = item.stop
   344|         0|            0|            0|  0.00%|                if start is None:
   345|         0|            0|            0|  0.00%|                    start = 0
   346|         0|            0|            0|  0.00%|                if step is None:
   347|         0|            0|            0|  0.00%|                    step = 1
   348|         0|            0|            0|  0.00%|                if isinstance(step, (_nx.complexfloating, complex)):
   349|         0|            0|            0|  0.00%|                    size = int(abs(step))
   350|         0|            0|            0|  0.00%|                    newobj = linspace(start, stop, num=size)
   351|         0|            0|            0|  0.00%|                else:
   352|         0|            0|            0|  0.00%|                    newobj = _nx.arange(start, stop, step)
   353|         0|            0|            0|  0.00%|                if ndmin > 1:
   354|         0|            0|            0|  0.00%|                    newobj = array(newobj, copy=False, ndmin=ndmin)
   355|         0|            0|            0|  0.00%|                    if trans1d != -1:
   356|         0|            0|            0|  0.00%|                        newobj = newobj.swapaxes(-1, trans1d)
   357|         0|            0|            0|  0.00%|            elif isinstance(item, str):
   358|         0|            0|            0|  0.00%|                if k != 0:
   359|         0|            0|            0|  0.00%|                    raise ValueError("special directives must be the "
   360|         0|            0|            0|  0.00%|                            "first entry.")
   361|         0|            0|            0|  0.00%|                if item in ('r', 'c'):
   362|         0|            0|            0|  0.00%|                    matrix = True
   363|         0|            0|            0|  0.00%|                    col = (item == 'c')
   364|         0|            0|            0|  0.00%|                    continue
   365|         0|            0|            0|  0.00%|                if ',' in item:
   366|         0|            0|            0|  0.00%|                    vec = item.split(',')
   367|         0|            0|            0|  0.00%|                    try:
   368|         0|            0|            0|  0.00%|                        axis, ndmin = [int(x) for x in vec[:2]]
   369|         0|            0|            0|  0.00%|                        if len(vec) == 3:
   370|         0|            0|            0|  0.00%|                            trans1d = int(vec[2])
   371|         0|            0|            0|  0.00%|                        continue
   372|         0|            0|            0|  0.00%|                    except Exception as e:
   373|         0|            0|            0|  0.00%|                        raise ValueError(
   374|         0|            0|            0|  0.00%|                            "unknown special directive {!r}".format(item)
   375|         0|            0|            0|  0.00%|                        ) from e
   376|         0|            0|            0|  0.00%|                try:
   377|         0|            0|            0|  0.00%|                    axis = int(item)
   378|         0|            0|            0|  0.00%|                    continue
   379|         0|            0|            0|  0.00%|                except (ValueError, TypeError):
   380|         0|            0|            0|  0.00%|                    raise ValueError("unknown special directive")
   381|         0|            0|            0|  0.00%|            elif type(item) in ScalarType:
   382|         0|            0|            0|  0.00%|                newobj = array(item, ndmin=ndmin)
   383|         0|            0|            0|  0.00%|                scalars.append(len(objs))
   384|         0|            0|            0|  0.00%|                scalar = True
   385|         0|            0|            0|  0.00%|                scalartypes.append(newobj.dtype)
   386|         0|            0|            0|  0.00%|            else:
   387|         0|            0|            0|  0.00%|                item_ndim = ndim(item)
   388|         0|            0|            0|  0.00%|                newobj = array(item, copy=False, subok=True, ndmin=ndmin)
   389|         0|            0|            0|  0.00%|                if trans1d != -1 and item_ndim < ndmin:
   390|         0|            0|            0|  0.00%|                    k2 = ndmin - item_ndim
   391|         0|            0|            0|  0.00%|                    k1 = trans1d
   392|         0|            0|            0|  0.00%|                    if k1 < 0:
   393|         0|            0|            0|  0.00%|                        k1 += k2 + 1
   394|         0|            0|            0|  0.00%|                    defaxes = list(range(ndmin))
   395|         0|            0|            0|  0.00%|                    axes = defaxes[:k1] + defaxes[k2:] + defaxes[k1:k2]
   396|         0|            0|            0|  0.00%|                    newobj = newobj.transpose(axes)
   397|         0|            0|            0|  0.00%|            objs.append(newobj)
   398|         0|            0|            0|  0.00%|            if not scalar and isinstance(newobj, _nx.ndarray):
   399|         0|            0|            0|  0.00%|                arraytypes.append(newobj.dtype)
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|        # Ensure that scalars won't up-cast unless warranted
   402|         0|            0|            0|  0.00%|        final_dtype = find_common_type(arraytypes, scalartypes)
   403|         0|            0|            0|  0.00%|        if final_dtype is not None:
   404|         0|            0|            0|  0.00%|            for k in scalars:
   405|         0|            0|            0|  0.00%|                objs[k] = objs[k].astype(final_dtype)
   406|         0|            0|            0|  0.00%|
   407|         0|            0|            0|  0.00%|        res = self.concatenate(tuple(objs), axis=axis)
   408|         0|            0|            0|  0.00%|
   409|         0|            0|            0|  0.00%|        if matrix:
   410|         0|            0|            0|  0.00%|            oldndim = res.ndim
   411|         0|            0|            0|  0.00%|            res = self.makemat(res)
   412|         0|            0|            0|  0.00%|            if oldndim == 1 and col:
   413|         0|            0|            0|  0.00%|                res = res.T
   414|         0|            0|            0|  0.00%|        return res
   415|         0|            0|            0|  0.00%|
   416|         0|            0|            0|  0.00%|    def __len__(self):
   417|         0|            0|            0|  0.00%|        return 0
   418|         0|            0|            0|  0.00%|
   419|         0|            0|            0|  0.00%|# separate classes are used here instead of just making r_ = concatentor(0),
   420|         0|            0|            0|  0.00%|# etc. because otherwise we couldn't get the doc string to come out right
   421|         0|            0|            0|  0.00%|# in help(r_)
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|class RClass(AxisConcatenator):
   424|         0|            0|            0|  0.00%|    """
   425|         0|            0|            0|  0.00%|    Translates slice objects to concatenation along the first axis.
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|    This is a simple way to build up arrays quickly. There are two use cases.
   428|         0|            0|            0|  0.00%|
   429|         0|            0|            0|  0.00%|    1. If the index expression contains comma separated arrays, then stack
   430|         0|            0|            0|  0.00%|       them along their first axis.
   431|         0|            0|            0|  0.00%|    2. If the index expression contains slice notation or scalars then create
   432|         0|            0|            0|  0.00%|       a 1-D array with a range indicated by the slice notation.
   433|         0|            0|            0|  0.00%|
   434|         0|            0|            0|  0.00%|    If slice notation is used, the syntax ``start:stop:step`` is equivalent
   435|         0|            0|            0|  0.00%|    to ``np.arange(start, stop, step)`` inside of the brackets. However, if
   436|         0|            0|            0|  0.00%|    ``step`` is an imaginary number (i.e. 100j) then its integer portion is
   437|         0|            0|            0|  0.00%|    interpreted as a number-of-points desired and the start and stop are
   438|         0|            0|            0|  0.00%|    inclusive. In other words ``start:stop:stepj`` is interpreted as
   439|         0|            0|            0|  0.00%|    ``np.linspace(start, stop, step, endpoint=1)`` inside of the brackets.
   440|         0|            0|            0|  0.00%|    After expansion of slice notation, all comma separated sequences are
   441|         0|            0|            0|  0.00%|    concatenated together.
   442|         0|            0|            0|  0.00%|
   443|         0|            0|            0|  0.00%|    Optional character strings placed as the first element of the index
   444|         0|            0|            0|  0.00%|    expression can be used to change the output. The strings 'r' or 'c' result
   445|         0|            0|            0|  0.00%|    in matrix output. If the result is 1-D and 'r' is specified a 1 x N (row)
   446|         0|            0|            0|  0.00%|    matrix is produced. If the result is 1-D and 'c' is specified, then a N x 1
   447|         0|            0|            0|  0.00%|    (column) matrix is produced. If the result is 2-D then both provide the
   448|         0|            0|            0|  0.00%|    same matrix result.
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|    A string integer specifies which axis to stack multiple comma separated
   451|         0|            0|            0|  0.00%|    arrays along. A string of two comma-separated integers allows indication
   452|         0|            0|            0|  0.00%|    of the minimum number of dimensions to force each entry into as the
   453|         0|            0|            0|  0.00%|    second integer (the axis to concatenate along is still the first integer).
   454|         0|            0|            0|  0.00%|
   455|         0|            0|            0|  0.00%|    A string with three comma-separated integers allows specification of the
   456|         0|            0|            0|  0.00%|    axis to concatenate along, the minimum number of dimensions to force the
   457|         0|            0|            0|  0.00%|    entries to, and which axis should contain the start of the arrays which
   458|         0|            0|            0|  0.00%|    are less than the specified number of dimensions. In other words the third
   459|         0|            0|            0|  0.00%|    integer allows you to specify where the 1's should be placed in the shape
   460|         0|            0|            0|  0.00%|    of the arrays that have their shapes upgraded. By default, they are placed
   461|         0|            0|            0|  0.00%|    in the front of the shape tuple. The third argument allows you to specify
   462|         0|            0|            0|  0.00%|    where the start of the array should be instead. Thus, a third argument of
   463|         0|            0|            0|  0.00%|    '0' would place the 1's at the end of the array shape. Negative integers
   464|         0|            0|            0|  0.00%|    specify where in the new shape tuple the last dimension of upgraded arrays
   465|         0|            0|            0|  0.00%|    should be placed, so the default is '-1'.
   466|         0|            0|            0|  0.00%|
   467|         0|            0|            0|  0.00%|    Parameters
   468|         0|            0|            0|  0.00%|    ----------
   469|         0|            0|            0|  0.00%|    Not a function, so takes no parameters
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|
   472|         0|            0|            0|  0.00%|    Returns
   473|         0|            0|            0|  0.00%|    -------
   474|         0|            0|            0|  0.00%|    A concatenated ndarray or matrix.
   475|         0|            0|            0|  0.00%|
   476|         0|            0|            0|  0.00%|    See Also
   477|         0|            0|            0|  0.00%|    --------
   478|         0|            0|            0|  0.00%|    concatenate : Join a sequence of arrays along an existing axis.
   479|         0|            0|            0|  0.00%|    c_ : Translates slice objects to concatenation along the second axis.
   480|         0|            0|            0|  0.00%|
   481|         0|            0|            0|  0.00%|    Examples
   482|         0|            0|            0|  0.00%|    --------
   483|         0|            0|            0|  0.00%|    >>> np.r_[np.array([1,2,3]), 0, 0, np.array([4,5,6])]
   484|         0|            0|            0|  0.00%|    array([1, 2, 3, ..., 4, 5, 6])
   485|         0|            0|            0|  0.00%|    >>> np.r_[-1:1:6j, [0]*3, 5, 6]
   486|         0|            0|            0|  0.00%|    array([-1. , -0.6, -0.2,  0.2,  0.6,  1. ,  0. ,  0. ,  0. ,  5. ,  6. ])
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    String integers specify the axis to concatenate along or the minimum
   489|         0|            0|            0|  0.00%|    number of dimensions to force entries into.
   490|         0|            0|            0|  0.00%|
   491|         0|            0|            0|  0.00%|    >>> a = np.array([[0, 1, 2], [3, 4, 5]])
   492|         0|            0|            0|  0.00%|    >>> np.r_['-1', a, a] # concatenate along last axis
   493|         0|            0|            0|  0.00%|    array([[0, 1, 2, 0, 1, 2],
   494|         0|            0|            0|  0.00%|           [3, 4, 5, 3, 4, 5]])
   495|         0|            0|            0|  0.00%|    >>> np.r_['0,2', [1,2,3], [4,5,6]] # concatenate along first axis, dim>=2
   496|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   497|         0|            0|            0|  0.00%|           [4, 5, 6]])
   498|         0|            0|            0|  0.00%|
   499|         0|            0|            0|  0.00%|    >>> np.r_['0,2,0', [1,2,3], [4,5,6]]
   500|         0|            0|            0|  0.00%|    array([[1],
   501|         0|            0|            0|  0.00%|           [2],
   502|         0|            0|            0|  0.00%|           [3],
   503|         0|            0|            0|  0.00%|           [4],
   504|         0|            0|            0|  0.00%|           [5],
   505|         0|            0|            0|  0.00%|           [6]])
   506|         0|            0|            0|  0.00%|    >>> np.r_['1,2,0', [1,2,3], [4,5,6]]
   507|         0|            0|            0|  0.00%|    array([[1, 4],
   508|         0|            0|            0|  0.00%|           [2, 5],
   509|         0|            0|            0|  0.00%|           [3, 6]])
   510|         0|            0|            0|  0.00%|
   511|         0|            0|            0|  0.00%|    Using 'r' or 'c' as a first string argument creates a matrix.
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|    >>> np.r_['r',[1,2,3], [4,5,6]]
   514|         0|            0|            0|  0.00%|    matrix([[1, 2, 3, 4, 5, 6]])
   515|         0|            0|            0|  0.00%|
   516|         0|            0|            0|  0.00%|    """
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|    def __init__(self):
   519|         0|            0|            0|  0.00%|        AxisConcatenator.__init__(self, 0)
   520|         0|            0|            0|  0.00%|
   521|         0|            0|            0|  0.00%|r_ = RClass()
   522|         0|            0|            0|  0.00%|
   523|         0|            0|            0|  0.00%|class CClass(AxisConcatenator):
   524|         0|            0|            0|  0.00%|    """
   525|         0|            0|            0|  0.00%|    Translates slice objects to concatenation along the second axis.
   526|         0|            0|            0|  0.00%|
   527|         0|            0|            0|  0.00%|    This is short-hand for ``np.r_['-1,2,0', index expression]``, which is
   528|         0|            0|            0|  0.00%|    useful because of its common occurrence. In particular, arrays will be
   529|         0|            0|            0|  0.00%|    stacked along their last axis after being upgraded to at least 2-D with
   530|         0|            0|            0|  0.00%|    1's post-pended to the shape (column vectors made out of 1-D arrays).
   531|         0|            0|            0|  0.00%|
   532|         0|            0|            0|  0.00%|    See Also
   533|         0|            0|            0|  0.00%|    --------
   534|         0|            0|            0|  0.00%|    column_stack : Stack 1-D arrays as columns into a 2-D array.
   535|         0|            0|            0|  0.00%|    r_ : For more detailed documentation.
   536|         0|            0|            0|  0.00%|
   537|         0|            0|            0|  0.00%|    Examples
   538|         0|            0|            0|  0.00%|    --------
   539|         0|            0|            0|  0.00%|    >>> np.c_[np.array([1,2,3]), np.array([4,5,6])]
   540|         0|            0|            0|  0.00%|    array([[1, 4],
   541|         0|            0|            0|  0.00%|           [2, 5],
   542|         0|            0|            0|  0.00%|           [3, 6]])
   543|         0|            0|            0|  0.00%|    >>> np.c_[np.array([[1,2,3]]), 0, 0, np.array([[4,5,6]])]
   544|         0|            0|            0|  0.00%|    array([[1, 2, 3, ..., 4, 5, 6]])
   545|         0|            0|            0|  0.00%|
   546|         0|            0|            0|  0.00%|    """
   547|         0|            0|            0|  0.00%|
   548|         0|            0|            0|  0.00%|    def __init__(self):
   549|         0|            0|            0|  0.00%|        AxisConcatenator.__init__(self, -1, ndmin=2, trans1d=0)
   550|         0|            0|            0|  0.00%|
   551|         0|            0|            0|  0.00%|
   552|         0|            0|            0|  0.00%|c_ = CClass()
   553|         0|            0|            0|  0.00%|
   554|         0|            0|            0|  0.00%|
   555|         0|            0|            0|  0.00%|@set_module('numpy')
   556|         0|            0|            0|  0.00%|class ndenumerate:
   557|         0|            0|            0|  0.00%|    """
   558|         0|            0|            0|  0.00%|    Multidimensional index iterator.
   559|         0|            0|            0|  0.00%|
   560|         0|            0|            0|  0.00%|    Return an iterator yielding pairs of array coordinates and values.
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|    Parameters
   563|         0|            0|            0|  0.00%|    ----------
   564|         0|            0|            0|  0.00%|    arr : ndarray
   565|         0|            0|            0|  0.00%|      Input array.
   566|         0|            0|            0|  0.00%|
   567|         0|            0|            0|  0.00%|    See Also
   568|         0|            0|            0|  0.00%|    --------
   569|         0|            0|            0|  0.00%|    ndindex, flatiter
   570|         0|            0|            0|  0.00%|
   571|         0|            0|            0|  0.00%|    Examples
   572|         0|            0|            0|  0.00%|    --------
   573|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
   574|         0|            0|            0|  0.00%|    >>> for index, x in np.ndenumerate(a):
   575|         0|            0|            0|  0.00%|    ...     print(index, x)
   576|         0|            0|            0|  0.00%|    (0, 0) 1
   577|         0|            0|            0|  0.00%|    (0, 1) 2
   578|         0|            0|            0|  0.00%|    (1, 0) 3
   579|         0|            0|            0|  0.00%|    (1, 1) 4
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    """
   582|         0|            0|            0|  0.00%|
   583|         0|            0|            0|  0.00%|    def __init__(self, arr):
   584|         0|            0|            0|  0.00%|        self.iter = asarray(arr).flat
   585|         0|            0|            0|  0.00%|
   586|         0|            0|            0|  0.00%|    def __next__(self):
   587|         0|            0|            0|  0.00%|        """
   588|         0|            0|            0|  0.00%|        Standard iterator method, returns the index tuple and array value.
   589|         0|            0|            0|  0.00%|
   590|         0|            0|            0|  0.00%|        Returns
   591|         0|            0|            0|  0.00%|        -------
   592|         0|            0|            0|  0.00%|        coords : tuple of ints
   593|         0|            0|            0|  0.00%|            The indices of the current iteration.
   594|         0|            0|            0|  0.00%|        val : scalar
   595|         0|            0|            0|  0.00%|            The array element of the current iteration.
   596|         0|            0|            0|  0.00%|
   597|         0|            0|            0|  0.00%|        """
   598|         0|            0|            0|  0.00%|        return self.iter.coords, next(self.iter)
   599|         0|            0|            0|  0.00%|
   600|         0|            0|            0|  0.00%|    def __iter__(self):
   601|         0|            0|            0|  0.00%|        return self
   602|         0|            0|            0|  0.00%|
   603|         0|            0|            0|  0.00%|
   604|         0|            0|            0|  0.00%|@set_module('numpy')
   605|         0|            0|            0|  0.00%|class ndindex:
   606|         0|            0|            0|  0.00%|    """
   607|         0|            0|            0|  0.00%|    An N-dimensional iterator object to index arrays.
   608|         0|            0|            0|  0.00%|
   609|         0|            0|            0|  0.00%|    Given the shape of an array, an `ndindex` instance iterates over
   610|         0|            0|            0|  0.00%|    the N-dimensional index of the array. At each iteration a tuple
   611|         0|            0|            0|  0.00%|    of indices is returned, the last dimension is iterated over first.
   612|         0|            0|            0|  0.00%|
   613|         0|            0|            0|  0.00%|    Parameters
   614|         0|            0|            0|  0.00%|    ----------
   615|         0|            0|            0|  0.00%|    shape : ints, or a single tuple of ints
   616|         0|            0|            0|  0.00%|        The size of each dimension of the array can be passed as
   617|         0|            0|            0|  0.00%|        individual parameters or as the elements of a tuple.
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|    See Also
   620|         0|            0|            0|  0.00%|    --------
   621|         0|            0|            0|  0.00%|    ndenumerate, flatiter
   622|         0|            0|            0|  0.00%|
   623|         0|            0|            0|  0.00%|    Examples
   624|         0|            0|            0|  0.00%|    --------
   625|         0|            0|            0|  0.00%|    # dimensions as individual arguments
   626|         0|            0|            0|  0.00%|    >>> for index in np.ndindex(3, 2, 1):
   627|         0|            0|            0|  0.00%|    ...     print(index)
   628|         0|            0|            0|  0.00%|    (0, 0, 0)
   629|         0|            0|            0|  0.00%|    (0, 1, 0)
   630|         0|            0|            0|  0.00%|    (1, 0, 0)
   631|         0|            0|            0|  0.00%|    (1, 1, 0)
   632|         0|            0|            0|  0.00%|    (2, 0, 0)
   633|         0|            0|            0|  0.00%|    (2, 1, 0)
   634|         0|            0|            0|  0.00%|
   635|         0|            0|            0|  0.00%|    # same dimensions - but in a tuple (3, 2, 1)
   636|         0|            0|            0|  0.00%|    >>> for index in np.ndindex((3, 2, 1)):
   637|         0|            0|            0|  0.00%|    ...     print(index)
   638|         0|            0|            0|  0.00%|    (0, 0, 0)
   639|         0|            0|            0|  0.00%|    (0, 1, 0)
   640|         0|            0|            0|  0.00%|    (1, 0, 0)
   641|         0|            0|            0|  0.00%|    (1, 1, 0)
   642|         0|            0|            0|  0.00%|    (2, 0, 0)
   643|         0|            0|            0|  0.00%|    (2, 1, 0)
   644|         0|            0|            0|  0.00%|
   645|         0|            0|            0|  0.00%|    """
   646|         0|            0|            0|  0.00%|
   647|         1|  3.09944e-06|  3.09944e-06|  0.00%|    def __init__(self, *shape):
   648|         1|  5.72205e-06|  5.72205e-06|  0.00%|        if len(shape) == 1 and isinstance(shape[0], tuple):
   649|         1|  2.14577e-06|  2.14577e-06|  0.00%|            shape = shape[0]
   650|         2|  1.33514e-05|  6.67572e-06|  0.00%|        x = as_strided(_nx.zeros(1), shape=shape,
(call)|         1|  9.53674e-05|  9.53674e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/stride_tricks.py:38 as_strided
   651|         1|  7.39098e-06|  7.39098e-06|  0.00%|                       strides=_nx.zeros_like(shape))
(call)|         1|   0.00010705|   0.00010705|  0.01%|# <__array_function__ internals>_8:2 zeros_like
   652|         2|  8.82149e-06|  4.41074e-06|  0.00%|        self._it = _nx.nditer(x, flags=['multi_index', 'zerosize_ok'],
   653|         1|  2.38419e-06|  2.38419e-06|  0.00%|                              order='C')
   654|         0|            0|            0|  0.00%|
   655|         1|  1.90735e-06|  1.90735e-06|  0.00%|    def __iter__(self):
   656|         1|  2.14577e-06|  2.14577e-06|  0.00%|        return self
   657|         0|            0|            0|  0.00%|
   658|         0|            0|            0|  0.00%|    def ndincr(self):
   659|         0|            0|            0|  0.00%|        """
   660|         0|            0|            0|  0.00%|        Increment the multi-dimensional index by one.
   661|         0|            0|            0|  0.00%|
   662|         0|            0|            0|  0.00%|        This method is for backward compatibility only: do not use.
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|        .. deprecated:: 1.20.0
   665|         0|            0|            0|  0.00%|            This method has been advised against since numpy 1.8.0, but only
   666|         0|            0|            0|  0.00%|            started emitting DeprecationWarning as of this version.
   667|         0|            0|            0|  0.00%|        """
   668|         0|            0|            0|  0.00%|        # NumPy 1.20.0, 2020-09-08
   669|         0|            0|            0|  0.00%|        warnings.warn(
   670|         0|            0|            0|  0.00%|            "`ndindex.ndincr()` is deprecated, use `next(ndindex)` instead",
   671|         0|            0|            0|  0.00%|            DeprecationWarning, stacklevel=2)
   672|         0|            0|            0|  0.00%|        next(self)
   673|         0|            0|            0|  0.00%|
   674|      1001|   0.00115776|   1.1566e-06|  0.13%|    def __next__(self):
   675|         0|            0|            0|  0.00%|        """
   676|         0|            0|            0|  0.00%|        Standard iterator method, updates the index and returns the index
   677|         0|            0|            0|  0.00%|        tuple.
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|        Returns
   680|         0|            0|            0|  0.00%|        -------
   681|         0|            0|            0|  0.00%|        val : tuple of ints
   682|         0|            0|            0|  0.00%|            Returns a tuple containing the indices of the current
   683|         0|            0|            0|  0.00%|            iteration.
   684|         0|            0|            0|  0.00%|
   685|         0|            0|            0|  0.00%|        """
   686|      1001|   0.00179744|  1.79564e-06|  0.21%|        next(self._it)
   687|      1000|   0.00151253|  1.51253e-06|  0.18%|        return self._it.multi_index
   688|         0|            0|            0|  0.00%|
   689|         0|            0|            0|  0.00%|
   690|         0|            0|            0|  0.00%|# You can do all this with slice() plus a few special objects,
   691|         0|            0|            0|  0.00%|# but there's a lot to remember. This version is simpler because
   692|         0|            0|            0|  0.00%|# it uses the standard array indexing syntax.
   693|         0|            0|            0|  0.00%|#
   694|         0|            0|            0|  0.00%|# Written by Konrad Hinsen <hinsen@cnrs-orleans.fr>
   695|         0|            0|            0|  0.00%|# last revision: 1999-7-23
   696|         0|            0|            0|  0.00%|#
   697|         0|            0|            0|  0.00%|# Cosmetic changes by T. Oliphant 2001
   698|         0|            0|            0|  0.00%|#
   699|         0|            0|            0|  0.00%|#
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|class IndexExpression:
   702|         0|            0|            0|  0.00%|    """
   703|         0|            0|            0|  0.00%|    A nicer way to build up index tuples for arrays.
   704|         0|            0|            0|  0.00%|
   705|         0|            0|            0|  0.00%|    .. note::
   706|         0|            0|            0|  0.00%|       Use one of the two predefined instances `index_exp` or `s_`
   707|         0|            0|            0|  0.00%|       rather than directly using `IndexExpression`.
   708|         0|            0|            0|  0.00%|
   709|         0|            0|            0|  0.00%|    For any index combination, including slicing and axis insertion,
   710|         0|            0|            0|  0.00%|    ``a[indices]`` is the same as ``a[np.index_exp[indices]]`` for any
   711|         0|            0|            0|  0.00%|    array `a`. However, ``np.index_exp[indices]`` can be used anywhere
   712|         0|            0|            0|  0.00%|    in Python code and returns a tuple of slice objects that can be
   713|         0|            0|            0|  0.00%|    used in the construction of complex index expressions.
   714|         0|            0|            0|  0.00%|
   715|         0|            0|            0|  0.00%|    Parameters
   716|         0|            0|            0|  0.00%|    ----------
   717|         0|            0|            0|  0.00%|    maketuple : bool
   718|         0|            0|            0|  0.00%|        If True, always returns a tuple.
   719|         0|            0|            0|  0.00%|
   720|         0|            0|            0|  0.00%|    See Also
   721|         0|            0|            0|  0.00%|    --------
   722|         0|            0|            0|  0.00%|    index_exp : Predefined instance that always returns a tuple:
   723|         0|            0|            0|  0.00%|       `index_exp = IndexExpression(maketuple=True)`.
   724|         0|            0|            0|  0.00%|    s_ : Predefined instance without tuple conversion:
   725|         0|            0|            0|  0.00%|       `s_ = IndexExpression(maketuple=False)`.
   726|         0|            0|            0|  0.00%|
   727|         0|            0|            0|  0.00%|    Notes
   728|         0|            0|            0|  0.00%|    -----
   729|         0|            0|            0|  0.00%|    You can do all this with `slice()` plus a few special objects,
   730|         0|            0|            0|  0.00%|    but there's a lot to remember and this version is simpler because
   731|         0|            0|            0|  0.00%|    it uses the standard array indexing syntax.
   732|         0|            0|            0|  0.00%|
   733|         0|            0|            0|  0.00%|    Examples
   734|         0|            0|            0|  0.00%|    --------
   735|         0|            0|            0|  0.00%|    >>> np.s_[2::2]
   736|         0|            0|            0|  0.00%|    slice(2, None, 2)
   737|         0|            0|            0|  0.00%|    >>> np.index_exp[2::2]
   738|         0|            0|            0|  0.00%|    (slice(2, None, 2),)
   739|         0|            0|            0|  0.00%|
   740|         0|            0|            0|  0.00%|    >>> np.array([0, 1, 2, 3, 4])[np.s_[2::2]]
   741|         0|            0|            0|  0.00%|    array([2, 4])
   742|         0|            0|            0|  0.00%|
   743|         0|            0|            0|  0.00%|    """
   744|         0|            0|            0|  0.00%|
   745|         0|            0|            0|  0.00%|    def __init__(self, maketuple):
   746|         0|            0|            0|  0.00%|        self.maketuple = maketuple
   747|         0|            0|            0|  0.00%|
   748|         0|            0|            0|  0.00%|    def __getitem__(self, item):
   749|         0|            0|            0|  0.00%|        if self.maketuple and not isinstance(item, tuple):
   750|         0|            0|            0|  0.00%|            return (item,)
   751|         0|            0|            0|  0.00%|        else:
   752|         0|            0|            0|  0.00%|            return item
   753|         0|            0|            0|  0.00%|
   754|         0|            0|            0|  0.00%|index_exp = IndexExpression(maketuple=True)
   755|         0|            0|            0|  0.00%|s_ = IndexExpression(maketuple=False)
   756|         0|            0|            0|  0.00%|
   757|         0|            0|            0|  0.00%|# End contribution from Konrad.
   758|         0|            0|            0|  0.00%|
   759|         0|            0|            0|  0.00%|
   760|         0|            0|            0|  0.00%|# The following functions complement those in twodim_base, but are
   761|         0|            0|            0|  0.00%|# applicable to N-dimensions.
   762|         0|            0|            0|  0.00%|
   763|         0|            0|            0|  0.00%|
   764|         0|            0|            0|  0.00%|def _fill_diagonal_dispatcher(a, val, wrap=None):
   765|         0|            0|            0|  0.00%|    return (a,)
   766|         0|            0|            0|  0.00%|
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|@array_function_dispatch(_fill_diagonal_dispatcher)
   769|         0|            0|            0|  0.00%|def fill_diagonal(a, val, wrap=False):
   770|         0|            0|            0|  0.00%|    """Fill the main diagonal of the given array of any dimensionality.
   771|         0|            0|            0|  0.00%|
   772|         0|            0|            0|  0.00%|    For an array `a` with ``a.ndim >= 2``, the diagonal is the list of
   773|         0|            0|            0|  0.00%|    locations with indices ``a[i, ..., i]`` all identical. This function
   774|         0|            0|            0|  0.00%|    modifies the input array in-place, it does not return a value.
   775|         0|            0|            0|  0.00%|
   776|         0|            0|            0|  0.00%|    Parameters
   777|         0|            0|            0|  0.00%|    ----------
   778|         0|            0|            0|  0.00%|    a : array, at least 2-D.
   779|         0|            0|            0|  0.00%|      Array whose diagonal is to be filled, it gets modified in-place.
   780|         0|            0|            0|  0.00%|
   781|         0|            0|            0|  0.00%|    val : scalar or array_like
   782|         0|            0|            0|  0.00%|      Value(s) to write on the diagonal. If `val` is scalar, the value is
   783|         0|            0|            0|  0.00%|      written along the diagonal. If array-like, the flattened `val` is
   784|         0|            0|            0|  0.00%|      written along the diagonal, repeating if necessary to fill all
   785|         0|            0|            0|  0.00%|      diagonal entries.
   786|         0|            0|            0|  0.00%|
   787|         0|            0|            0|  0.00%|    wrap : bool
   788|         0|            0|            0|  0.00%|      For tall matrices in NumPy version up to 1.6.2, the
   789|         0|            0|            0|  0.00%|      diagonal "wrapped" after N columns. You can have this behavior
   790|         0|            0|            0|  0.00%|      with this option. This affects only tall matrices.
   791|         0|            0|            0|  0.00%|
   792|         0|            0|            0|  0.00%|    See also
   793|         0|            0|            0|  0.00%|    --------
   794|         0|            0|            0|  0.00%|    diag_indices, diag_indices_from
   795|         0|            0|            0|  0.00%|
   796|         0|            0|            0|  0.00%|    Notes
   797|         0|            0|            0|  0.00%|    -----
   798|         0|            0|            0|  0.00%|    .. versionadded:: 1.4.0
   799|         0|            0|            0|  0.00%|
   800|         0|            0|            0|  0.00%|    This functionality can be obtained via `diag_indices`, but internally
   801|         0|            0|            0|  0.00%|    this version uses a much faster implementation that never constructs the
   802|         0|            0|            0|  0.00%|    indices and uses simple slicing.
   803|         0|            0|            0|  0.00%|
   804|         0|            0|            0|  0.00%|    Examples
   805|         0|            0|            0|  0.00%|    --------
   806|         0|            0|            0|  0.00%|    >>> a = np.zeros((3, 3), int)
   807|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(a, 5)
   808|         0|            0|            0|  0.00%|    >>> a
   809|         0|            0|            0|  0.00%|    array([[5, 0, 0],
   810|         0|            0|            0|  0.00%|           [0, 5, 0],
   811|         0|            0|            0|  0.00%|           [0, 0, 5]])
   812|         0|            0|            0|  0.00%|
   813|         0|            0|            0|  0.00%|    The same function can operate on a 4-D array:
   814|         0|            0|            0|  0.00%|
   815|         0|            0|            0|  0.00%|    >>> a = np.zeros((3, 3, 3, 3), int)
   816|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(a, 4)
   817|         0|            0|            0|  0.00%|
   818|         0|            0|            0|  0.00%|    We only show a few blocks for clarity:
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|    >>> a[0, 0]
   821|         0|            0|            0|  0.00%|    array([[4, 0, 0],
   822|         0|            0|            0|  0.00%|           [0, 0, 0],
   823|         0|            0|            0|  0.00%|           [0, 0, 0]])
   824|         0|            0|            0|  0.00%|    >>> a[1, 1]
   825|         0|            0|            0|  0.00%|    array([[0, 0, 0],
   826|         0|            0|            0|  0.00%|           [0, 4, 0],
   827|         0|            0|            0|  0.00%|           [0, 0, 0]])
   828|         0|            0|            0|  0.00%|    >>> a[2, 2]
   829|         0|            0|            0|  0.00%|    array([[0, 0, 0],
   830|         0|            0|            0|  0.00%|           [0, 0, 0],
   831|         0|            0|            0|  0.00%|           [0, 0, 4]])
   832|         0|            0|            0|  0.00%|
   833|         0|            0|            0|  0.00%|    The wrap option affects only tall matrices:
   834|         0|            0|            0|  0.00%|
   835|         0|            0|            0|  0.00%|    >>> # tall matrices no wrap
   836|         0|            0|            0|  0.00%|    >>> a = np.zeros((5, 3), int)
   837|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(a, 4)
   838|         0|            0|            0|  0.00%|    >>> a
   839|         0|            0|            0|  0.00%|    array([[4, 0, 0],
   840|         0|            0|            0|  0.00%|           [0, 4, 0],
   841|         0|            0|            0|  0.00%|           [0, 0, 4],
   842|         0|            0|            0|  0.00%|           [0, 0, 0],
   843|         0|            0|            0|  0.00%|           [0, 0, 0]])
   844|         0|            0|            0|  0.00%|
   845|         0|            0|            0|  0.00%|    >>> # tall matrices wrap
   846|         0|            0|            0|  0.00%|    >>> a = np.zeros((5, 3), int)
   847|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(a, 4, wrap=True)
   848|         0|            0|            0|  0.00%|    >>> a
   849|         0|            0|            0|  0.00%|    array([[4, 0, 0],
   850|         0|            0|            0|  0.00%|           [0, 4, 0],
   851|         0|            0|            0|  0.00%|           [0, 0, 4],
   852|         0|            0|            0|  0.00%|           [0, 0, 0],
   853|         0|            0|            0|  0.00%|           [4, 0, 0]])
   854|         0|            0|            0|  0.00%|
   855|         0|            0|            0|  0.00%|    >>> # wide matrices
   856|         0|            0|            0|  0.00%|    >>> a = np.zeros((3, 5), int)
   857|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(a, 4, wrap=True)
   858|         0|            0|            0|  0.00%|    >>> a
   859|         0|            0|            0|  0.00%|    array([[4, 0, 0, 0, 0],
   860|         0|            0|            0|  0.00%|           [0, 4, 0, 0, 0],
   861|         0|            0|            0|  0.00%|           [0, 0, 4, 0, 0]])
   862|         0|            0|            0|  0.00%|
   863|         0|            0|            0|  0.00%|    The anti-diagonal can be filled by reversing the order of elements
   864|         0|            0|            0|  0.00%|    using either `numpy.flipud` or `numpy.fliplr`.
   865|         0|            0|            0|  0.00%|
   866|         0|            0|            0|  0.00%|    >>> a = np.zeros((3, 3), int);
   867|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(np.fliplr(a), [1,2,3])  # Horizontal flip
   868|         0|            0|            0|  0.00%|    >>> a
   869|         0|            0|            0|  0.00%|    array([[0, 0, 1],
   870|         0|            0|            0|  0.00%|           [0, 2, 0],
   871|         0|            0|            0|  0.00%|           [3, 0, 0]])
   872|         0|            0|            0|  0.00%|    >>> np.fill_diagonal(np.flipud(a), [1,2,3])  # Vertical flip
   873|         0|            0|            0|  0.00%|    >>> a
   874|         0|            0|            0|  0.00%|    array([[0, 0, 3],
   875|         0|            0|            0|  0.00%|           [0, 2, 0],
   876|         0|            0|            0|  0.00%|           [1, 0, 0]])
   877|         0|            0|            0|  0.00%|
   878|         0|            0|            0|  0.00%|    Note that the order in which the diagonal is filled varies depending
   879|         0|            0|            0|  0.00%|    on the flip function.
   880|         0|            0|            0|  0.00%|    """
   881|         0|            0|            0|  0.00%|    if a.ndim < 2:
   882|         0|            0|            0|  0.00%|        raise ValueError("array must be at least 2-d")
   883|         0|            0|            0|  0.00%|    end = None
   884|         0|            0|            0|  0.00%|    if a.ndim == 2:
   885|         0|            0|            0|  0.00%|        # Explicit, fast formula for the common case.  For 2-d arrays, we
   886|         0|            0|            0|  0.00%|        # accept rectangular ones.
   887|         0|            0|            0|  0.00%|        step = a.shape[1] + 1
   888|         0|            0|            0|  0.00%|        #This is needed to don't have tall matrix have the diagonal wrap.
   889|         0|            0|            0|  0.00%|        if not wrap:
   890|         0|            0|            0|  0.00%|            end = a.shape[1] * a.shape[1]
   891|         0|            0|            0|  0.00%|    else:
   892|         0|            0|            0|  0.00%|        # For more than d=2, the strided formula is only valid for arrays with
   893|         0|            0|            0|  0.00%|        # all dimensions equal, so we check first.
   894|         0|            0|            0|  0.00%|        if not alltrue(diff(a.shape) == 0):
   895|         0|            0|            0|  0.00%|            raise ValueError("All dimensions of input must be of equal length")
   896|         0|            0|            0|  0.00%|        step = 1 + (cumprod(a.shape[:-1])).sum()
   897|         0|            0|            0|  0.00%|
   898|         0|            0|            0|  0.00%|    # Write the value out into the diagonal.
   899|         0|            0|            0|  0.00%|    a.flat[:end:step] = val
   900|         0|            0|            0|  0.00%|
   901|         0|            0|            0|  0.00%|
   902|         0|            0|            0|  0.00%|@set_module('numpy')
   903|         0|            0|            0|  0.00%|def diag_indices(n, ndim=2):
   904|         0|            0|            0|  0.00%|    """
   905|         0|            0|            0|  0.00%|    Return the indices to access the main diagonal of an array.
   906|         0|            0|            0|  0.00%|
   907|         0|            0|            0|  0.00%|    This returns a tuple of indices that can be used to access the main
   908|         0|            0|            0|  0.00%|    diagonal of an array `a` with ``a.ndim >= 2`` dimensions and shape
   909|         0|            0|            0|  0.00%|    (n, n, ..., n). For ``a.ndim = 2`` this is the usual diagonal, for
   910|         0|            0|            0|  0.00%|    ``a.ndim > 2`` this is the set of indices to access ``a[i, i, ..., i]``
   911|         0|            0|            0|  0.00%|    for ``i = [0..n-1]``.
   912|         0|            0|            0|  0.00%|
   913|         0|            0|            0|  0.00%|    Parameters
   914|         0|            0|            0|  0.00%|    ----------
   915|         0|            0|            0|  0.00%|    n : int
   916|         0|            0|            0|  0.00%|      The size, along each dimension, of the arrays for which the returned
   917|         0|            0|            0|  0.00%|      indices can be used.
   918|         0|            0|            0|  0.00%|
   919|         0|            0|            0|  0.00%|    ndim : int, optional
   920|         0|            0|            0|  0.00%|      The number of dimensions.
   921|         0|            0|            0|  0.00%|
   922|         0|            0|            0|  0.00%|    See Also
   923|         0|            0|            0|  0.00%|    --------
   924|         0|            0|            0|  0.00%|    diag_indices_from
   925|         0|            0|            0|  0.00%|
   926|         0|            0|            0|  0.00%|    Notes
   927|         0|            0|            0|  0.00%|    -----
   928|         0|            0|            0|  0.00%|    .. versionadded:: 1.4.0
   929|         0|            0|            0|  0.00%|
   930|         0|            0|            0|  0.00%|    Examples
   931|         0|            0|            0|  0.00%|    --------
   932|         0|            0|            0|  0.00%|    Create a set of indices to access the diagonal of a (4, 4) array:
   933|         0|            0|            0|  0.00%|
   934|         0|            0|            0|  0.00%|    >>> di = np.diag_indices(4)
   935|         0|            0|            0|  0.00%|    >>> di
   936|         0|            0|            0|  0.00%|    (array([0, 1, 2, 3]), array([0, 1, 2, 3]))
   937|         0|            0|            0|  0.00%|    >>> a = np.arange(16).reshape(4, 4)
   938|         0|            0|            0|  0.00%|    >>> a
   939|         0|            0|            0|  0.00%|    array([[ 0,  1,  2,  3],
   940|         0|            0|            0|  0.00%|           [ 4,  5,  6,  7],
   941|         0|            0|            0|  0.00%|           [ 8,  9, 10, 11],
   942|         0|            0|            0|  0.00%|           [12, 13, 14, 15]])
   943|         0|            0|            0|  0.00%|    >>> a[di] = 100
   944|         0|            0|            0|  0.00%|    >>> a
   945|         0|            0|            0|  0.00%|    array([[100,   1,   2,   3],
   946|         0|            0|            0|  0.00%|           [  4, 100,   6,   7],
   947|         0|            0|            0|  0.00%|           [  8,   9, 100,  11],
   948|         0|            0|            0|  0.00%|           [ 12,  13,  14, 100]])
   949|         0|            0|            0|  0.00%|
   950|         0|            0|            0|  0.00%|    Now, we create indices to manipulate a 3-D array:
   951|         0|            0|            0|  0.00%|
   952|         0|            0|            0|  0.00%|    >>> d3 = np.diag_indices(2, 3)
   953|         0|            0|            0|  0.00%|    >>> d3
   954|         0|            0|            0|  0.00%|    (array([0, 1]), array([0, 1]), array([0, 1]))
   955|         0|            0|            0|  0.00%|
   956|         0|            0|            0|  0.00%|    And use it to set the diagonal of an array of zeros to 1:
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|    >>> a = np.zeros((2, 2, 2), dtype=int)
   959|         0|            0|            0|  0.00%|    >>> a[d3] = 1
   960|         0|            0|            0|  0.00%|    >>> a
   961|         0|            0|            0|  0.00%|    array([[[1, 0],
   962|         0|            0|            0|  0.00%|            [0, 0]],
   963|         0|            0|            0|  0.00%|           [[0, 0],
   964|         0|            0|            0|  0.00%|            [0, 1]]])
   965|         0|            0|            0|  0.00%|
   966|         0|            0|            0|  0.00%|    """
   967|         0|            0|            0|  0.00%|    idx = arange(n)
   968|         0|            0|            0|  0.00%|    return (idx,) * ndim
   969|         0|            0|            0|  0.00%|
   970|         0|            0|            0|  0.00%|
   971|         0|            0|            0|  0.00%|def _diag_indices_from(arr):
   972|         0|            0|            0|  0.00%|    return (arr,)
   973|         0|            0|            0|  0.00%|
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|@array_function_dispatch(_diag_indices_from)
   976|         0|            0|            0|  0.00%|def diag_indices_from(arr):
   977|         0|            0|            0|  0.00%|    """
   978|         0|            0|            0|  0.00%|    Return the indices to access the main diagonal of an n-dimensional array.
   979|         0|            0|            0|  0.00%|
   980|         0|            0|            0|  0.00%|    See `diag_indices` for full details.
   981|         0|            0|            0|  0.00%|
   982|         0|            0|            0|  0.00%|    Parameters
   983|         0|            0|            0|  0.00%|    ----------
   984|         0|            0|            0|  0.00%|    arr : array, at least 2-D
   985|         0|            0|            0|  0.00%|
   986|         0|            0|            0|  0.00%|    See Also
   987|         0|            0|            0|  0.00%|    --------
   988|         0|            0|            0|  0.00%|    diag_indices
   989|         0|            0|            0|  0.00%|
   990|         0|            0|            0|  0.00%|    Notes
   991|         0|            0|            0|  0.00%|    -----
   992|         0|            0|            0|  0.00%|    .. versionadded:: 1.4.0
   993|         0|            0|            0|  0.00%|
   994|         0|            0|            0|  0.00%|    """
   995|         0|            0|            0|  0.00%|
   996|         0|            0|            0|  0.00%|    if not arr.ndim >= 2:
   997|         0|            0|            0|  0.00%|        raise ValueError("input array must be at least 2-d")
   998|         0|            0|            0|  0.00%|    # For more than d=2, the strided formula is only valid for arrays with
   999|         0|            0|            0|  0.00%|    # all dimensions equal, so we check first.
  1000|         0|            0|            0|  0.00%|    if not alltrue(diff(arr.shape) == 0):
  1001|         0|            0|            0|  0.00%|        raise ValueError("All dimensions of input must be of equal length")
  1002|         0|            0|            0|  0.00%|
  1003|         0|            0|            0|  0.00%|    return diag_indices(arr.shape[0], arr.ndim)
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py
File duration: 0.000273705s (0.03%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Functions for changing global ufunc configuration
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|This provides helpers which wrap `umath.geterrobj` and `umath.seterrobj`
     5|         0|            0|            0|  0.00%|"""
     6|         0|            0|            0|  0.00%|import collections.abc
     7|         0|            0|            0|  0.00%|import contextlib
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|from .overrides import set_module
    10|         0|            0|            0|  0.00%|from .umath import (
    11|         0|            0|            0|  0.00%|    UFUNC_BUFSIZE_DEFAULT,
    12|         0|            0|            0|  0.00%|    ERR_IGNORE, ERR_WARN, ERR_RAISE, ERR_CALL, ERR_PRINT, ERR_LOG, ERR_DEFAULT,
    13|         0|            0|            0|  0.00%|    SHIFT_DIVIDEBYZERO, SHIFT_OVERFLOW, SHIFT_UNDERFLOW, SHIFT_INVALID,
    14|         0|            0|            0|  0.00%|)
    15|         0|            0|            0|  0.00%|from . import umath
    16|         0|            0|            0|  0.00%|
    17|         0|            0|            0|  0.00%|__all__ = [
    18|         0|            0|            0|  0.00%|    "seterr", "geterr", "setbufsize", "getbufsize", "seterrcall", "geterrcall",
    19|         0|            0|            0|  0.00%|    "errstate",
    20|         0|            0|            0|  0.00%|]
    21|         0|            0|            0|  0.00%|
    22|         0|            0|            0|  0.00%|_errdict = {"ignore": ERR_IGNORE,
    23|         0|            0|            0|  0.00%|            "warn": ERR_WARN,
    24|         0|            0|            0|  0.00%|            "raise": ERR_RAISE,
    25|         0|            0|            0|  0.00%|            "call": ERR_CALL,
    26|         0|            0|            0|  0.00%|            "print": ERR_PRINT,
    27|         0|            0|            0|  0.00%|            "log": ERR_LOG}
    28|         0|            0|            0|  0.00%|
    29|         0|            0|            0|  0.00%|_errdict_rev = {value: key for key, value in _errdict.items()}
    30|         0|            0|            0|  0.00%|
    31|         0|            0|            0|  0.00%|
    32|         2|  6.91414e-06|  3.45707e-06|  0.00%|@set_module('numpy')
    33|         0|            0|            0|  0.00%|def seterr(all=None, divide=None, over=None, under=None, invalid=None):
    34|         0|            0|            0|  0.00%|    """
    35|         0|            0|            0|  0.00%|    Set how floating-point errors are handled.
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|    Note that operations on integer scalar types (such as `int16`) are
    38|         0|            0|            0|  0.00%|    handled like floating point, and are affected by these settings.
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|    Parameters
    41|         0|            0|            0|  0.00%|    ----------
    42|         0|            0|            0|  0.00%|    all : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
    43|         0|            0|            0|  0.00%|        Set treatment for all types of floating-point errors at once:
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|        - ignore: Take no action when the exception occurs.
    46|         0|            0|            0|  0.00%|        - warn: Print a `RuntimeWarning` (via the Python `warnings` module).
    47|         0|            0|            0|  0.00%|        - raise: Raise a `FloatingPointError`.
    48|         0|            0|            0|  0.00%|        - call: Call a function specified using the `seterrcall` function.
    49|         0|            0|            0|  0.00%|        - print: Print a warning directly to ``stdout``.
    50|         0|            0|            0|  0.00%|        - log: Record error in a Log object specified by `seterrcall`.
    51|         0|            0|            0|  0.00%|
    52|         0|            0|            0|  0.00%|        The default is not to change the current behavior.
    53|         0|            0|            0|  0.00%|    divide : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
    54|         0|            0|            0|  0.00%|        Treatment for division by zero.
    55|         0|            0|            0|  0.00%|    over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
    56|         0|            0|            0|  0.00%|        Treatment for floating-point overflow.
    57|         0|            0|            0|  0.00%|    under : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
    58|         0|            0|            0|  0.00%|        Treatment for floating-point underflow.
    59|         0|            0|            0|  0.00%|    invalid : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional
    60|         0|            0|            0|  0.00%|        Treatment for invalid floating-point operation.
    61|         0|            0|            0|  0.00%|
    62|         0|            0|            0|  0.00%|    Returns
    63|         0|            0|            0|  0.00%|    -------
    64|         0|            0|            0|  0.00%|    old_settings : dict
    65|         0|            0|            0|  0.00%|        Dictionary containing the old settings.
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|    See also
    68|         0|            0|            0|  0.00%|    --------
    69|         0|            0|            0|  0.00%|    seterrcall : Set a callback function for the 'call' mode.
    70|         0|            0|            0|  0.00%|    geterr, geterrcall, errstate
    71|         0|            0|            0|  0.00%|
    72|         0|            0|            0|  0.00%|    Notes
    73|         0|            0|            0|  0.00%|    -----
    74|         0|            0|            0|  0.00%|    The floating-point exceptions are defined in the IEEE 754 standard [1]_:
    75|         0|            0|            0|  0.00%|
    76|         0|            0|            0|  0.00%|    - Division by zero: infinite result obtained from finite numbers.
    77|         0|            0|            0|  0.00%|    - Overflow: result too large to be expressed.
    78|         0|            0|            0|  0.00%|    - Underflow: result so close to zero that some precision
    79|         0|            0|            0|  0.00%|      was lost.
    80|         0|            0|            0|  0.00%|    - Invalid operation: result is not an expressible number, typically
    81|         0|            0|            0|  0.00%|      indicates that a NaN was produced.
    82|         0|            0|            0|  0.00%|
    83|         0|            0|            0|  0.00%|    .. [1] https://en.wikipedia.org/wiki/IEEE_754
    84|         0|            0|            0|  0.00%|
    85|         0|            0|            0|  0.00%|    Examples
    86|         0|            0|            0|  0.00%|    --------
    87|         0|            0|            0|  0.00%|    >>> old_settings = np.seterr(all='ignore')  #seterr to known value
    88|         0|            0|            0|  0.00%|    >>> np.seterr(over='raise')
    89|         0|            0|            0|  0.00%|    {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}
    90|         0|            0|            0|  0.00%|    >>> np.seterr(**old_settings)  # reset to default
    91|         0|            0|            0|  0.00%|    {'divide': 'ignore', 'over': 'raise', 'under': 'ignore', 'invalid': 'ignore'}
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|    >>> np.int16(32000) * np.int16(3)
    94|         0|            0|            0|  0.00%|    30464
    95|         0|            0|            0|  0.00%|    >>> old_settings = np.seterr(all='warn', over='raise')
    96|         0|            0|            0|  0.00%|    >>> np.int16(32000) * np.int16(3)
    97|         0|            0|            0|  0.00%|    Traceback (most recent call last):
    98|         0|            0|            0|  0.00%|      File "<stdin>", line 1, in <module>
    99|         0|            0|            0|  0.00%|    FloatingPointError: overflow encountered in short_scalars
   100|         0|            0|            0|  0.00%|
   101|         0|            0|            0|  0.00%|    >>> from collections import OrderedDict
   102|         0|            0|            0|  0.00%|    >>> old_settings = np.seterr(all='print')
   103|         0|            0|            0|  0.00%|    >>> OrderedDict(np.geterr())
   104|         0|            0|            0|  0.00%|    OrderedDict([('divide', 'print'), ('over', 'print'), ('under', 'print'), ('invalid', 'print')])
   105|         0|            0|            0|  0.00%|    >>> np.int16(32000) * np.int16(3)
   106|         0|            0|            0|  0.00%|    30464
   107|         0|            0|            0|  0.00%|
   108|         0|            0|            0|  0.00%|    """
   109|         0|            0|            0|  0.00%|
   110|         2|  6.67572e-06|  3.33786e-06|  0.00%|    pyvals = umath.geterrobj()
   111|         2|  1.45435e-05|  7.27177e-06|  0.00%|    old = geterr()
(call)|         2|  0.000145435|  7.27177e-05|  0.02%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py:132 geterr
   112|         0|            0|            0|  0.00%|
   113|         2|  4.52995e-06|  2.26498e-06|  0.00%|    if divide is None:
   114|         1|   2.6226e-06|   2.6226e-06|  0.00%|        divide = all or old['divide']
   115|         2|  4.52995e-06|  2.26498e-06|  0.00%|    if over is None:
   116|         1|  2.38419e-06|  2.38419e-06|  0.00%|        over = all or old['over']
   117|         2|  3.57628e-06|  1.78814e-06|  0.00%|    if under is None:
   118|         1|  2.38419e-06|  2.38419e-06|  0.00%|        under = all or old['under']
   119|         2|   3.8147e-06|  1.90735e-06|  0.00%|    if invalid is None:
   120|         0|            0|            0|  0.00%|        invalid = all or old['invalid']
   121|         0|            0|            0|  0.00%|
   122|         8|  1.52588e-05|  1.90735e-06|  0.00%|    maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +
   123|         2|  3.57628e-06|  1.78814e-06|  0.00%|                 (_errdict[over] << SHIFT_OVERFLOW) +
   124|         2|  3.33786e-06|  1.66893e-06|  0.00%|                 (_errdict[under] << SHIFT_UNDERFLOW) +
   125|         2|  3.33786e-06|  1.66893e-06|  0.00%|                 (_errdict[invalid] << SHIFT_INVALID))
   126|         0|            0|            0|  0.00%|
   127|         2|  4.05312e-06|  2.02656e-06|  0.00%|    pyvals[1] = maskvalue
   128|         2|  6.91414e-06|  3.45707e-06|  0.00%|    umath.seterrobj(pyvals)
   129|         2|  4.05312e-06|  2.02656e-06|  0.00%|    return old
   130|         0|            0|            0|  0.00%|
   131|         0|            0|            0|  0.00%|
   132|         2|  9.75132e-05|  4.87566e-05|  0.01%|@set_module('numpy')
   133|         0|            0|            0|  0.00%|def geterr():
   134|         0|            0|            0|  0.00%|    """
   135|         0|            0|            0|  0.00%|    Get the current way of handling floating-point errors.
   136|         0|            0|            0|  0.00%|
   137|         0|            0|            0|  0.00%|    Returns
   138|         0|            0|            0|  0.00%|    -------
   139|         0|            0|            0|  0.00%|    res : dict
   140|         0|            0|            0|  0.00%|        A dictionary with keys "divide", "over", "under", and "invalid",
   141|         0|            0|            0|  0.00%|        whose values are from the strings "ignore", "print", "log", "warn",
   142|         0|            0|            0|  0.00%|        "raise", and "call". The keys represent possible floating-point
   143|         0|            0|            0|  0.00%|        exceptions, and the values define how these exceptions are handled.
   144|         0|            0|            0|  0.00%|
   145|         0|            0|            0|  0.00%|    See Also
   146|         0|            0|            0|  0.00%|    --------
   147|         0|            0|            0|  0.00%|    geterrcall, seterr, seterrcall
   148|         0|            0|            0|  0.00%|
   149|         0|            0|            0|  0.00%|    Notes
   150|         0|            0|            0|  0.00%|    -----
   151|         0|            0|            0|  0.00%|    For complete documentation of the types of floating-point exceptions and
   152|         0|            0|            0|  0.00%|    treatment options, see `seterr`.
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|    Examples
   155|         0|            0|            0|  0.00%|    --------
   156|         0|            0|            0|  0.00%|    >>> from collections import OrderedDict
   157|         0|            0|            0|  0.00%|    >>> sorted(np.geterr().items())
   158|         0|            0|            0|  0.00%|    [('divide', 'warn'), ('invalid', 'warn'), ('over', 'warn'), ('under', 'ignore')]
   159|         0|            0|            0|  0.00%|    >>> np.arange(3.) / np.arange(3.)
   160|         0|            0|            0|  0.00%|    array([nan,  1.,  1.])
   161|         0|            0|            0|  0.00%|
   162|         0|            0|            0|  0.00%|    >>> oldsettings = np.seterr(all='warn', over='raise')
   163|         0|            0|            0|  0.00%|    >>> OrderedDict(sorted(np.geterr().items()))
   164|         0|            0|            0|  0.00%|    OrderedDict([('divide', 'warn'), ('invalid', 'warn'), ('over', 'raise'), ('under', 'warn')])
   165|         0|            0|            0|  0.00%|    >>> np.arange(3.) / np.arange(3.)
   166|         0|            0|            0|  0.00%|    array([nan,  1.,  1.])
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|    """
   169|         2|  7.15256e-06|  3.57628e-06|  0.00%|    maskvalue = umath.geterrobj()[1]
   170|         2|  4.05312e-06|  2.02656e-06|  0.00%|    mask = 7
   171|         2|  4.05312e-06|  2.02656e-06|  0.00%|    res = {}
   172|         2|  4.05312e-06|  2.02656e-06|  0.00%|    val = (maskvalue >> SHIFT_DIVIDEBYZERO) & mask
   173|         2|  4.76837e-06|  2.38419e-06|  0.00%|    res['divide'] = _errdict_rev[val]
   174|         2|  3.33786e-06|  1.66893e-06|  0.00%|    val = (maskvalue >> SHIFT_OVERFLOW) & mask
   175|         2|  3.57628e-06|  1.78814e-06|  0.00%|    res['over'] = _errdict_rev[val]
   176|         2|  3.57628e-06|  1.78814e-06|  0.00%|    val = (maskvalue >> SHIFT_UNDERFLOW) & mask
   177|         2|  3.33786e-06|  1.66893e-06|  0.00%|    res['under'] = _errdict_rev[val]
   178|         2|   3.8147e-06|  1.90735e-06|  0.00%|    val = (maskvalue >> SHIFT_INVALID) & mask
   179|         2|  3.09944e-06|  1.54972e-06|  0.00%|    res['invalid'] = _errdict_rev[val]
   180|         2|  3.09944e-06|  1.54972e-06|  0.00%|    return res
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|
   183|         0|            0|            0|  0.00%|@set_module('numpy')
   184|         0|            0|            0|  0.00%|def setbufsize(size):
   185|         0|            0|            0|  0.00%|    """
   186|         0|            0|            0|  0.00%|    Set the size of the buffer used in ufuncs.
   187|         0|            0|            0|  0.00%|
   188|         0|            0|            0|  0.00%|    Parameters
   189|         0|            0|            0|  0.00%|    ----------
   190|         0|            0|            0|  0.00%|    size : int
   191|         0|            0|            0|  0.00%|        Size of buffer.
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    """
   194|         0|            0|            0|  0.00%|    if size > 10e6:
   195|         0|            0|            0|  0.00%|        raise ValueError("Buffer size, %s, is too big." % size)
   196|         0|            0|            0|  0.00%|    if size < 5:
   197|         0|            0|            0|  0.00%|        raise ValueError("Buffer size, %s, is too small." % size)
   198|         0|            0|            0|  0.00%|    if size % 16 != 0:
   199|         0|            0|            0|  0.00%|        raise ValueError("Buffer size, %s, is not a multiple of 16." % size)
   200|         0|            0|            0|  0.00%|
   201|         0|            0|            0|  0.00%|    pyvals = umath.geterrobj()
   202|         0|            0|            0|  0.00%|    old = getbufsize()
   203|         0|            0|            0|  0.00%|    pyvals[0] = size
   204|         0|            0|            0|  0.00%|    umath.seterrobj(pyvals)
   205|         0|            0|            0|  0.00%|    return old
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|@set_module('numpy')
   209|         0|            0|            0|  0.00%|def getbufsize():
   210|         0|            0|            0|  0.00%|    """
   211|         0|            0|            0|  0.00%|    Return the size of the buffer used in ufuncs.
   212|         0|            0|            0|  0.00%|
   213|         0|            0|            0|  0.00%|    Returns
   214|         0|            0|            0|  0.00%|    -------
   215|         0|            0|            0|  0.00%|    getbufsize : int
   216|         0|            0|            0|  0.00%|        Size of ufunc buffer in bytes.
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|    """
   219|         0|            0|            0|  0.00%|    return umath.geterrobj()[0]
   220|         0|            0|            0|  0.00%|
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|@set_module('numpy')
   223|         0|            0|            0|  0.00%|def seterrcall(func):
   224|         0|            0|            0|  0.00%|    """
   225|         0|            0|            0|  0.00%|    Set the floating-point error callback function or log object.
   226|         0|            0|            0|  0.00%|
   227|         0|            0|            0|  0.00%|    There are two ways to capture floating-point error messages.  The first
   228|         0|            0|            0|  0.00%|    is to set the error-handler to 'call', using `seterr`.  Then, set
   229|         0|            0|            0|  0.00%|    the function to call using this function.
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|    The second is to set the error-handler to 'log', using `seterr`.
   232|         0|            0|            0|  0.00%|    Floating-point errors then trigger a call to the 'write' method of
   233|         0|            0|            0|  0.00%|    the provided object.
   234|         0|            0|            0|  0.00%|
   235|         0|            0|            0|  0.00%|    Parameters
   236|         0|            0|            0|  0.00%|    ----------
   237|         0|            0|            0|  0.00%|    func : callable f(err, flag) or object with write method
   238|         0|            0|            0|  0.00%|        Function to call upon floating-point errors ('call'-mode) or
   239|         0|            0|            0|  0.00%|        object whose 'write' method is used to log such message ('log'-mode).
   240|         0|            0|            0|  0.00%|
   241|         0|            0|            0|  0.00%|        The call function takes two arguments. The first is a string describing
   242|         0|            0|            0|  0.00%|        the type of error (such as "divide by zero", "overflow", "underflow",
   243|         0|            0|            0|  0.00%|        or "invalid value"), and the second is the status flag.  The flag is a
   244|         0|            0|            0|  0.00%|        byte, whose four least-significant bits indicate the type of error, one
   245|         0|            0|            0|  0.00%|        of "divide", "over", "under", "invalid"::
   246|         0|            0|            0|  0.00%|
   247|         0|            0|            0|  0.00%|          [0 0 0 0 divide over under invalid]
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|        In other words, ``flags = divide + 2*over + 4*under + 8*invalid``.
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|        If an object is provided, its write method should take one argument,
   252|         0|            0|            0|  0.00%|        a string.
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    Returns
   255|         0|            0|            0|  0.00%|    -------
   256|         0|            0|            0|  0.00%|    h : callable, log instance or None
   257|         0|            0|            0|  0.00%|        The old error handler.
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    See Also
   260|         0|            0|            0|  0.00%|    --------
   261|         0|            0|            0|  0.00%|    seterr, geterr, geterrcall
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|    Examples
   264|         0|            0|            0|  0.00%|    --------
   265|         0|            0|            0|  0.00%|    Callback upon error:
   266|         0|            0|            0|  0.00%|
   267|         0|            0|            0|  0.00%|    >>> def err_handler(type, flag):
   268|         0|            0|            0|  0.00%|    ...     print("Floating point error (%s), with flag %s" % (type, flag))
   269|         0|            0|            0|  0.00%|    ...
   270|         0|            0|            0|  0.00%|
   271|         0|            0|            0|  0.00%|    >>> saved_handler = np.seterrcall(err_handler)
   272|         0|            0|            0|  0.00%|    >>> save_err = np.seterr(all='call')
   273|         0|            0|            0|  0.00%|    >>> from collections import OrderedDict
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    >>> np.array([1, 2, 3]) / 0.0
   276|         0|            0|            0|  0.00%|    Floating point error (divide by zero), with flag 1
   277|         0|            0|            0|  0.00%|    array([inf, inf, inf])
   278|         0|            0|            0|  0.00%|
   279|         0|            0|            0|  0.00%|    >>> np.seterrcall(saved_handler)
   280|         0|            0|            0|  0.00%|    <function err_handler at 0x...>
   281|         0|            0|            0|  0.00%|    >>> OrderedDict(sorted(np.seterr(**save_err).items()))
   282|         0|            0|            0|  0.00%|    OrderedDict([('divide', 'call'), ('invalid', 'call'), ('over', 'call'), ('under', 'call')])
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|    Log error message:
   285|         0|            0|            0|  0.00%|
   286|         0|            0|            0|  0.00%|    >>> class Log:
   287|         0|            0|            0|  0.00%|    ...     def write(self, msg):
   288|         0|            0|            0|  0.00%|    ...         print("LOG: %s" % msg)
   289|         0|            0|            0|  0.00%|    ...
   290|         0|            0|            0|  0.00%|
   291|         0|            0|            0|  0.00%|    >>> log = Log()
   292|         0|            0|            0|  0.00%|    >>> saved_handler = np.seterrcall(log)
   293|         0|            0|            0|  0.00%|    >>> save_err = np.seterr(all='log')
   294|         0|            0|            0|  0.00%|
   295|         0|            0|            0|  0.00%|    >>> np.array([1, 2, 3]) / 0.0
   296|         0|            0|            0|  0.00%|    LOG: Warning: divide by zero encountered in true_divide
   297|         0|            0|            0|  0.00%|    array([inf, inf, inf])
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|    >>> np.seterrcall(saved_handler)
   300|         0|            0|            0|  0.00%|    <numpy.core.numeric.Log object at 0x...>
   301|         0|            0|            0|  0.00%|    >>> OrderedDict(sorted(np.seterr(**save_err).items()))
   302|         0|            0|            0|  0.00%|    OrderedDict([('divide', 'log'), ('invalid', 'log'), ('over', 'log'), ('under', 'log')])
   303|         0|            0|            0|  0.00%|
   304|         0|            0|            0|  0.00%|    """
   305|         0|            0|            0|  0.00%|    if func is not None and not isinstance(func, collections.abc.Callable):
   306|         0|            0|            0|  0.00%|        if (not hasattr(func, 'write') or
   307|         0|            0|            0|  0.00%|                not isinstance(func.write, collections.abc.Callable)):
   308|         0|            0|            0|  0.00%|            raise ValueError("Only callable can be used as callback")
   309|         0|            0|            0|  0.00%|    pyvals = umath.geterrobj()
   310|         0|            0|            0|  0.00%|    old = geterrcall()
   311|         0|            0|            0|  0.00%|    pyvals[2] = func
   312|         0|            0|            0|  0.00%|    umath.seterrobj(pyvals)
   313|         0|            0|            0|  0.00%|    return old
   314|         0|            0|            0|  0.00%|
   315|         0|            0|            0|  0.00%|
   316|         0|            0|            0|  0.00%|@set_module('numpy')
   317|         0|            0|            0|  0.00%|def geterrcall():
   318|         0|            0|            0|  0.00%|    """
   319|         0|            0|            0|  0.00%|    Return the current callback function used on floating-point errors.
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|    When the error handling for a floating-point error (one of "divide",
   322|         0|            0|            0|  0.00%|    "over", "under", or "invalid") is set to 'call' or 'log', the function
   323|         0|            0|            0|  0.00%|    that is called or the log instance that is written to is returned by
   324|         0|            0|            0|  0.00%|    `geterrcall`. This function or log instance has been set with
   325|         0|            0|            0|  0.00%|    `seterrcall`.
   326|         0|            0|            0|  0.00%|
   327|         0|            0|            0|  0.00%|    Returns
   328|         0|            0|            0|  0.00%|    -------
   329|         0|            0|            0|  0.00%|    errobj : callable, log instance or None
   330|         0|            0|            0|  0.00%|        The current error handler. If no handler was set through `seterrcall`,
   331|         0|            0|            0|  0.00%|        ``None`` is returned.
   332|         0|            0|            0|  0.00%|
   333|         0|            0|            0|  0.00%|    See Also
   334|         0|            0|            0|  0.00%|    --------
   335|         0|            0|            0|  0.00%|    seterrcall, seterr, geterr
   336|         0|            0|            0|  0.00%|
   337|         0|            0|            0|  0.00%|    Notes
   338|         0|            0|            0|  0.00%|    -----
   339|         0|            0|            0|  0.00%|    For complete documentation of the types of floating-point exceptions and
   340|         0|            0|            0|  0.00%|    treatment options, see `seterr`.
   341|         0|            0|            0|  0.00%|
   342|         0|            0|            0|  0.00%|    Examples
   343|         0|            0|            0|  0.00%|    --------
   344|         0|            0|            0|  0.00%|    >>> np.geterrcall()  # we did not yet set a handler, returns None
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|    >>> oldsettings = np.seterr(all='call')
   347|         0|            0|            0|  0.00%|    >>> def err_handler(type, flag):
   348|         0|            0|            0|  0.00%|    ...     print("Floating point error (%s), with flag %s" % (type, flag))
   349|         0|            0|            0|  0.00%|    >>> oldhandler = np.seterrcall(err_handler)
   350|         0|            0|            0|  0.00%|    >>> np.array([1, 2, 3]) / 0.0
   351|         0|            0|            0|  0.00%|    Floating point error (divide by zero), with flag 1
   352|         0|            0|            0|  0.00%|    array([inf, inf, inf])
   353|         0|            0|            0|  0.00%|
   354|         0|            0|            0|  0.00%|    >>> cur_handler = np.geterrcall()
   355|         0|            0|            0|  0.00%|    >>> cur_handler is err_handler
   356|         0|            0|            0|  0.00%|    True
   357|         0|            0|            0|  0.00%|
   358|         0|            0|            0|  0.00%|    """
   359|         0|            0|            0|  0.00%|    return umath.geterrobj()[2]
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|class _unspecified:
   363|         0|            0|            0|  0.00%|    pass
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|
   366|         0|            0|            0|  0.00%|_Unspecified = _unspecified()
   367|         0|            0|            0|  0.00%|
   368|         0|            0|            0|  0.00%|
   369|         0|            0|            0|  0.00%|@set_module('numpy')
   370|         0|            0|            0|  0.00%|class errstate(contextlib.ContextDecorator):
   371|         0|            0|            0|  0.00%|    """
   372|         0|            0|            0|  0.00%|    errstate(**kwargs)
   373|         0|            0|            0|  0.00%|
   374|         0|            0|            0|  0.00%|    Context manager for floating-point error handling.
   375|         0|            0|            0|  0.00%|
   376|         0|            0|            0|  0.00%|    Using an instance of `errstate` as a context manager allows statements in
   377|         0|            0|            0|  0.00%|    that context to execute with a known error handling behavior. Upon entering
   378|         0|            0|            0|  0.00%|    the context the error handling is set with `seterr` and `seterrcall`, and
   379|         0|            0|            0|  0.00%|    upon exiting it is reset to what it was before.
   380|         0|            0|            0|  0.00%|
   381|         0|            0|            0|  0.00%|    ..  versionchanged:: 1.17.0
   382|         0|            0|            0|  0.00%|        `errstate` is also usable as a function decorator, saving
   383|         0|            0|            0|  0.00%|        a level of indentation if an entire function is wrapped.
   384|         0|            0|            0|  0.00%|        See :py:class:`contextlib.ContextDecorator` for more information.
   385|         0|            0|            0|  0.00%|
   386|         0|            0|            0|  0.00%|    Parameters
   387|         0|            0|            0|  0.00%|    ----------
   388|         0|            0|            0|  0.00%|    kwargs : {divide, over, under, invalid}
   389|         0|            0|            0|  0.00%|        Keyword arguments. The valid keywords are the possible floating-point
   390|         0|            0|            0|  0.00%|        exceptions. Each keyword should have a string value that defines the
   391|         0|            0|            0|  0.00%|        treatment for the particular error. Possible values are
   392|         0|            0|            0|  0.00%|        {'ignore', 'warn', 'raise', 'call', 'print', 'log'}.
   393|         0|            0|            0|  0.00%|
   394|         0|            0|            0|  0.00%|    See Also
   395|         0|            0|            0|  0.00%|    --------
   396|         0|            0|            0|  0.00%|    seterr, geterr, seterrcall, geterrcall
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|    Notes
   399|         0|            0|            0|  0.00%|    -----
   400|         0|            0|            0|  0.00%|    For complete documentation of the types of floating-point exceptions and
   401|         0|            0|            0|  0.00%|    treatment options, see `seterr`.
   402|         0|            0|            0|  0.00%|
   403|         0|            0|            0|  0.00%|    Examples
   404|         0|            0|            0|  0.00%|    --------
   405|         0|            0|            0|  0.00%|    >>> from collections import OrderedDict
   406|         0|            0|            0|  0.00%|    >>> olderr = np.seterr(all='ignore')  # Set error handling to known state.
   407|         0|            0|            0|  0.00%|
   408|         0|            0|            0|  0.00%|    >>> np.arange(3) / 0.
   409|         0|            0|            0|  0.00%|    array([nan, inf, inf])
   410|         0|            0|            0|  0.00%|    >>> with np.errstate(divide='warn'):
   411|         0|            0|            0|  0.00%|    ...     np.arange(3) / 0.
   412|         0|            0|            0|  0.00%|    array([nan, inf, inf])
   413|         0|            0|            0|  0.00%|
   414|         0|            0|            0|  0.00%|    >>> np.sqrt(-1)
   415|         0|            0|            0|  0.00%|    nan
   416|         0|            0|            0|  0.00%|    >>> with np.errstate(invalid='raise'):
   417|         0|            0|            0|  0.00%|    ...     np.sqrt(-1)
   418|         0|            0|            0|  0.00%|    Traceback (most recent call last):
   419|         0|            0|            0|  0.00%|      File "<stdin>", line 2, in <module>
   420|         0|            0|            0|  0.00%|    FloatingPointError: invalid value encountered in sqrt
   421|         0|            0|            0|  0.00%|
   422|         0|            0|            0|  0.00%|    Outside the context the error handling behavior has not changed:
   423|         0|            0|            0|  0.00%|
   424|         0|            0|            0|  0.00%|    >>> OrderedDict(sorted(np.geterr().items()))
   425|         0|            0|            0|  0.00%|    OrderedDict([('divide', 'ignore'), ('invalid', 'ignore'), ('over', 'ignore'), ('under', 'ignore')])
   426|         0|            0|            0|  0.00%|
   427|         0|            0|            0|  0.00%|    """
   428|         0|            0|            0|  0.00%|
   429|         1|  1.90735e-06|  1.90735e-06|  0.00%|    def __init__(self, *, call=_Unspecified, **kwargs):
   430|         1|  5.96046e-06|  5.96046e-06|  0.00%|        self.call = call
   431|         1|  1.90735e-06|  1.90735e-06|  0.00%|        self.kwargs = kwargs
   432|         0|            0|            0|  0.00%|
   433|         1|  1.90735e-06|  1.90735e-06|  0.00%|    def __enter__(self):
   434|         1|  8.34465e-06|  8.34465e-06|  0.00%|        self.oldstate = seterr(**self.kwargs)
(call)|         1|  0.000185728|  0.000185728|  0.02%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py:32 seterr
   435|         1|   2.6226e-06|   2.6226e-06|  0.00%|        if self.call is not _Unspecified:
   436|         0|            0|            0|  0.00%|            self.oldcall = seterrcall(self.call)
   437|         0|            0|            0|  0.00%|
   438|         1|  2.86102e-06|  2.86102e-06|  0.00%|    def __exit__(self, *exc_info):
   439|         1|  7.86781e-06|  7.86781e-06|  0.00%|        seterr(**self.oldstate)
(call)|         1|  5.22137e-05|  5.22137e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py:32 seterr
   440|         1|  2.38419e-06|  2.38419e-06|  0.00%|        if self.call is not _Unspecified:
   441|         0|            0|            0|  0.00%|            seterrcall(self.oldcall)
   442|         0|            0|            0|  0.00%|
   443|         0|            0|            0|  0.00%|
   444|         0|            0|            0|  0.00%|def _setdef():
   445|         0|            0|            0|  0.00%|    defval = [UFUNC_BUFSIZE_DEFAULT, ERR_DEFAULT, None]
   446|         0|            0|            0|  0.00%|    umath.seterrobj(defval)
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|
   449|         0|            0|            0|  0.00%|# set the default values
   450|         0|            0|            0|  0.00%|_setdef()
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py
File duration: 0.000191212s (0.02%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Array methods which are called by both the C-code for the method
     3|         0|            0|            0|  0.00%|and the Python code for the NumPy-namespace function
     4|         0|            0|            0|  0.00%|
     5|         0|            0|            0|  0.00%|"""
     6|         0|            0|            0|  0.00%|import warnings
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|from numpy.core import multiarray as mu
     9|         0|            0|            0|  0.00%|from numpy.core import umath as um
    10|         0|            0|            0|  0.00%|from numpy.core._asarray import asanyarray
    11|         0|            0|            0|  0.00%|from numpy.core import numerictypes as nt
    12|         0|            0|            0|  0.00%|from numpy.core import _exceptions
    13|         0|            0|            0|  0.00%|from numpy._globals import _NoValue
    14|         0|            0|            0|  0.00%|from numpy.compat import pickle, os_fspath, contextlib_nullcontext
    15|         0|            0|            0|  0.00%|
    16|         0|            0|            0|  0.00%|# save those O(100) nanoseconds!
    17|         0|            0|            0|  0.00%|umr_maximum = um.maximum.reduce
    18|         0|            0|            0|  0.00%|umr_minimum = um.minimum.reduce
    19|         0|            0|            0|  0.00%|umr_sum = um.add.reduce
    20|         0|            0|            0|  0.00%|umr_prod = um.multiply.reduce
    21|         0|            0|            0|  0.00%|umr_any = um.logical_or.reduce
    22|         0|            0|            0|  0.00%|umr_all = um.logical_and.reduce
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|# Complex types to -> (2,)float view for fast-path computation in _var()
    25|         0|            0|            0|  0.00%|_complex_to_float = {
    26|         0|            0|            0|  0.00%|    nt.dtype(nt.csingle) : nt.dtype(nt.single),
    27|         0|            0|            0|  0.00%|    nt.dtype(nt.cdouble) : nt.dtype(nt.double),
    28|         0|            0|            0|  0.00%|}
    29|         0|            0|            0|  0.00%|# Special case for windows: ensure double takes precedence
    30|         0|            0|            0|  0.00%|if nt.dtype(nt.longdouble) != nt.dtype(nt.double):
    31|         0|            0|            0|  0.00%|    _complex_to_float.update({
    32|         0|            0|            0|  0.00%|        nt.dtype(nt.clongdouble) : nt.dtype(nt.longdouble),
    33|         0|            0|            0|  0.00%|    })
    34|         0|            0|            0|  0.00%|
    35|         0|            0|            0|  0.00%|# avoid keyword arguments to speed up parsing, saves about 15%-20% for very
    36|         0|            0|            0|  0.00%|# small reductions
    37|         0|            0|            0|  0.00%|def _amax(a, axis=None, out=None, keepdims=False,
    38|         0|            0|            0|  0.00%|          initial=_NoValue, where=True):
    39|         0|            0|            0|  0.00%|    return umr_maximum(a, axis, None, out, keepdims, initial, where)
    40|         0|            0|            0|  0.00%|
    41|         0|            0|            0|  0.00%|def _amin(a, axis=None, out=None, keepdims=False,
    42|         0|            0|            0|  0.00%|          initial=_NoValue, where=True):
    43|         0|            0|            0|  0.00%|    return umr_minimum(a, axis, None, out, keepdims, initial, where)
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|def _sum(a, axis=None, dtype=None, out=None, keepdims=False,
    46|         0|            0|            0|  0.00%|         initial=_NoValue, where=True):
    47|         0|            0|            0|  0.00%|    return umr_sum(a, axis, dtype, out, keepdims, initial, where)
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|def _prod(a, axis=None, dtype=None, out=None, keepdims=False,
    50|         0|            0|            0|  0.00%|          initial=_NoValue, where=True):
    51|         0|            0|            0|  0.00%|    return umr_prod(a, axis, dtype, out, keepdims, initial, where)
    52|         0|            0|            0|  0.00%|
    53|         0|            0|            0|  0.00%|def _any(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):
    54|         0|            0|            0|  0.00%|    # Parsing keyword arguments is currently fairly slow, so avoid it for now
    55|         0|            0|            0|  0.00%|    if where is True:
    56|         0|            0|            0|  0.00%|        return umr_any(a, axis, dtype, out, keepdims)
    57|         0|            0|            0|  0.00%|    return umr_any(a, axis, dtype, out, keepdims, where=where)
    58|         0|            0|            0|  0.00%|
    59|         2|  4.29153e-06|  2.14577e-06|  0.00%|def _all(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):
    60|         0|            0|            0|  0.00%|    # Parsing keyword arguments is currently fairly slow, so avoid it for now
    61|         2|  4.05312e-06|  2.02656e-06|  0.00%|    if where is True:
    62|         2|   1.4782e-05|  7.39098e-06|  0.00%|        return umr_all(a, axis, dtype, out, keepdims)
    63|         0|            0|            0|  0.00%|    return umr_all(a, axis, dtype, out, keepdims, where=where)
    64|         0|            0|            0|  0.00%|
    65|         0|            0|            0|  0.00%|def _count_reduce_items(arr, axis, keepdims=False, where=True):
    66|         0|            0|            0|  0.00%|    # fast-path for the default case
    67|         0|            0|            0|  0.00%|    if where is True:
    68|         0|            0|            0|  0.00%|        # no boolean mask given, calculate items according to axis
    69|         0|            0|            0|  0.00%|        if axis is None:
    70|         0|            0|            0|  0.00%|            axis = tuple(range(arr.ndim))
    71|         0|            0|            0|  0.00%|        elif not isinstance(axis, tuple):
    72|         0|            0|            0|  0.00%|            axis = (axis,)
    73|         0|            0|            0|  0.00%|        items = nt.intp(1)
    74|         0|            0|            0|  0.00%|        for ax in axis:
    75|         0|            0|            0|  0.00%|            items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]
    76|         0|            0|            0|  0.00%|    else:
    77|         0|            0|            0|  0.00%|        # TODO: Optimize case when `where` is broadcast along a non-reduction
    78|         0|            0|            0|  0.00%|        # axis and full sum is more excessive than needed.
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|        # guarded to protect circular imports
    81|         0|            0|            0|  0.00%|        from numpy.lib.stride_tricks import broadcast_to
    82|         0|            0|            0|  0.00%|        # count True values in (potentially broadcasted) boolean mask
    83|         0|            0|            0|  0.00%|        items = umr_sum(broadcast_to(where, arr.shape), axis, nt.intp, None,
    84|         0|            0|            0|  0.00%|                        keepdims)
    85|         0|            0|            0|  0.00%|    return items
    86|         0|            0|            0|  0.00%|
    87|         0|            0|            0|  0.00%|# Numpy 1.17.0, 2019-02-24
    88|         0|            0|            0|  0.00%|# Various clip behavior deprecations, marked with _clip_dep as a prefix.
    89|         0|            0|            0|  0.00%|
    90|         2|  5.48363e-06|  2.74181e-06|  0.00%|def _clip_dep_is_scalar_nan(a):
    91|         0|            0|            0|  0.00%|    # guarded to protect circular imports
    92|         2|  1.83582e-05|  9.17912e-06|  0.00%|    from numpy.core.fromnumeric import ndim
    93|         2|  1.57356e-05|  7.86781e-06|  0.00%|    if ndim(a) != 0:
(call)|         2|  0.000145912|  7.29561e-05|  0.02%|# <__array_function__ internals>_0:2 ndim
    94|         0|            0|            0|  0.00%|        return False
    95|         2|  4.76837e-06|  2.38419e-06|  0.00%|    try:
    96|         2|  1.50204e-05|  7.51019e-06|  0.00%|        return um.isnan(a)
    97|         0|            0|            0|  0.00%|    except TypeError:
    98|         0|            0|            0|  0.00%|        return False
    99|         0|            0|            0|  0.00%|
   100|         2|  3.57628e-06|  1.78814e-06|  0.00%|def _clip_dep_is_byte_swapped(a):
   101|         2|  4.52995e-06|  2.26498e-06|  0.00%|    if isinstance(a, mu.ndarray):
   102|         1|   3.8147e-06|   3.8147e-06|  0.00%|        return not a.dtype.isnative
   103|         1|  1.19209e-06|  1.19209e-06|  0.00%|    return False
   104|         0|            0|            0|  0.00%|
   105|         1|  3.57628e-06|  3.57628e-06|  0.00%|def _clip_dep_invoke_with_casting(ufunc, *args, out=None, casting=None, **kwargs):
   106|         0|            0|            0|  0.00%|    # normal path
   107|         1|  2.86102e-06|  2.86102e-06|  0.00%|    if casting is not None:
   108|         0|            0|            0|  0.00%|        return ufunc(*args, out=out, casting=casting, **kwargs)
   109|         0|            0|            0|  0.00%|
   110|         0|            0|            0|  0.00%|    # try to deal with broken casting rules
   111|         1|  2.86102e-06|  2.86102e-06|  0.00%|    try:
   112|         1|  1.69277e-05|  1.69277e-05|  0.00%|        return ufunc(*args, out=out, **kwargs)
   113|         0|            0|            0|  0.00%|    except _exceptions._UFuncOutputCastingError as e:
   114|         0|            0|            0|  0.00%|        # Numpy 1.17.0, 2019-02-24
   115|         0|            0|            0|  0.00%|        warnings.warn(
   116|         0|            0|            0|  0.00%|            "Converting the output of clip from {!r} to {!r} is deprecated. "
   117|         0|            0|            0|  0.00%|            "Pass `casting=\"unsafe\"` explicitly to silence this warning, or "
   118|         0|            0|            0|  0.00%|            "correct the type of the variables.".format(e.from_, e.to),
   119|         0|            0|            0|  0.00%|            DeprecationWarning,
   120|         0|            0|            0|  0.00%|            stacklevel=2
   121|         0|            0|            0|  0.00%|        )
   122|         0|            0|            0|  0.00%|        return ufunc(*args, out=out, casting="unsafe", **kwargs)
   123|         0|            0|            0|  0.00%|
   124|         1|  4.05312e-06|  4.05312e-06|  0.00%|def _clip(a, min=None, max=None, out=None, *, casting=None, **kwargs):
   125|         1|  5.00679e-06|  5.00679e-06|  0.00%|    if min is None and max is None:
   126|         0|            0|            0|  0.00%|        raise ValueError("One of max or min must be given")
   127|         0|            0|            0|  0.00%|
   128|         0|            0|            0|  0.00%|    # Numpy 1.17.0, 2019-02-24
   129|         0|            0|            0|  0.00%|    # This deprecation probably incurs a substantial slowdown for small arrays,
   130|         0|            0|            0|  0.00%|    # it will be good to get rid of it.
   131|         1|  1.19209e-05|  1.19209e-05|  0.00%|    if not _clip_dep_is_byte_swapped(a) and not _clip_dep_is_byte_swapped(out):
(call)|         2|   1.3113e-05|  6.55651e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py:100 _clip_dep_is_byte_swapped
   132|         1|  2.38419e-06|  2.38419e-06|  0.00%|        using_deprecated_nan = False
   133|         1|  7.62939e-06|  7.62939e-06|  0.00%|        if _clip_dep_is_scalar_nan(min):
(call)|         1|  0.000154734|  0.000154734|  0.02%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py:90 _clip_dep_is_scalar_nan
   134|         0|            0|            0|  0.00%|            min = -float('inf')
   135|         0|            0|            0|  0.00%|            using_deprecated_nan = True
   136|         1|  9.77516e-06|  9.77516e-06|  0.00%|        if _clip_dep_is_scalar_nan(max):
(call)|         1|  5.05447e-05|  5.05447e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py:90 _clip_dep_is_scalar_nan
   137|         0|            0|            0|  0.00%|            max = float('inf')
   138|         0|            0|            0|  0.00%|            using_deprecated_nan = True
   139|         1|  3.33786e-06|  3.33786e-06|  0.00%|        if using_deprecated_nan:
   140|         0|            0|            0|  0.00%|            warnings.warn(
   141|         0|            0|            0|  0.00%|                "Passing `np.nan` to mean no clipping in np.clip has always "
   142|         0|            0|            0|  0.00%|                "been unreliable, and is now deprecated. "
   143|         0|            0|            0|  0.00%|                "In future, this will always return nan, like it already does "
   144|         0|            0|            0|  0.00%|                "when min or max are arrays that contain nan. "
   145|         0|            0|            0|  0.00%|                "To skip a bound, pass either None or an np.inf of an "
   146|         0|            0|            0|  0.00%|                "appropriate sign.",
   147|         0|            0|            0|  0.00%|                DeprecationWarning,
   148|         0|            0|            0|  0.00%|                stacklevel=2
   149|         0|            0|            0|  0.00%|            )
   150|         0|            0|            0|  0.00%|
   151|         1|   2.6226e-06|   2.6226e-06|  0.00%|    if min is None:
   152|         0|            0|            0|  0.00%|        return _clip_dep_invoke_with_casting(
   153|         0|            0|            0|  0.00%|            um.minimum, a, max, out=out, casting=casting, **kwargs)
   154|         1|  2.14577e-06|  2.14577e-06|  0.00%|    elif max is None:
   155|         0|            0|            0|  0.00%|        return _clip_dep_invoke_with_casting(
   156|         0|            0|            0|  0.00%|            um.maximum, a, min, out=out, casting=casting, **kwargs)
   157|         0|            0|            0|  0.00%|    else:
   158|         4|  1.57356e-05|  3.93391e-06|  0.00%|        return _clip_dep_invoke_with_casting(
(call)|         1|   2.6226e-05|   2.6226e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_methods.py:105 _clip_dep_invoke_with_casting
   159|         3|  4.76837e-06|  1.58946e-06|  0.00%|            um.clip, a, min, max, out=out, casting=casting, **kwargs)
   160|         0|            0|            0|  0.00%|
   161|         0|            0|            0|  0.00%|def _mean(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):
   162|         0|            0|            0|  0.00%|    arr = asanyarray(a)
   163|         0|            0|            0|  0.00%|
   164|         0|            0|            0|  0.00%|    is_float16_result = False
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
   167|         0|            0|            0|  0.00%|    if rcount == 0 if where is True else umr_any(rcount == 0, axis=None):
   168|         0|            0|            0|  0.00%|        warnings.warn("Mean of empty slice.", RuntimeWarning, stacklevel=2)
   169|         0|            0|            0|  0.00%|
   170|         0|            0|            0|  0.00%|    # Cast bool, unsigned int, and int to float64 by default
   171|         0|            0|            0|  0.00%|    if dtype is None:
   172|         0|            0|            0|  0.00%|        if issubclass(arr.dtype.type, (nt.integer, nt.bool_)):
   173|         0|            0|            0|  0.00%|            dtype = mu.dtype('f8')
   174|         0|            0|            0|  0.00%|        elif issubclass(arr.dtype.type, nt.float16):
   175|         0|            0|            0|  0.00%|            dtype = mu.dtype('f4')
   176|         0|            0|            0|  0.00%|            is_float16_result = True
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
   179|         0|            0|            0|  0.00%|    if isinstance(ret, mu.ndarray):
   180|         0|            0|            0|  0.00%|        ret = um.true_divide(
   181|         0|            0|            0|  0.00%|                ret, rcount, out=ret, casting='unsafe', subok=False)
   182|         0|            0|            0|  0.00%|        if is_float16_result and out is None:
   183|         0|            0|            0|  0.00%|            ret = arr.dtype.type(ret)
   184|         0|            0|            0|  0.00%|    elif hasattr(ret, 'dtype'):
   185|         0|            0|            0|  0.00%|        if is_float16_result:
   186|         0|            0|            0|  0.00%|            ret = arr.dtype.type(ret / rcount)
   187|         0|            0|            0|  0.00%|        else:
   188|         0|            0|            0|  0.00%|            ret = ret.dtype.type(ret / rcount)
   189|         0|            0|            0|  0.00%|    else:
   190|         0|            0|            0|  0.00%|        ret = ret / rcount
   191|         0|            0|            0|  0.00%|
   192|         0|            0|            0|  0.00%|    return ret
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|def _var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,
   195|         0|            0|            0|  0.00%|         where=True):
   196|         0|            0|            0|  0.00%|    arr = asanyarray(a)
   197|         0|            0|            0|  0.00%|
   198|         0|            0|            0|  0.00%|    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)
   199|         0|            0|            0|  0.00%|    # Make this warning show up on top.
   200|         0|            0|            0|  0.00%|    if ddof >= rcount if where is True else umr_any(ddof >= rcount, axis=None):
   201|         0|            0|            0|  0.00%|        warnings.warn("Degrees of freedom <= 0 for slice", RuntimeWarning,
   202|         0|            0|            0|  0.00%|                      stacklevel=2)
   203|         0|            0|            0|  0.00%|
   204|         0|            0|            0|  0.00%|    # Cast bool, unsigned int, and int to float64 by default
   205|         0|            0|            0|  0.00%|    if dtype is None and issubclass(arr.dtype.type, (nt.integer, nt.bool_)):
   206|         0|            0|            0|  0.00%|        dtype = mu.dtype('f8')
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|    # Compute the mean.
   209|         0|            0|            0|  0.00%|    # Note that if dtype is not of inexact type then arraymean will
   210|         0|            0|            0|  0.00%|    # not be either.
   211|         0|            0|            0|  0.00%|    arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)
   212|         0|            0|            0|  0.00%|    # The shape of rcount has to match arrmean to not change the shape of out
   213|         0|            0|            0|  0.00%|    # in broadcasting. Otherwise, it cannot be stored back to arrmean.
   214|         0|            0|            0|  0.00%|    if rcount.ndim == 0:
   215|         0|            0|            0|  0.00%|        # fast-path for default case when where is True
   216|         0|            0|            0|  0.00%|        div = rcount
   217|         0|            0|            0|  0.00%|    else:
   218|         0|            0|            0|  0.00%|        # matching rcount to arrmean when where is specified as array
   219|         0|            0|            0|  0.00%|        div = rcount.reshape(arrmean.shape)
   220|         0|            0|            0|  0.00%|    if isinstance(arrmean, mu.ndarray):
   221|         0|            0|            0|  0.00%|        arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',
   222|         0|            0|            0|  0.00%|                                 subok=False)
   223|         0|            0|            0|  0.00%|    else:
   224|         0|            0|            0|  0.00%|        arrmean = arrmean.dtype.type(arrmean / rcount)
   225|         0|            0|            0|  0.00%|
   226|         0|            0|            0|  0.00%|    # Compute sum of squared deviations from mean
   227|         0|            0|            0|  0.00%|    # Note that x may not be inexact and that we need it to be an array,
   228|         0|            0|            0|  0.00%|    # not a scalar.
   229|         0|            0|            0|  0.00%|    x = asanyarray(arr - arrmean)
   230|         0|            0|            0|  0.00%|
   231|         0|            0|            0|  0.00%|    if issubclass(arr.dtype.type, (nt.floating, nt.integer)):
   232|         0|            0|            0|  0.00%|        x = um.multiply(x, x, out=x)
   233|         0|            0|            0|  0.00%|    # Fast-paths for built-in complex types
   234|         0|            0|            0|  0.00%|    elif x.dtype in _complex_to_float:
   235|         0|            0|            0|  0.00%|        xv = x.view(dtype=(_complex_to_float[x.dtype], (2,)))
   236|         0|            0|            0|  0.00%|        um.multiply(xv, xv, out=xv)
   237|         0|            0|            0|  0.00%|        x = um.add(xv[..., 0], xv[..., 1], out=x.real).real
   238|         0|            0|            0|  0.00%|    # Most general case; includes handling object arrays containing imaginary
   239|         0|            0|            0|  0.00%|    # numbers and complex types with non-native byteorder
   240|         0|            0|            0|  0.00%|    else:
   241|         0|            0|            0|  0.00%|        x = um.multiply(x, um.conjugate(x), out=x).real
   242|         0|            0|            0|  0.00%|
   243|         0|            0|            0|  0.00%|    ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)
   244|         0|            0|            0|  0.00%|
   245|         0|            0|            0|  0.00%|    # Compute degrees of freedom and make sure it is not negative.
   246|         0|            0|            0|  0.00%|    rcount = um.maximum(rcount - ddof, 0)
   247|         0|            0|            0|  0.00%|
   248|         0|            0|            0|  0.00%|    # divide by degrees of freedom
   249|         0|            0|            0|  0.00%|    if isinstance(ret, mu.ndarray):
   250|         0|            0|            0|  0.00%|        ret = um.true_divide(
   251|         0|            0|            0|  0.00%|                ret, rcount, out=ret, casting='unsafe', subok=False)
   252|         0|            0|            0|  0.00%|    elif hasattr(ret, 'dtype'):
   253|         0|            0|            0|  0.00%|        ret = ret.dtype.type(ret / rcount)
   254|         0|            0|            0|  0.00%|    else:
   255|         0|            0|            0|  0.00%|        ret = ret / rcount
   256|         0|            0|            0|  0.00%|
   257|         0|            0|            0|  0.00%|    return ret
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|def _std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,
   260|         0|            0|            0|  0.00%|         where=True):
   261|         0|            0|            0|  0.00%|    ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
   262|         0|            0|            0|  0.00%|               keepdims=keepdims, where=where)
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|    if isinstance(ret, mu.ndarray):
   265|         0|            0|            0|  0.00%|        ret = um.sqrt(ret, out=ret)
   266|         0|            0|            0|  0.00%|    elif hasattr(ret, 'dtype'):
   267|         0|            0|            0|  0.00%|        ret = ret.dtype.type(um.sqrt(ret))
   268|         0|            0|            0|  0.00%|    else:
   269|         0|            0|            0|  0.00%|        ret = um.sqrt(ret)
   270|         0|            0|            0|  0.00%|
   271|         0|            0|            0|  0.00%|    return ret
   272|         0|            0|            0|  0.00%|
   273|         0|            0|            0|  0.00%|def _ptp(a, axis=None, out=None, keepdims=False):
   274|         0|            0|            0|  0.00%|    return um.subtract(
   275|         0|            0|            0|  0.00%|        umr_maximum(a, axis, None, out, keepdims),
   276|         0|            0|            0|  0.00%|        umr_minimum(a, axis, None, None, keepdims),
   277|         0|            0|            0|  0.00%|        out
   278|         0|            0|            0|  0.00%|    )
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|def _dump(self, file, protocol=2):
   281|         0|            0|            0|  0.00%|    if hasattr(file, 'write'):
   282|         0|            0|            0|  0.00%|        ctx = contextlib_nullcontext(file)
   283|         0|            0|            0|  0.00%|    else:
   284|         0|            0|            0|  0.00%|        ctx = open(os_fspath(file), "wb")
   285|         0|            0|            0|  0.00%|    with ctx as f:
   286|         0|            0|            0|  0.00%|        pickle.dump(self, f, protocol=protocol)
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|def _dumps(self, protocol=2):
   289|         0|            0|            0|  0.00%|    return pickle.dumps(self, protocol=protocol)
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py
File duration: 0.000184536s (0.02%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|import functools
     2|         0|            0|            0|  0.00%|import itertools
     3|         0|            0|            0|  0.00%|import operator
     4|         0|            0|            0|  0.00%|import sys
     5|         0|            0|            0|  0.00%|import warnings
     6|         0|            0|            0|  0.00%|import numbers
     7|         0|            0|            0|  0.00%|
     8|         0|            0|            0|  0.00%|import numpy as np
     9|         0|            0|            0|  0.00%|from . import multiarray
    10|         0|            0|            0|  0.00%|from .multiarray import (
    11|         0|            0|            0|  0.00%|    _fastCopyAndTranspose as fastCopyAndTranspose, ALLOW_THREADS,
    12|         0|            0|            0|  0.00%|    BUFSIZE, CLIP, MAXDIMS, MAY_SHARE_BOUNDS, MAY_SHARE_EXACT, RAISE,
    13|         0|            0|            0|  0.00%|    WRAP, arange, array, broadcast, can_cast, compare_chararrays,
    14|         0|            0|            0|  0.00%|    concatenate, copyto, dot, dtype, empty,
    15|         0|            0|            0|  0.00%|    empty_like, flatiter, frombuffer, fromfile, fromiter, fromstring,
    16|         0|            0|            0|  0.00%|    inner, lexsort, matmul, may_share_memory,
    17|         0|            0|            0|  0.00%|    min_scalar_type, ndarray, nditer, nested_iters, promote_types,
    18|         0|            0|            0|  0.00%|    putmask, result_type, set_numeric_ops, shares_memory, vdot, where,
    19|         0|            0|            0|  0.00%|    zeros, normalize_axis_index)
    20|         0|            0|            0|  0.00%|
    21|         0|            0|            0|  0.00%|from . import overrides
    22|         0|            0|            0|  0.00%|from . import umath
    23|         0|            0|            0|  0.00%|from . import shape_base
    24|         0|            0|            0|  0.00%|from .overrides import set_array_function_like_doc, set_module
    25|         0|            0|            0|  0.00%|from .umath import (multiply, invert, sin, PINF, NAN)
    26|         0|            0|            0|  0.00%|from . import numerictypes
    27|         0|            0|            0|  0.00%|from .numerictypes import longlong, intc, int_, float_, complex_, bool_
    28|         0|            0|            0|  0.00%|from ._exceptions import TooHardError, AxisError
    29|         0|            0|            0|  0.00%|from ._asarray import asarray, asanyarray
    30|         0|            0|            0|  0.00%|from ._ufunc_config import errstate
    31|         0|            0|            0|  0.00%|
    32|         0|            0|            0|  0.00%|bitwise_not = invert
    33|         0|            0|            0|  0.00%|ufunc = type(sin)
    34|         0|            0|            0|  0.00%|newaxis = None
    35|         0|            0|            0|  0.00%|
    36|         0|            0|            0|  0.00%|array_function_dispatch = functools.partial(
    37|         0|            0|            0|  0.00%|    overrides.array_function_dispatch, module='numpy')
    38|         0|            0|            0|  0.00%|
    39|         0|            0|            0|  0.00%|
    40|         0|            0|            0|  0.00%|__all__ = [
    41|         0|            0|            0|  0.00%|    'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',
    42|         0|            0|            0|  0.00%|    'arange', 'array', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',
    43|         0|            0|            0|  0.00%|    'fromstring', 'fromfile', 'frombuffer', 'where',
    44|         0|            0|            0|  0.00%|    'argwhere', 'copyto', 'concatenate', 'fastCopyAndTranspose', 'lexsort',
    45|         0|            0|            0|  0.00%|    'set_numeric_ops', 'can_cast', 'promote_types', 'min_scalar_type',
    46|         0|            0|            0|  0.00%|    'result_type', 'isfortran', 'empty_like', 'zeros_like', 'ones_like',
    47|         0|            0|            0|  0.00%|    'correlate', 'convolve', 'inner', 'dot', 'outer', 'vdot', 'roll',
    48|         0|            0|            0|  0.00%|    'rollaxis', 'moveaxis', 'cross', 'tensordot', 'little_endian',
    49|         0|            0|            0|  0.00%|    'fromiter', 'array_equal', 'array_equiv', 'indices', 'fromfunction',
    50|         0|            0|            0|  0.00%|    'isclose', 'isscalar', 'binary_repr', 'base_repr', 'ones',
    51|         0|            0|            0|  0.00%|    'identity', 'allclose', 'compare_chararrays', 'putmask',
    52|         0|            0|            0|  0.00%|    'flatnonzero', 'Inf', 'inf', 'infty', 'Infinity', 'nan', 'NaN',
    53|         0|            0|            0|  0.00%|    'False_', 'True_', 'bitwise_not', 'CLIP', 'RAISE', 'WRAP', 'MAXDIMS',
    54|         0|            0|            0|  0.00%|    'BUFSIZE', 'ALLOW_THREADS', 'ComplexWarning', 'full', 'full_like',
    55|         0|            0|            0|  0.00%|    'matmul', 'shares_memory', 'may_share_memory', 'MAY_SHARE_BOUNDS',
    56|         0|            0|            0|  0.00%|    'MAY_SHARE_EXACT', 'TooHardError', 'AxisError']
    57|         0|            0|            0|  0.00%|
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|@set_module('numpy')
    60|         0|            0|            0|  0.00%|class ComplexWarning(RuntimeWarning):
    61|         0|            0|            0|  0.00%|    """
    62|         0|            0|            0|  0.00%|    The warning raised when casting a complex dtype to a real dtype.
    63|         0|            0|            0|  0.00%|
    64|         0|            0|            0|  0.00%|    As implemented, casting a complex number to a real discards its imaginary
    65|         0|            0|            0|  0.00%|    part, but this behavior may not be what the user actually wants.
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|    """
    68|         0|            0|            0|  0.00%|    pass
    69|         0|            0|            0|  0.00%|
    70|         0|            0|            0|  0.00%|
    71|         1|  1.66893e-06|  1.66893e-06|  0.00%|def _zeros_like_dispatcher(a, dtype=None, order=None, subok=None, shape=None):
    72|         1|  2.86102e-06|  2.86102e-06|  0.00%|    return (a,)
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|
    75|         1|   3.8147e-06|   3.8147e-06|  0.00%|@array_function_dispatch(_zeros_like_dispatcher)
    76|         0|            0|            0|  0.00%|def zeros_like(a, dtype=None, order='K', subok=True, shape=None):
    77|         0|            0|            0|  0.00%|    """
    78|         0|            0|            0|  0.00%|    Return an array of zeros with the same shape and type as a given array.
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|    Parameters
    81|         0|            0|            0|  0.00%|    ----------
    82|         0|            0|            0|  0.00%|    a : array_like
    83|         0|            0|            0|  0.00%|        The shape and data-type of `a` define these same attributes of
    84|         0|            0|            0|  0.00%|        the returned array.
    85|         0|            0|            0|  0.00%|    dtype : data-type, optional
    86|         0|            0|            0|  0.00%|        Overrides the data type of the result.
    87|         0|            0|            0|  0.00%|
    88|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    89|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
    90|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
    91|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
    92|         0|            0|            0|  0.00%|        'C' otherwise. 'K' means match the layout of `a` as closely
    93|         0|            0|            0|  0.00%|        as possible.
    94|         0|            0|            0|  0.00%|
    95|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    96|         0|            0|            0|  0.00%|    subok : bool, optional.
    97|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
    98|         0|            0|            0|  0.00%|        type of `a`, otherwise it will be a base-class array. Defaults
    99|         0|            0|            0|  0.00%|        to True.
   100|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   101|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   102|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   103|         0|            0|            0|  0.00%|        order='C' is implied.
   104|         0|            0|            0|  0.00%|
   105|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|    Returns
   108|         0|            0|            0|  0.00%|    -------
   109|         0|            0|            0|  0.00%|    out : ndarray
   110|         0|            0|            0|  0.00%|        Array of zeros with the same shape and type as `a`.
   111|         0|            0|            0|  0.00%|
   112|         0|            0|            0|  0.00%|    See Also
   113|         0|            0|            0|  0.00%|    --------
   114|         0|            0|            0|  0.00%|    empty_like : Return an empty array with shape and type of input.
   115|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   116|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   117|         0|            0|            0|  0.00%|    zeros : Return a new array setting values to zero.
   118|         0|            0|            0|  0.00%|
   119|         0|            0|            0|  0.00%|    Examples
   120|         0|            0|            0|  0.00%|    --------
   121|         0|            0|            0|  0.00%|    >>> x = np.arange(6)
   122|         0|            0|            0|  0.00%|    >>> x = x.reshape((2, 3))
   123|         0|            0|            0|  0.00%|    >>> x
   124|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   125|         0|            0|            0|  0.00%|           [3, 4, 5]])
   126|         0|            0|            0|  0.00%|    >>> np.zeros_like(x)
   127|         0|            0|            0|  0.00%|    array([[0, 0, 0],
   128|         0|            0|            0|  0.00%|           [0, 0, 0]])
   129|         0|            0|            0|  0.00%|
   130|         0|            0|            0|  0.00%|    >>> y = np.arange(3, dtype=float)
   131|         0|            0|            0|  0.00%|    >>> y
   132|         0|            0|            0|  0.00%|    array([0., 1., 2.])
   133|         0|            0|            0|  0.00%|    >>> np.zeros_like(y)
   134|         0|            0|            0|  0.00%|    array([0.,  0.,  0.])
   135|         0|            0|            0|  0.00%|
   136|         0|            0|            0|  0.00%|    """
   137|         1|  8.34465e-06|  8.34465e-06|  0.00%|    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)
(call)|         1|  2.76566e-05|  2.76566e-05|  0.00%|# <__array_function__ internals>_9:2 empty_like
   138|         0|            0|            0|  0.00%|    # needed instead of a 0 to get same result as zeros for for string dtypes
   139|         1|  4.05312e-06|  4.05312e-06|  0.00%|    z = zeros(1, dtype=res.dtype)
   140|         1|  1.12057e-05|  1.12057e-05|  0.00%|    multiarray.copyto(res, z, casting='unsafe')
(call)|         1|  2.07424e-05|  2.07424e-05|  0.00%|# <__array_function__ internals>_4:2 copyto
   141|         1|  3.57628e-06|  3.57628e-06|  0.00%|    return res
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|
   144|         0|            0|            0|  0.00%|def _ones_dispatcher(shape, dtype=None, order=None, *, like=None):
   145|         0|            0|            0|  0.00%|    return(like,)
   146|         0|            0|            0|  0.00%|
   147|         0|            0|            0|  0.00%|
   148|         1|  4.05312e-06|  4.05312e-06|  0.00%|@set_array_function_like_doc
   149|         0|            0|            0|  0.00%|@set_module('numpy')
   150|         0|            0|            0|  0.00%|def ones(shape, dtype=None, order='C', *, like=None):
   151|         0|            0|            0|  0.00%|    """
   152|         0|            0|            0|  0.00%|    Return a new array of given shape and type, filled with ones.
   153|         0|            0|            0|  0.00%|
   154|         0|            0|            0|  0.00%|    Parameters
   155|         0|            0|            0|  0.00%|    ----------
   156|         0|            0|            0|  0.00%|    shape : int or sequence of ints
   157|         0|            0|            0|  0.00%|        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
   158|         0|            0|            0|  0.00%|    dtype : data-type, optional
   159|         0|            0|            0|  0.00%|        The desired data-type for the array, e.g., `numpy.int8`.  Default is
   160|         0|            0|            0|  0.00%|        `numpy.float64`.
   161|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional, default: C
   162|         0|            0|            0|  0.00%|        Whether to store multi-dimensional data in row-major
   163|         0|            0|            0|  0.00%|        (C-style) or column-major (Fortran-style) order in
   164|         0|            0|            0|  0.00%|        memory.
   165|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   166|         0|            0|            0|  0.00%|
   167|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    Returns
   170|         0|            0|            0|  0.00%|    -------
   171|         0|            0|            0|  0.00%|    out : ndarray
   172|         0|            0|            0|  0.00%|        Array of ones with the given shape, dtype, and order.
   173|         0|            0|            0|  0.00%|
   174|         0|            0|            0|  0.00%|    See Also
   175|         0|            0|            0|  0.00%|    --------
   176|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   177|         0|            0|            0|  0.00%|    empty : Return a new uninitialized array.
   178|         0|            0|            0|  0.00%|    zeros : Return a new array setting values to zero.
   179|         0|            0|            0|  0.00%|    full : Return a new array of given shape filled with value.
   180|         0|            0|            0|  0.00%|
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|    Examples
   183|         0|            0|            0|  0.00%|    --------
   184|         0|            0|            0|  0.00%|    >>> np.ones(5)
   185|         0|            0|            0|  0.00%|    array([1., 1., 1., 1., 1.])
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|    >>> np.ones((5,), dtype=int)
   188|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1])
   189|         0|            0|            0|  0.00%|
   190|         0|            0|            0|  0.00%|    >>> np.ones((2, 1))
   191|         0|            0|            0|  0.00%|    array([[1.],
   192|         0|            0|            0|  0.00%|           [1.]])
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|    >>> s = (2,2)
   195|         0|            0|            0|  0.00%|    >>> np.ones(s)
   196|         0|            0|            0|  0.00%|    array([[1.,  1.],
   197|         0|            0|            0|  0.00%|           [1.,  1.]])
   198|         0|            0|            0|  0.00%|
   199|         0|            0|            0|  0.00%|    """
   200|         1|  2.86102e-06|  2.86102e-06|  0.00%|    if like is not None:
   201|         0|            0|            0|  0.00%|        return _ones_with_like(shape, dtype=dtype, order=order, like=like)
   202|         0|            0|            0|  0.00%|
   203|         1|  4.76837e-06|  4.76837e-06|  0.00%|    a = empty(shape, dtype, order)
   204|         1|  8.58307e-06|  8.58307e-06|  0.00%|    multiarray.copyto(a, 1, casting='unsafe')
(call)|         1|  3.98159e-05|  3.98159e-05|  0.00%|# <__array_function__ internals>_4:2 copyto
   205|         1|   2.6226e-06|   2.6226e-06|  0.00%|    return a
   206|         0|            0|            0|  0.00%|
   207|         0|            0|            0|  0.00%|
   208|         0|            0|            0|  0.00%|_ones_with_like = array_function_dispatch(
   209|         0|            0|            0|  0.00%|    _ones_dispatcher
   210|         0|            0|            0|  0.00%|)(ones)
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|
   213|         0|            0|            0|  0.00%|def _ones_like_dispatcher(a, dtype=None, order=None, subok=None, shape=None):
   214|         0|            0|            0|  0.00%|    return (a,)
   215|         0|            0|            0|  0.00%|
   216|         0|            0|            0|  0.00%|
   217|         0|            0|            0|  0.00%|@array_function_dispatch(_ones_like_dispatcher)
   218|         0|            0|            0|  0.00%|def ones_like(a, dtype=None, order='K', subok=True, shape=None):
   219|         0|            0|            0|  0.00%|    """
   220|         0|            0|            0|  0.00%|    Return an array of ones with the same shape and type as a given array.
   221|         0|            0|            0|  0.00%|
   222|         0|            0|            0|  0.00%|    Parameters
   223|         0|            0|            0|  0.00%|    ----------
   224|         0|            0|            0|  0.00%|    a : array_like
   225|         0|            0|            0|  0.00%|        The shape and data-type of `a` define these same attributes of
   226|         0|            0|            0|  0.00%|        the returned array.
   227|         0|            0|            0|  0.00%|    dtype : data-type, optional
   228|         0|            0|            0|  0.00%|        Overrides the data type of the result.
   229|         0|            0|            0|  0.00%|
   230|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   231|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
   232|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
   233|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
   234|         0|            0|            0|  0.00%|        'C' otherwise. 'K' means match the layout of `a` as closely
   235|         0|            0|            0|  0.00%|        as possible.
   236|         0|            0|            0|  0.00%|
   237|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   238|         0|            0|            0|  0.00%|    subok : bool, optional.
   239|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
   240|         0|            0|            0|  0.00%|        type of `a`, otherwise it will be a base-class array. Defaults
   241|         0|            0|            0|  0.00%|        to True.
   242|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   243|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   244|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   245|         0|            0|            0|  0.00%|        order='C' is implied.
   246|         0|            0|            0|  0.00%|
   247|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|    Returns
   250|         0|            0|            0|  0.00%|    -------
   251|         0|            0|            0|  0.00%|    out : ndarray
   252|         0|            0|            0|  0.00%|        Array of ones with the same shape and type as `a`.
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    See Also
   255|         0|            0|            0|  0.00%|    --------
   256|         0|            0|            0|  0.00%|    empty_like : Return an empty array with shape and type of input.
   257|         0|            0|            0|  0.00%|    zeros_like : Return an array of zeros with shape and type of input.
   258|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   259|         0|            0|            0|  0.00%|    ones : Return a new array setting values to one.
   260|         0|            0|            0|  0.00%|
   261|         0|            0|            0|  0.00%|    Examples
   262|         0|            0|            0|  0.00%|    --------
   263|         0|            0|            0|  0.00%|    >>> x = np.arange(6)
   264|         0|            0|            0|  0.00%|    >>> x = x.reshape((2, 3))
   265|         0|            0|            0|  0.00%|    >>> x
   266|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   267|         0|            0|            0|  0.00%|           [3, 4, 5]])
   268|         0|            0|            0|  0.00%|    >>> np.ones_like(x)
   269|         0|            0|            0|  0.00%|    array([[1, 1, 1],
   270|         0|            0|            0|  0.00%|           [1, 1, 1]])
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    >>> y = np.arange(3, dtype=float)
   273|         0|            0|            0|  0.00%|    >>> y
   274|         0|            0|            0|  0.00%|    array([0., 1., 2.])
   275|         0|            0|            0|  0.00%|    >>> np.ones_like(y)
   276|         0|            0|            0|  0.00%|    array([1.,  1.,  1.])
   277|         0|            0|            0|  0.00%|
   278|         0|            0|            0|  0.00%|    """
   279|         0|            0|            0|  0.00%|    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)
   280|         0|            0|            0|  0.00%|    multiarray.copyto(res, 1, casting='unsafe')
   281|         0|            0|            0|  0.00%|    return res
   282|         0|            0|            0|  0.00%|
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|def _full_dispatcher(shape, fill_value, dtype=None, order=None, *, like=None):
   285|         0|            0|            0|  0.00%|    return(like,)
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|
   288|         0|            0|            0|  0.00%|@set_array_function_like_doc
   289|         0|            0|            0|  0.00%|@set_module('numpy')
   290|         0|            0|            0|  0.00%|def full(shape, fill_value, dtype=None, order='C', *, like=None):
   291|         0|            0|            0|  0.00%|    """
   292|         0|            0|            0|  0.00%|    Return a new array of given shape and type, filled with `fill_value`.
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    Parameters
   295|         0|            0|            0|  0.00%|    ----------
   296|         0|            0|            0|  0.00%|    shape : int or sequence of ints
   297|         0|            0|            0|  0.00%|        Shape of the new array, e.g., ``(2, 3)`` or ``2``.
   298|         0|            0|            0|  0.00%|    fill_value : scalar or array_like
   299|         0|            0|            0|  0.00%|        Fill value.
   300|         0|            0|            0|  0.00%|    dtype : data-type, optional
   301|         0|            0|            0|  0.00%|        The desired data-type for the array  The default, None, means
   302|         0|            0|            0|  0.00%|         `np.array(fill_value).dtype`.
   303|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional
   304|         0|            0|            0|  0.00%|        Whether to store multidimensional data in C- or Fortran-contiguous
   305|         0|            0|            0|  0.00%|        (row- or column-wise) order in memory.
   306|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
   307|         0|            0|            0|  0.00%|
   308|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   309|         0|            0|            0|  0.00%|
   310|         0|            0|            0|  0.00%|    Returns
   311|         0|            0|            0|  0.00%|    -------
   312|         0|            0|            0|  0.00%|    out : ndarray
   313|         0|            0|            0|  0.00%|        Array of `fill_value` with the given shape, dtype, and order.
   314|         0|            0|            0|  0.00%|
   315|         0|            0|            0|  0.00%|    See Also
   316|         0|            0|            0|  0.00%|    --------
   317|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   318|         0|            0|            0|  0.00%|    empty : Return a new uninitialized array.
   319|         0|            0|            0|  0.00%|    ones : Return a new array setting values to one.
   320|         0|            0|            0|  0.00%|    zeros : Return a new array setting values to zero.
   321|         0|            0|            0|  0.00%|
   322|         0|            0|            0|  0.00%|    Examples
   323|         0|            0|            0|  0.00%|    --------
   324|         0|            0|            0|  0.00%|    >>> np.full((2, 2), np.inf)
   325|         0|            0|            0|  0.00%|    array([[inf, inf],
   326|         0|            0|            0|  0.00%|           [inf, inf]])
   327|         0|            0|            0|  0.00%|    >>> np.full((2, 2), 10)
   328|         0|            0|            0|  0.00%|    array([[10, 10],
   329|         0|            0|            0|  0.00%|           [10, 10]])
   330|         0|            0|            0|  0.00%|
   331|         0|            0|            0|  0.00%|    >>> np.full((2, 2), [1, 2])
   332|         0|            0|            0|  0.00%|    array([[1, 2],
   333|         0|            0|            0|  0.00%|           [1, 2]])
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|    """
   336|         0|            0|            0|  0.00%|    if like is not None:
   337|         0|            0|            0|  0.00%|        return _full_with_like(shape, fill_value, dtype=dtype, order=order, like=like)
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|    if dtype is None:
   340|         0|            0|            0|  0.00%|        fill_value = asarray(fill_value)
   341|         0|            0|            0|  0.00%|        dtype = fill_value.dtype
   342|         0|            0|            0|  0.00%|    a = empty(shape, dtype, order)
   343|         0|            0|            0|  0.00%|    multiarray.copyto(a, fill_value, casting='unsafe')
   344|         0|            0|            0|  0.00%|    return a
   345|         0|            0|            0|  0.00%|
   346|         0|            0|            0|  0.00%|
   347|         0|            0|            0|  0.00%|_full_with_like = array_function_dispatch(
   348|         0|            0|            0|  0.00%|    _full_dispatcher
   349|         0|            0|            0|  0.00%|)(full)
   350|         0|            0|            0|  0.00%|
   351|         0|            0|            0|  0.00%|
   352|         0|            0|            0|  0.00%|def _full_like_dispatcher(a, fill_value, dtype=None, order=None, subok=None, shape=None):
   353|         0|            0|            0|  0.00%|    return (a,)
   354|         0|            0|            0|  0.00%|
   355|         0|            0|            0|  0.00%|
   356|         0|            0|            0|  0.00%|@array_function_dispatch(_full_like_dispatcher)
   357|         0|            0|            0|  0.00%|def full_like(a, fill_value, dtype=None, order='K', subok=True, shape=None):
   358|         0|            0|            0|  0.00%|    """
   359|         0|            0|            0|  0.00%|    Return a full array with the same shape and type as a given array.
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|    Parameters
   362|         0|            0|            0|  0.00%|    ----------
   363|         0|            0|            0|  0.00%|    a : array_like
   364|         0|            0|            0|  0.00%|        The shape and data-type of `a` define these same attributes of
   365|         0|            0|            0|  0.00%|        the returned array.
   366|         0|            0|            0|  0.00%|    fill_value : scalar
   367|         0|            0|            0|  0.00%|        Fill value.
   368|         0|            0|            0|  0.00%|    dtype : data-type, optional
   369|         0|            0|            0|  0.00%|        Overrides the data type of the result.
   370|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
   371|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
   372|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,
   373|         0|            0|            0|  0.00%|        'C' otherwise. 'K' means match the layout of `a` as closely
   374|         0|            0|            0|  0.00%|        as possible.
   375|         0|            0|            0|  0.00%|    subok : bool, optional.
   376|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
   377|         0|            0|            0|  0.00%|        type of `a`, otherwise it will be a base-class array. Defaults
   378|         0|            0|            0|  0.00%|        to True.
   379|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   380|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   381|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   382|         0|            0|            0|  0.00%|        order='C' is implied.
   383|         0|            0|            0|  0.00%|
   384|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   385|         0|            0|            0|  0.00%|
   386|         0|            0|            0|  0.00%|    Returns
   387|         0|            0|            0|  0.00%|    -------
   388|         0|            0|            0|  0.00%|    out : ndarray
   389|         0|            0|            0|  0.00%|        Array of `fill_value` with the same shape and type as `a`.
   390|         0|            0|            0|  0.00%|
   391|         0|            0|            0|  0.00%|    See Also
   392|         0|            0|            0|  0.00%|    --------
   393|         0|            0|            0|  0.00%|    empty_like : Return an empty array with shape and type of input.
   394|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   395|         0|            0|            0|  0.00%|    zeros_like : Return an array of zeros with shape and type of input.
   396|         0|            0|            0|  0.00%|    full : Return a new array of given shape filled with value.
   397|         0|            0|            0|  0.00%|
   398|         0|            0|            0|  0.00%|    Examples
   399|         0|            0|            0|  0.00%|    --------
   400|         0|            0|            0|  0.00%|    >>> x = np.arange(6, dtype=int)
   401|         0|            0|            0|  0.00%|    >>> np.full_like(x, 1)
   402|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1, 1])
   403|         0|            0|            0|  0.00%|    >>> np.full_like(x, 0.1)
   404|         0|            0|            0|  0.00%|    array([0, 0, 0, 0, 0, 0])
   405|         0|            0|            0|  0.00%|    >>> np.full_like(x, 0.1, dtype=np.double)
   406|         0|            0|            0|  0.00%|    array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
   407|         0|            0|            0|  0.00%|    >>> np.full_like(x, np.nan, dtype=np.double)
   408|         0|            0|            0|  0.00%|    array([nan, nan, nan, nan, nan, nan])
   409|         0|            0|            0|  0.00%|
   410|         0|            0|            0|  0.00%|    >>> y = np.arange(6, dtype=np.double)
   411|         0|            0|            0|  0.00%|    >>> np.full_like(y, 0.1)
   412|         0|            0|            0|  0.00%|    array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
   413|         0|            0|            0|  0.00%|
   414|         0|            0|            0|  0.00%|    """
   415|         0|            0|            0|  0.00%|    res = empty_like(a, dtype=dtype, order=order, subok=subok, shape=shape)
   416|         0|            0|            0|  0.00%|    multiarray.copyto(res, fill_value, casting='unsafe')
   417|         0|            0|            0|  0.00%|    return res
   418|         0|            0|            0|  0.00%|
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|def _count_nonzero_dispatcher(a, axis=None, *, keepdims=None):
   421|         0|            0|            0|  0.00%|    return (a,)
   422|         0|            0|            0|  0.00%|
   423|         0|            0|            0|  0.00%|
   424|         0|            0|            0|  0.00%|@array_function_dispatch(_count_nonzero_dispatcher)
   425|         0|            0|            0|  0.00%|def count_nonzero(a, axis=None, *, keepdims=False):
   426|         0|            0|            0|  0.00%|    """
   427|         0|            0|            0|  0.00%|    Counts the number of non-zero values in the array ``a``.
   428|         0|            0|            0|  0.00%|
   429|         0|            0|            0|  0.00%|    The word "non-zero" is in reference to the Python 2.x
   430|         0|            0|            0|  0.00%|    built-in method ``__nonzero__()`` (renamed ``__bool__()``
   431|         0|            0|            0|  0.00%|    in Python 3.x) of Python objects that tests an object's
   432|         0|            0|            0|  0.00%|    "truthfulness". For example, any number is considered
   433|         0|            0|            0|  0.00%|    truthful if it is nonzero, whereas any string is considered
   434|         0|            0|            0|  0.00%|    truthful if it is not the empty string. Thus, this function
   435|         0|            0|            0|  0.00%|    (recursively) counts how many elements in ``a`` (and in
   436|         0|            0|            0|  0.00%|    sub-arrays thereof) have their ``__nonzero__()`` or ``__bool__()``
   437|         0|            0|            0|  0.00%|    method evaluated to ``True``.
   438|         0|            0|            0|  0.00%|
   439|         0|            0|            0|  0.00%|    Parameters
   440|         0|            0|            0|  0.00%|    ----------
   441|         0|            0|            0|  0.00%|    a : array_like
   442|         0|            0|            0|  0.00%|        The array for which to count non-zeros.
   443|         0|            0|            0|  0.00%|    axis : int or tuple, optional
   444|         0|            0|            0|  0.00%|        Axis or tuple of axes along which to count non-zeros.
   445|         0|            0|            0|  0.00%|        Default is None, meaning that non-zeros will be counted
   446|         0|            0|            0|  0.00%|        along a flattened version of ``a``.
   447|         0|            0|            0|  0.00%|
   448|         0|            0|            0|  0.00%|        .. versionadded:: 1.12.0
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|    keepdims : bool, optional
   451|         0|            0|            0|  0.00%|        If this is set to True, the axes that are counted are left
   452|         0|            0|            0|  0.00%|        in the result as dimensions with size one. With this option,
   453|         0|            0|            0|  0.00%|        the result will broadcast correctly against the input array.
   454|         0|            0|            0|  0.00%|
   455|         0|            0|            0|  0.00%|        .. versionadded:: 1.19.0
   456|         0|            0|            0|  0.00%|
   457|         0|            0|            0|  0.00%|    Returns
   458|         0|            0|            0|  0.00%|    -------
   459|         0|            0|            0|  0.00%|    count : int or array of int
   460|         0|            0|            0|  0.00%|        Number of non-zero values in the array along a given axis.
   461|         0|            0|            0|  0.00%|        Otherwise, the total number of non-zero values in the array
   462|         0|            0|            0|  0.00%|        is returned.
   463|         0|            0|            0|  0.00%|
   464|         0|            0|            0|  0.00%|    See Also
   465|         0|            0|            0|  0.00%|    --------
   466|         0|            0|            0|  0.00%|    nonzero : Return the coordinates of all the non-zero values.
   467|         0|            0|            0|  0.00%|
   468|         0|            0|            0|  0.00%|    Examples
   469|         0|            0|            0|  0.00%|    --------
   470|         0|            0|            0|  0.00%|    >>> np.count_nonzero(np.eye(4))
   471|         0|            0|            0|  0.00%|    4
   472|         0|            0|            0|  0.00%|    >>> a = np.array([[0, 1, 7, 0],
   473|         0|            0|            0|  0.00%|    ...               [3, 0, 2, 19]])
   474|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a)
   475|         0|            0|            0|  0.00%|    5
   476|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a, axis=0)
   477|         0|            0|            0|  0.00%|    array([1, 1, 2, 1])
   478|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a, axis=1)
   479|         0|            0|            0|  0.00%|    array([2, 3])
   480|         0|            0|            0|  0.00%|    >>> np.count_nonzero(a, axis=1, keepdims=True)
   481|         0|            0|            0|  0.00%|    array([[2],
   482|         0|            0|            0|  0.00%|           [3]])
   483|         0|            0|            0|  0.00%|    """
   484|         0|            0|            0|  0.00%|    if axis is None and not keepdims:
   485|         0|            0|            0|  0.00%|        return multiarray.count_nonzero(a)
   486|         0|            0|            0|  0.00%|
   487|         0|            0|            0|  0.00%|    a = asanyarray(a)
   488|         0|            0|            0|  0.00%|
   489|         0|            0|            0|  0.00%|    # TODO: this works around .astype(bool) not working properly (gh-9847)
   490|         0|            0|            0|  0.00%|    if np.issubdtype(a.dtype, np.character):
   491|         0|            0|            0|  0.00%|        a_bool = a != a.dtype.type()
   492|         0|            0|            0|  0.00%|    else:
   493|         0|            0|            0|  0.00%|        a_bool = a.astype(np.bool_, copy=False)
   494|         0|            0|            0|  0.00%|
   495|         0|            0|            0|  0.00%|    return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims)
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|
   498|         0|            0|            0|  0.00%|@set_module('numpy')
   499|         0|            0|            0|  0.00%|def isfortran(a):
   500|         0|            0|            0|  0.00%|    """
   501|         0|            0|            0|  0.00%|    Check if the array is Fortran contiguous but *not* C contiguous.
   502|         0|            0|            0|  0.00%|
   503|         0|            0|            0|  0.00%|    This function is obsolete and, because of changes due to relaxed stride
   504|         0|            0|            0|  0.00%|    checking, its return value for the same array may differ for versions
   505|         0|            0|            0|  0.00%|    of NumPy >= 1.10.0 and previous versions. If you only want to check if an
   506|         0|            0|            0|  0.00%|    array is Fortran contiguous use ``a.flags.f_contiguous`` instead.
   507|         0|            0|            0|  0.00%|
   508|         0|            0|            0|  0.00%|    Parameters
   509|         0|            0|            0|  0.00%|    ----------
   510|         0|            0|            0|  0.00%|    a : ndarray
   511|         0|            0|            0|  0.00%|        Input array.
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|    Returns
   514|         0|            0|            0|  0.00%|    -------
   515|         0|            0|            0|  0.00%|    isfortran : bool
   516|         0|            0|            0|  0.00%|        Returns True if the array is Fortran contiguous but *not* C contiguous.
   517|         0|            0|            0|  0.00%|
   518|         0|            0|            0|  0.00%|
   519|         0|            0|            0|  0.00%|    Examples
   520|         0|            0|            0|  0.00%|    --------
   521|         0|            0|            0|  0.00%|
   522|         0|            0|            0|  0.00%|    np.array allows to specify whether the array is written in C-contiguous
   523|         0|            0|            0|  0.00%|    order (last index varies the fastest), or FORTRAN-contiguous order in
   524|         0|            0|            0|  0.00%|    memory (first index varies the fastest).
   525|         0|            0|            0|  0.00%|
   526|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')
   527|         0|            0|            0|  0.00%|    >>> a
   528|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   529|         0|            0|            0|  0.00%|           [4, 5, 6]])
   530|         0|            0|            0|  0.00%|    >>> np.isfortran(a)
   531|         0|            0|            0|  0.00%|    False
   532|         0|            0|            0|  0.00%|
   533|         0|            0|            0|  0.00%|    >>> b = np.array([[1, 2, 3], [4, 5, 6]], order='F')
   534|         0|            0|            0|  0.00%|    >>> b
   535|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   536|         0|            0|            0|  0.00%|           [4, 5, 6]])
   537|         0|            0|            0|  0.00%|    >>> np.isfortran(b)
   538|         0|            0|            0|  0.00%|    True
   539|         0|            0|            0|  0.00%|
   540|         0|            0|            0|  0.00%|
   541|         0|            0|            0|  0.00%|    The transpose of a C-ordered array is a FORTRAN-ordered array.
   542|         0|            0|            0|  0.00%|
   543|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C')
   544|         0|            0|            0|  0.00%|    >>> a
   545|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   546|         0|            0|            0|  0.00%|           [4, 5, 6]])
   547|         0|            0|            0|  0.00%|    >>> np.isfortran(a)
   548|         0|            0|            0|  0.00%|    False
   549|         0|            0|            0|  0.00%|    >>> b = a.T
   550|         0|            0|            0|  0.00%|    >>> b
   551|         0|            0|            0|  0.00%|    array([[1, 4],
   552|         0|            0|            0|  0.00%|           [2, 5],
   553|         0|            0|            0|  0.00%|           [3, 6]])
   554|         0|            0|            0|  0.00%|    >>> np.isfortran(b)
   555|         0|            0|            0|  0.00%|    True
   556|         0|            0|            0|  0.00%|
   557|         0|            0|            0|  0.00%|    C-ordered arrays evaluate as False even if they are also FORTRAN-ordered.
   558|         0|            0|            0|  0.00%|
   559|         0|            0|            0|  0.00%|    >>> np.isfortran(np.array([1, 2], order='F'))
   560|         0|            0|            0|  0.00%|    False
   561|         0|            0|            0|  0.00%|
   562|         0|            0|            0|  0.00%|    """
   563|         0|            0|            0|  0.00%|    return a.flags.fnc
   564|         0|            0|            0|  0.00%|
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|def _argwhere_dispatcher(a):
   567|         0|            0|            0|  0.00%|    return (a,)
   568|         0|            0|            0|  0.00%|
   569|         0|            0|            0|  0.00%|
   570|         0|            0|            0|  0.00%|@array_function_dispatch(_argwhere_dispatcher)
   571|         0|            0|            0|  0.00%|def argwhere(a):
   572|         0|            0|            0|  0.00%|    """
   573|         0|            0|            0|  0.00%|    Find the indices of array elements that are non-zero, grouped by element.
   574|         0|            0|            0|  0.00%|
   575|         0|            0|            0|  0.00%|    Parameters
   576|         0|            0|            0|  0.00%|    ----------
   577|         0|            0|            0|  0.00%|    a : array_like
   578|         0|            0|            0|  0.00%|        Input data.
   579|         0|            0|            0|  0.00%|
   580|         0|            0|            0|  0.00%|    Returns
   581|         0|            0|            0|  0.00%|    -------
   582|         0|            0|            0|  0.00%|    index_array : (N, a.ndim) ndarray
   583|         0|            0|            0|  0.00%|        Indices of elements that are non-zero. Indices are grouped by element.
   584|         0|            0|            0|  0.00%|        This array will have shape ``(N, a.ndim)`` where ``N`` is the number of
   585|         0|            0|            0|  0.00%|        non-zero items.
   586|         0|            0|            0|  0.00%|
   587|         0|            0|            0|  0.00%|    See Also
   588|         0|            0|            0|  0.00%|    --------
   589|         0|            0|            0|  0.00%|    where, nonzero
   590|         0|            0|            0|  0.00%|
   591|         0|            0|            0|  0.00%|    Notes
   592|         0|            0|            0|  0.00%|    -----
   593|         0|            0|            0|  0.00%|    ``np.argwhere(a)`` is almost the same as ``np.transpose(np.nonzero(a))``,
   594|         0|            0|            0|  0.00%|    but produces a result of the correct shape for a 0D array.
   595|         0|            0|            0|  0.00%|
   596|         0|            0|            0|  0.00%|    The output of ``argwhere`` is not suitable for indexing arrays.
   597|         0|            0|            0|  0.00%|    For this purpose use ``nonzero(a)`` instead.
   598|         0|            0|            0|  0.00%|
   599|         0|            0|            0|  0.00%|    Examples
   600|         0|            0|            0|  0.00%|    --------
   601|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2,3)
   602|         0|            0|            0|  0.00%|    >>> x
   603|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   604|         0|            0|            0|  0.00%|           [3, 4, 5]])
   605|         0|            0|            0|  0.00%|    >>> np.argwhere(x>1)
   606|         0|            0|            0|  0.00%|    array([[0, 2],
   607|         0|            0|            0|  0.00%|           [1, 0],
   608|         0|            0|            0|  0.00%|           [1, 1],
   609|         0|            0|            0|  0.00%|           [1, 2]])
   610|         0|            0|            0|  0.00%|
   611|         0|            0|            0|  0.00%|    """
   612|         0|            0|            0|  0.00%|    # nonzero does not behave well on 0d, so promote to 1d
   613|         0|            0|            0|  0.00%|    if np.ndim(a) == 0:
   614|         0|            0|            0|  0.00%|        a = shape_base.atleast_1d(a)
   615|         0|            0|            0|  0.00%|        # then remove the added dimension
   616|         0|            0|            0|  0.00%|        return argwhere(a)[:,:0]
   617|         0|            0|            0|  0.00%|    return transpose(nonzero(a))
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|
   620|         0|            0|            0|  0.00%|def _flatnonzero_dispatcher(a):
   621|         0|            0|            0|  0.00%|    return (a,)
   622|         0|            0|            0|  0.00%|
   623|         0|            0|            0|  0.00%|
   624|         0|            0|            0|  0.00%|@array_function_dispatch(_flatnonzero_dispatcher)
   625|         0|            0|            0|  0.00%|def flatnonzero(a):
   626|         0|            0|            0|  0.00%|    """
   627|         0|            0|            0|  0.00%|    Return indices that are non-zero in the flattened version of a.
   628|         0|            0|            0|  0.00%|
   629|         0|            0|            0|  0.00%|    This is equivalent to np.nonzero(np.ravel(a))[0].
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|    Parameters
   632|         0|            0|            0|  0.00%|    ----------
   633|         0|            0|            0|  0.00%|    a : array_like
   634|         0|            0|            0|  0.00%|        Input data.
   635|         0|            0|            0|  0.00%|
   636|         0|            0|            0|  0.00%|    Returns
   637|         0|            0|            0|  0.00%|    -------
   638|         0|            0|            0|  0.00%|    res : ndarray
   639|         0|            0|            0|  0.00%|        Output array, containing the indices of the elements of `a.ravel()`
   640|         0|            0|            0|  0.00%|        that are non-zero.
   641|         0|            0|            0|  0.00%|
   642|         0|            0|            0|  0.00%|    See Also
   643|         0|            0|            0|  0.00%|    --------
   644|         0|            0|            0|  0.00%|    nonzero : Return the indices of the non-zero elements of the input array.
   645|         0|            0|            0|  0.00%|    ravel : Return a 1-D array containing the elements of the input array.
   646|         0|            0|            0|  0.00%|
   647|         0|            0|            0|  0.00%|    Examples
   648|         0|            0|            0|  0.00%|    --------
   649|         0|            0|            0|  0.00%|    >>> x = np.arange(-2, 3)
   650|         0|            0|            0|  0.00%|    >>> x
   651|         0|            0|            0|  0.00%|    array([-2, -1,  0,  1,  2])
   652|         0|            0|            0|  0.00%|    >>> np.flatnonzero(x)
   653|         0|            0|            0|  0.00%|    array([0, 1, 3, 4])
   654|         0|            0|            0|  0.00%|
   655|         0|            0|            0|  0.00%|    Use the indices of the non-zero elements as an index array to extract
   656|         0|            0|            0|  0.00%|    these elements:
   657|         0|            0|            0|  0.00%|
   658|         0|            0|            0|  0.00%|    >>> x.ravel()[np.flatnonzero(x)]
   659|         0|            0|            0|  0.00%|    array([-2, -1,  1,  2])
   660|         0|            0|            0|  0.00%|
   661|         0|            0|            0|  0.00%|    """
   662|         0|            0|            0|  0.00%|    return np.nonzero(np.ravel(a))[0]
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|
   665|         0|            0|            0|  0.00%|_mode_from_name_dict = {'v': 0,
   666|         0|            0|            0|  0.00%|                        's': 1,
   667|         0|            0|            0|  0.00%|                        'f': 2}
   668|         0|            0|            0|  0.00%|
   669|         0|            0|            0|  0.00%|
   670|         0|            0|            0|  0.00%|def _mode_from_name(mode):
   671|         0|            0|            0|  0.00%|    if isinstance(mode, str):
   672|         0|            0|            0|  0.00%|        return _mode_from_name_dict[mode.lower()[0]]
   673|         0|            0|            0|  0.00%|    return mode
   674|         0|            0|            0|  0.00%|
   675|         0|            0|            0|  0.00%|
   676|         0|            0|            0|  0.00%|def _correlate_dispatcher(a, v, mode=None):
   677|         0|            0|            0|  0.00%|    return (a, v)
   678|         0|            0|            0|  0.00%|
   679|         0|            0|            0|  0.00%|
   680|         0|            0|            0|  0.00%|@array_function_dispatch(_correlate_dispatcher)
   681|         0|            0|            0|  0.00%|def correlate(a, v, mode='valid'):
   682|         0|            0|            0|  0.00%|    """
   683|         0|            0|            0|  0.00%|    Cross-correlation of two 1-dimensional sequences.
   684|         0|            0|            0|  0.00%|
   685|         0|            0|            0|  0.00%|    This function computes the correlation as generally defined in signal
   686|         0|            0|            0|  0.00%|    processing texts::
   687|         0|            0|            0|  0.00%|
   688|         0|            0|            0|  0.00%|        c_{av}[k] = sum_n a[n+k] * conj(v[n])
   689|         0|            0|            0|  0.00%|
   690|         0|            0|            0|  0.00%|    with a and v sequences being zero-padded where necessary and conj being
   691|         0|            0|            0|  0.00%|    the conjugate.
   692|         0|            0|            0|  0.00%|
   693|         0|            0|            0|  0.00%|    Parameters
   694|         0|            0|            0|  0.00%|    ----------
   695|         0|            0|            0|  0.00%|    a, v : array_like
   696|         0|            0|            0|  0.00%|        Input sequences.
   697|         0|            0|            0|  0.00%|    mode : {'valid', 'same', 'full'}, optional
   698|         0|            0|            0|  0.00%|        Refer to the `convolve` docstring.  Note that the default
   699|         0|            0|            0|  0.00%|        is 'valid', unlike `convolve`, which uses 'full'.
   700|         0|            0|            0|  0.00%|    old_behavior : bool
   701|         0|            0|            0|  0.00%|        `old_behavior` was removed in NumPy 1.10. If you need the old
   702|         0|            0|            0|  0.00%|        behavior, use `multiarray.correlate`.
   703|         0|            0|            0|  0.00%|
   704|         0|            0|            0|  0.00%|    Returns
   705|         0|            0|            0|  0.00%|    -------
   706|         0|            0|            0|  0.00%|    out : ndarray
   707|         0|            0|            0|  0.00%|        Discrete cross-correlation of `a` and `v`.
   708|         0|            0|            0|  0.00%|
   709|         0|            0|            0|  0.00%|    See Also
   710|         0|            0|            0|  0.00%|    --------
   711|         0|            0|            0|  0.00%|    convolve : Discrete, linear convolution of two one-dimensional sequences.
   712|         0|            0|            0|  0.00%|    multiarray.correlate : Old, no conjugate, version of correlate.
   713|         0|            0|            0|  0.00%|
   714|         0|            0|            0|  0.00%|    Notes
   715|         0|            0|            0|  0.00%|    -----
   716|         0|            0|            0|  0.00%|    The definition of correlation above is not unique and sometimes correlation
   717|         0|            0|            0|  0.00%|    may be defined differently. Another common definition is::
   718|         0|            0|            0|  0.00%|
   719|         0|            0|            0|  0.00%|        c'_{av}[k] = sum_n a[n] conj(v[n+k])
   720|         0|            0|            0|  0.00%|
   721|         0|            0|            0|  0.00%|    which is related to ``c_{av}[k]`` by ``c'_{av}[k] = c_{av}[-k]``.
   722|         0|            0|            0|  0.00%|
   723|         0|            0|            0|  0.00%|    Examples
   724|         0|            0|            0|  0.00%|    --------
   725|         0|            0|            0|  0.00%|    >>> np.correlate([1, 2, 3], [0, 1, 0.5])
   726|         0|            0|            0|  0.00%|    array([3.5])
   727|         0|            0|            0|  0.00%|    >>> np.correlate([1, 2, 3], [0, 1, 0.5], "same")
   728|         0|            0|            0|  0.00%|    array([2. ,  3.5,  3. ])
   729|         0|            0|            0|  0.00%|    >>> np.correlate([1, 2, 3], [0, 1, 0.5], "full")
   730|         0|            0|            0|  0.00%|    array([0.5,  2. ,  3.5,  3. ,  0. ])
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|    Using complex sequences:
   733|         0|            0|            0|  0.00%|
   734|         0|            0|            0|  0.00%|    >>> np.correlate([1+1j, 2, 3-1j], [0, 1, 0.5j], 'full')
   735|         0|            0|            0|  0.00%|    array([ 0.5-0.5j,  1.0+0.j ,  1.5-1.5j,  3.0-1.j ,  0.0+0.j ])
   736|         0|            0|            0|  0.00%|
   737|         0|            0|            0|  0.00%|    Note that you get the time reversed, complex conjugated result
   738|         0|            0|            0|  0.00%|    when the two input sequences change places, i.e.,
   739|         0|            0|            0|  0.00%|    ``c_{va}[k] = c^{*}_{av}[-k]``:
   740|         0|            0|            0|  0.00%|
   741|         0|            0|            0|  0.00%|    >>> np.correlate([0, 1, 0.5j], [1+1j, 2, 3-1j], 'full')
   742|         0|            0|            0|  0.00%|    array([ 0.0+0.j ,  3.0+1.j ,  1.5+1.5j,  1.0+0.j ,  0.5+0.5j])
   743|         0|            0|            0|  0.00%|
   744|         0|            0|            0|  0.00%|    """
   745|         0|            0|            0|  0.00%|    mode = _mode_from_name(mode)
   746|         0|            0|            0|  0.00%|    return multiarray.correlate2(a, v, mode)
   747|         0|            0|            0|  0.00%|
   748|         0|            0|            0|  0.00%|
   749|         0|            0|            0|  0.00%|def _convolve_dispatcher(a, v, mode=None):
   750|         0|            0|            0|  0.00%|    return (a, v)
   751|         0|            0|            0|  0.00%|
   752|         0|            0|            0|  0.00%|
   753|         0|            0|            0|  0.00%|@array_function_dispatch(_convolve_dispatcher)
   754|         0|            0|            0|  0.00%|def convolve(a, v, mode='full'):
   755|         0|            0|            0|  0.00%|    """
   756|         0|            0|            0|  0.00%|    Returns the discrete, linear convolution of two one-dimensional sequences.
   757|         0|            0|            0|  0.00%|
   758|         0|            0|            0|  0.00%|    The convolution operator is often seen in signal processing, where it
   759|         0|            0|            0|  0.00%|    models the effect of a linear time-invariant system on a signal [1]_.  In
   760|         0|            0|            0|  0.00%|    probability theory, the sum of two independent random variables is
   761|         0|            0|            0|  0.00%|    distributed according to the convolution of their individual
   762|         0|            0|            0|  0.00%|    distributions.
   763|         0|            0|            0|  0.00%|
   764|         0|            0|            0|  0.00%|    If `v` is longer than `a`, the arrays are swapped before computation.
   765|         0|            0|            0|  0.00%|
   766|         0|            0|            0|  0.00%|    Parameters
   767|         0|            0|            0|  0.00%|    ----------
   768|         0|            0|            0|  0.00%|    a : (N,) array_like
   769|         0|            0|            0|  0.00%|        First one-dimensional input array.
   770|         0|            0|            0|  0.00%|    v : (M,) array_like
   771|         0|            0|            0|  0.00%|        Second one-dimensional input array.
   772|         0|            0|            0|  0.00%|    mode : {'full', 'valid', 'same'}, optional
   773|         0|            0|            0|  0.00%|        'full':
   774|         0|            0|            0|  0.00%|          By default, mode is 'full'.  This returns the convolution
   775|         0|            0|            0|  0.00%|          at each point of overlap, with an output shape of (N+M-1,). At
   776|         0|            0|            0|  0.00%|          the end-points of the convolution, the signals do not overlap
   777|         0|            0|            0|  0.00%|          completely, and boundary effects may be seen.
   778|         0|            0|            0|  0.00%|
   779|         0|            0|            0|  0.00%|        'same':
   780|         0|            0|            0|  0.00%|          Mode 'same' returns output of length ``max(M, N)``.  Boundary
   781|         0|            0|            0|  0.00%|          effects are still visible.
   782|         0|            0|            0|  0.00%|
   783|         0|            0|            0|  0.00%|        'valid':
   784|         0|            0|            0|  0.00%|          Mode 'valid' returns output of length
   785|         0|            0|            0|  0.00%|          ``max(M, N) - min(M, N) + 1``.  The convolution product is only given
   786|         0|            0|            0|  0.00%|          for points where the signals overlap completely.  Values outside
   787|         0|            0|            0|  0.00%|          the signal boundary have no effect.
   788|         0|            0|            0|  0.00%|
   789|         0|            0|            0|  0.00%|    Returns
   790|         0|            0|            0|  0.00%|    -------
   791|         0|            0|            0|  0.00%|    out : ndarray
   792|         0|            0|            0|  0.00%|        Discrete, linear convolution of `a` and `v`.
   793|         0|            0|            0|  0.00%|
   794|         0|            0|            0|  0.00%|    See Also
   795|         0|            0|            0|  0.00%|    --------
   796|         0|            0|            0|  0.00%|    scipy.signal.fftconvolve : Convolve two arrays using the Fast Fourier
   797|         0|            0|            0|  0.00%|                               Transform.
   798|         0|            0|            0|  0.00%|    scipy.linalg.toeplitz : Used to construct the convolution operator.
   799|         0|            0|            0|  0.00%|    polymul : Polynomial multiplication. Same output as convolve, but also
   800|         0|            0|            0|  0.00%|              accepts poly1d objects as input.
   801|         0|            0|            0|  0.00%|
   802|         0|            0|            0|  0.00%|    Notes
   803|         0|            0|            0|  0.00%|    -----
   804|         0|            0|            0|  0.00%|    The discrete convolution operation is defined as
   805|         0|            0|            0|  0.00%|
   806|         0|            0|            0|  0.00%|    .. math:: (a * v)[n] = \\sum_{m = -\\infty}^{\\infty} a[m] v[n - m]
   807|         0|            0|            0|  0.00%|
   808|         0|            0|            0|  0.00%|    It can be shown that a convolution :math:`x(t) * y(t)` in time/space
   809|         0|            0|            0|  0.00%|    is equivalent to the multiplication :math:`X(f) Y(f)` in the Fourier
   810|         0|            0|            0|  0.00%|    domain, after appropriate padding (padding is necessary to prevent
   811|         0|            0|            0|  0.00%|    circular convolution).  Since multiplication is more efficient (faster)
   812|         0|            0|            0|  0.00%|    than convolution, the function `scipy.signal.fftconvolve` exploits the
   813|         0|            0|            0|  0.00%|    FFT to calculate the convolution of large data-sets.
   814|         0|            0|            0|  0.00%|
   815|         0|            0|            0|  0.00%|    References
   816|         0|            0|            0|  0.00%|    ----------
   817|         0|            0|            0|  0.00%|    .. [1] Wikipedia, "Convolution",
   818|         0|            0|            0|  0.00%|        https://en.wikipedia.org/wiki/Convolution
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|    Examples
   821|         0|            0|            0|  0.00%|    --------
   822|         0|            0|            0|  0.00%|    Note how the convolution operator flips the second array
   823|         0|            0|            0|  0.00%|    before "sliding" the two across one another:
   824|         0|            0|            0|  0.00%|
   825|         0|            0|            0|  0.00%|    >>> np.convolve([1, 2, 3], [0, 1, 0.5])
   826|         0|            0|            0|  0.00%|    array([0. , 1. , 2.5, 4. , 1.5])
   827|         0|            0|            0|  0.00%|
   828|         0|            0|            0|  0.00%|    Only return the middle values of the convolution.
   829|         0|            0|            0|  0.00%|    Contains boundary effects, where zeros are taken
   830|         0|            0|            0|  0.00%|    into account:
   831|         0|            0|            0|  0.00%|
   832|         0|            0|            0|  0.00%|    >>> np.convolve([1,2,3],[0,1,0.5], 'same')
   833|         0|            0|            0|  0.00%|    array([1. ,  2.5,  4. ])
   834|         0|            0|            0|  0.00%|
   835|         0|            0|            0|  0.00%|    The two arrays are of the same length, so there
   836|         0|            0|            0|  0.00%|    is only one position where they completely overlap:
   837|         0|            0|            0|  0.00%|
   838|         0|            0|            0|  0.00%|    >>> np.convolve([1,2,3],[0,1,0.5], 'valid')
   839|         0|            0|            0|  0.00%|    array([2.5])
   840|         0|            0|            0|  0.00%|
   841|         0|            0|            0|  0.00%|    """
   842|         0|            0|            0|  0.00%|    a, v = array(a, copy=False, ndmin=1), array(v, copy=False, ndmin=1)
   843|         0|            0|            0|  0.00%|    if (len(v) > len(a)):
   844|         0|            0|            0|  0.00%|        a, v = v, a
   845|         0|            0|            0|  0.00%|    if len(a) == 0:
   846|         0|            0|            0|  0.00%|        raise ValueError('a cannot be empty')
   847|         0|            0|            0|  0.00%|    if len(v) == 0:
   848|         0|            0|            0|  0.00%|        raise ValueError('v cannot be empty')
   849|         0|            0|            0|  0.00%|    mode = _mode_from_name(mode)
   850|         0|            0|            0|  0.00%|    return multiarray.correlate(a, v[::-1], mode)
   851|         0|            0|            0|  0.00%|
   852|         0|            0|            0|  0.00%|
   853|         0|            0|            0|  0.00%|def _outer_dispatcher(a, b, out=None):
   854|         0|            0|            0|  0.00%|    return (a, b, out)
   855|         0|            0|            0|  0.00%|
   856|         0|            0|            0|  0.00%|
   857|         0|            0|            0|  0.00%|@array_function_dispatch(_outer_dispatcher)
   858|         0|            0|            0|  0.00%|def outer(a, b, out=None):
   859|         0|            0|            0|  0.00%|    """
   860|         0|            0|            0|  0.00%|    Compute the outer product of two vectors.
   861|         0|            0|            0|  0.00%|
   862|         0|            0|            0|  0.00%|    Given two vectors, ``a = [a0, a1, ..., aM]`` and
   863|         0|            0|            0|  0.00%|    ``b = [b0, b1, ..., bN]``,
   864|         0|            0|            0|  0.00%|    the outer product [1]_ is::
   865|         0|            0|            0|  0.00%|
   866|         0|            0|            0|  0.00%|      [[a0*b0  a0*b1 ... a0*bN ]
   867|         0|            0|            0|  0.00%|       [a1*b0    .
   868|         0|            0|            0|  0.00%|       [ ...          .
   869|         0|            0|            0|  0.00%|       [aM*b0            aM*bN ]]
   870|         0|            0|            0|  0.00%|
   871|         0|            0|            0|  0.00%|    Parameters
   872|         0|            0|            0|  0.00%|    ----------
   873|         0|            0|            0|  0.00%|    a : (M,) array_like
   874|         0|            0|            0|  0.00%|        First input vector.  Input is flattened if
   875|         0|            0|            0|  0.00%|        not already 1-dimensional.
   876|         0|            0|            0|  0.00%|    b : (N,) array_like
   877|         0|            0|            0|  0.00%|        Second input vector.  Input is flattened if
   878|         0|            0|            0|  0.00%|        not already 1-dimensional.
   879|         0|            0|            0|  0.00%|    out : (M, N) ndarray, optional
   880|         0|            0|            0|  0.00%|        A location where the result is stored
   881|         0|            0|            0|  0.00%|
   882|         0|            0|            0|  0.00%|        .. versionadded:: 1.9.0
   883|         0|            0|            0|  0.00%|
   884|         0|            0|            0|  0.00%|    Returns
   885|         0|            0|            0|  0.00%|    -------
   886|         0|            0|            0|  0.00%|    out : (M, N) ndarray
   887|         0|            0|            0|  0.00%|        ``out[i, j] = a[i] * b[j]``
   888|         0|            0|            0|  0.00%|
   889|         0|            0|            0|  0.00%|    See also
   890|         0|            0|            0|  0.00%|    --------
   891|         0|            0|            0|  0.00%|    inner
   892|         0|            0|            0|  0.00%|    einsum : ``einsum('i,j->ij', a.ravel(), b.ravel())`` is the equivalent.
   893|         0|            0|            0|  0.00%|    ufunc.outer : A generalization to dimensions other than 1D and other
   894|         0|            0|            0|  0.00%|                  operations. ``np.multiply.outer(a.ravel(), b.ravel())``
   895|         0|            0|            0|  0.00%|                  is the equivalent.
   896|         0|            0|            0|  0.00%|    tensordot : ``np.tensordot(a.ravel(), b.ravel(), axes=((), ()))``
   897|         0|            0|            0|  0.00%|                is the equivalent.
   898|         0|            0|            0|  0.00%|
   899|         0|            0|            0|  0.00%|    References
   900|         0|            0|            0|  0.00%|    ----------
   901|         0|            0|            0|  0.00%|    .. [1] : G. H. Golub and C. F. Van Loan, *Matrix Computations*, 3rd
   902|         0|            0|            0|  0.00%|             ed., Baltimore, MD, Johns Hopkins University Press, 1996,
   903|         0|            0|            0|  0.00%|             pg. 8.
   904|         0|            0|            0|  0.00%|
   905|         0|            0|            0|  0.00%|    Examples
   906|         0|            0|            0|  0.00%|    --------
   907|         0|            0|            0|  0.00%|    Make a (*very* coarse) grid for computing a Mandelbrot set:
   908|         0|            0|            0|  0.00%|
   909|         0|            0|            0|  0.00%|    >>> rl = np.outer(np.ones((5,)), np.linspace(-2, 2, 5))
   910|         0|            0|            0|  0.00%|    >>> rl
   911|         0|            0|            0|  0.00%|    array([[-2., -1.,  0.,  1.,  2.],
   912|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.],
   913|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.],
   914|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.],
   915|         0|            0|            0|  0.00%|           [-2., -1.,  0.,  1.,  2.]])
   916|         0|            0|            0|  0.00%|    >>> im = np.outer(1j*np.linspace(2, -2, 5), np.ones((5,)))
   917|         0|            0|            0|  0.00%|    >>> im
   918|         0|            0|            0|  0.00%|    array([[0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j],
   919|         0|            0|            0|  0.00%|           [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
   920|         0|            0|            0|  0.00%|           [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
   921|         0|            0|            0|  0.00%|           [0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j],
   922|         0|            0|            0|  0.00%|           [0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j]])
   923|         0|            0|            0|  0.00%|    >>> grid = rl + im
   924|         0|            0|            0|  0.00%|    >>> grid
   925|         0|            0|            0|  0.00%|    array([[-2.+2.j, -1.+2.j,  0.+2.j,  1.+2.j,  2.+2.j],
   926|         0|            0|            0|  0.00%|           [-2.+1.j, -1.+1.j,  0.+1.j,  1.+1.j,  2.+1.j],
   927|         0|            0|            0|  0.00%|           [-2.+0.j, -1.+0.j,  0.+0.j,  1.+0.j,  2.+0.j],
   928|         0|            0|            0|  0.00%|           [-2.-1.j, -1.-1.j,  0.-1.j,  1.-1.j,  2.-1.j],
   929|         0|            0|            0|  0.00%|           [-2.-2.j, -1.-2.j,  0.-2.j,  1.-2.j,  2.-2.j]])
   930|         0|            0|            0|  0.00%|
   931|         0|            0|            0|  0.00%|    An example using a "vector" of letters:
   932|         0|            0|            0|  0.00%|
   933|         0|            0|            0|  0.00%|    >>> x = np.array(['a', 'b', 'c'], dtype=object)
   934|         0|            0|            0|  0.00%|    >>> np.outer(x, [1, 2, 3])
   935|         0|            0|            0|  0.00%|    array([['a', 'aa', 'aaa'],
   936|         0|            0|            0|  0.00%|           ['b', 'bb', 'bbb'],
   937|         0|            0|            0|  0.00%|           ['c', 'cc', 'ccc']], dtype=object)
   938|         0|            0|            0|  0.00%|
   939|         0|            0|            0|  0.00%|    """
   940|         0|            0|            0|  0.00%|    a = asarray(a)
   941|         0|            0|            0|  0.00%|    b = asarray(b)
   942|         0|            0|            0|  0.00%|    return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)
   943|         0|            0|            0|  0.00%|
   944|         0|            0|            0|  0.00%|
   945|         0|            0|            0|  0.00%|def _tensordot_dispatcher(a, b, axes=None):
   946|         0|            0|            0|  0.00%|    return (a, b)
   947|         0|            0|            0|  0.00%|
   948|         0|            0|            0|  0.00%|
   949|         0|            0|            0|  0.00%|@array_function_dispatch(_tensordot_dispatcher)
   950|         0|            0|            0|  0.00%|def tensordot(a, b, axes=2):
   951|         0|            0|            0|  0.00%|    """
   952|         0|            0|            0|  0.00%|    Compute tensor dot product along specified axes.
   953|         0|            0|            0|  0.00%|
   954|         0|            0|            0|  0.00%|    Given two tensors, `a` and `b`, and an array_like object containing
   955|         0|            0|            0|  0.00%|    two array_like objects, ``(a_axes, b_axes)``, sum the products of
   956|         0|            0|            0|  0.00%|    `a`'s and `b`'s elements (components) over the axes specified by
   957|         0|            0|            0|  0.00%|    ``a_axes`` and ``b_axes``. The third argument can be a single non-negative
   958|         0|            0|            0|  0.00%|    integer_like scalar, ``N``; if it is such, then the last ``N`` dimensions
   959|         0|            0|            0|  0.00%|    of `a` and the first ``N`` dimensions of `b` are summed over.
   960|         0|            0|            0|  0.00%|
   961|         0|            0|            0|  0.00%|    Parameters
   962|         0|            0|            0|  0.00%|    ----------
   963|         0|            0|            0|  0.00%|    a, b : array_like
   964|         0|            0|            0|  0.00%|        Tensors to "dot".
   965|         0|            0|            0|  0.00%|
   966|         0|            0|            0|  0.00%|    axes : int or (2,) array_like
   967|         0|            0|            0|  0.00%|        * integer_like
   968|         0|            0|            0|  0.00%|          If an int N, sum over the last N axes of `a` and the first N axes
   969|         0|            0|            0|  0.00%|          of `b` in order. The sizes of the corresponding axes must match.
   970|         0|            0|            0|  0.00%|        * (2,) array_like
   971|         0|            0|            0|  0.00%|          Or, a list of axes to be summed over, first sequence applying to `a`,
   972|         0|            0|            0|  0.00%|          second to `b`. Both elements array_like must be of the same length.
   973|         0|            0|            0|  0.00%|
   974|         0|            0|            0|  0.00%|    Returns
   975|         0|            0|            0|  0.00%|    -------
   976|         0|            0|            0|  0.00%|    output : ndarray
   977|         0|            0|            0|  0.00%|        The tensor dot product of the input.
   978|         0|            0|            0|  0.00%|
   979|         0|            0|            0|  0.00%|    See Also
   980|         0|            0|            0|  0.00%|    --------
   981|         0|            0|            0|  0.00%|    dot, einsum
   982|         0|            0|            0|  0.00%|
   983|         0|            0|            0|  0.00%|    Notes
   984|         0|            0|            0|  0.00%|    -----
   985|         0|            0|            0|  0.00%|    Three common use cases are:
   986|         0|            0|            0|  0.00%|        * ``axes = 0`` : tensor product :math:`a\\otimes b`
   987|         0|            0|            0|  0.00%|        * ``axes = 1`` : tensor dot product :math:`a\\cdot b`
   988|         0|            0|            0|  0.00%|        * ``axes = 2`` : (default) tensor double contraction :math:`a:b`
   989|         0|            0|            0|  0.00%|
   990|         0|            0|            0|  0.00%|    When `axes` is integer_like, the sequence for evaluation will be: first
   991|         0|            0|            0|  0.00%|    the -Nth axis in `a` and 0th axis in `b`, and the -1th axis in `a` and
   992|         0|            0|            0|  0.00%|    Nth axis in `b` last.
   993|         0|            0|            0|  0.00%|
   994|         0|            0|            0|  0.00%|    When there is more than one axis to sum over - and they are not the last
   995|         0|            0|            0|  0.00%|    (first) axes of `a` (`b`) - the argument `axes` should consist of
   996|         0|            0|            0|  0.00%|    two sequences of the same length, with the first axis to sum over given
   997|         0|            0|            0|  0.00%|    first in both sequences, the second axis second, and so forth.
   998|         0|            0|            0|  0.00%|
   999|         0|            0|            0|  0.00%|    The shape of the result consists of the non-contracted axes of the
  1000|         0|            0|            0|  0.00%|    first tensor, followed by the non-contracted axes of the second.
  1001|         0|            0|            0|  0.00%|
  1002|         0|            0|            0|  0.00%|    Examples
  1003|         0|            0|            0|  0.00%|    --------
  1004|         0|            0|            0|  0.00%|    A "traditional" example:
  1005|         0|            0|            0|  0.00%|
  1006|         0|            0|            0|  0.00%|    >>> a = np.arange(60.).reshape(3,4,5)
  1007|         0|            0|            0|  0.00%|    >>> b = np.arange(24.).reshape(4,3,2)
  1008|         0|            0|            0|  0.00%|    >>> c = np.tensordot(a,b, axes=([1,0],[0,1]))
  1009|         0|            0|            0|  0.00%|    >>> c.shape
  1010|         0|            0|            0|  0.00%|    (5, 2)
  1011|         0|            0|            0|  0.00%|    >>> c
  1012|         0|            0|            0|  0.00%|    array([[4400., 4730.],
  1013|         0|            0|            0|  0.00%|           [4532., 4874.],
  1014|         0|            0|            0|  0.00%|           [4664., 5018.],
  1015|         0|            0|            0|  0.00%|           [4796., 5162.],
  1016|         0|            0|            0|  0.00%|           [4928., 5306.]])
  1017|         0|            0|            0|  0.00%|    >>> # A slower but equivalent way of computing the same...
  1018|         0|            0|            0|  0.00%|    >>> d = np.zeros((5,2))
  1019|         0|            0|            0|  0.00%|    >>> for i in range(5):
  1020|         0|            0|            0|  0.00%|    ...   for j in range(2):
  1021|         0|            0|            0|  0.00%|    ...     for k in range(3):
  1022|         0|            0|            0|  0.00%|    ...       for n in range(4):
  1023|         0|            0|            0|  0.00%|    ...         d[i,j] += a[k,n,i] * b[n,k,j]
  1024|         0|            0|            0|  0.00%|    >>> c == d
  1025|         0|            0|            0|  0.00%|    array([[ True,  True],
  1026|         0|            0|            0|  0.00%|           [ True,  True],
  1027|         0|            0|            0|  0.00%|           [ True,  True],
  1028|         0|            0|            0|  0.00%|           [ True,  True],
  1029|         0|            0|            0|  0.00%|           [ True,  True]])
  1030|         0|            0|            0|  0.00%|
  1031|         0|            0|            0|  0.00%|    An extended example taking advantage of the overloading of + and \\*:
  1032|         0|            0|            0|  0.00%|
  1033|         0|            0|            0|  0.00%|    >>> a = np.array(range(1, 9))
  1034|         0|            0|            0|  0.00%|    >>> a.shape = (2, 2, 2)
  1035|         0|            0|            0|  0.00%|    >>> A = np.array(('a', 'b', 'c', 'd'), dtype=object)
  1036|         0|            0|            0|  0.00%|    >>> A.shape = (2, 2)
  1037|         0|            0|            0|  0.00%|    >>> a; A
  1038|         0|            0|            0|  0.00%|    array([[[1, 2],
  1039|         0|            0|            0|  0.00%|            [3, 4]],
  1040|         0|            0|            0|  0.00%|           [[5, 6],
  1041|         0|            0|            0|  0.00%|            [7, 8]]])
  1042|         0|            0|            0|  0.00%|    array([['a', 'b'],
  1043|         0|            0|            0|  0.00%|           ['c', 'd']], dtype=object)
  1044|         0|            0|            0|  0.00%|
  1045|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A) # third argument default is 2 for double-contraction
  1046|         0|            0|            0|  0.00%|    array(['abbcccdddd', 'aaaaabbbbbbcccccccdddddddd'], dtype=object)
  1047|         0|            0|            0|  0.00%|
  1048|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, 1)
  1049|         0|            0|            0|  0.00%|    array([[['acc', 'bdd'],
  1050|         0|            0|            0|  0.00%|            ['aaacccc', 'bbbdddd']],
  1051|         0|            0|            0|  0.00%|           [['aaaaacccccc', 'bbbbbdddddd'],
  1052|         0|            0|            0|  0.00%|            ['aaaaaaacccccccc', 'bbbbbbbdddddddd']]], dtype=object)
  1053|         0|            0|            0|  0.00%|
  1054|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, 0) # tensor product (result too long to incl.)
  1055|         0|            0|            0|  0.00%|    array([[[[['a', 'b'],
  1056|         0|            0|            0|  0.00%|              ['c', 'd']],
  1057|         0|            0|            0|  0.00%|              ...
  1058|         0|            0|            0|  0.00%|
  1059|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, (0, 1))
  1060|         0|            0|            0|  0.00%|    array([[['abbbbb', 'cddddd'],
  1061|         0|            0|            0|  0.00%|            ['aabbbbbb', 'ccdddddd']],
  1062|         0|            0|            0|  0.00%|           [['aaabbbbbbb', 'cccddddddd'],
  1063|         0|            0|            0|  0.00%|            ['aaaabbbbbbbb', 'ccccdddddddd']]], dtype=object)
  1064|         0|            0|            0|  0.00%|
  1065|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, (2, 1))
  1066|         0|            0|            0|  0.00%|    array([[['abb', 'cdd'],
  1067|         0|            0|            0|  0.00%|            ['aaabbbb', 'cccdddd']],
  1068|         0|            0|            0|  0.00%|           [['aaaaabbbbbb', 'cccccdddddd'],
  1069|         0|            0|            0|  0.00%|            ['aaaaaaabbbbbbbb', 'cccccccdddddddd']]], dtype=object)
  1070|         0|            0|            0|  0.00%|
  1071|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, ((0, 1), (0, 1)))
  1072|         0|            0|            0|  0.00%|    array(['abbbcccccddddddd', 'aabbbbccccccdddddddd'], dtype=object)
  1073|         0|            0|            0|  0.00%|
  1074|         0|            0|            0|  0.00%|    >>> np.tensordot(a, A, ((2, 1), (1, 0)))
  1075|         0|            0|            0|  0.00%|    array(['acccbbdddd', 'aaaaacccccccbbbbbbdddddddd'], dtype=object)
  1076|         0|            0|            0|  0.00%|
  1077|         0|            0|            0|  0.00%|    """
  1078|         0|            0|            0|  0.00%|    try:
  1079|         0|            0|            0|  0.00%|        iter(axes)
  1080|         0|            0|            0|  0.00%|    except Exception:
  1081|         0|            0|            0|  0.00%|        axes_a = list(range(-axes, 0))
  1082|         0|            0|            0|  0.00%|        axes_b = list(range(0, axes))
  1083|         0|            0|            0|  0.00%|    else:
  1084|         0|            0|            0|  0.00%|        axes_a, axes_b = axes
  1085|         0|            0|            0|  0.00%|    try:
  1086|         0|            0|            0|  0.00%|        na = len(axes_a)
  1087|         0|            0|            0|  0.00%|        axes_a = list(axes_a)
  1088|         0|            0|            0|  0.00%|    except TypeError:
  1089|         0|            0|            0|  0.00%|        axes_a = [axes_a]
  1090|         0|            0|            0|  0.00%|        na = 1
  1091|         0|            0|            0|  0.00%|    try:
  1092|         0|            0|            0|  0.00%|        nb = len(axes_b)
  1093|         0|            0|            0|  0.00%|        axes_b = list(axes_b)
  1094|         0|            0|            0|  0.00%|    except TypeError:
  1095|         0|            0|            0|  0.00%|        axes_b = [axes_b]
  1096|         0|            0|            0|  0.00%|        nb = 1
  1097|         0|            0|            0|  0.00%|
  1098|         0|            0|            0|  0.00%|    a, b = asarray(a), asarray(b)
  1099|         0|            0|            0|  0.00%|    as_ = a.shape
  1100|         0|            0|            0|  0.00%|    nda = a.ndim
  1101|         0|            0|            0|  0.00%|    bs = b.shape
  1102|         0|            0|            0|  0.00%|    ndb = b.ndim
  1103|         0|            0|            0|  0.00%|    equal = True
  1104|         0|            0|            0|  0.00%|    if na != nb:
  1105|         0|            0|            0|  0.00%|        equal = False
  1106|         0|            0|            0|  0.00%|    else:
  1107|         0|            0|            0|  0.00%|        for k in range(na):
  1108|         0|            0|            0|  0.00%|            if as_[axes_a[k]] != bs[axes_b[k]]:
  1109|         0|            0|            0|  0.00%|                equal = False
  1110|         0|            0|            0|  0.00%|                break
  1111|         0|            0|            0|  0.00%|            if axes_a[k] < 0:
  1112|         0|            0|            0|  0.00%|                axes_a[k] += nda
  1113|         0|            0|            0|  0.00%|            if axes_b[k] < 0:
  1114|         0|            0|            0|  0.00%|                axes_b[k] += ndb
  1115|         0|            0|            0|  0.00%|    if not equal:
  1116|         0|            0|            0|  0.00%|        raise ValueError("shape-mismatch for sum")
  1117|         0|            0|            0|  0.00%|
  1118|         0|            0|            0|  0.00%|    # Move the axes to sum over to the end of "a"
  1119|         0|            0|            0|  0.00%|    # and to the front of "b"
  1120|         0|            0|            0|  0.00%|    notin = [k for k in range(nda) if k not in axes_a]
  1121|         0|            0|            0|  0.00%|    newaxes_a = notin + axes_a
  1122|         0|            0|            0|  0.00%|    N2 = 1
  1123|         0|            0|            0|  0.00%|    for axis in axes_a:
  1124|         0|            0|            0|  0.00%|        N2 *= as_[axis]
  1125|         0|            0|            0|  0.00%|    newshape_a = (int(multiply.reduce([as_[ax] for ax in notin])), N2)
  1126|         0|            0|            0|  0.00%|    olda = [as_[axis] for axis in notin]
  1127|         0|            0|            0|  0.00%|
  1128|         0|            0|            0|  0.00%|    notin = [k for k in range(ndb) if k not in axes_b]
  1129|         0|            0|            0|  0.00%|    newaxes_b = axes_b + notin
  1130|         0|            0|            0|  0.00%|    N2 = 1
  1131|         0|            0|            0|  0.00%|    for axis in axes_b:
  1132|         0|            0|            0|  0.00%|        N2 *= bs[axis]
  1133|         0|            0|            0|  0.00%|    newshape_b = (N2, int(multiply.reduce([bs[ax] for ax in notin])))
  1134|         0|            0|            0|  0.00%|    oldb = [bs[axis] for axis in notin]
  1135|         0|            0|            0|  0.00%|
  1136|         0|            0|            0|  0.00%|    at = a.transpose(newaxes_a).reshape(newshape_a)
  1137|         0|            0|            0|  0.00%|    bt = b.transpose(newaxes_b).reshape(newshape_b)
  1138|         0|            0|            0|  0.00%|    res = dot(at, bt)
  1139|         0|            0|            0|  0.00%|    return res.reshape(olda + oldb)
  1140|         0|            0|            0|  0.00%|
  1141|         0|            0|            0|  0.00%|
  1142|         0|            0|            0|  0.00%|def _roll_dispatcher(a, shift, axis=None):
  1143|         0|            0|            0|  0.00%|    return (a,)
  1144|         0|            0|            0|  0.00%|
  1145|         0|            0|            0|  0.00%|
  1146|         0|            0|            0|  0.00%|@array_function_dispatch(_roll_dispatcher)
  1147|         0|            0|            0|  0.00%|def roll(a, shift, axis=None):
  1148|         0|            0|            0|  0.00%|    """
  1149|         0|            0|            0|  0.00%|    Roll array elements along a given axis.
  1150|         0|            0|            0|  0.00%|
  1151|         0|            0|            0|  0.00%|    Elements that roll beyond the last position are re-introduced at
  1152|         0|            0|            0|  0.00%|    the first.
  1153|         0|            0|            0|  0.00%|
  1154|         0|            0|            0|  0.00%|    Parameters
  1155|         0|            0|            0|  0.00%|    ----------
  1156|         0|            0|            0|  0.00%|    a : array_like
  1157|         0|            0|            0|  0.00%|        Input array.
  1158|         0|            0|            0|  0.00%|    shift : int or tuple of ints
  1159|         0|            0|            0|  0.00%|        The number of places by which elements are shifted.  If a tuple,
  1160|         0|            0|            0|  0.00%|        then `axis` must be a tuple of the same size, and each of the
  1161|         0|            0|            0|  0.00%|        given axes is shifted by the corresponding number.  If an int
  1162|         0|            0|            0|  0.00%|        while `axis` is a tuple of ints, then the same value is used for
  1163|         0|            0|            0|  0.00%|        all given axes.
  1164|         0|            0|            0|  0.00%|    axis : int or tuple of ints, optional
  1165|         0|            0|            0|  0.00%|        Axis or axes along which elements are shifted.  By default, the
  1166|         0|            0|            0|  0.00%|        array is flattened before shifting, after which the original
  1167|         0|            0|            0|  0.00%|        shape is restored.
  1168|         0|            0|            0|  0.00%|
  1169|         0|            0|            0|  0.00%|    Returns
  1170|         0|            0|            0|  0.00%|    -------
  1171|         0|            0|            0|  0.00%|    res : ndarray
  1172|         0|            0|            0|  0.00%|        Output array, with the same shape as `a`.
  1173|         0|            0|            0|  0.00%|
  1174|         0|            0|            0|  0.00%|    See Also
  1175|         0|            0|            0|  0.00%|    --------
  1176|         0|            0|            0|  0.00%|    rollaxis : Roll the specified axis backwards, until it lies in a
  1177|         0|            0|            0|  0.00%|               given position.
  1178|         0|            0|            0|  0.00%|
  1179|         0|            0|            0|  0.00%|    Notes
  1180|         0|            0|            0|  0.00%|    -----
  1181|         0|            0|            0|  0.00%|    .. versionadded:: 1.12.0
  1182|         0|            0|            0|  0.00%|
  1183|         0|            0|            0|  0.00%|    Supports rolling over multiple dimensions simultaneously.
  1184|         0|            0|            0|  0.00%|
  1185|         0|            0|            0|  0.00%|    Examples
  1186|         0|            0|            0|  0.00%|    --------
  1187|         0|            0|            0|  0.00%|    >>> x = np.arange(10)
  1188|         0|            0|            0|  0.00%|    >>> np.roll(x, 2)
  1189|         0|            0|            0|  0.00%|    array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7])
  1190|         0|            0|            0|  0.00%|    >>> np.roll(x, -2)
  1191|         0|            0|            0|  0.00%|    array([2, 3, 4, 5, 6, 7, 8, 9, 0, 1])
  1192|         0|            0|            0|  0.00%|
  1193|         0|            0|            0|  0.00%|    >>> x2 = np.reshape(x, (2,5))
  1194|         0|            0|            0|  0.00%|    >>> x2
  1195|         0|            0|            0|  0.00%|    array([[0, 1, 2, 3, 4],
  1196|         0|            0|            0|  0.00%|           [5, 6, 7, 8, 9]])
  1197|         0|            0|            0|  0.00%|    >>> np.roll(x2, 1)
  1198|         0|            0|            0|  0.00%|    array([[9, 0, 1, 2, 3],
  1199|         0|            0|            0|  0.00%|           [4, 5, 6, 7, 8]])
  1200|         0|            0|            0|  0.00%|    >>> np.roll(x2, -1)
  1201|         0|            0|            0|  0.00%|    array([[1, 2, 3, 4, 5],
  1202|         0|            0|            0|  0.00%|           [6, 7, 8, 9, 0]])
  1203|         0|            0|            0|  0.00%|    >>> np.roll(x2, 1, axis=0)
  1204|         0|            0|            0|  0.00%|    array([[5, 6, 7, 8, 9],
  1205|         0|            0|            0|  0.00%|           [0, 1, 2, 3, 4]])
  1206|         0|            0|            0|  0.00%|    >>> np.roll(x2, -1, axis=0)
  1207|         0|            0|            0|  0.00%|    array([[5, 6, 7, 8, 9],
  1208|         0|            0|            0|  0.00%|           [0, 1, 2, 3, 4]])
  1209|         0|            0|            0|  0.00%|    >>> np.roll(x2, 1, axis=1)
  1210|         0|            0|            0|  0.00%|    array([[4, 0, 1, 2, 3],
  1211|         0|            0|            0|  0.00%|           [9, 5, 6, 7, 8]])
  1212|         0|            0|            0|  0.00%|    >>> np.roll(x2, -1, axis=1)
  1213|         0|            0|            0|  0.00%|    array([[1, 2, 3, 4, 0],
  1214|         0|            0|            0|  0.00%|           [6, 7, 8, 9, 5]])
  1215|         0|            0|            0|  0.00%|
  1216|         0|            0|            0|  0.00%|    """
  1217|         0|            0|            0|  0.00%|    a = asanyarray(a)
  1218|         0|            0|            0|  0.00%|    if axis is None:
  1219|         0|            0|            0|  0.00%|        return roll(a.ravel(), shift, 0).reshape(a.shape)
  1220|         0|            0|            0|  0.00%|
  1221|         0|            0|            0|  0.00%|    else:
  1222|         0|            0|            0|  0.00%|        axis = normalize_axis_tuple(axis, a.ndim, allow_duplicate=True)
  1223|         0|            0|            0|  0.00%|        broadcasted = broadcast(shift, axis)
  1224|         0|            0|            0|  0.00%|        if broadcasted.ndim > 1:
  1225|         0|            0|            0|  0.00%|            raise ValueError(
  1226|         0|            0|            0|  0.00%|                "'shift' and 'axis' should be scalars or 1D sequences")
  1227|         0|            0|            0|  0.00%|        shifts = {ax: 0 for ax in range(a.ndim)}
  1228|         0|            0|            0|  0.00%|        for sh, ax in broadcasted:
  1229|         0|            0|            0|  0.00%|            shifts[ax] += sh
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|        rolls = [((slice(None), slice(None)),)] * a.ndim
  1232|         0|            0|            0|  0.00%|        for ax, offset in shifts.items():
  1233|         0|            0|            0|  0.00%|            offset %= a.shape[ax] or 1  # If `a` is empty, nothing matters.
  1234|         0|            0|            0|  0.00%|            if offset:
  1235|         0|            0|            0|  0.00%|                # (original, result), (original, result)
  1236|         0|            0|            0|  0.00%|                rolls[ax] = ((slice(None, -offset), slice(offset, None)),
  1237|         0|            0|            0|  0.00%|                             (slice(-offset, None), slice(None, offset)))
  1238|         0|            0|            0|  0.00%|
  1239|         0|            0|            0|  0.00%|        result = empty_like(a)
  1240|         0|            0|            0|  0.00%|        for indices in itertools.product(*rolls):
  1241|         0|            0|            0|  0.00%|            arr_index, res_index = zip(*indices)
  1242|         0|            0|            0|  0.00%|            result[res_index] = a[arr_index]
  1243|         0|            0|            0|  0.00%|
  1244|         0|            0|            0|  0.00%|        return result
  1245|         0|            0|            0|  0.00%|
  1246|         0|            0|            0|  0.00%|
  1247|         0|            0|            0|  0.00%|def _rollaxis_dispatcher(a, axis, start=None):
  1248|         0|            0|            0|  0.00%|    return (a,)
  1249|         0|            0|            0|  0.00%|
  1250|         0|            0|            0|  0.00%|
  1251|         0|            0|            0|  0.00%|@array_function_dispatch(_rollaxis_dispatcher)
  1252|         0|            0|            0|  0.00%|def rollaxis(a, axis, start=0):
  1253|         0|            0|            0|  0.00%|    """
  1254|         0|            0|            0|  0.00%|    Roll the specified axis backwards, until it lies in a given position.
  1255|         0|            0|            0|  0.00%|
  1256|         0|            0|            0|  0.00%|    This function continues to be supported for backward compatibility, but you
  1257|         0|            0|            0|  0.00%|    should prefer `moveaxis`. The `moveaxis` function was added in NumPy
  1258|         0|            0|            0|  0.00%|    1.11.
  1259|         0|            0|            0|  0.00%|
  1260|         0|            0|            0|  0.00%|    Parameters
  1261|         0|            0|            0|  0.00%|    ----------
  1262|         0|            0|            0|  0.00%|    a : ndarray
  1263|         0|            0|            0|  0.00%|        Input array.
  1264|         0|            0|            0|  0.00%|    axis : int
  1265|         0|            0|            0|  0.00%|        The axis to be rolled. The positions of the other axes do not
  1266|         0|            0|            0|  0.00%|        change relative to one another.
  1267|         0|            0|            0|  0.00%|    start : int, optional
  1268|         0|            0|            0|  0.00%|        When ``start <= axis``, the axis is rolled back until it lies in
  1269|         0|            0|            0|  0.00%|        this position. When ``start > axis``, the axis is rolled until it
  1270|         0|            0|            0|  0.00%|        lies before this position. The default, 0, results in a "complete"
  1271|         0|            0|            0|  0.00%|        roll. The following table describes how negative values of ``start``
  1272|         0|            0|            0|  0.00%|        are interpreted:
  1273|         0|            0|            0|  0.00%|
  1274|         0|            0|            0|  0.00%|        .. table::
  1275|         0|            0|            0|  0.00%|           :align: left
  1276|         0|            0|            0|  0.00%|
  1277|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1278|         0|            0|            0|  0.00%|           |     ``start``     | Normalized ``start`` |
  1279|         0|            0|            0|  0.00%|           +===================+======================+
  1280|         0|            0|            0|  0.00%|           | ``-(arr.ndim+1)`` | raise ``AxisError``  |
  1281|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1282|         0|            0|            0|  0.00%|           | ``-arr.ndim``     | 0                    |
  1283|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1284|         0|            0|            0|  0.00%|           | |vdots|           | |vdots|              |
  1285|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1286|         0|            0|            0|  0.00%|           | ``-1``            | ``arr.ndim-1``       |
  1287|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1288|         0|            0|            0|  0.00%|           | ``0``             | ``0``                |
  1289|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1290|         0|            0|            0|  0.00%|           | |vdots|           | |vdots|              |
  1291|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1292|         0|            0|            0|  0.00%|           | ``arr.ndim``      | ``arr.ndim``         |
  1293|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1294|         0|            0|            0|  0.00%|           | ``arr.ndim + 1``  | raise ``AxisError``  |
  1295|         0|            0|            0|  0.00%|           +-------------------+----------------------+
  1296|         0|            0|            0|  0.00%|
  1297|         0|            0|            0|  0.00%|        .. |vdots|   unicode:: U+22EE .. Vertical Ellipsis
  1298|         0|            0|            0|  0.00%|
  1299|         0|            0|            0|  0.00%|    Returns
  1300|         0|            0|            0|  0.00%|    -------
  1301|         0|            0|            0|  0.00%|    res : ndarray
  1302|         0|            0|            0|  0.00%|        For NumPy >= 1.10.0 a view of `a` is always returned. For earlier
  1303|         0|            0|            0|  0.00%|        NumPy versions a view of `a` is returned only if the order of the
  1304|         0|            0|            0|  0.00%|        axes is changed, otherwise the input array is returned.
  1305|         0|            0|            0|  0.00%|
  1306|         0|            0|            0|  0.00%|    See Also
  1307|         0|            0|            0|  0.00%|    --------
  1308|         0|            0|            0|  0.00%|    moveaxis : Move array axes to new positions.
  1309|         0|            0|            0|  0.00%|    roll : Roll the elements of an array by a number of positions along a
  1310|         0|            0|            0|  0.00%|        given axis.
  1311|         0|            0|            0|  0.00%|
  1312|         0|            0|            0|  0.00%|    Examples
  1313|         0|            0|            0|  0.00%|    --------
  1314|         0|            0|            0|  0.00%|    >>> a = np.ones((3,4,5,6))
  1315|         0|            0|            0|  0.00%|    >>> np.rollaxis(a, 3, 1).shape
  1316|         0|            0|            0|  0.00%|    (3, 6, 4, 5)
  1317|         0|            0|            0|  0.00%|    >>> np.rollaxis(a, 2).shape
  1318|         0|            0|            0|  0.00%|    (5, 3, 4, 6)
  1319|         0|            0|            0|  0.00%|    >>> np.rollaxis(a, 1, 4).shape
  1320|         0|            0|            0|  0.00%|    (3, 5, 6, 4)
  1321|         0|            0|            0|  0.00%|
  1322|         0|            0|            0|  0.00%|    """
  1323|         0|            0|            0|  0.00%|    n = a.ndim
  1324|         0|            0|            0|  0.00%|    axis = normalize_axis_index(axis, n)
  1325|         0|            0|            0|  0.00%|    if start < 0:
  1326|         0|            0|            0|  0.00%|        start += n
  1327|         0|            0|            0|  0.00%|    msg = "'%s' arg requires %d <= %s < %d, but %d was passed in"
  1328|         0|            0|            0|  0.00%|    if not (0 <= start < n + 1):
  1329|         0|            0|            0|  0.00%|        raise AxisError(msg % ('start', -n, 'start', n + 1, start))
  1330|         0|            0|            0|  0.00%|    if axis < start:
  1331|         0|            0|            0|  0.00%|        # it's been removed
  1332|         0|            0|            0|  0.00%|        start -= 1
  1333|         0|            0|            0|  0.00%|    if axis == start:
  1334|         0|            0|            0|  0.00%|        return a[...]
  1335|         0|            0|            0|  0.00%|    axes = list(range(0, n))
  1336|         0|            0|            0|  0.00%|    axes.remove(axis)
  1337|         0|            0|            0|  0.00%|    axes.insert(start, axis)
  1338|         0|            0|            0|  0.00%|    return a.transpose(axes)
  1339|         0|            0|            0|  0.00%|
  1340|         0|            0|            0|  0.00%|
  1341|         0|            0|            0|  0.00%|def normalize_axis_tuple(axis, ndim, argname=None, allow_duplicate=False):
  1342|         0|            0|            0|  0.00%|    """
  1343|         0|            0|            0|  0.00%|    Normalizes an axis argument into a tuple of non-negative integer axes.
  1344|         0|            0|            0|  0.00%|
  1345|         0|            0|            0|  0.00%|    This handles shorthands such as ``1`` and converts them to ``(1,)``,
  1346|         0|            0|            0|  0.00%|    as well as performing the handling of negative indices covered by
  1347|         0|            0|            0|  0.00%|    `normalize_axis_index`.
  1348|         0|            0|            0|  0.00%|
  1349|         0|            0|            0|  0.00%|    By default, this forbids axes from being specified multiple times.
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|    Used internally by multi-axis-checking logic.
  1352|         0|            0|            0|  0.00%|
  1353|         0|            0|            0|  0.00%|    .. versionadded:: 1.13.0
  1354|         0|            0|            0|  0.00%|
  1355|         0|            0|            0|  0.00%|    Parameters
  1356|         0|            0|            0|  0.00%|    ----------
  1357|         0|            0|            0|  0.00%|    axis : int, iterable of int
  1358|         0|            0|            0|  0.00%|        The un-normalized index or indices of the axis.
  1359|         0|            0|            0|  0.00%|    ndim : int
  1360|         0|            0|            0|  0.00%|        The number of dimensions of the array that `axis` should be normalized
  1361|         0|            0|            0|  0.00%|        against.
  1362|         0|            0|            0|  0.00%|    argname : str, optional
  1363|         0|            0|            0|  0.00%|        A prefix to put before the error message, typically the name of the
  1364|         0|            0|            0|  0.00%|        argument.
  1365|         0|            0|            0|  0.00%|    allow_duplicate : bool, optional
  1366|         0|            0|            0|  0.00%|        If False, the default, disallow an axis from being specified twice.
  1367|         0|            0|            0|  0.00%|
  1368|         0|            0|            0|  0.00%|    Returns
  1369|         0|            0|            0|  0.00%|    -------
  1370|         0|            0|            0|  0.00%|    normalized_axes : tuple of int
  1371|         0|            0|            0|  0.00%|        The normalized axis index, such that `0 <= normalized_axis < ndim`
  1372|         0|            0|            0|  0.00%|
  1373|         0|            0|            0|  0.00%|    Raises
  1374|         0|            0|            0|  0.00%|    ------
  1375|         0|            0|            0|  0.00%|    AxisError
  1376|         0|            0|            0|  0.00%|        If any axis provided is out of range
  1377|         0|            0|            0|  0.00%|    ValueError
  1378|         0|            0|            0|  0.00%|        If an axis is repeated
  1379|         0|            0|            0|  0.00%|
  1380|         0|            0|            0|  0.00%|    See also
  1381|         0|            0|            0|  0.00%|    --------
  1382|         0|            0|            0|  0.00%|    normalize_axis_index : normalizing a single scalar axis
  1383|         0|            0|            0|  0.00%|    """
  1384|         0|            0|            0|  0.00%|    # Optimization to speed-up the most common cases.
  1385|         0|            0|            0|  0.00%|    if type(axis) not in (tuple, list):
  1386|         0|            0|            0|  0.00%|        try:
  1387|         0|            0|            0|  0.00%|            axis = [operator.index(axis)]
  1388|         0|            0|            0|  0.00%|        except TypeError:
  1389|         0|            0|            0|  0.00%|            pass
  1390|         0|            0|            0|  0.00%|    # Going via an iterator directly is slower than via list comprehension.
  1391|         0|            0|            0|  0.00%|    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])
  1392|         0|            0|            0|  0.00%|    if not allow_duplicate and len(set(axis)) != len(axis):
  1393|         0|            0|            0|  0.00%|        if argname:
  1394|         0|            0|            0|  0.00%|            raise ValueError('repeated axis in `{}` argument'.format(argname))
  1395|         0|            0|            0|  0.00%|        else:
  1396|         0|            0|            0|  0.00%|            raise ValueError('repeated axis')
  1397|         0|            0|            0|  0.00%|    return axis
  1398|         0|            0|            0|  0.00%|
  1399|         0|            0|            0|  0.00%|
  1400|         0|            0|            0|  0.00%|def _moveaxis_dispatcher(a, source, destination):
  1401|         0|            0|            0|  0.00%|    return (a,)
  1402|         0|            0|            0|  0.00%|
  1403|         0|            0|            0|  0.00%|
  1404|         0|            0|            0|  0.00%|@array_function_dispatch(_moveaxis_dispatcher)
  1405|         0|            0|            0|  0.00%|def moveaxis(a, source, destination):
  1406|         0|            0|            0|  0.00%|    """
  1407|         0|            0|            0|  0.00%|    Move axes of an array to new positions.
  1408|         0|            0|            0|  0.00%|
  1409|         0|            0|            0|  0.00%|    Other axes remain in their original order.
  1410|         0|            0|            0|  0.00%|
  1411|         0|            0|            0|  0.00%|    .. versionadded:: 1.11.0
  1412|         0|            0|            0|  0.00%|
  1413|         0|            0|            0|  0.00%|    Parameters
  1414|         0|            0|            0|  0.00%|    ----------
  1415|         0|            0|            0|  0.00%|    a : np.ndarray
  1416|         0|            0|            0|  0.00%|        The array whose axes should be reordered.
  1417|         0|            0|            0|  0.00%|    source : int or sequence of int
  1418|         0|            0|            0|  0.00%|        Original positions of the axes to move. These must be unique.
  1419|         0|            0|            0|  0.00%|    destination : int or sequence of int
  1420|         0|            0|            0|  0.00%|        Destination positions for each of the original axes. These must also be
  1421|         0|            0|            0|  0.00%|        unique.
  1422|         0|            0|            0|  0.00%|
  1423|         0|            0|            0|  0.00%|    Returns
  1424|         0|            0|            0|  0.00%|    -------
  1425|         0|            0|            0|  0.00%|    result : np.ndarray
  1426|         0|            0|            0|  0.00%|        Array with moved axes. This array is a view of the input array.
  1427|         0|            0|            0|  0.00%|
  1428|         0|            0|            0|  0.00%|    See Also
  1429|         0|            0|            0|  0.00%|    --------
  1430|         0|            0|            0|  0.00%|    transpose: Permute the dimensions of an array.
  1431|         0|            0|            0|  0.00%|    swapaxes: Interchange two axes of an array.
  1432|         0|            0|            0|  0.00%|
  1433|         0|            0|            0|  0.00%|    Examples
  1434|         0|            0|            0|  0.00%|    --------
  1435|         0|            0|            0|  0.00%|
  1436|         0|            0|            0|  0.00%|    >>> x = np.zeros((3, 4, 5))
  1437|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, 0, -1).shape
  1438|         0|            0|            0|  0.00%|    (4, 5, 3)
  1439|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, -1, 0).shape
  1440|         0|            0|            0|  0.00%|    (5, 3, 4)
  1441|         0|            0|            0|  0.00%|
  1442|         0|            0|            0|  0.00%|    These all achieve the same result:
  1443|         0|            0|            0|  0.00%|
  1444|         0|            0|            0|  0.00%|    >>> np.transpose(x).shape
  1445|         0|            0|            0|  0.00%|    (5, 4, 3)
  1446|         0|            0|            0|  0.00%|    >>> np.swapaxes(x, 0, -1).shape
  1447|         0|            0|            0|  0.00%|    (5, 4, 3)
  1448|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, [0, 1], [-1, -2]).shape
  1449|         0|            0|            0|  0.00%|    (5, 4, 3)
  1450|         0|            0|            0|  0.00%|    >>> np.moveaxis(x, [0, 1, 2], [-1, -2, -3]).shape
  1451|         0|            0|            0|  0.00%|    (5, 4, 3)
  1452|         0|            0|            0|  0.00%|
  1453|         0|            0|            0|  0.00%|    """
  1454|         0|            0|            0|  0.00%|    try:
  1455|         0|            0|            0|  0.00%|        # allow duck-array types if they define transpose
  1456|         0|            0|            0|  0.00%|        transpose = a.transpose
  1457|         0|            0|            0|  0.00%|    except AttributeError:
  1458|         0|            0|            0|  0.00%|        a = asarray(a)
  1459|         0|            0|            0|  0.00%|        transpose = a.transpose
  1460|         0|            0|            0|  0.00%|
  1461|         0|            0|            0|  0.00%|    source = normalize_axis_tuple(source, a.ndim, 'source')
  1462|         0|            0|            0|  0.00%|    destination = normalize_axis_tuple(destination, a.ndim, 'destination')
  1463|         0|            0|            0|  0.00%|    if len(source) != len(destination):
  1464|         0|            0|            0|  0.00%|        raise ValueError('`source` and `destination` arguments must have '
  1465|         0|            0|            0|  0.00%|                         'the same number of elements')
  1466|         0|            0|            0|  0.00%|
  1467|         0|            0|            0|  0.00%|    order = [n for n in range(a.ndim) if n not in source]
  1468|         0|            0|            0|  0.00%|
  1469|         0|            0|            0|  0.00%|    for dest, src in sorted(zip(destination, source)):
  1470|         0|            0|            0|  0.00%|        order.insert(dest, src)
  1471|         0|            0|            0|  0.00%|
  1472|         0|            0|            0|  0.00%|    result = transpose(order)
  1473|         0|            0|            0|  0.00%|    return result
  1474|         0|            0|            0|  0.00%|
  1475|         0|            0|            0|  0.00%|
  1476|         0|            0|            0|  0.00%|# fix hack in scipy which imports this function
  1477|         0|            0|            0|  0.00%|def _move_axis_to_0(a, axis):
  1478|         0|            0|            0|  0.00%|    return moveaxis(a, axis, 0)
  1479|         0|            0|            0|  0.00%|
  1480|         0|            0|            0|  0.00%|
  1481|         0|            0|            0|  0.00%|def _cross_dispatcher(a, b, axisa=None, axisb=None, axisc=None, axis=None):
  1482|         0|            0|            0|  0.00%|    return (a, b)
  1483|         0|            0|            0|  0.00%|
  1484|         0|            0|            0|  0.00%|
  1485|         0|            0|            0|  0.00%|@array_function_dispatch(_cross_dispatcher)
  1486|         0|            0|            0|  0.00%|def cross(a, b, axisa=-1, axisb=-1, axisc=-1, axis=None):
  1487|         0|            0|            0|  0.00%|    """
  1488|         0|            0|            0|  0.00%|    Return the cross product of two (arrays of) vectors.
  1489|         0|            0|            0|  0.00%|
  1490|         0|            0|            0|  0.00%|    The cross product of `a` and `b` in :math:`R^3` is a vector perpendicular
  1491|         0|            0|            0|  0.00%|    to both `a` and `b`.  If `a` and `b` are arrays of vectors, the vectors
  1492|         0|            0|            0|  0.00%|    are defined by the last axis of `a` and `b` by default, and these axes
  1493|         0|            0|            0|  0.00%|    can have dimensions 2 or 3.  Where the dimension of either `a` or `b` is
  1494|         0|            0|            0|  0.00%|    2, the third component of the input vector is assumed to be zero and the
  1495|         0|            0|            0|  0.00%|    cross product calculated accordingly.  In cases where both input vectors
  1496|         0|            0|            0|  0.00%|    have dimension 2, the z-component of the cross product is returned.
  1497|         0|            0|            0|  0.00%|
  1498|         0|            0|            0|  0.00%|    Parameters
  1499|         0|            0|            0|  0.00%|    ----------
  1500|         0|            0|            0|  0.00%|    a : array_like
  1501|         0|            0|            0|  0.00%|        Components of the first vector(s).
  1502|         0|            0|            0|  0.00%|    b : array_like
  1503|         0|            0|            0|  0.00%|        Components of the second vector(s).
  1504|         0|            0|            0|  0.00%|    axisa : int, optional
  1505|         0|            0|            0|  0.00%|        Axis of `a` that defines the vector(s).  By default, the last axis.
  1506|         0|            0|            0|  0.00%|    axisb : int, optional
  1507|         0|            0|            0|  0.00%|        Axis of `b` that defines the vector(s).  By default, the last axis.
  1508|         0|            0|            0|  0.00%|    axisc : int, optional
  1509|         0|            0|            0|  0.00%|        Axis of `c` containing the cross product vector(s).  Ignored if
  1510|         0|            0|            0|  0.00%|        both input vectors have dimension 2, as the return is scalar.
  1511|         0|            0|            0|  0.00%|        By default, the last axis.
  1512|         0|            0|            0|  0.00%|    axis : int, optional
  1513|         0|            0|            0|  0.00%|        If defined, the axis of `a`, `b` and `c` that defines the vector(s)
  1514|         0|            0|            0|  0.00%|        and cross product(s).  Overrides `axisa`, `axisb` and `axisc`.
  1515|         0|            0|            0|  0.00%|
  1516|         0|            0|            0|  0.00%|    Returns
  1517|         0|            0|            0|  0.00%|    -------
  1518|         0|            0|            0|  0.00%|    c : ndarray
  1519|         0|            0|            0|  0.00%|        Vector cross product(s).
  1520|         0|            0|            0|  0.00%|
  1521|         0|            0|            0|  0.00%|    Raises
  1522|         0|            0|            0|  0.00%|    ------
  1523|         0|            0|            0|  0.00%|    ValueError
  1524|         0|            0|            0|  0.00%|        When the dimension of the vector(s) in `a` and/or `b` does not
  1525|         0|            0|            0|  0.00%|        equal 2 or 3.
  1526|         0|            0|            0|  0.00%|
  1527|         0|            0|            0|  0.00%|    See Also
  1528|         0|            0|            0|  0.00%|    --------
  1529|         0|            0|            0|  0.00%|    inner : Inner product
  1530|         0|            0|            0|  0.00%|    outer : Outer product.
  1531|         0|            0|            0|  0.00%|    ix_ : Construct index arrays.
  1532|         0|            0|            0|  0.00%|
  1533|         0|            0|            0|  0.00%|    Notes
  1534|         0|            0|            0|  0.00%|    -----
  1535|         0|            0|            0|  0.00%|    .. versionadded:: 1.9.0
  1536|         0|            0|            0|  0.00%|
  1537|         0|            0|            0|  0.00%|    Supports full broadcasting of the inputs.
  1538|         0|            0|            0|  0.00%|
  1539|         0|            0|            0|  0.00%|    Examples
  1540|         0|            0|            0|  0.00%|    --------
  1541|         0|            0|            0|  0.00%|    Vector cross-product.
  1542|         0|            0|            0|  0.00%|
  1543|         0|            0|            0|  0.00%|    >>> x = [1, 2, 3]
  1544|         0|            0|            0|  0.00%|    >>> y = [4, 5, 6]
  1545|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1546|         0|            0|            0|  0.00%|    array([-3,  6, -3])
  1547|         0|            0|            0|  0.00%|
  1548|         0|            0|            0|  0.00%|    One vector with dimension 2.
  1549|         0|            0|            0|  0.00%|
  1550|         0|            0|            0|  0.00%|    >>> x = [1, 2]
  1551|         0|            0|            0|  0.00%|    >>> y = [4, 5, 6]
  1552|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1553|         0|            0|            0|  0.00%|    array([12, -6, -3])
  1554|         0|            0|            0|  0.00%|
  1555|         0|            0|            0|  0.00%|    Equivalently:
  1556|         0|            0|            0|  0.00%|
  1557|         0|            0|            0|  0.00%|    >>> x = [1, 2, 0]
  1558|         0|            0|            0|  0.00%|    >>> y = [4, 5, 6]
  1559|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1560|         0|            0|            0|  0.00%|    array([12, -6, -3])
  1561|         0|            0|            0|  0.00%|
  1562|         0|            0|            0|  0.00%|    Both vectors with dimension 2.
  1563|         0|            0|            0|  0.00%|
  1564|         0|            0|            0|  0.00%|    >>> x = [1,2]
  1565|         0|            0|            0|  0.00%|    >>> y = [4,5]
  1566|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1567|         0|            0|            0|  0.00%|    array(-3)
  1568|         0|            0|            0|  0.00%|
  1569|         0|            0|            0|  0.00%|    Multiple vector cross-products. Note that the direction of the cross
  1570|         0|            0|            0|  0.00%|    product vector is defined by the `right-hand rule`.
  1571|         0|            0|            0|  0.00%|
  1572|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3], [4,5,6]])
  1573|         0|            0|            0|  0.00%|    >>> y = np.array([[4,5,6], [1,2,3]])
  1574|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1575|         0|            0|            0|  0.00%|    array([[-3,  6, -3],
  1576|         0|            0|            0|  0.00%|           [ 3, -6,  3]])
  1577|         0|            0|            0|  0.00%|
  1578|         0|            0|            0|  0.00%|    The orientation of `c` can be changed using the `axisc` keyword.
  1579|         0|            0|            0|  0.00%|
  1580|         0|            0|            0|  0.00%|    >>> np.cross(x, y, axisc=0)
  1581|         0|            0|            0|  0.00%|    array([[-3,  3],
  1582|         0|            0|            0|  0.00%|           [ 6, -6],
  1583|         0|            0|            0|  0.00%|           [-3,  3]])
  1584|         0|            0|            0|  0.00%|
  1585|         0|            0|            0|  0.00%|    Change the vector definition of `x` and `y` using `axisa` and `axisb`.
  1586|         0|            0|            0|  0.00%|
  1587|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3], [4,5,6], [7, 8, 9]])
  1588|         0|            0|            0|  0.00%|    >>> y = np.array([[7, 8, 9], [4,5,6], [1,2,3]])
  1589|         0|            0|            0|  0.00%|    >>> np.cross(x, y)
  1590|         0|            0|            0|  0.00%|    array([[ -6,  12,  -6],
  1591|         0|            0|            0|  0.00%|           [  0,   0,   0],
  1592|         0|            0|            0|  0.00%|           [  6, -12,   6]])
  1593|         0|            0|            0|  0.00%|    >>> np.cross(x, y, axisa=0, axisb=0)
  1594|         0|            0|            0|  0.00%|    array([[-24,  48, -24],
  1595|         0|            0|            0|  0.00%|           [-30,  60, -30],
  1596|         0|            0|            0|  0.00%|           [-36,  72, -36]])
  1597|         0|            0|            0|  0.00%|
  1598|         0|            0|            0|  0.00%|    """
  1599|         0|            0|            0|  0.00%|    if axis is not None:
  1600|         0|            0|            0|  0.00%|        axisa, axisb, axisc = (axis,) * 3
  1601|         0|            0|            0|  0.00%|    a = asarray(a)
  1602|         0|            0|            0|  0.00%|    b = asarray(b)
  1603|         0|            0|            0|  0.00%|    # Check axisa and axisb are within bounds
  1604|         0|            0|            0|  0.00%|    axisa = normalize_axis_index(axisa, a.ndim, msg_prefix='axisa')
  1605|         0|            0|            0|  0.00%|    axisb = normalize_axis_index(axisb, b.ndim, msg_prefix='axisb')
  1606|         0|            0|            0|  0.00%|
  1607|         0|            0|            0|  0.00%|    # Move working axis to the end of the shape
  1608|         0|            0|            0|  0.00%|    a = moveaxis(a, axisa, -1)
  1609|         0|            0|            0|  0.00%|    b = moveaxis(b, axisb, -1)
  1610|         0|            0|            0|  0.00%|    msg = ("incompatible dimensions for cross product\n"
  1611|         0|            0|            0|  0.00%|           "(dimension must be 2 or 3)")
  1612|         0|            0|            0|  0.00%|    if a.shape[-1] not in (2, 3) or b.shape[-1] not in (2, 3):
  1613|         0|            0|            0|  0.00%|        raise ValueError(msg)
  1614|         0|            0|            0|  0.00%|
  1615|         0|            0|            0|  0.00%|    # Create the output array
  1616|         0|            0|            0|  0.00%|    shape = broadcast(a[..., 0], b[..., 0]).shape
  1617|         0|            0|            0|  0.00%|    if a.shape[-1] == 3 or b.shape[-1] == 3:
  1618|         0|            0|            0|  0.00%|        shape += (3,)
  1619|         0|            0|            0|  0.00%|        # Check axisc is within bounds
  1620|         0|            0|            0|  0.00%|        axisc = normalize_axis_index(axisc, len(shape), msg_prefix='axisc')
  1621|         0|            0|            0|  0.00%|    dtype = promote_types(a.dtype, b.dtype)
  1622|         0|            0|            0|  0.00%|    cp = empty(shape, dtype)
  1623|         0|            0|            0|  0.00%|
  1624|         0|            0|            0|  0.00%|    # create local aliases for readability
  1625|         0|            0|            0|  0.00%|    a0 = a[..., 0]
  1626|         0|            0|            0|  0.00%|    a1 = a[..., 1]
  1627|         0|            0|            0|  0.00%|    if a.shape[-1] == 3:
  1628|         0|            0|            0|  0.00%|        a2 = a[..., 2]
  1629|         0|            0|            0|  0.00%|    b0 = b[..., 0]
  1630|         0|            0|            0|  0.00%|    b1 = b[..., 1]
  1631|         0|            0|            0|  0.00%|    if b.shape[-1] == 3:
  1632|         0|            0|            0|  0.00%|        b2 = b[..., 2]
  1633|         0|            0|            0|  0.00%|    if cp.ndim != 0 and cp.shape[-1] == 3:
  1634|         0|            0|            0|  0.00%|        cp0 = cp[..., 0]
  1635|         0|            0|            0|  0.00%|        cp1 = cp[..., 1]
  1636|         0|            0|            0|  0.00%|        cp2 = cp[..., 2]
  1637|         0|            0|            0|  0.00%|
  1638|         0|            0|            0|  0.00%|    if a.shape[-1] == 2:
  1639|         0|            0|            0|  0.00%|        if b.shape[-1] == 2:
  1640|         0|            0|            0|  0.00%|            # a0 * b1 - a1 * b0
  1641|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp)
  1642|         0|            0|            0|  0.00%|            cp -= a1 * b0
  1643|         0|            0|            0|  0.00%|            return cp
  1644|         0|            0|            0|  0.00%|        else:
  1645|         0|            0|            0|  0.00%|            assert b.shape[-1] == 3
  1646|         0|            0|            0|  0.00%|            # cp0 = a1 * b2 - 0  (a2 = 0)
  1647|         0|            0|            0|  0.00%|            # cp1 = 0 - a0 * b2  (a2 = 0)
  1648|         0|            0|            0|  0.00%|            # cp2 = a0 * b1 - a1 * b0
  1649|         0|            0|            0|  0.00%|            multiply(a1, b2, out=cp0)
  1650|         0|            0|            0|  0.00%|            multiply(a0, b2, out=cp1)
  1651|         0|            0|            0|  0.00%|            negative(cp1, out=cp1)
  1652|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp2)
  1653|         0|            0|            0|  0.00%|            cp2 -= a1 * b0
  1654|         0|            0|            0|  0.00%|    else:
  1655|         0|            0|            0|  0.00%|        assert a.shape[-1] == 3
  1656|         0|            0|            0|  0.00%|        if b.shape[-1] == 3:
  1657|         0|            0|            0|  0.00%|            # cp0 = a1 * b2 - a2 * b1
  1658|         0|            0|            0|  0.00%|            # cp1 = a2 * b0 - a0 * b2
  1659|         0|            0|            0|  0.00%|            # cp2 = a0 * b1 - a1 * b0
  1660|         0|            0|            0|  0.00%|            multiply(a1, b2, out=cp0)
  1661|         0|            0|            0|  0.00%|            tmp = array(a2 * b1)
  1662|         0|            0|            0|  0.00%|            cp0 -= tmp
  1663|         0|            0|            0|  0.00%|            multiply(a2, b0, out=cp1)
  1664|         0|            0|            0|  0.00%|            multiply(a0, b2, out=tmp)
  1665|         0|            0|            0|  0.00%|            cp1 -= tmp
  1666|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp2)
  1667|         0|            0|            0|  0.00%|            multiply(a1, b0, out=tmp)
  1668|         0|            0|            0|  0.00%|            cp2 -= tmp
  1669|         0|            0|            0|  0.00%|        else:
  1670|         0|            0|            0|  0.00%|            assert b.shape[-1] == 2
  1671|         0|            0|            0|  0.00%|            # cp0 = 0 - a2 * b1  (b2 = 0)
  1672|         0|            0|            0|  0.00%|            # cp1 = a2 * b0 - 0  (b2 = 0)
  1673|         0|            0|            0|  0.00%|            # cp2 = a0 * b1 - a1 * b0
  1674|         0|            0|            0|  0.00%|            multiply(a2, b1, out=cp0)
  1675|         0|            0|            0|  0.00%|            negative(cp0, out=cp0)
  1676|         0|            0|            0|  0.00%|            multiply(a2, b0, out=cp1)
  1677|         0|            0|            0|  0.00%|            multiply(a0, b1, out=cp2)
  1678|         0|            0|            0|  0.00%|            cp2 -= a1 * b0
  1679|         0|            0|            0|  0.00%|
  1680|         0|            0|            0|  0.00%|    return moveaxis(cp, -1, axisc)
  1681|         0|            0|            0|  0.00%|
  1682|         0|            0|            0|  0.00%|
  1683|         0|            0|            0|  0.00%|little_endian = (sys.byteorder == 'little')
  1684|         0|            0|            0|  0.00%|
  1685|         0|            0|            0|  0.00%|
  1686|         0|            0|            0|  0.00%|@set_module('numpy')
  1687|         0|            0|            0|  0.00%|def indices(dimensions, dtype=int, sparse=False):
  1688|         0|            0|            0|  0.00%|    """
  1689|         0|            0|            0|  0.00%|    Return an array representing the indices of a grid.
  1690|         0|            0|            0|  0.00%|
  1691|         0|            0|            0|  0.00%|    Compute an array where the subarrays contain index values 0, 1, ...
  1692|         0|            0|            0|  0.00%|    varying only along the corresponding axis.
  1693|         0|            0|            0|  0.00%|
  1694|         0|            0|            0|  0.00%|    Parameters
  1695|         0|            0|            0|  0.00%|    ----------
  1696|         0|            0|            0|  0.00%|    dimensions : sequence of ints
  1697|         0|            0|            0|  0.00%|        The shape of the grid.
  1698|         0|            0|            0|  0.00%|    dtype : dtype, optional
  1699|         0|            0|            0|  0.00%|        Data type of the result.
  1700|         0|            0|            0|  0.00%|    sparse : boolean, optional
  1701|         0|            0|            0|  0.00%|        Return a sparse representation of the grid instead of a dense
  1702|         0|            0|            0|  0.00%|        representation. Default is False.
  1703|         0|            0|            0|  0.00%|
  1704|         0|            0|            0|  0.00%|        .. versionadded:: 1.17
  1705|         0|            0|            0|  0.00%|
  1706|         0|            0|            0|  0.00%|    Returns
  1707|         0|            0|            0|  0.00%|    -------
  1708|         0|            0|            0|  0.00%|    grid : one ndarray or tuple of ndarrays
  1709|         0|            0|            0|  0.00%|        If sparse is False:
  1710|         0|            0|            0|  0.00%|            Returns one array of grid indices,
  1711|         0|            0|            0|  0.00%|            ``grid.shape = (len(dimensions),) + tuple(dimensions)``.
  1712|         0|            0|            0|  0.00%|        If sparse is True:
  1713|         0|            0|            0|  0.00%|            Returns a tuple of arrays, with
  1714|         0|            0|            0|  0.00%|            ``grid[i].shape = (1, ..., 1, dimensions[i], 1, ..., 1)`` with
  1715|         0|            0|            0|  0.00%|            dimensions[i] in the ith place
  1716|         0|            0|            0|  0.00%|
  1717|         0|            0|            0|  0.00%|    See Also
  1718|         0|            0|            0|  0.00%|    --------
  1719|         0|            0|            0|  0.00%|    mgrid, ogrid, meshgrid
  1720|         0|            0|            0|  0.00%|
  1721|         0|            0|            0|  0.00%|    Notes
  1722|         0|            0|            0|  0.00%|    -----
  1723|         0|            0|            0|  0.00%|    The output shape in the dense case is obtained by prepending the number
  1724|         0|            0|            0|  0.00%|    of dimensions in front of the tuple of dimensions, i.e. if `dimensions`
  1725|         0|            0|            0|  0.00%|    is a tuple ``(r0, ..., rN-1)`` of length ``N``, the output shape is
  1726|         0|            0|            0|  0.00%|    ``(N, r0, ..., rN-1)``.
  1727|         0|            0|            0|  0.00%|
  1728|         0|            0|            0|  0.00%|    The subarrays ``grid[k]`` contains the N-D array of indices along the
  1729|         0|            0|            0|  0.00%|    ``k-th`` axis. Explicitly::
  1730|         0|            0|            0|  0.00%|
  1731|         0|            0|            0|  0.00%|        grid[k, i0, i1, ..., iN-1] = ik
  1732|         0|            0|            0|  0.00%|
  1733|         0|            0|            0|  0.00%|    Examples
  1734|         0|            0|            0|  0.00%|    --------
  1735|         0|            0|            0|  0.00%|    >>> grid = np.indices((2, 3))
  1736|         0|            0|            0|  0.00%|    >>> grid.shape
  1737|         0|            0|            0|  0.00%|    (2, 2, 3)
  1738|         0|            0|            0|  0.00%|    >>> grid[0]        # row indices
  1739|         0|            0|            0|  0.00%|    array([[0, 0, 0],
  1740|         0|            0|            0|  0.00%|           [1, 1, 1]])
  1741|         0|            0|            0|  0.00%|    >>> grid[1]        # column indices
  1742|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1743|         0|            0|            0|  0.00%|           [0, 1, 2]])
  1744|         0|            0|            0|  0.00%|
  1745|         0|            0|            0|  0.00%|    The indices can be used as an index into an array.
  1746|         0|            0|            0|  0.00%|
  1747|         0|            0|            0|  0.00%|    >>> x = np.arange(20).reshape(5, 4)
  1748|         0|            0|            0|  0.00%|    >>> row, col = np.indices((2, 3))
  1749|         0|            0|            0|  0.00%|    >>> x[row, col]
  1750|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1751|         0|            0|            0|  0.00%|           [4, 5, 6]])
  1752|         0|            0|            0|  0.00%|
  1753|         0|            0|            0|  0.00%|    Note that it would be more straightforward in the above example to
  1754|         0|            0|            0|  0.00%|    extract the required elements directly with ``x[:2, :3]``.
  1755|         0|            0|            0|  0.00%|
  1756|         0|            0|            0|  0.00%|    If sparse is set to true, the grid will be returned in a sparse
  1757|         0|            0|            0|  0.00%|    representation.
  1758|         0|            0|            0|  0.00%|
  1759|         0|            0|            0|  0.00%|    >>> i, j = np.indices((2, 3), sparse=True)
  1760|         0|            0|            0|  0.00%|    >>> i.shape
  1761|         0|            0|            0|  0.00%|    (2, 1)
  1762|         0|            0|            0|  0.00%|    >>> j.shape
  1763|         0|            0|            0|  0.00%|    (1, 3)
  1764|         0|            0|            0|  0.00%|    >>> i        # row indices
  1765|         0|            0|            0|  0.00%|    array([[0],
  1766|         0|            0|            0|  0.00%|           [1]])
  1767|         0|            0|            0|  0.00%|    >>> j        # column indices
  1768|         0|            0|            0|  0.00%|    array([[0, 1, 2]])
  1769|         0|            0|            0|  0.00%|
  1770|         0|            0|            0|  0.00%|    """
  1771|         0|            0|            0|  0.00%|    dimensions = tuple(dimensions)
  1772|         0|            0|            0|  0.00%|    N = len(dimensions)
  1773|         0|            0|            0|  0.00%|    shape = (1,)*N
  1774|         0|            0|            0|  0.00%|    if sparse:
  1775|         0|            0|            0|  0.00%|        res = tuple()
  1776|         0|            0|            0|  0.00%|    else:
  1777|         0|            0|            0|  0.00%|        res = empty((N,)+dimensions, dtype=dtype)
  1778|         0|            0|            0|  0.00%|    for i, dim in enumerate(dimensions):
  1779|         0|            0|            0|  0.00%|        idx = arange(dim, dtype=dtype).reshape(
  1780|         0|            0|            0|  0.00%|            shape[:i] + (dim,) + shape[i+1:]
  1781|         0|            0|            0|  0.00%|        )
  1782|         0|            0|            0|  0.00%|        if sparse:
  1783|         0|            0|            0|  0.00%|            res = res + (idx,)
  1784|         0|            0|            0|  0.00%|        else:
  1785|         0|            0|            0|  0.00%|            res[i] = idx
  1786|         0|            0|            0|  0.00%|    return res
  1787|         0|            0|            0|  0.00%|
  1788|         0|            0|            0|  0.00%|
  1789|         0|            0|            0|  0.00%|def _fromfunction_dispatcher(function, shape, *, dtype=None, like=None, **kwargs):
  1790|         0|            0|            0|  0.00%|    return (like,)
  1791|         0|            0|            0|  0.00%|
  1792|         0|            0|            0|  0.00%|
  1793|         0|            0|            0|  0.00%|@set_array_function_like_doc
  1794|         0|            0|            0|  0.00%|@set_module('numpy')
  1795|         0|            0|            0|  0.00%|def fromfunction(function, shape, *, dtype=float, like=None, **kwargs):
  1796|         0|            0|            0|  0.00%|    """
  1797|         0|            0|            0|  0.00%|    Construct an array by executing a function over each coordinate.
  1798|         0|            0|            0|  0.00%|
  1799|         0|            0|            0|  0.00%|    The resulting array therefore has a value ``fn(x, y, z)`` at
  1800|         0|            0|            0|  0.00%|    coordinate ``(x, y, z)``.
  1801|         0|            0|            0|  0.00%|
  1802|         0|            0|            0|  0.00%|    Parameters
  1803|         0|            0|            0|  0.00%|    ----------
  1804|         0|            0|            0|  0.00%|    function : callable
  1805|         0|            0|            0|  0.00%|        The function is called with N parameters, where N is the rank of
  1806|         0|            0|            0|  0.00%|        `shape`.  Each parameter represents the coordinates of the array
  1807|         0|            0|            0|  0.00%|        varying along a specific axis.  For example, if `shape`
  1808|         0|            0|            0|  0.00%|        were ``(2, 2)``, then the parameters would be
  1809|         0|            0|            0|  0.00%|        ``array([[0, 0], [1, 1]])`` and ``array([[0, 1], [0, 1]])``
  1810|         0|            0|            0|  0.00%|    shape : (N,) tuple of ints
  1811|         0|            0|            0|  0.00%|        Shape of the output array, which also determines the shape of
  1812|         0|            0|            0|  0.00%|        the coordinate arrays passed to `function`.
  1813|         0|            0|            0|  0.00%|    dtype : data-type, optional
  1814|         0|            0|            0|  0.00%|        Data-type of the coordinate arrays passed to `function`.
  1815|         0|            0|            0|  0.00%|        By default, `dtype` is float.
  1816|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
  1817|         0|            0|            0|  0.00%|
  1818|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  1819|         0|            0|            0|  0.00%|
  1820|         0|            0|            0|  0.00%|    Returns
  1821|         0|            0|            0|  0.00%|    -------
  1822|         0|            0|            0|  0.00%|    fromfunction : any
  1823|         0|            0|            0|  0.00%|        The result of the call to `function` is passed back directly.
  1824|         0|            0|            0|  0.00%|        Therefore the shape of `fromfunction` is completely determined by
  1825|         0|            0|            0|  0.00%|        `function`.  If `function` returns a scalar value, the shape of
  1826|         0|            0|            0|  0.00%|        `fromfunction` would not match the `shape` parameter.
  1827|         0|            0|            0|  0.00%|
  1828|         0|            0|            0|  0.00%|    See Also
  1829|         0|            0|            0|  0.00%|    --------
  1830|         0|            0|            0|  0.00%|    indices, meshgrid
  1831|         0|            0|            0|  0.00%|
  1832|         0|            0|            0|  0.00%|    Notes
  1833|         0|            0|            0|  0.00%|    -----
  1834|         0|            0|            0|  0.00%|    Keywords other than `dtype` are passed to `function`.
  1835|         0|            0|            0|  0.00%|
  1836|         0|            0|            0|  0.00%|    Examples
  1837|         0|            0|            0|  0.00%|    --------
  1838|         0|            0|            0|  0.00%|    >>> np.fromfunction(lambda i, j: i == j, (3, 3), dtype=int)
  1839|         0|            0|            0|  0.00%|    array([[ True, False, False],
  1840|         0|            0|            0|  0.00%|           [False,  True, False],
  1841|         0|            0|            0|  0.00%|           [False, False,  True]])
  1842|         0|            0|            0|  0.00%|
  1843|         0|            0|            0|  0.00%|    >>> np.fromfunction(lambda i, j: i + j, (3, 3), dtype=int)
  1844|         0|            0|            0|  0.00%|    array([[0, 1, 2],
  1845|         0|            0|            0|  0.00%|           [1, 2, 3],
  1846|         0|            0|            0|  0.00%|           [2, 3, 4]])
  1847|         0|            0|            0|  0.00%|
  1848|         0|            0|            0|  0.00%|    """
  1849|         0|            0|            0|  0.00%|    if like is not None:
  1850|         0|            0|            0|  0.00%|        return _fromfunction_with_like(function, shape, dtype=dtype, like=like, **kwargs)
  1851|         0|            0|            0|  0.00%|
  1852|         0|            0|            0|  0.00%|    args = indices(shape, dtype=dtype)
  1853|         0|            0|            0|  0.00%|    return function(*args, **kwargs)
  1854|         0|            0|            0|  0.00%|
  1855|         0|            0|            0|  0.00%|
  1856|         0|            0|            0|  0.00%|_fromfunction_with_like = array_function_dispatch(
  1857|         0|            0|            0|  0.00%|    _fromfunction_dispatcher
  1858|         0|            0|            0|  0.00%|)(fromfunction)
  1859|         0|            0|            0|  0.00%|
  1860|         0|            0|            0|  0.00%|
  1861|         0|            0|            0|  0.00%|def _frombuffer(buf, dtype, shape, order):
  1862|         0|            0|            0|  0.00%|    return frombuffer(buf, dtype=dtype).reshape(shape, order=order)
  1863|         0|            0|            0|  0.00%|
  1864|         0|            0|            0|  0.00%|
  1865|         0|            0|            0|  0.00%|@set_module('numpy')
  1866|         0|            0|            0|  0.00%|def isscalar(element):
  1867|         0|            0|            0|  0.00%|    """
  1868|         0|            0|            0|  0.00%|    Returns True if the type of `element` is a scalar type.
  1869|         0|            0|            0|  0.00%|
  1870|         0|            0|            0|  0.00%|    Parameters
  1871|         0|            0|            0|  0.00%|    ----------
  1872|         0|            0|            0|  0.00%|    element : any
  1873|         0|            0|            0|  0.00%|        Input argument, can be of any type and shape.
  1874|         0|            0|            0|  0.00%|
  1875|         0|            0|            0|  0.00%|    Returns
  1876|         0|            0|            0|  0.00%|    -------
  1877|         0|            0|            0|  0.00%|    val : bool
  1878|         0|            0|            0|  0.00%|        True if `element` is a scalar type, False if it is not.
  1879|         0|            0|            0|  0.00%|
  1880|         0|            0|            0|  0.00%|    See Also
  1881|         0|            0|            0|  0.00%|    --------
  1882|         0|            0|            0|  0.00%|    ndim : Get the number of dimensions of an array
  1883|         0|            0|            0|  0.00%|
  1884|         0|            0|            0|  0.00%|    Notes
  1885|         0|            0|            0|  0.00%|    -----
  1886|         0|            0|            0|  0.00%|    If you need a stricter way to identify a *numerical* scalar, use
  1887|         0|            0|            0|  0.00%|    ``isinstance(x, numbers.Number)``, as that returns ``False`` for most
  1888|         0|            0|            0|  0.00%|    non-numerical elements such as strings.
  1889|         0|            0|            0|  0.00%|
  1890|         0|            0|            0|  0.00%|    In most cases ``np.ndim(x) == 0`` should be used instead of this function,
  1891|         0|            0|            0|  0.00%|    as that will also return true for 0d arrays. This is how numpy overloads
  1892|         0|            0|            0|  0.00%|    functions in the style of the ``dx`` arguments to `gradient` and the ``bins``
  1893|         0|            0|            0|  0.00%|    argument to `histogram`. Some key differences:
  1894|         0|            0|            0|  0.00%|
  1895|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1896|         0|            0|            0|  0.00%|    | x                                    |``isscalar(x)``|``np.ndim(x) == 0``|
  1897|         0|            0|            0|  0.00%|    +======================================+===============+===================+
  1898|         0|            0|            0|  0.00%|    | PEP 3141 numeric objects (including  | ``True``      | ``True``          |
  1899|         0|            0|            0|  0.00%|    | builtins)                            |               |                   |
  1900|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1901|         0|            0|            0|  0.00%|    | builtin string and buffer objects    | ``True``      | ``True``          |
  1902|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1903|         0|            0|            0|  0.00%|    | other builtin objects, like          | ``False``     | ``True``          |
  1904|         0|            0|            0|  0.00%|    | `pathlib.Path`, `Exception`,         |               |                   |
  1905|         0|            0|            0|  0.00%|    | the result of `re.compile`           |               |                   |
  1906|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1907|         0|            0|            0|  0.00%|    | third-party objects like             | ``False``     | ``True``          |
  1908|         0|            0|            0|  0.00%|    | `matplotlib.figure.Figure`           |               |                   |
  1909|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1910|         0|            0|            0|  0.00%|    | zero-dimensional numpy arrays        | ``False``     | ``True``          |
  1911|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1912|         0|            0|            0|  0.00%|    | other numpy arrays                   | ``False``     | ``False``         |
  1913|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1914|         0|            0|            0|  0.00%|    | `list`, `tuple`, and other sequence  | ``False``     | ``False``         |
  1915|         0|            0|            0|  0.00%|    | objects                              |               |                   |
  1916|         0|            0|            0|  0.00%|    +--------------------------------------+---------------+-------------------+
  1917|         0|            0|            0|  0.00%|
  1918|         0|            0|            0|  0.00%|    Examples
  1919|         0|            0|            0|  0.00%|    --------
  1920|         0|            0|            0|  0.00%|    >>> np.isscalar(3.1)
  1921|         0|            0|            0|  0.00%|    True
  1922|         0|            0|            0|  0.00%|    >>> np.isscalar(np.array(3.1))
  1923|         0|            0|            0|  0.00%|    False
  1924|         0|            0|            0|  0.00%|    >>> np.isscalar([3.1])
  1925|         0|            0|            0|  0.00%|    False
  1926|         0|            0|            0|  0.00%|    >>> np.isscalar(False)
  1927|         0|            0|            0|  0.00%|    True
  1928|         0|            0|            0|  0.00%|    >>> np.isscalar('numpy')
  1929|         0|            0|            0|  0.00%|    True
  1930|         0|            0|            0|  0.00%|
  1931|         0|            0|            0|  0.00%|    NumPy supports PEP 3141 numbers:
  1932|         0|            0|            0|  0.00%|
  1933|         0|            0|            0|  0.00%|    >>> from fractions import Fraction
  1934|         0|            0|            0|  0.00%|    >>> np.isscalar(Fraction(5, 17))
  1935|         0|            0|            0|  0.00%|    True
  1936|         0|            0|            0|  0.00%|    >>> from numbers import Number
  1937|         0|            0|            0|  0.00%|    >>> np.isscalar(Number())
  1938|         0|            0|            0|  0.00%|    True
  1939|         0|            0|            0|  0.00%|
  1940|         0|            0|            0|  0.00%|    """
  1941|         0|            0|            0|  0.00%|    return (isinstance(element, generic)
  1942|         0|            0|            0|  0.00%|            or type(element) in ScalarType
  1943|         0|            0|            0|  0.00%|            or isinstance(element, numbers.Number))
  1944|         0|            0|            0|  0.00%|
  1945|         0|            0|            0|  0.00%|
  1946|         0|            0|            0|  0.00%|@set_module('numpy')
  1947|         0|            0|            0|  0.00%|def binary_repr(num, width=None):
  1948|         0|            0|            0|  0.00%|    """
  1949|         0|            0|            0|  0.00%|    Return the binary representation of the input number as a string.
  1950|         0|            0|            0|  0.00%|
  1951|         0|            0|            0|  0.00%|    For negative numbers, if width is not given, a minus sign is added to the
  1952|         0|            0|            0|  0.00%|    front. If width is given, the two's complement of the number is
  1953|         0|            0|            0|  0.00%|    returned, with respect to that width.
  1954|         0|            0|            0|  0.00%|
  1955|         0|            0|            0|  0.00%|    In a two's-complement system negative numbers are represented by the two's
  1956|         0|            0|            0|  0.00%|    complement of the absolute value. This is the most common method of
  1957|         0|            0|            0|  0.00%|    representing signed integers on computers [1]_. A N-bit two's-complement
  1958|         0|            0|            0|  0.00%|    system can represent every integer in the range
  1959|         0|            0|            0|  0.00%|    :math:`-2^{N-1}` to :math:`+2^{N-1}-1`.
  1960|         0|            0|            0|  0.00%|
  1961|         0|            0|            0|  0.00%|    Parameters
  1962|         0|            0|            0|  0.00%|    ----------
  1963|         0|            0|            0|  0.00%|    num : int
  1964|         0|            0|            0|  0.00%|        Only an integer decimal number can be used.
  1965|         0|            0|            0|  0.00%|    width : int, optional
  1966|         0|            0|            0|  0.00%|        The length of the returned string if `num` is positive, or the length
  1967|         0|            0|            0|  0.00%|        of the two's complement if `num` is negative, provided that `width` is
  1968|         0|            0|            0|  0.00%|        at least a sufficient number of bits for `num` to be represented in the
  1969|         0|            0|            0|  0.00%|        designated form.
  1970|         0|            0|            0|  0.00%|
  1971|         0|            0|            0|  0.00%|        If the `width` value is insufficient, it will be ignored, and `num` will
  1972|         0|            0|            0|  0.00%|        be returned in binary (`num` > 0) or two's complement (`num` < 0) form
  1973|         0|            0|            0|  0.00%|        with its width equal to the minimum number of bits needed to represent
  1974|         0|            0|            0|  0.00%|        the number in the designated form. This behavior is deprecated and will
  1975|         0|            0|            0|  0.00%|        later raise an error.
  1976|         0|            0|            0|  0.00%|
  1977|         0|            0|            0|  0.00%|        .. deprecated:: 1.12.0
  1978|         0|            0|            0|  0.00%|
  1979|         0|            0|            0|  0.00%|    Returns
  1980|         0|            0|            0|  0.00%|    -------
  1981|         0|            0|            0|  0.00%|    bin : str
  1982|         0|            0|            0|  0.00%|        Binary representation of `num` or two's complement of `num`.
  1983|         0|            0|            0|  0.00%|
  1984|         0|            0|            0|  0.00%|    See Also
  1985|         0|            0|            0|  0.00%|    --------
  1986|         0|            0|            0|  0.00%|    base_repr: Return a string representation of a number in the given base
  1987|         0|            0|            0|  0.00%|               system.
  1988|         0|            0|            0|  0.00%|    bin: Python's built-in binary representation generator of an integer.
  1989|         0|            0|            0|  0.00%|
  1990|         0|            0|            0|  0.00%|    Notes
  1991|         0|            0|            0|  0.00%|    -----
  1992|         0|            0|            0|  0.00%|    `binary_repr` is equivalent to using `base_repr` with base 2, but about 25x
  1993|         0|            0|            0|  0.00%|    faster.
  1994|         0|            0|            0|  0.00%|
  1995|         0|            0|            0|  0.00%|    References
  1996|         0|            0|            0|  0.00%|    ----------
  1997|         0|            0|            0|  0.00%|    .. [1] Wikipedia, "Two's complement",
  1998|         0|            0|            0|  0.00%|        https://en.wikipedia.org/wiki/Two's_complement
  1999|         0|            0|            0|  0.00%|
  2000|         0|            0|            0|  0.00%|    Examples
  2001|         0|            0|            0|  0.00%|    --------
  2002|         0|            0|            0|  0.00%|    >>> np.binary_repr(3)
  2003|         0|            0|            0|  0.00%|    '11'
  2004|         0|            0|            0|  0.00%|    >>> np.binary_repr(-3)
  2005|         0|            0|            0|  0.00%|    '-11'
  2006|         0|            0|            0|  0.00%|    >>> np.binary_repr(3, width=4)
  2007|         0|            0|            0|  0.00%|    '0011'
  2008|         0|            0|            0|  0.00%|
  2009|         0|            0|            0|  0.00%|    The two's complement is returned when the input number is negative and
  2010|         0|            0|            0|  0.00%|    width is specified:
  2011|         0|            0|            0|  0.00%|
  2012|         0|            0|            0|  0.00%|    >>> np.binary_repr(-3, width=3)
  2013|         0|            0|            0|  0.00%|    '101'
  2014|         0|            0|            0|  0.00%|    >>> np.binary_repr(-3, width=5)
  2015|         0|            0|            0|  0.00%|    '11101'
  2016|         0|            0|            0|  0.00%|
  2017|         0|            0|            0|  0.00%|    """
  2018|         0|            0|            0|  0.00%|    def warn_if_insufficient(width, binwidth):
  2019|         0|            0|            0|  0.00%|        if width is not None and width < binwidth:
  2020|         0|            0|            0|  0.00%|            warnings.warn(
  2021|         0|            0|            0|  0.00%|                "Insufficient bit width provided. This behavior "
  2022|         0|            0|            0|  0.00%|                "will raise an error in the future.", DeprecationWarning,
  2023|         0|            0|            0|  0.00%|                stacklevel=3)
  2024|         0|            0|            0|  0.00%|
  2025|         0|            0|            0|  0.00%|    # Ensure that num is a Python integer to avoid overflow or unwanted
  2026|         0|            0|            0|  0.00%|    # casts to floating point.
  2027|         0|            0|            0|  0.00%|    num = operator.index(num)
  2028|         0|            0|            0|  0.00%|
  2029|         0|            0|            0|  0.00%|    if num == 0:
  2030|         0|            0|            0|  0.00%|        return '0' * (width or 1)
  2031|         0|            0|            0|  0.00%|
  2032|         0|            0|            0|  0.00%|    elif num > 0:
  2033|         0|            0|            0|  0.00%|        binary = bin(num)[2:]
  2034|         0|            0|            0|  0.00%|        binwidth = len(binary)
  2035|         0|            0|            0|  0.00%|        outwidth = (binwidth if width is None
  2036|         0|            0|            0|  0.00%|                    else max(binwidth, width))
  2037|         0|            0|            0|  0.00%|        warn_if_insufficient(width, binwidth)
  2038|         0|            0|            0|  0.00%|        return binary.zfill(outwidth)
  2039|         0|            0|            0|  0.00%|
  2040|         0|            0|            0|  0.00%|    else:
  2041|         0|            0|            0|  0.00%|        if width is None:
  2042|         0|            0|            0|  0.00%|            return '-' + bin(-num)[2:]
  2043|         0|            0|            0|  0.00%|
  2044|         0|            0|            0|  0.00%|        else:
  2045|         0|            0|            0|  0.00%|            poswidth = len(bin(-num)[2:])
  2046|         0|            0|            0|  0.00%|
  2047|         0|            0|            0|  0.00%|            # See gh-8679: remove extra digit
  2048|         0|            0|            0|  0.00%|            # for numbers at boundaries.
  2049|         0|            0|            0|  0.00%|            if 2**(poswidth - 1) == -num:
  2050|         0|            0|            0|  0.00%|                poswidth -= 1
  2051|         0|            0|            0|  0.00%|
  2052|         0|            0|            0|  0.00%|            twocomp = 2**(poswidth + 1) + num
  2053|         0|            0|            0|  0.00%|            binary = bin(twocomp)[2:]
  2054|         0|            0|            0|  0.00%|            binwidth = len(binary)
  2055|         0|            0|            0|  0.00%|
  2056|         0|            0|            0|  0.00%|            outwidth = max(binwidth, width)
  2057|         0|            0|            0|  0.00%|            warn_if_insufficient(width, binwidth)
  2058|         0|            0|            0|  0.00%|            return '1' * (outwidth - binwidth) + binary
  2059|         0|            0|            0|  0.00%|
  2060|         0|            0|            0|  0.00%|
  2061|         0|            0|            0|  0.00%|@set_module('numpy')
  2062|         0|            0|            0|  0.00%|def base_repr(number, base=2, padding=0):
  2063|         0|            0|            0|  0.00%|    """
  2064|         0|            0|            0|  0.00%|    Return a string representation of a number in the given base system.
  2065|         0|            0|            0|  0.00%|
  2066|         0|            0|            0|  0.00%|    Parameters
  2067|         0|            0|            0|  0.00%|    ----------
  2068|         0|            0|            0|  0.00%|    number : int
  2069|         0|            0|            0|  0.00%|        The value to convert. Positive and negative values are handled.
  2070|         0|            0|            0|  0.00%|    base : int, optional
  2071|         0|            0|            0|  0.00%|        Convert `number` to the `base` number system. The valid range is 2-36,
  2072|         0|            0|            0|  0.00%|        the default value is 2.
  2073|         0|            0|            0|  0.00%|    padding : int, optional
  2074|         0|            0|            0|  0.00%|        Number of zeros padded on the left. Default is 0 (no padding).
  2075|         0|            0|            0|  0.00%|
  2076|         0|            0|            0|  0.00%|    Returns
  2077|         0|            0|            0|  0.00%|    -------
  2078|         0|            0|            0|  0.00%|    out : str
  2079|         0|            0|            0|  0.00%|        String representation of `number` in `base` system.
  2080|         0|            0|            0|  0.00%|
  2081|         0|            0|            0|  0.00%|    See Also
  2082|         0|            0|            0|  0.00%|    --------
  2083|         0|            0|            0|  0.00%|    binary_repr : Faster version of `base_repr` for base 2.
  2084|         0|            0|            0|  0.00%|
  2085|         0|            0|            0|  0.00%|    Examples
  2086|         0|            0|            0|  0.00%|    --------
  2087|         0|            0|            0|  0.00%|    >>> np.base_repr(5)
  2088|         0|            0|            0|  0.00%|    '101'
  2089|         0|            0|            0|  0.00%|    >>> np.base_repr(6, 5)
  2090|         0|            0|            0|  0.00%|    '11'
  2091|         0|            0|            0|  0.00%|    >>> np.base_repr(7, base=5, padding=3)
  2092|         0|            0|            0|  0.00%|    '00012'
  2093|         0|            0|            0|  0.00%|
  2094|         0|            0|            0|  0.00%|    >>> np.base_repr(10, base=16)
  2095|         0|            0|            0|  0.00%|    'A'
  2096|         0|            0|            0|  0.00%|    >>> np.base_repr(32, base=16)
  2097|         0|            0|            0|  0.00%|    '20'
  2098|         0|            0|            0|  0.00%|
  2099|         0|            0|            0|  0.00%|    """
  2100|         0|            0|            0|  0.00%|    digits = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
  2101|         0|            0|            0|  0.00%|    if base > len(digits):
  2102|         0|            0|            0|  0.00%|        raise ValueError("Bases greater than 36 not handled in base_repr.")
  2103|         0|            0|            0|  0.00%|    elif base < 2:
  2104|         0|            0|            0|  0.00%|        raise ValueError("Bases less than 2 not handled in base_repr.")
  2105|         0|            0|            0|  0.00%|
  2106|         0|            0|            0|  0.00%|    num = abs(number)
  2107|         0|            0|            0|  0.00%|    res = []
  2108|         0|            0|            0|  0.00%|    while num:
  2109|         0|            0|            0|  0.00%|        res.append(digits[num % base])
  2110|         0|            0|            0|  0.00%|        num //= base
  2111|         0|            0|            0|  0.00%|    if padding:
  2112|         0|            0|            0|  0.00%|        res.append('0' * padding)
  2113|         0|            0|            0|  0.00%|    if number < 0:
  2114|         0|            0|            0|  0.00%|        res.append('-')
  2115|         0|            0|            0|  0.00%|    return ''.join(reversed(res or '0'))
  2116|         0|            0|            0|  0.00%|
  2117|         0|            0|            0|  0.00%|
  2118|         0|            0|            0|  0.00%|# These are all essentially abbreviations
  2119|         0|            0|            0|  0.00%|# These might wind up in a special abbreviations module
  2120|         0|            0|            0|  0.00%|
  2121|         0|            0|            0|  0.00%|
  2122|         0|            0|            0|  0.00%|def _maketup(descr, val):
  2123|         0|            0|            0|  0.00%|    dt = dtype(descr)
  2124|         0|            0|            0|  0.00%|    # Place val in all scalar tuples:
  2125|         0|            0|            0|  0.00%|    fields = dt.fields
  2126|         0|            0|            0|  0.00%|    if fields is None:
  2127|         0|            0|            0|  0.00%|        return val
  2128|         0|            0|            0|  0.00%|    else:
  2129|         0|            0|            0|  0.00%|        res = [_maketup(fields[name][0], val) for name in dt.names]
  2130|         0|            0|            0|  0.00%|        return tuple(res)
  2131|         0|            0|            0|  0.00%|
  2132|         0|            0|            0|  0.00%|
  2133|         0|            0|            0|  0.00%|def _identity_dispatcher(n, dtype=None, *, like=None):
  2134|         0|            0|            0|  0.00%|    return (like,)
  2135|         0|            0|            0|  0.00%|
  2136|         0|            0|            0|  0.00%|
  2137|         0|            0|            0|  0.00%|@set_array_function_like_doc
  2138|         0|            0|            0|  0.00%|@set_module('numpy')
  2139|         0|            0|            0|  0.00%|def identity(n, dtype=None, *, like=None):
  2140|         0|            0|            0|  0.00%|    """
  2141|         0|            0|            0|  0.00%|    Return the identity array.
  2142|         0|            0|            0|  0.00%|
  2143|         0|            0|            0|  0.00%|    The identity array is a square array with ones on
  2144|         0|            0|            0|  0.00%|    the main diagonal.
  2145|         0|            0|            0|  0.00%|
  2146|         0|            0|            0|  0.00%|    Parameters
  2147|         0|            0|            0|  0.00%|    ----------
  2148|         0|            0|            0|  0.00%|    n : int
  2149|         0|            0|            0|  0.00%|        Number of rows (and columns) in `n` x `n` output.
  2150|         0|            0|            0|  0.00%|    dtype : data-type, optional
  2151|         0|            0|            0|  0.00%|        Data-type of the output.  Defaults to ``float``.
  2152|         0|            0|            0|  0.00%|    ${ARRAY_FUNCTION_LIKE}
  2153|         0|            0|            0|  0.00%|
  2154|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
  2155|         0|            0|            0|  0.00%|
  2156|         0|            0|            0|  0.00%|    Returns
  2157|         0|            0|            0|  0.00%|    -------
  2158|         0|            0|            0|  0.00%|    out : ndarray
  2159|         0|            0|            0|  0.00%|        `n` x `n` array with its main diagonal set to one,
  2160|         0|            0|            0|  0.00%|        and all other elements 0.
  2161|         0|            0|            0|  0.00%|
  2162|         0|            0|            0|  0.00%|    Examples
  2163|         0|            0|            0|  0.00%|    --------
  2164|         0|            0|            0|  0.00%|    >>> np.identity(3)
  2165|         0|            0|            0|  0.00%|    array([[1.,  0.,  0.],
  2166|         0|            0|            0|  0.00%|           [0.,  1.,  0.],
  2167|         0|            0|            0|  0.00%|           [0.,  0.,  1.]])
  2168|         0|            0|            0|  0.00%|
  2169|         0|            0|            0|  0.00%|    """
  2170|         0|            0|            0|  0.00%|    if like is not None:
  2171|         0|            0|            0|  0.00%|        return _identity_with_like(n, dtype=dtype, like=like)
  2172|         0|            0|            0|  0.00%|
  2173|         0|            0|            0|  0.00%|    from numpy import eye
  2174|         0|            0|            0|  0.00%|    return eye(n, dtype=dtype, like=like)
  2175|         0|            0|            0|  0.00%|
  2176|         0|            0|            0|  0.00%|
  2177|         0|            0|            0|  0.00%|_identity_with_like = array_function_dispatch(
  2178|         0|            0|            0|  0.00%|    _identity_dispatcher
  2179|         0|            0|            0|  0.00%|)(identity)
  2180|         0|            0|            0|  0.00%|
  2181|         0|            0|            0|  0.00%|
  2182|         0|            0|            0|  0.00%|def _allclose_dispatcher(a, b, rtol=None, atol=None, equal_nan=None):
  2183|         0|            0|            0|  0.00%|    return (a, b)
  2184|         0|            0|            0|  0.00%|
  2185|         0|            0|            0|  0.00%|
  2186|         0|            0|            0|  0.00%|@array_function_dispatch(_allclose_dispatcher)
  2187|         0|            0|            0|  0.00%|def allclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):
  2188|         0|            0|            0|  0.00%|    """
  2189|         0|            0|            0|  0.00%|    Returns True if two arrays are element-wise equal within a tolerance.
  2190|         0|            0|            0|  0.00%|
  2191|         0|            0|            0|  0.00%|    The tolerance values are positive, typically very small numbers.  The
  2192|         0|            0|            0|  0.00%|    relative difference (`rtol` * abs(`b`)) and the absolute difference
  2193|         0|            0|            0|  0.00%|    `atol` are added together to compare against the absolute difference
  2194|         0|            0|            0|  0.00%|    between `a` and `b`.
  2195|         0|            0|            0|  0.00%|
  2196|         0|            0|            0|  0.00%|    NaNs are treated as equal if they are in the same place and if
  2197|         0|            0|            0|  0.00%|    ``equal_nan=True``.  Infs are treated as equal if they are in the same
  2198|         0|            0|            0|  0.00%|    place and of the same sign in both arrays.
  2199|         0|            0|            0|  0.00%|
  2200|         0|            0|            0|  0.00%|    Parameters
  2201|         0|            0|            0|  0.00%|    ----------
  2202|         0|            0|            0|  0.00%|    a, b : array_like
  2203|         0|            0|            0|  0.00%|        Input arrays to compare.
  2204|         0|            0|            0|  0.00%|    rtol : float
  2205|         0|            0|            0|  0.00%|        The relative tolerance parameter (see Notes).
  2206|         0|            0|            0|  0.00%|    atol : float
  2207|         0|            0|            0|  0.00%|        The absolute tolerance parameter (see Notes).
  2208|         0|            0|            0|  0.00%|    equal_nan : bool
  2209|         0|            0|            0|  0.00%|        Whether to compare NaN's as equal.  If True, NaN's in `a` will be
  2210|         0|            0|            0|  0.00%|        considered equal to NaN's in `b` in the output array.
  2211|         0|            0|            0|  0.00%|
  2212|         0|            0|            0|  0.00%|        .. versionadded:: 1.10.0
  2213|         0|            0|            0|  0.00%|
  2214|         0|            0|            0|  0.00%|    Returns
  2215|         0|            0|            0|  0.00%|    -------
  2216|         0|            0|            0|  0.00%|    allclose : bool
  2217|         0|            0|            0|  0.00%|        Returns True if the two arrays are equal within the given
  2218|         0|            0|            0|  0.00%|        tolerance; False otherwise.
  2219|         0|            0|            0|  0.00%|
  2220|         0|            0|            0|  0.00%|    See Also
  2221|         0|            0|            0|  0.00%|    --------
  2222|         0|            0|            0|  0.00%|    isclose, all, any, equal
  2223|         0|            0|            0|  0.00%|
  2224|         0|            0|            0|  0.00%|    Notes
  2225|         0|            0|            0|  0.00%|    -----
  2226|         0|            0|            0|  0.00%|    If the following equation is element-wise True, then allclose returns
  2227|         0|            0|            0|  0.00%|    True.
  2228|         0|            0|            0|  0.00%|
  2229|         0|            0|            0|  0.00%|     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))
  2230|         0|            0|            0|  0.00%|
  2231|         0|            0|            0|  0.00%|    The above equation is not symmetric in `a` and `b`, so that
  2232|         0|            0|            0|  0.00%|    ``allclose(a, b)`` might be different from ``allclose(b, a)`` in
  2233|         0|            0|            0|  0.00%|    some rare cases.
  2234|         0|            0|            0|  0.00%|
  2235|         0|            0|            0|  0.00%|    The comparison of `a` and `b` uses standard broadcasting, which
  2236|         0|            0|            0|  0.00%|    means that `a` and `b` need not have the same shape in order for
  2237|         0|            0|            0|  0.00%|    ``allclose(a, b)`` to evaluate to True.  The same is true for
  2238|         0|            0|            0|  0.00%|    `equal` but not `array_equal`.
  2239|         0|            0|            0|  0.00%|
  2240|         0|            0|            0|  0.00%|    `allclose` is not defined for non-numeric data types.
  2241|         0|            0|            0|  0.00%|
  2242|         0|            0|            0|  0.00%|    Examples
  2243|         0|            0|            0|  0.00%|    --------
  2244|         0|            0|            0|  0.00%|    >>> np.allclose([1e10,1e-7], [1.00001e10,1e-8])
  2245|         0|            0|            0|  0.00%|    False
  2246|         0|            0|            0|  0.00%|    >>> np.allclose([1e10,1e-8], [1.00001e10,1e-9])
  2247|         0|            0|            0|  0.00%|    True
  2248|         0|            0|            0|  0.00%|    >>> np.allclose([1e10,1e-8], [1.0001e10,1e-9])
  2249|         0|            0|            0|  0.00%|    False
  2250|         0|            0|            0|  0.00%|    >>> np.allclose([1.0, np.nan], [1.0, np.nan])
  2251|         0|            0|            0|  0.00%|    False
  2252|         0|            0|            0|  0.00%|    >>> np.allclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)
  2253|         0|            0|            0|  0.00%|    True
  2254|         0|            0|            0|  0.00%|
  2255|         0|            0|            0|  0.00%|    """
  2256|         0|            0|            0|  0.00%|    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))
  2257|         0|            0|            0|  0.00%|    return bool(res)
  2258|         0|            0|            0|  0.00%|
  2259|         0|            0|            0|  0.00%|
  2260|         1|  2.38419e-06|  2.38419e-06|  0.00%|def _isclose_dispatcher(a, b, rtol=None, atol=None, equal_nan=None):
  2261|         1|  4.76837e-06|  4.76837e-06|  0.00%|    return (a, b)
  2262|         0|            0|            0|  0.00%|
  2263|         0|            0|            0|  0.00%|
  2264|         1|  5.96046e-06|  5.96046e-06|  0.00%|@array_function_dispatch(_isclose_dispatcher)
  2265|         0|            0|            0|  0.00%|def isclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):
  2266|         0|            0|            0|  0.00%|    """
  2267|         0|            0|            0|  0.00%|    Returns a boolean array where two arrays are element-wise equal within a
  2268|         0|            0|            0|  0.00%|    tolerance.
  2269|         0|            0|            0|  0.00%|
  2270|         0|            0|            0|  0.00%|    The tolerance values are positive, typically very small numbers.  The
  2271|         0|            0|            0|  0.00%|    relative difference (`rtol` * abs(`b`)) and the absolute difference
  2272|         0|            0|            0|  0.00%|    `atol` are added together to compare against the absolute difference
  2273|         0|            0|            0|  0.00%|    between `a` and `b`.
  2274|         0|            0|            0|  0.00%|
  2275|         0|            0|            0|  0.00%|    .. warning:: The default `atol` is not appropriate for comparing numbers
  2276|         0|            0|            0|  0.00%|                 that are much smaller than one (see Notes).
  2277|         0|            0|            0|  0.00%|
  2278|         0|            0|            0|  0.00%|    Parameters
  2279|         0|            0|            0|  0.00%|    ----------
  2280|         0|            0|            0|  0.00%|    a, b : array_like
  2281|         0|            0|            0|  0.00%|        Input arrays to compare.
  2282|         0|            0|            0|  0.00%|    rtol : float
  2283|         0|            0|            0|  0.00%|        The relative tolerance parameter (see Notes).
  2284|         0|            0|            0|  0.00%|    atol : float
  2285|         0|            0|            0|  0.00%|        The absolute tolerance parameter (see Notes).
  2286|         0|            0|            0|  0.00%|    equal_nan : bool
  2287|         0|            0|            0|  0.00%|        Whether to compare NaN's as equal.  If True, NaN's in `a` will be
  2288|         0|            0|            0|  0.00%|        considered equal to NaN's in `b` in the output array.
  2289|         0|            0|            0|  0.00%|
  2290|         0|            0|            0|  0.00%|    Returns
  2291|         0|            0|            0|  0.00%|    -------
  2292|         0|            0|            0|  0.00%|    y : array_like
  2293|         0|            0|            0|  0.00%|        Returns a boolean array of where `a` and `b` are equal within the
  2294|         0|            0|            0|  0.00%|        given tolerance. If both `a` and `b` are scalars, returns a single
  2295|         0|            0|            0|  0.00%|        boolean value.
  2296|         0|            0|            0|  0.00%|
  2297|         0|            0|            0|  0.00%|    See Also
  2298|         0|            0|            0|  0.00%|    --------
  2299|         0|            0|            0|  0.00%|    allclose
  2300|         0|            0|            0|  0.00%|    math.isclose
  2301|         0|            0|            0|  0.00%|
  2302|         0|            0|            0|  0.00%|    Notes
  2303|         0|            0|            0|  0.00%|    -----
  2304|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  2305|         0|            0|            0|  0.00%|
  2306|         0|            0|            0|  0.00%|    For finite values, isclose uses the following equation to test whether
  2307|         0|            0|            0|  0.00%|    two floating point values are equivalent.
  2308|         0|            0|            0|  0.00%|
  2309|         0|            0|            0|  0.00%|     absolute(`a` - `b`) <= (`atol` + `rtol` * absolute(`b`))
  2310|         0|            0|            0|  0.00%|
  2311|         0|            0|            0|  0.00%|    Unlike the built-in `math.isclose`, the above equation is not symmetric
  2312|         0|            0|            0|  0.00%|    in `a` and `b` -- it assumes `b` is the reference value -- so that
  2313|         0|            0|            0|  0.00%|    `isclose(a, b)` might be different from `isclose(b, a)`. Furthermore,
  2314|         0|            0|            0|  0.00%|    the default value of atol is not zero, and is used to determine what
  2315|         0|            0|            0|  0.00%|    small values should be considered close to zero. The default value is
  2316|         0|            0|            0|  0.00%|    appropriate for expected values of order unity: if the expected values
  2317|         0|            0|            0|  0.00%|    are significantly smaller than one, it can result in false positives.
  2318|         0|            0|            0|  0.00%|    `atol` should be carefully selected for the use case at hand. A zero value
  2319|         0|            0|            0|  0.00%|    for `atol` will result in `False` if either `a` or `b` is zero.
  2320|         0|            0|            0|  0.00%|
  2321|         0|            0|            0|  0.00%|    `isclose` is not defined for non-numeric data types.
  2322|         0|            0|            0|  0.00%|
  2323|         0|            0|            0|  0.00%|    Examples
  2324|         0|            0|            0|  0.00%|    --------
  2325|         0|            0|            0|  0.00%|    >>> np.isclose([1e10,1e-7], [1.00001e10,1e-8])
  2326|         0|            0|            0|  0.00%|    array([ True, False])
  2327|         0|            0|            0|  0.00%|    >>> np.isclose([1e10,1e-8], [1.00001e10,1e-9])
  2328|         0|            0|            0|  0.00%|    array([ True, True])
  2329|         0|            0|            0|  0.00%|    >>> np.isclose([1e10,1e-8], [1.0001e10,1e-9])
  2330|         0|            0|            0|  0.00%|    array([False,  True])
  2331|         0|            0|            0|  0.00%|    >>> np.isclose([1.0, np.nan], [1.0, np.nan])
  2332|         0|            0|            0|  0.00%|    array([ True, False])
  2333|         0|            0|            0|  0.00%|    >>> np.isclose([1.0, np.nan], [1.0, np.nan], equal_nan=True)
  2334|         0|            0|            0|  0.00%|    array([ True, True])
  2335|         0|            0|            0|  0.00%|    >>> np.isclose([1e-8, 1e-7], [0.0, 0.0])
  2336|         0|            0|            0|  0.00%|    array([ True, False])
  2337|         0|            0|            0|  0.00%|    >>> np.isclose([1e-100, 1e-7], [0.0, 0.0], atol=0.0)
  2338|         0|            0|            0|  0.00%|    array([False, False])
  2339|         0|            0|            0|  0.00%|    >>> np.isclose([1e-10, 1e-10], [1e-20, 0.0])
  2340|         0|            0|            0|  0.00%|    array([ True,  True])
  2341|         0|            0|            0|  0.00%|    >>> np.isclose([1e-10, 1e-10], [1e-20, 0.999999e-10], atol=0.0)
  2342|         0|            0|            0|  0.00%|    array([False,  True])
  2343|         0|            0|            0|  0.00%|    """
  2344|         2|  6.67572e-06|  3.33786e-06|  0.00%|    def within_tol(x, y, atol, rtol):
  2345|         1|  1.54972e-05|  1.54972e-05|  0.00%|        with errstate(invalid='ignore'):
(call)|         1|  9.77516e-06|  9.77516e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py:429 __init__
(call)|         1|  0.000198603|  0.000198603|  0.02%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py:433 __enter__
  2346|         1|  2.07424e-05|  2.07424e-05|  0.00%|            return less_equal(abs(x-y), atol + rtol * abs(y))
(call)|         1|  6.53267e-05|  6.53267e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_ufunc_config.py:438 __exit__
  2347|         0|            0|            0|  0.00%|
  2348|         1|  1.00136e-05|  1.00136e-05|  0.00%|    x = asanyarray(a)
(call)|         1|  1.07288e-05|  1.07288e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:110 asanyarray
  2349|         1|  7.62939e-06|  7.62939e-06|  0.00%|    y = asanyarray(b)
(call)|         1|  5.96046e-06|  5.96046e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:110 asanyarray
  2350|         0|            0|            0|  0.00%|
  2351|         0|            0|            0|  0.00%|    # Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).
  2352|         0|            0|            0|  0.00%|    # This will cause casting of x later. Also, make sure to allow subclasses
  2353|         0|            0|            0|  0.00%|    # (e.g., for numpy.ma).
  2354|         0|            0|            0|  0.00%|    # NOTE: We explicitly allow timedelta, which used to work. This could
  2355|         0|            0|            0|  0.00%|    #       possibly be deprecated. See also gh-18286.
  2356|         0|            0|            0|  0.00%|    #       timedelta works if `atol` is an integer or also a timedelta.
  2357|         0|            0|            0|  0.00%|    #       Although, the default tolerances are unlikely to be useful
  2358|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if y.dtype.kind != "m":
  2359|         1|  8.82149e-06|  8.82149e-06|  0.00%|        dt = multiarray.result_type(y, 1.)
(call)|         1|  2.90871e-05|  2.90871e-05|  0.00%|# <__array_function__ internals>_2:2 result_type
  2360|         1|  6.19888e-06|  6.19888e-06|  0.00%|        y = array(y, dtype=dt, copy=False, subok=True)
  2361|         0|            0|            0|  0.00%|
  2362|         1|  6.19888e-06|  6.19888e-06|  0.00%|    xfin = isfinite(x)
  2363|         1|  4.29153e-06|  4.29153e-06|  0.00%|    yfin = isfinite(y)
  2364|         1|  1.33514e-05|  1.33514e-05|  0.00%|    if all(xfin) and all(yfin):
(call)|         2|  0.000174522|  8.72612e-05|  0.02%|# <__array_function__ internals>_3:2 all
  2365|         1|  9.53674e-06|  9.53674e-06|  0.00%|        return within_tol(x, y, atol, rtol)
(call)|         1|  0.000312328|  0.000312328|  0.04%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py:2344 within_tol
  2366|         0|            0|            0|  0.00%|    else:
  2367|         0|            0|            0|  0.00%|        finite = xfin & yfin
  2368|         0|            0|            0|  0.00%|        cond = zeros_like(finite, subok=True)
  2369|         0|            0|            0|  0.00%|        # Because we're using boolean indexing, x & y must be the same shape.
  2370|         0|            0|            0|  0.00%|        # Ideally, we'd just do x, y = broadcast_arrays(x, y). It's in
  2371|         0|            0|            0|  0.00%|        # lib.stride_tricks, though, so we can't import it here.
  2372|         0|            0|            0|  0.00%|        x = x * ones_like(cond)
  2373|         0|            0|            0|  0.00%|        y = y * ones_like(cond)
  2374|         0|            0|            0|  0.00%|        # Avoid subtraction with infinite/nan values...
  2375|         0|            0|            0|  0.00%|        cond[finite] = within_tol(x[finite], y[finite], atol, rtol)
  2376|         0|            0|            0|  0.00%|        # Check for equality of infinite values...
  2377|         0|            0|            0|  0.00%|        cond[~finite] = (x[~finite] == y[~finite])
  2378|         0|            0|            0|  0.00%|        if equal_nan:
  2379|         0|            0|            0|  0.00%|            # Make NaN == NaN
  2380|         0|            0|            0|  0.00%|            both_nan = isnan(x) & isnan(y)
  2381|         0|            0|            0|  0.00%|
  2382|         0|            0|            0|  0.00%|            # Needed to treat masked arrays correctly. = True would not work.
  2383|         0|            0|            0|  0.00%|            cond[both_nan] = both_nan[both_nan]
  2384|         0|            0|            0|  0.00%|
  2385|         0|            0|            0|  0.00%|        return cond[()]  # Flatten 0d arrays to scalars
  2386|         0|            0|            0|  0.00%|
  2387|         0|            0|            0|  0.00%|
  2388|         0|            0|            0|  0.00%|def _array_equal_dispatcher(a1, a2, equal_nan=None):
  2389|         0|            0|            0|  0.00%|    return (a1, a2)
  2390|         0|            0|            0|  0.00%|
  2391|         0|            0|            0|  0.00%|
  2392|         0|            0|            0|  0.00%|@array_function_dispatch(_array_equal_dispatcher)
  2393|         0|            0|            0|  0.00%|def array_equal(a1, a2, equal_nan=False):
  2394|         0|            0|            0|  0.00%|    """
  2395|         0|            0|            0|  0.00%|    True if two arrays have the same shape and elements, False otherwise.
  2396|         0|            0|            0|  0.00%|
  2397|         0|            0|            0|  0.00%|    Parameters
  2398|         0|            0|            0|  0.00%|    ----------
  2399|         0|            0|            0|  0.00%|    a1, a2 : array_like
  2400|         0|            0|            0|  0.00%|        Input arrays.
  2401|         0|            0|            0|  0.00%|    equal_nan : bool
  2402|         0|            0|            0|  0.00%|        Whether to compare NaN's as equal. If the dtype of a1 and a2 is
  2403|         0|            0|            0|  0.00%|        complex, values will be considered equal if either the real or the
  2404|         0|            0|            0|  0.00%|        imaginary component of a given value is ``nan``.
  2405|         0|            0|            0|  0.00%|
  2406|         0|            0|            0|  0.00%|        .. versionadded:: 1.19.0
  2407|         0|            0|            0|  0.00%|
  2408|         0|            0|            0|  0.00%|    Returns
  2409|         0|            0|            0|  0.00%|    -------
  2410|         0|            0|            0|  0.00%|    b : bool
  2411|         0|            0|            0|  0.00%|        Returns True if the arrays are equal.
  2412|         0|            0|            0|  0.00%|
  2413|         0|            0|            0|  0.00%|    See Also
  2414|         0|            0|            0|  0.00%|    --------
  2415|         0|            0|            0|  0.00%|    allclose: Returns True if two arrays are element-wise equal within a
  2416|         0|            0|            0|  0.00%|              tolerance.
  2417|         0|            0|            0|  0.00%|    array_equiv: Returns True if input arrays are shape consistent and all
  2418|         0|            0|            0|  0.00%|                 elements equal.
  2419|         0|            0|            0|  0.00%|
  2420|         0|            0|            0|  0.00%|    Examples
  2421|         0|            0|            0|  0.00%|    --------
  2422|         0|            0|            0|  0.00%|    >>> np.array_equal([1, 2], [1, 2])
  2423|         0|            0|            0|  0.00%|    True
  2424|         0|            0|            0|  0.00%|    >>> np.array_equal(np.array([1, 2]), np.array([1, 2]))
  2425|         0|            0|            0|  0.00%|    True
  2426|         0|            0|            0|  0.00%|    >>> np.array_equal([1, 2], [1, 2, 3])
  2427|         0|            0|            0|  0.00%|    False
  2428|         0|            0|            0|  0.00%|    >>> np.array_equal([1, 2], [1, 4])
  2429|         0|            0|            0|  0.00%|    False
  2430|         0|            0|            0|  0.00%|    >>> a = np.array([1, np.nan])
  2431|         0|            0|            0|  0.00%|    >>> np.array_equal(a, a)
  2432|         0|            0|            0|  0.00%|    False
  2433|         0|            0|            0|  0.00%|    >>> np.array_equal(a, a, equal_nan=True)
  2434|         0|            0|            0|  0.00%|    True
  2435|         0|            0|            0|  0.00%|
  2436|         0|            0|            0|  0.00%|    When ``equal_nan`` is True, complex values with nan components are
  2437|         0|            0|            0|  0.00%|    considered equal if either the real *or* the imaginary components are nan.
  2438|         0|            0|            0|  0.00%|
  2439|         0|            0|            0|  0.00%|    >>> a = np.array([1 + 1j])
  2440|         0|            0|            0|  0.00%|    >>> b = a.copy()
  2441|         0|            0|            0|  0.00%|    >>> a.real = np.nan
  2442|         0|            0|            0|  0.00%|    >>> b.imag = np.nan
  2443|         0|            0|            0|  0.00%|    >>> np.array_equal(a, b, equal_nan=True)
  2444|         0|            0|            0|  0.00%|    True
  2445|         0|            0|            0|  0.00%|    """
  2446|         0|            0|            0|  0.00%|    try:
  2447|         0|            0|            0|  0.00%|        a1, a2 = asarray(a1), asarray(a2)
  2448|         0|            0|            0|  0.00%|    except Exception:
  2449|         0|            0|            0|  0.00%|        return False
  2450|         0|            0|            0|  0.00%|    if a1.shape != a2.shape:
  2451|         0|            0|            0|  0.00%|        return False
  2452|         0|            0|            0|  0.00%|    if not equal_nan:
  2453|         0|            0|            0|  0.00%|        return bool(asarray(a1 == a2).all())
  2454|         0|            0|            0|  0.00%|    # Handling NaN values if equal_nan is True
  2455|         0|            0|            0|  0.00%|    a1nan, a2nan = isnan(a1), isnan(a2)
  2456|         0|            0|            0|  0.00%|    # NaN's occur at different locations
  2457|         0|            0|            0|  0.00%|    if not (a1nan == a2nan).all():
  2458|         0|            0|            0|  0.00%|        return False
  2459|         0|            0|            0|  0.00%|    # Shapes of a1, a2 and masks are guaranteed to be consistent by this point
  2460|         0|            0|            0|  0.00%|    return bool(asarray(a1[~a1nan] == a2[~a1nan]).all())
  2461|         0|            0|            0|  0.00%|
  2462|         0|            0|            0|  0.00%|
  2463|         0|            0|            0|  0.00%|def _array_equiv_dispatcher(a1, a2):
  2464|         0|            0|            0|  0.00%|    return (a1, a2)
  2465|         0|            0|            0|  0.00%|
  2466|         0|            0|            0|  0.00%|
  2467|         0|            0|            0|  0.00%|@array_function_dispatch(_array_equiv_dispatcher)
  2468|         0|            0|            0|  0.00%|def array_equiv(a1, a2):
  2469|         0|            0|            0|  0.00%|    """
  2470|         0|            0|            0|  0.00%|    Returns True if input arrays are shape consistent and all elements equal.
  2471|         0|            0|            0|  0.00%|
  2472|         0|            0|            0|  0.00%|    Shape consistent means they are either the same shape, or one input array
  2473|         0|            0|            0|  0.00%|    can be broadcasted to create the same shape as the other one.
  2474|         0|            0|            0|  0.00%|
  2475|         0|            0|            0|  0.00%|    Parameters
  2476|         0|            0|            0|  0.00%|    ----------
  2477|         0|            0|            0|  0.00%|    a1, a2 : array_like
  2478|         0|            0|            0|  0.00%|        Input arrays.
  2479|         0|            0|            0|  0.00%|
  2480|         0|            0|            0|  0.00%|    Returns
  2481|         0|            0|            0|  0.00%|    -------
  2482|         0|            0|            0|  0.00%|    out : bool
  2483|         0|            0|            0|  0.00%|        True if equivalent, False otherwise.
  2484|         0|            0|            0|  0.00%|
  2485|         0|            0|            0|  0.00%|    Examples
  2486|         0|            0|            0|  0.00%|    --------
  2487|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [1, 2])
  2488|         0|            0|            0|  0.00%|    True
  2489|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [1, 3])
  2490|         0|            0|            0|  0.00%|    False
  2491|         0|            0|            0|  0.00%|
  2492|         0|            0|            0|  0.00%|    Showing the shape equivalence:
  2493|         0|            0|            0|  0.00%|
  2494|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [[1, 2], [1, 2]])
  2495|         0|            0|            0|  0.00%|    True
  2496|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [[1, 2, 1, 2], [1, 2, 1, 2]])
  2497|         0|            0|            0|  0.00%|    False
  2498|         0|            0|            0|  0.00%|
  2499|         0|            0|            0|  0.00%|    >>> np.array_equiv([1, 2], [[1, 2], [1, 3]])
  2500|         0|            0|            0|  0.00%|    False
  2501|         0|            0|            0|  0.00%|
  2502|         0|            0|            0|  0.00%|    """
  2503|         0|            0|            0|  0.00%|    try:
  2504|         0|            0|            0|  0.00%|        a1, a2 = asarray(a1), asarray(a2)
  2505|         0|            0|            0|  0.00%|    except Exception:
  2506|         0|            0|            0|  0.00%|        return False
  2507|         0|            0|            0|  0.00%|    try:
  2508|         0|            0|            0|  0.00%|        multiarray.broadcast(a1, a2)
  2509|         0|            0|            0|  0.00%|    except Exception:
  2510|         0|            0|            0|  0.00%|        return False
  2511|         0|            0|            0|  0.00%|
  2512|         0|            0|            0|  0.00%|    return bool(asarray(a1 == a2).all())
  2513|         0|            0|            0|  0.00%|
  2514|         0|            0|            0|  0.00%|
  2515|         0|            0|            0|  0.00%|Inf = inf = infty = Infinity = PINF
  2516|         0|            0|            0|  0.00%|nan = NaN = NAN
  2517|         0|            0|            0|  0.00%|False_ = bool_(False)
  2518|         0|            0|            0|  0.00%|True_ = bool_(True)
  2519|         0|            0|            0|  0.00%|
  2520|         0|            0|            0|  0.00%|
  2521|         0|            0|            0|  0.00%|def extend_all(module):
  2522|         0|            0|            0|  0.00%|    existing = set(__all__)
  2523|         0|            0|            0|  0.00%|    mall = getattr(module, '__all__')
  2524|         0|            0|            0|  0.00%|    for a in mall:
  2525|         0|            0|            0|  0.00%|        if a not in existing:
  2526|         0|            0|            0|  0.00%|            __all__.append(a)
  2527|         0|            0|            0|  0.00%|
  2528|         0|            0|            0|  0.00%|
  2529|         0|            0|            0|  0.00%|from .umath import *
  2530|         0|            0|            0|  0.00%|from .numerictypes import *
  2531|         0|            0|            0|  0.00%|from . import fromnumeric
  2532|         0|            0|            0|  0.00%|from .fromnumeric import *
  2533|         0|            0|            0|  0.00%|from . import arrayprint
  2534|         0|            0|            0|  0.00%|from .arrayprint import *
  2535|         0|            0|            0|  0.00%|from . import _asarray
  2536|         0|            0|            0|  0.00%|from ._asarray import *
  2537|         0|            0|            0|  0.00%|from . import _ufunc_config
  2538|         0|            0|            0|  0.00%|from ._ufunc_config import *
  2539|         0|            0|            0|  0.00%|extend_all(fromnumeric)
  2540|         0|            0|            0|  0.00%|extend_all(umath)
  2541|         0|            0|            0|  0.00%|extend_all(numerictypes)
  2542|         0|            0|            0|  0.00%|extend_all(arrayprint)
  2543|         0|            0|            0|  0.00%|extend_all(_asarray)
  2544|         0|            0|            0|  0.00%|extend_all(_ufunc_config)
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/stride_tricks.py
File duration: 8.15392e-05s (0.01%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Utilities that manipulate strides to achieve desirable effects.
     3|         0|            0|            0|  0.00%|
     4|         0|            0|            0|  0.00%|An explanation of strides can be found in the "ndarray.rst" file in the
     5|         0|            0|            0|  0.00%|NumPy reference guide.
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|"""
     8|         0|            0|            0|  0.00%|import numpy as np
     9|         0|            0|            0|  0.00%|from numpy.core.numeric import normalize_axis_tuple
    10|         0|            0|            0|  0.00%|from numpy.core.overrides import array_function_dispatch, set_module
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|__all__ = ['broadcast_to', 'broadcast_arrays', 'broadcast_shapes']
    13|         0|            0|            0|  0.00%|
    14|         0|            0|            0|  0.00%|
    15|         0|            0|            0|  0.00%|class DummyArray:
    16|         0|            0|            0|  0.00%|    """Dummy object that just exists to hang __array_interface__ dictionaries
    17|         0|            0|            0|  0.00%|    and possibly keep alive a reference to a base array.
    18|         0|            0|            0|  0.00%|    """
    19|         0|            0|            0|  0.00%|
    20|         1|  2.14577e-06|  2.14577e-06|  0.00%|    def __init__(self, interface, base=None):
    21|         1|   2.6226e-06|   2.6226e-06|  0.00%|        self.__array_interface__ = interface
    22|         1|  2.38419e-06|  2.38419e-06|  0.00%|        self.base = base
    23|         0|            0|            0|  0.00%|
    24|         0|            0|            0|  0.00%|
    25|         1|   2.6226e-06|   2.6226e-06|  0.00%|def _maybe_view_as_subclass(original_array, new_array):
    26|         1|   2.6226e-06|   2.6226e-06|  0.00%|    if type(original_array) is not type(new_array):
    27|         0|            0|            0|  0.00%|        # if input was an ndarray subclass and subclasses were OK,
    28|         0|            0|            0|  0.00%|        # then view the result as that subclass.
    29|         0|            0|            0|  0.00%|        new_array = new_array.view(type=type(original_array))
    30|         0|            0|            0|  0.00%|        # Since we have done something akin to a view from original_array, we
    31|         0|            0|            0|  0.00%|        # should let the subclass finalize (if it has it implemented, i.e., is
    32|         0|            0|            0|  0.00%|        # not None).
    33|         0|            0|            0|  0.00%|        if new_array.__array_finalize__:
    34|         0|            0|            0|  0.00%|            new_array.__array_finalize__(original_array)
    35|         1|  1.66893e-06|  1.66893e-06|  0.00%|    return new_array
    36|         0|            0|            0|  0.00%|
    37|         0|            0|            0|  0.00%|
    38|         1|  4.05312e-06|  4.05312e-06|  0.00%|def as_strided(x, shape=None, strides=None, subok=False, writeable=True):
    39|         0|            0|            0|  0.00%|    """
    40|         0|            0|            0|  0.00%|    Create a view into the array with the given shape and strides.
    41|         0|            0|            0|  0.00%|
    42|         0|            0|            0|  0.00%|    .. warning:: This function has to be used with extreme care, see notes.
    43|         0|            0|            0|  0.00%|
    44|         0|            0|            0|  0.00%|    Parameters
    45|         0|            0|            0|  0.00%|    ----------
    46|         0|            0|            0|  0.00%|    x : ndarray
    47|         0|            0|            0|  0.00%|        Array to create a new.
    48|         0|            0|            0|  0.00%|    shape : sequence of int, optional
    49|         0|            0|            0|  0.00%|        The shape of the new array. Defaults to ``x.shape``.
    50|         0|            0|            0|  0.00%|    strides : sequence of int, optional
    51|         0|            0|            0|  0.00%|        The strides of the new array. Defaults to ``x.strides``.
    52|         0|            0|            0|  0.00%|    subok : bool, optional
    53|         0|            0|            0|  0.00%|        .. versionadded:: 1.10
    54|         0|            0|            0|  0.00%|
    55|         0|            0|            0|  0.00%|        If True, subclasses are preserved.
    56|         0|            0|            0|  0.00%|    writeable : bool, optional
    57|         0|            0|            0|  0.00%|        .. versionadded:: 1.12
    58|         0|            0|            0|  0.00%|
    59|         0|            0|            0|  0.00%|        If set to False, the returned array will always be readonly.
    60|         0|            0|            0|  0.00%|        Otherwise it will be writable if the original array was. It
    61|         0|            0|            0|  0.00%|        is advisable to set this to False if possible (see Notes).
    62|         0|            0|            0|  0.00%|
    63|         0|            0|            0|  0.00%|    Returns
    64|         0|            0|            0|  0.00%|    -------
    65|         0|            0|            0|  0.00%|    view : ndarray
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|    See also
    68|         0|            0|            0|  0.00%|    --------
    69|         0|            0|            0|  0.00%|    broadcast_to : broadcast an array to a given shape.
    70|         0|            0|            0|  0.00%|    reshape : reshape an array.
    71|         0|            0|            0|  0.00%|    lib.stride_tricks.sliding_window_view :
    72|         0|            0|            0|  0.00%|        userfriendly and safe function for the creation of sliding window views.
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|    Notes
    75|         0|            0|            0|  0.00%|    -----
    76|         0|            0|            0|  0.00%|    ``as_strided`` creates a view into the array given the exact strides
    77|         0|            0|            0|  0.00%|    and shape. This means it manipulates the internal data structure of
    78|         0|            0|            0|  0.00%|    ndarray and, if done incorrectly, the array elements can point to
    79|         0|            0|            0|  0.00%|    invalid memory and can corrupt results or crash your program.
    80|         0|            0|            0|  0.00%|    It is advisable to always use the original ``x.strides`` when
    81|         0|            0|            0|  0.00%|    calculating new strides to avoid reliance on a contiguous memory
    82|         0|            0|            0|  0.00%|    layout.
    83|         0|            0|            0|  0.00%|
    84|         0|            0|            0|  0.00%|    Furthermore, arrays created with this function often contain self
    85|         0|            0|            0|  0.00%|    overlapping memory, so that two elements are identical.
    86|         0|            0|            0|  0.00%|    Vectorized write operations on such arrays will typically be
    87|         0|            0|            0|  0.00%|    unpredictable. They may even give different results for small, large,
    88|         0|            0|            0|  0.00%|    or transposed arrays.
    89|         0|            0|            0|  0.00%|    Since writing to these arrays has to be tested and done with great
    90|         0|            0|            0|  0.00%|    care, you may want to use ``writeable=False`` to avoid accidental write
    91|         0|            0|            0|  0.00%|    operations.
    92|         0|            0|            0|  0.00%|
    93|         0|            0|            0|  0.00%|    For these reasons it is advisable to avoid ``as_strided`` when
    94|         0|            0|            0|  0.00%|    possible.
    95|         0|            0|            0|  0.00%|    """
    96|         0|            0|            0|  0.00%|    # first convert input to array, possibly keeping subclass
    97|         1|   6.4373e-06|   6.4373e-06|  0.00%|    x = np.array(x, copy=False, subok=subok)
    98|         1|  1.09673e-05|  1.09673e-05|  0.00%|    interface = dict(x.__array_interface__)
    99|         1|   2.6226e-06|   2.6226e-06|  0.00%|    if shape is not None:
   100|         1|  2.38419e-06|  2.38419e-06|  0.00%|        interface['shape'] = tuple(shape)
   101|         1|  2.38419e-06|  2.38419e-06|  0.00%|    if strides is not None:
   102|         1|  4.52995e-06|  4.52995e-06|  0.00%|        interface['strides'] = tuple(strides)
   103|         0|            0|            0|  0.00%|
   104|         1|  1.74046e-05|  1.74046e-05|  0.00%|    array = np.asarray(DummyArray(interface, base=x))
(call)|         1|  7.15256e-06|  7.15256e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/stride_tricks.py:20 __init__
(call)|         1|  1.38283e-05|  1.38283e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/_asarray.py:23 asarray
   105|         0|            0|            0|  0.00%|    # The route via `__interface__` does not preserve structured
   106|         0|            0|            0|  0.00%|    # dtypes. Since dtype should remain unchanged, we set it explicitly.
   107|         1|   3.8147e-06|   3.8147e-06|  0.00%|    array.dtype = x.dtype
   108|         0|            0|            0|  0.00%|
   109|         1|  7.15256e-06|  7.15256e-06|  0.00%|    view = _maybe_view_as_subclass(x, array)
(call)|         1|  6.91414e-06|  6.91414e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/stride_tricks.py:25 _maybe_view_as_subclass
   110|         0|            0|            0|  0.00%|
   111|         1|  3.57628e-06|  3.57628e-06|  0.00%|    if view.flags.writeable and not writeable:
   112|         0|            0|            0|  0.00%|        view.flags.writeable = False
   113|         0|            0|            0|  0.00%|
   114|         1|  2.14577e-06|  2.14577e-06|  0.00%|    return view
   115|         0|            0|            0|  0.00%|
   116|         0|            0|            0|  0.00%|
   117|         0|            0|            0|  0.00%|def _sliding_window_view_dispatcher(x, window_shape, axis=None, *,
   118|         0|            0|            0|  0.00%|                                    subok=None, writeable=None):
   119|         0|            0|            0|  0.00%|    return (x,)
   120|         0|            0|            0|  0.00%|
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|@array_function_dispatch(_sliding_window_view_dispatcher)
   123|         0|            0|            0|  0.00%|def sliding_window_view(x, window_shape, axis=None, *,
   124|         0|            0|            0|  0.00%|                        subok=False, writeable=False):
   125|         0|            0|            0|  0.00%|    """
   126|         0|            0|            0|  0.00%|    Create a sliding window view into the array with the given window shape.
   127|         0|            0|            0|  0.00%|
   128|         0|            0|            0|  0.00%|    Also known as rolling or moving window, the window slides across all
   129|         0|            0|            0|  0.00%|    dimensions of the array and extracts subsets of the array at all window
   130|         0|            0|            0|  0.00%|    positions.
   131|         0|            0|            0|  0.00%|
   132|         0|            0|            0|  0.00%|    .. versionadded:: 1.20.0
   133|         0|            0|            0|  0.00%|
   134|         0|            0|            0|  0.00%|    Parameters
   135|         0|            0|            0|  0.00%|    ----------
   136|         0|            0|            0|  0.00%|    x : array_like
   137|         0|            0|            0|  0.00%|        Array to create the sliding window view from.
   138|         0|            0|            0|  0.00%|    window_shape : int or tuple of int
   139|         0|            0|            0|  0.00%|        Size of window over each axis that takes part in the sliding window.
   140|         0|            0|            0|  0.00%|        If `axis` is not present, must have same length as the number of input
   141|         0|            0|            0|  0.00%|        array dimensions. Single integers `i` are treated as if they were the
   142|         0|            0|            0|  0.00%|        tuple `(i,)`.
   143|         0|            0|            0|  0.00%|    axis : int or tuple of int, optional
   144|         0|            0|            0|  0.00%|        Axis or axes along which the sliding window is applied.
   145|         0|            0|            0|  0.00%|        By default, the sliding window is applied to all axes and
   146|         0|            0|            0|  0.00%|        `window_shape[i]` will refer to axis `i` of `x`.
   147|         0|            0|            0|  0.00%|        If `axis` is given as a `tuple of int`, `window_shape[i]` will refer to
   148|         0|            0|            0|  0.00%|        the axis `axis[i]` of `x`.
   149|         0|            0|            0|  0.00%|        Single integers `i` are treated as if they were the tuple `(i,)`.
   150|         0|            0|            0|  0.00%|    subok : bool, optional
   151|         0|            0|            0|  0.00%|        If True, sub-classes will be passed-through, otherwise the returned
   152|         0|            0|            0|  0.00%|        array will be forced to be a base-class array (default).
   153|         0|            0|            0|  0.00%|    writeable : bool, optional
   154|         0|            0|            0|  0.00%|        When true, allow writing to the returned view. The default is false,
   155|         0|            0|            0|  0.00%|        as this should be used with caution: the returned view contains the
   156|         0|            0|            0|  0.00%|        same memory location multiple times, so writing to one location will
   157|         0|            0|            0|  0.00%|        cause others to change.
   158|         0|            0|            0|  0.00%|
   159|         0|            0|            0|  0.00%|    Returns
   160|         0|            0|            0|  0.00%|    -------
   161|         0|            0|            0|  0.00%|    view : ndarray
   162|         0|            0|            0|  0.00%|        Sliding window view of the array. The sliding window dimensions are
   163|         0|            0|            0|  0.00%|        inserted at the end, and the original dimensions are trimmed as
   164|         0|            0|            0|  0.00%|        required by the size of the sliding window.
   165|         0|            0|            0|  0.00%|        That is, ``view.shape = x_shape_trimmed + window_shape``, where
   166|         0|            0|            0|  0.00%|        ``x_shape_trimmed`` is ``x.shape`` with every entry reduced by one less
   167|         0|            0|            0|  0.00%|        than the corresponding window size.
   168|         0|            0|            0|  0.00%|
   169|         0|            0|            0|  0.00%|    See Also
   170|         0|            0|            0|  0.00%|    --------
   171|         0|            0|            0|  0.00%|    lib.stride_tricks.as_strided: A lower-level and less safe routine for
   172|         0|            0|            0|  0.00%|        creating arbitrary views from custom shape and strides.
   173|         0|            0|            0|  0.00%|    broadcast_to: broadcast an array to a given shape.
   174|         0|            0|            0|  0.00%|
   175|         0|            0|            0|  0.00%|    Notes
   176|         0|            0|            0|  0.00%|    -----
   177|         0|            0|            0|  0.00%|    For many applications using a sliding window view can be convenient, but
   178|         0|            0|            0|  0.00%|    potentially very slow. Often specialized solutions exist, for example:
   179|         0|            0|            0|  0.00%|
   180|         0|            0|            0|  0.00%|    - `scipy.signal.fftconvolve`
   181|         0|            0|            0|  0.00%|
   182|         0|            0|            0|  0.00%|    - filtering functions in `scipy.ndimage`
   183|         0|            0|            0|  0.00%|
   184|         0|            0|            0|  0.00%|    - moving window functions provided by
   185|         0|            0|            0|  0.00%|      `bottleneck <https://github.com/pydata/bottleneck>`_.
   186|         0|            0|            0|  0.00%|
   187|         0|            0|            0|  0.00%|    As a rough estimate, a sliding window approach with an input size of `N`
   188|         0|            0|            0|  0.00%|    and a window size of `W` will scale as `O(N*W)` where frequently a special
   189|         0|            0|            0|  0.00%|    algorithm can achieve `O(N)`. That means that the sliding window variant
   190|         0|            0|            0|  0.00%|    for a window size of 100 can be a 100 times slower than a more specialized
   191|         0|            0|            0|  0.00%|    version.
   192|         0|            0|            0|  0.00%|
   193|         0|            0|            0|  0.00%|    Nevertheless, for small window sizes, when no custom algorithm exists, or
   194|         0|            0|            0|  0.00%|    as a prototyping and developing tool, this function can be a good solution.
   195|         0|            0|            0|  0.00%|
   196|         0|            0|            0|  0.00%|    Examples
   197|         0|            0|            0|  0.00%|    --------
   198|         0|            0|            0|  0.00%|    >>> x = np.arange(6)
   199|         0|            0|            0|  0.00%|    >>> x.shape
   200|         0|            0|            0|  0.00%|    (6,)
   201|         0|            0|            0|  0.00%|    >>> v = sliding_window_view(x, 3)
   202|         0|            0|            0|  0.00%|    >>> v.shape
   203|         0|            0|            0|  0.00%|    (4, 3)
   204|         0|            0|            0|  0.00%|    >>> v
   205|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   206|         0|            0|            0|  0.00%|           [1, 2, 3],
   207|         0|            0|            0|  0.00%|           [2, 3, 4],
   208|         0|            0|            0|  0.00%|           [3, 4, 5]])
   209|         0|            0|            0|  0.00%|
   210|         0|            0|            0|  0.00%|    This also works in more dimensions, e.g.
   211|         0|            0|            0|  0.00%|
   212|         0|            0|            0|  0.00%|    >>> i, j = np.ogrid[:3, :4]
   213|         0|            0|            0|  0.00%|    >>> x = 10*i + j
   214|         0|            0|            0|  0.00%|    >>> x.shape
   215|         0|            0|            0|  0.00%|    (3, 4)
   216|         0|            0|            0|  0.00%|    >>> x
   217|         0|            0|            0|  0.00%|    array([[ 0,  1,  2,  3],
   218|         0|            0|            0|  0.00%|           [10, 11, 12, 13],
   219|         0|            0|            0|  0.00%|           [20, 21, 22, 23]])
   220|         0|            0|            0|  0.00%|    >>> shape = (2,2)
   221|         0|            0|            0|  0.00%|    >>> v = sliding_window_view(x, shape)
   222|         0|            0|            0|  0.00%|    >>> v.shape
   223|         0|            0|            0|  0.00%|    (2, 3, 2, 2)
   224|         0|            0|            0|  0.00%|    >>> v
   225|         0|            0|            0|  0.00%|    array([[[[ 0,  1],
   226|         0|            0|            0|  0.00%|             [10, 11]],
   227|         0|            0|            0|  0.00%|            [[ 1,  2],
   228|         0|            0|            0|  0.00%|             [11, 12]],
   229|         0|            0|            0|  0.00%|            [[ 2,  3],
   230|         0|            0|            0|  0.00%|             [12, 13]]],
   231|         0|            0|            0|  0.00%|           [[[10, 11],
   232|         0|            0|            0|  0.00%|             [20, 21]],
   233|         0|            0|            0|  0.00%|            [[11, 12],
   234|         0|            0|            0|  0.00%|             [21, 22]],
   235|         0|            0|            0|  0.00%|            [[12, 13],
   236|         0|            0|            0|  0.00%|             [22, 23]]]])
   237|         0|            0|            0|  0.00%|
   238|         0|            0|            0|  0.00%|    The axis can be specified explicitly:
   239|         0|            0|            0|  0.00%|
   240|         0|            0|            0|  0.00%|    >>> v = sliding_window_view(x, 3, 0)
   241|         0|            0|            0|  0.00%|    >>> v.shape
   242|         0|            0|            0|  0.00%|    (1, 4, 3)
   243|         0|            0|            0|  0.00%|    >>> v
   244|         0|            0|            0|  0.00%|    array([[[ 0, 10, 20],
   245|         0|            0|            0|  0.00%|            [ 1, 11, 21],
   246|         0|            0|            0|  0.00%|            [ 2, 12, 22],
   247|         0|            0|            0|  0.00%|            [ 3, 13, 23]]])
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|    The same axis can be used several times. In that case, every use reduces
   250|         0|            0|            0|  0.00%|    the corresponding original dimension:
   251|         0|            0|            0|  0.00%|
   252|         0|            0|            0|  0.00%|    >>> v = sliding_window_view(x, (2, 3), (1, 1))
   253|         0|            0|            0|  0.00%|    >>> v.shape
   254|         0|            0|            0|  0.00%|    (3, 1, 2, 3)
   255|         0|            0|            0|  0.00%|    >>> v
   256|         0|            0|            0|  0.00%|    array([[[[ 0,  1,  2],
   257|         0|            0|            0|  0.00%|             [ 1,  2,  3]]],
   258|         0|            0|            0|  0.00%|           [[[10, 11, 12],
   259|         0|            0|            0|  0.00%|             [11, 12, 13]]],
   260|         0|            0|            0|  0.00%|           [[[20, 21, 22],
   261|         0|            0|            0|  0.00%|             [21, 22, 23]]]])
   262|         0|            0|            0|  0.00%|
   263|         0|            0|            0|  0.00%|    Combining with stepped slicing (`::step`), this can be used to take sliding
   264|         0|            0|            0|  0.00%|    views which skip elements:
   265|         0|            0|            0|  0.00%|
   266|         0|            0|            0|  0.00%|    >>> x = np.arange(7)
   267|         0|            0|            0|  0.00%|    >>> sliding_window_view(x, 5)[:, ::2]
   268|         0|            0|            0|  0.00%|    array([[0, 2, 4],
   269|         0|            0|            0|  0.00%|           [1, 3, 5],
   270|         0|            0|            0|  0.00%|           [2, 4, 6]])
   271|         0|            0|            0|  0.00%|
   272|         0|            0|            0|  0.00%|    or views which move by multiple elements
   273|         0|            0|            0|  0.00%|
   274|         0|            0|            0|  0.00%|    >>> x = np.arange(7)
   275|         0|            0|            0|  0.00%|    >>> sliding_window_view(x, 3)[::2, :]
   276|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   277|         0|            0|            0|  0.00%|           [2, 3, 4],
   278|         0|            0|            0|  0.00%|           [4, 5, 6]])
   279|         0|            0|            0|  0.00%|
   280|         0|            0|            0|  0.00%|    A common application of `sliding_window_view` is the calculation of running
   281|         0|            0|            0|  0.00%|    statistics. The simplest example is the
   282|         0|            0|            0|  0.00%|    `moving average <https://en.wikipedia.org/wiki/Moving_average>`_:
   283|         0|            0|            0|  0.00%|
   284|         0|            0|            0|  0.00%|    >>> x = np.arange(6)
   285|         0|            0|            0|  0.00%|    >>> x.shape
   286|         0|            0|            0|  0.00%|    (6,)
   287|         0|            0|            0|  0.00%|    >>> v = sliding_window_view(x, 3)
   288|         0|            0|            0|  0.00%|    >>> v.shape
   289|         0|            0|            0|  0.00%|    (4, 3)
   290|         0|            0|            0|  0.00%|    >>> v
   291|         0|            0|            0|  0.00%|    array([[0, 1, 2],
   292|         0|            0|            0|  0.00%|           [1, 2, 3],
   293|         0|            0|            0|  0.00%|           [2, 3, 4],
   294|         0|            0|            0|  0.00%|           [3, 4, 5]])
   295|         0|            0|            0|  0.00%|    >>> moving_average = v.mean(axis=-1)
   296|         0|            0|            0|  0.00%|    >>> moving_average
   297|         0|            0|            0|  0.00%|    array([1., 2., 3., 4.])
   298|         0|            0|            0|  0.00%|
   299|         0|            0|            0|  0.00%|    Note that a sliding window approach is often **not** optimal (see Notes).
   300|         0|            0|            0|  0.00%|    """
   301|         0|            0|            0|  0.00%|    window_shape = (tuple(window_shape)
   302|         0|            0|            0|  0.00%|                    if np.iterable(window_shape)
   303|         0|            0|            0|  0.00%|                    else (window_shape,))
   304|         0|            0|            0|  0.00%|    # first convert input to array, possibly keeping subclass
   305|         0|            0|            0|  0.00%|    x = np.array(x, copy=False, subok=subok)
   306|         0|            0|            0|  0.00%|
   307|         0|            0|            0|  0.00%|    window_shape_array = np.array(window_shape)
   308|         0|            0|            0|  0.00%|    if np.any(window_shape_array < 0):
   309|         0|            0|            0|  0.00%|        raise ValueError('`window_shape` cannot contain negative values')
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|    if axis is None:
   312|         0|            0|            0|  0.00%|        axis = tuple(range(x.ndim))
   313|         0|            0|            0|  0.00%|        if len(window_shape) != len(axis):
   314|         0|            0|            0|  0.00%|            raise ValueError(f'Since axis is `None`, must provide '
   315|         0|            0|            0|  0.00%|                             f'window_shape for all dimensions of `x`; '
   316|         0|            0|            0|  0.00%|                             f'got {len(window_shape)} window_shape elements '
   317|         0|            0|            0|  0.00%|                             f'and `x.ndim` is {x.ndim}.')
   318|         0|            0|            0|  0.00%|    else:
   319|         0|            0|            0|  0.00%|        axis = normalize_axis_tuple(axis, x.ndim, allow_duplicate=True)
   320|         0|            0|            0|  0.00%|        if len(window_shape) != len(axis):
   321|         0|            0|            0|  0.00%|            raise ValueError(f'Must provide matching length window_shape and '
   322|         0|            0|            0|  0.00%|                             f'axis; got {len(window_shape)} window_shape '
   323|         0|            0|            0|  0.00%|                             f'elements and {len(axis)} axes elements.')
   324|         0|            0|            0|  0.00%|
   325|         0|            0|            0|  0.00%|    out_strides = x.strides + tuple(x.strides[ax] for ax in axis)
   326|         0|            0|            0|  0.00%|
   327|         0|            0|            0|  0.00%|    # note: same axis can be windowed repeatedly
   328|         0|            0|            0|  0.00%|    x_shape_trimmed = list(x.shape)
   329|         0|            0|            0|  0.00%|    for ax, dim in zip(axis, window_shape):
   330|         0|            0|            0|  0.00%|        if x_shape_trimmed[ax] < dim:
   331|         0|            0|            0|  0.00%|            raise ValueError(
   332|         0|            0|            0|  0.00%|                'window shape cannot be larger than input array shape')
   333|         0|            0|            0|  0.00%|        x_shape_trimmed[ax] -= dim - 1
   334|         0|            0|            0|  0.00%|    out_shape = tuple(x_shape_trimmed) + window_shape
   335|         0|            0|            0|  0.00%|    return as_strided(x, strides=out_strides, shape=out_shape,
   336|         0|            0|            0|  0.00%|                      subok=subok, writeable=writeable)
   337|         0|            0|            0|  0.00%|
   338|         0|            0|            0|  0.00%|
   339|         0|            0|            0|  0.00%|def _broadcast_to(array, shape, subok, readonly):
   340|         0|            0|            0|  0.00%|    shape = tuple(shape) if np.iterable(shape) else (shape,)
   341|         0|            0|            0|  0.00%|    array = np.array(array, copy=False, subok=subok)
   342|         0|            0|            0|  0.00%|    if not shape and array.shape:
   343|         0|            0|            0|  0.00%|        raise ValueError('cannot broadcast a non-scalar to a scalar array')
   344|         0|            0|            0|  0.00%|    if any(size < 0 for size in shape):
   345|         0|            0|            0|  0.00%|        raise ValueError('all elements of broadcast shape must be non-'
   346|         0|            0|            0|  0.00%|                         'negative')
   347|         0|            0|            0|  0.00%|    extras = []
   348|         0|            0|            0|  0.00%|    it = np.nditer(
   349|         0|            0|            0|  0.00%|        (array,), flags=['multi_index', 'refs_ok', 'zerosize_ok'] + extras,
   350|         0|            0|            0|  0.00%|        op_flags=['readonly'], itershape=shape, order='C')
   351|         0|            0|            0|  0.00%|    with it:
   352|         0|            0|            0|  0.00%|        # never really has writebackifcopy semantics
   353|         0|            0|            0|  0.00%|        broadcast = it.itviews[0]
   354|         0|            0|            0|  0.00%|    result = _maybe_view_as_subclass(array, broadcast)
   355|         0|            0|            0|  0.00%|    # In a future version this will go away
   356|         0|            0|            0|  0.00%|    if not readonly and array.flags._writeable_no_warn:
   357|         0|            0|            0|  0.00%|        result.flags.writeable = True
   358|         0|            0|            0|  0.00%|        result.flags._warn_on_write = True
   359|         0|            0|            0|  0.00%|    return result
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|
   362|         0|            0|            0|  0.00%|def _broadcast_to_dispatcher(array, shape, subok=None):
   363|         0|            0|            0|  0.00%|    return (array,)
   364|         0|            0|            0|  0.00%|
   365|         0|            0|            0|  0.00%|
   366|         0|            0|            0|  0.00%|@array_function_dispatch(_broadcast_to_dispatcher, module='numpy')
   367|         0|            0|            0|  0.00%|def broadcast_to(array, shape, subok=False):
   368|         0|            0|            0|  0.00%|    """Broadcast an array to a new shape.
   369|         0|            0|            0|  0.00%|
   370|         0|            0|            0|  0.00%|    Parameters
   371|         0|            0|            0|  0.00%|    ----------
   372|         0|            0|            0|  0.00%|    array : array_like
   373|         0|            0|            0|  0.00%|        The array to broadcast.
   374|         0|            0|            0|  0.00%|    shape : tuple
   375|         0|            0|            0|  0.00%|        The shape of the desired array.
   376|         0|            0|            0|  0.00%|    subok : bool, optional
   377|         0|            0|            0|  0.00%|        If True, then sub-classes will be passed-through, otherwise
   378|         0|            0|            0|  0.00%|        the returned array will be forced to be a base-class array (default).
   379|         0|            0|            0|  0.00%|
   380|         0|            0|            0|  0.00%|    Returns
   381|         0|            0|            0|  0.00%|    -------
   382|         0|            0|            0|  0.00%|    broadcast : array
   383|         0|            0|            0|  0.00%|        A readonly view on the original array with the given shape. It is
   384|         0|            0|            0|  0.00%|        typically not contiguous. Furthermore, more than one element of a
   385|         0|            0|            0|  0.00%|        broadcasted array may refer to a single memory location.
   386|         0|            0|            0|  0.00%|
   387|         0|            0|            0|  0.00%|    Raises
   388|         0|            0|            0|  0.00%|    ------
   389|         0|            0|            0|  0.00%|    ValueError
   390|         0|            0|            0|  0.00%|        If the array is not compatible with the new shape according to NumPy's
   391|         0|            0|            0|  0.00%|        broadcasting rules.
   392|         0|            0|            0|  0.00%|
   393|         0|            0|            0|  0.00%|    See Also
   394|         0|            0|            0|  0.00%|    --------
   395|         0|            0|            0|  0.00%|    broadcast
   396|         0|            0|            0|  0.00%|    broadcast_arrays
   397|         0|            0|            0|  0.00%|    broadcast_shapes
   398|         0|            0|            0|  0.00%|
   399|         0|            0|            0|  0.00%|    Notes
   400|         0|            0|            0|  0.00%|    -----
   401|         0|            0|            0|  0.00%|    .. versionadded:: 1.10.0
   402|         0|            0|            0|  0.00%|
   403|         0|            0|            0|  0.00%|    Examples
   404|         0|            0|            0|  0.00%|    --------
   405|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3])
   406|         0|            0|            0|  0.00%|    >>> np.broadcast_to(x, (3, 3))
   407|         0|            0|            0|  0.00%|    array([[1, 2, 3],
   408|         0|            0|            0|  0.00%|           [1, 2, 3],
   409|         0|            0|            0|  0.00%|           [1, 2, 3]])
   410|         0|            0|            0|  0.00%|    """
   411|         0|            0|            0|  0.00%|    return _broadcast_to(array, shape, subok=subok, readonly=True)
   412|         0|            0|            0|  0.00%|
   413|         0|            0|            0|  0.00%|
   414|         0|            0|            0|  0.00%|def _broadcast_shape(*args):
   415|         0|            0|            0|  0.00%|    """Returns the shape of the arrays that would result from broadcasting the
   416|         0|            0|            0|  0.00%|    supplied arrays against each other.
   417|         0|            0|            0|  0.00%|    """
   418|         0|            0|            0|  0.00%|    # use the old-iterator because np.nditer does not handle size 0 arrays
   419|         0|            0|            0|  0.00%|    # consistently
   420|         0|            0|            0|  0.00%|    b = np.broadcast(*args[:32])
   421|         0|            0|            0|  0.00%|    # unfortunately, it cannot handle 32 or more arguments directly
   422|         0|            0|            0|  0.00%|    for pos in range(32, len(args), 31):
   423|         0|            0|            0|  0.00%|        # ironically, np.broadcast does not properly handle np.broadcast
   424|         0|            0|            0|  0.00%|        # objects (it treats them as scalars)
   425|         0|            0|            0|  0.00%|        # use broadcasting to avoid allocating the full array
   426|         0|            0|            0|  0.00%|        b = broadcast_to(0, b.shape)
   427|         0|            0|            0|  0.00%|        b = np.broadcast(b, *args[pos:(pos + 31)])
   428|         0|            0|            0|  0.00%|    return b.shape
   429|         0|            0|            0|  0.00%|
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|@set_module('numpy')
   432|         0|            0|            0|  0.00%|def broadcast_shapes(*args):
   433|         0|            0|            0|  0.00%|    """
   434|         0|            0|            0|  0.00%|    Broadcast the input shapes into a single shape.
   435|         0|            0|            0|  0.00%|
   436|         0|            0|            0|  0.00%|    :ref:`Learn more about broadcasting here <basics.broadcasting>`.
   437|         0|            0|            0|  0.00%|
   438|         0|            0|            0|  0.00%|    .. versionadded:: 1.20.0
   439|         0|            0|            0|  0.00%|
   440|         0|            0|            0|  0.00%|    Parameters
   441|         0|            0|            0|  0.00%|    ----------
   442|         0|            0|            0|  0.00%|    `*args` : tuples of ints, or ints
   443|         0|            0|            0|  0.00%|        The shapes to be broadcast against each other.
   444|         0|            0|            0|  0.00%|
   445|         0|            0|            0|  0.00%|    Returns
   446|         0|            0|            0|  0.00%|    -------
   447|         0|            0|            0|  0.00%|    tuple
   448|         0|            0|            0|  0.00%|        Broadcasted shape.
   449|         0|            0|            0|  0.00%|
   450|         0|            0|            0|  0.00%|    Raises
   451|         0|            0|            0|  0.00%|    ------
   452|         0|            0|            0|  0.00%|    ValueError
   453|         0|            0|            0|  0.00%|        If the shapes are not compatible and cannot be broadcast according
   454|         0|            0|            0|  0.00%|        to NumPy's broadcasting rules.
   455|         0|            0|            0|  0.00%|
   456|         0|            0|            0|  0.00%|    See Also
   457|         0|            0|            0|  0.00%|    --------
   458|         0|            0|            0|  0.00%|    broadcast
   459|         0|            0|            0|  0.00%|    broadcast_arrays
   460|         0|            0|            0|  0.00%|    broadcast_to
   461|         0|            0|            0|  0.00%|
   462|         0|            0|            0|  0.00%|    Examples
   463|         0|            0|            0|  0.00%|    --------
   464|         0|            0|            0|  0.00%|    >>> np.broadcast_shapes((1, 2), (3, 1), (3, 2))
   465|         0|            0|            0|  0.00%|    (3, 2)
   466|         0|            0|            0|  0.00%|
   467|         0|            0|            0|  0.00%|    >>> np.broadcast_shapes((6, 7), (5, 6, 1), (7,), (5, 1, 7))
   468|         0|            0|            0|  0.00%|    (5, 6, 7)
   469|         0|            0|            0|  0.00%|    """
   470|         0|            0|            0|  0.00%|    arrays = [np.empty(x, dtype=[]) for x in args]
   471|         0|            0|            0|  0.00%|    return _broadcast_shape(*arrays)
   472|         0|            0|            0|  0.00%|
   473|         0|            0|            0|  0.00%|
   474|         0|            0|            0|  0.00%|def _broadcast_arrays_dispatcher(*args, subok=None):
   475|         0|            0|            0|  0.00%|    return args
   476|         0|            0|            0|  0.00%|
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|@array_function_dispatch(_broadcast_arrays_dispatcher, module='numpy')
   479|         0|            0|            0|  0.00%|def broadcast_arrays(*args, subok=False):
   480|         0|            0|            0|  0.00%|    """
   481|         0|            0|            0|  0.00%|    Broadcast any number of arrays against each other.
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|    Parameters
   484|         0|            0|            0|  0.00%|    ----------
   485|         0|            0|            0|  0.00%|    `*args` : array_likes
   486|         0|            0|            0|  0.00%|        The arrays to broadcast.
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    subok : bool, optional
   489|         0|            0|            0|  0.00%|        If True, then sub-classes will be passed-through, otherwise
   490|         0|            0|            0|  0.00%|        the returned arrays will be forced to be a base-class array (default).
   491|         0|            0|            0|  0.00%|
   492|         0|            0|            0|  0.00%|    Returns
   493|         0|            0|            0|  0.00%|    -------
   494|         0|            0|            0|  0.00%|    broadcasted : list of arrays
   495|         0|            0|            0|  0.00%|        These arrays are views on the original arrays.  They are typically
   496|         0|            0|            0|  0.00%|        not contiguous.  Furthermore, more than one element of a
   497|         0|            0|            0|  0.00%|        broadcasted array may refer to a single memory location. If you need
   498|         0|            0|            0|  0.00%|        to write to the arrays, make copies first. While you can set the
   499|         0|            0|            0|  0.00%|        ``writable`` flag True, writing to a single output value may end up
   500|         0|            0|            0|  0.00%|        changing more than one location in the output array.
   501|         0|            0|            0|  0.00%|
   502|         0|            0|            0|  0.00%|        .. deprecated:: 1.17
   503|         0|            0|            0|  0.00%|            The output is currently marked so that if written to, a deprecation
   504|         0|            0|            0|  0.00%|            warning will be emitted. A future version will set the
   505|         0|            0|            0|  0.00%|            ``writable`` flag False so writing to it will raise an error.
   506|         0|            0|            0|  0.00%|
   507|         0|            0|            0|  0.00%|    See Also
   508|         0|            0|            0|  0.00%|    --------
   509|         0|            0|            0|  0.00%|    broadcast
   510|         0|            0|            0|  0.00%|    broadcast_to
   511|         0|            0|            0|  0.00%|    broadcast_shapes
   512|         0|            0|            0|  0.00%|
   513|         0|            0|            0|  0.00%|    Examples
   514|         0|            0|            0|  0.00%|    --------
   515|         0|            0|            0|  0.00%|    >>> x = np.array([[1,2,3]])
   516|         0|            0|            0|  0.00%|    >>> y = np.array([[4],[5]])
   517|         0|            0|            0|  0.00%|    >>> np.broadcast_arrays(x, y)
   518|         0|            0|            0|  0.00%|    [array([[1, 2, 3],
   519|         0|            0|            0|  0.00%|           [1, 2, 3]]), array([[4, 4, 4],
   520|         0|            0|            0|  0.00%|           [5, 5, 5]])]
   521|         0|            0|            0|  0.00%|
   522|         0|            0|            0|  0.00%|    Here is a useful idiom for getting contiguous copies instead of
   523|         0|            0|            0|  0.00%|    non-contiguous views.
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|    >>> [np.array(a) for a in np.broadcast_arrays(x, y)]
   526|         0|            0|            0|  0.00%|    [array([[1, 2, 3],
   527|         0|            0|            0|  0.00%|           [1, 2, 3]]), array([[4, 4, 4],
   528|         0|            0|            0|  0.00%|           [5, 5, 5]])]
   529|         0|            0|            0|  0.00%|
   530|         0|            0|            0|  0.00%|    """
   531|         0|            0|            0|  0.00%|    # nditer is not used here to avoid the limit of 32 arrays.
   532|         0|            0|            0|  0.00%|    # Otherwise, something like the following one-liner would suffice:
   533|         0|            0|            0|  0.00%|    # return np.nditer(args, flags=['multi_index', 'zerosize_ok'],
   534|         0|            0|            0|  0.00%|    #                  order='C').itviews
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|    args = [np.array(_m, copy=False, subok=subok) for _m in args]
   537|         0|            0|            0|  0.00%|
   538|         0|            0|            0|  0.00%|    shape = _broadcast_shape(*args)
   539|         0|            0|            0|  0.00%|
   540|         0|            0|            0|  0.00%|    if all(array.shape == shape for array in args):
   541|         0|            0|            0|  0.00%|        # Common case where nothing needs to be broadcasted.
   542|         0|            0|            0|  0.00%|        return args
   543|         0|            0|            0|  0.00%|
   544|         0|            0|            0|  0.00%|    return [_broadcast_to(array, shape, subok=subok, readonly=False)
   545|         0|            0|            0|  0.00%|            for array in args]
File: <__array_function__ internals>_4
File duration: 5.22137e-05s (0.01%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         2|  4.52995e-06|  2.26498e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         2|  1.62125e-05|  8.10623e-06|  0.00%|
(call)|         2|  8.34465e-06|  4.17233e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/multiarray.py:1054 copyto
     5|         4|  2.81334e-05|  7.03335e-06|  0.00%|
     6|         2|  3.33786e-06|  1.66893e-06|  0.00%|
File: <__array_function__ internals>_6
File duration: 3.98159e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         1|  4.29153e-06|  4.29153e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         1|   1.7643e-05|   1.7643e-05|  0.00%|
(call)|         1|  8.82149e-06|  8.82149e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/shape_base.py:263 _apply_along_axis_dispatcher
     5|         2|  1.54972e-05|   7.7486e-06|  0.00%|
(call)|         1|      0.20136|      0.20136| 23.47%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/lib/shape_base.py:267 apply_along_axis
     6|         1|  2.38419e-06|  2.38419e-06|  0.00%|
File: <__array_function__ internals>_7
File duration: 3.95775e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         2|  4.52995e-06|  2.26498e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         2|  1.64509e-05|  8.22544e-06|  0.00%|
(call)|         2|  7.62939e-06|   3.8147e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:598 _transpose_dispatcher
     5|         4|  1.50204e-05|  3.75509e-06|  0.00%|
(call)|         2|   3.8147e-05|  1.90735e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:602 transpose
     6|         2|  3.57628e-06|  1.78814e-06|  0.00%|
File: <__array_function__ internals>_3
File duration: 3.95775e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         2|  4.05312e-06|  2.02656e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         2|  1.43051e-05|  7.15256e-06|  0.00%|
(call)|         2|  7.15256e-06|  3.57628e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2350 _all_dispatcher
     5|         4|  1.83582e-05|  4.58956e-06|  0.00%|
(call)|         2|  0.000127792|  6.38962e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2355 all
     6|         2|  2.86102e-06|  1.43051e-06|  0.00%|
File: <__array_function__ internals>_0
File duration: 3.91006e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         2|  4.76837e-06|  2.38419e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         2|  1.57356e-05|  7.86781e-06|  0.00%|
(call)|         2|   3.0756e-05|   1.5378e-05|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3102 _ndim_dispatcher
     5|         4|   1.4782e-05|  3.69549e-06|  0.00%|
(call)|         2|  7.60555e-05|  3.80278e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3106 ndim
     6|         2|   3.8147e-06|  1.90735e-06|  0.00%|
File: <__array_function__ internals>
File duration: 2.88486e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         1|  3.33786e-06|  3.33786e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         1|   1.3113e-05|   1.3113e-05|  0.00%|
(call)|         1|  7.86781e-06|  7.86781e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2040 _clip_dispatcher
     5|         2|   1.0252e-05|    5.126e-06|  0.00%|
(call)|         1|  0.000396013|  0.000396013|  0.05%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2044 clip
     6|         1|  2.14577e-06|  2.14577e-06|  0.00%|
File: <__array_function__ internals>_1
File duration: 2.64645e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         1|  2.86102e-06|  2.86102e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         1|   1.0252e-05|   1.0252e-05|  0.00%|
(call)|         1|  7.15256e-06|  7.15256e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py:2260 _isclose_dispatcher
     5|         2|  1.14441e-05|  5.72205e-06|  0.00%|
(call)|         1|  0.000612974|  0.000612974|  0.07%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py:2264 isclose
     6|         1|  1.90735e-06|  1.90735e-06|  0.00%|
File: <__array_function__ internals>_8
File duration: 2.31266e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         1|  1.66893e-06|  1.66893e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         1|  1.00136e-05|  1.00136e-05|  0.00%|
(call)|         1|  4.52995e-06|  4.52995e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py:71 _zeros_like_dispatcher
     5|         2|  9.29832e-06|  4.64916e-06|  0.00%|
(call)|         1|  7.93934e-05|  7.93934e-05|  0.01%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/numeric.py:75 zeros_like
     6|         1|  2.14577e-06|  2.14577e-06|  0.00%|
File: <__array_function__ internals>_2
File duration: 2.21729e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         1|  2.38419e-06|  2.38419e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         1|   1.0252e-05|   1.0252e-05|  0.00%|
(call)|         1|  6.91414e-06|  6.91414e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/multiarray.py:644 result_type
     5|         2|  7.15256e-06|  3.57628e-06|  0.00%|
     6|         1|  2.38419e-06|  2.38419e-06|  0.00%|
File: /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/multiarray.py
File duration: 2.14577e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|"""
     2|         0|            0|            0|  0.00%|Create the numpy.core.multiarray namespace for backward compatibility. In v1.16
     3|         0|            0|            0|  0.00%|the multiarray and umath c-extension modules were merged into a single
     4|         0|            0|            0|  0.00%|_multiarray_umath extension module. So we replicate the old namespace
     5|         0|            0|            0|  0.00%|by importing from the extension module.
     6|         0|            0|            0|  0.00%|
     7|         0|            0|            0|  0.00%|"""
     8|         0|            0|            0|  0.00%|
     9|         0|            0|            0|  0.00%|import functools
    10|         0|            0|            0|  0.00%|import warnings
    11|         0|            0|            0|  0.00%|
    12|         0|            0|            0|  0.00%|from . import overrides
    13|         0|            0|            0|  0.00%|from . import _multiarray_umath
    14|         0|            0|            0|  0.00%|from ._multiarray_umath import *  # noqa: F403
    15|         0|            0|            0|  0.00%|# These imports are needed for backward compatibility,
    16|         0|            0|            0|  0.00%|# do not change them. issue gh-15518
    17|         0|            0|            0|  0.00%|# _get_ndarray_c_version is semi-public, on purpose not added to __all__
    18|         0|            0|            0|  0.00%|from ._multiarray_umath import (
    19|         0|            0|            0|  0.00%|    _fastCopyAndTranspose, _flagdict, _insert, _reconstruct, _vec_string,
    20|         0|            0|            0|  0.00%|    _ARRAY_API, _monotonicity, _get_ndarray_c_version, _set_madvise_hugepage,
    21|         0|            0|            0|  0.00%|    )
    22|         0|            0|            0|  0.00%|
    23|         0|            0|            0|  0.00%|__all__ = [
    24|         0|            0|            0|  0.00%|    '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',
    25|         0|            0|            0|  0.00%|    'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',
    26|         0|            0|            0|  0.00%|    'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',
    27|         0|            0|            0|  0.00%|    'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',
    28|         0|            0|            0|  0.00%|    '_flagdict', '_insert', '_reconstruct', '_vec_string', '_monotonicity',
    29|         0|            0|            0|  0.00%|    'add_docstring', 'arange', 'array', 'bincount', 'broadcast',
    30|         0|            0|            0|  0.00%|    'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',
    31|         0|            0|            0|  0.00%|    'compare_chararrays', 'concatenate', 'copyto', 'correlate', 'correlate2',
    32|         0|            0|            0|  0.00%|    'count_nonzero', 'c_einsum', 'datetime_as_string', 'datetime_data',
    33|         0|            0|            0|  0.00%|    'digitize', 'dot', 'dragon4_positional', 'dragon4_scientific', 'dtype',
    34|         0|            0|            0|  0.00%|    'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',
    35|         0|            0|            0|  0.00%|    'frombuffer', 'fromfile', 'fromiter', 'fromstring', 'inner',
    36|         0|            0|            0|  0.00%|    'interp', 'interp_complex', 'is_busday', 'lexsort',
    37|         0|            0|            0|  0.00%|    'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray', 'nditer',
    38|         0|            0|            0|  0.00%|    'nested_iters', 'normalize_axis_index', 'packbits',
    39|         0|            0|            0|  0.00%|    'promote_types', 'putmask', 'ravel_multi_index', 'result_type', 'scalar',
    40|         0|            0|            0|  0.00%|    'set_datetimeparse_function', 'set_legacy_print_mode', 'set_numeric_ops',
    41|         0|            0|            0|  0.00%|    'set_string_function', 'set_typeDict', 'shares_memory',
    42|         0|            0|            0|  0.00%|    'tracemalloc_domain', 'typeinfo', 'unpackbits', 'unravel_index', 'vdot',
    43|         0|            0|            0|  0.00%|    'where', 'zeros']
    44|         0|            0|            0|  0.00%|
    45|         0|            0|            0|  0.00%|# For backward compatibility, make sure pickle imports these functions from here
    46|         0|            0|            0|  0.00%|_reconstruct.__module__ = 'numpy.core.multiarray'
    47|         0|            0|            0|  0.00%|scalar.__module__ = 'numpy.core.multiarray'
    48|         0|            0|            0|  0.00%|
    49|         0|            0|            0|  0.00%|
    50|         0|            0|            0|  0.00%|arange.__module__ = 'numpy'
    51|         0|            0|            0|  0.00%|array.__module__ = 'numpy'
    52|         0|            0|            0|  0.00%|datetime_data.__module__ = 'numpy'
    53|         0|            0|            0|  0.00%|empty.__module__ = 'numpy'
    54|         0|            0|            0|  0.00%|frombuffer.__module__ = 'numpy'
    55|         0|            0|            0|  0.00%|fromfile.__module__ = 'numpy'
    56|         0|            0|            0|  0.00%|fromiter.__module__ = 'numpy'
    57|         0|            0|            0|  0.00%|frompyfunc.__module__ = 'numpy'
    58|         0|            0|            0|  0.00%|fromstring.__module__ = 'numpy'
    59|         0|            0|            0|  0.00%|geterrobj.__module__ = 'numpy'
    60|         0|            0|            0|  0.00%|may_share_memory.__module__ = 'numpy'
    61|         0|            0|            0|  0.00%|nested_iters.__module__ = 'numpy'
    62|         0|            0|            0|  0.00%|promote_types.__module__ = 'numpy'
    63|         0|            0|            0|  0.00%|set_numeric_ops.__module__ = 'numpy'
    64|         0|            0|            0|  0.00%|seterrobj.__module__ = 'numpy'
    65|         0|            0|            0|  0.00%|zeros.__module__ = 'numpy'
    66|         0|            0|            0|  0.00%|
    67|         0|            0|            0|  0.00%|
    68|         0|            0|            0|  0.00%|# We can't verify dispatcher signatures because NumPy's C functions don't
    69|         0|            0|            0|  0.00%|# support introspection.
    70|         0|            0|            0|  0.00%|array_function_from_c_func_and_dispatcher = functools.partial(
    71|         0|            0|            0|  0.00%|    overrides.array_function_from_dispatcher,
    72|         0|            0|            0|  0.00%|    module='numpy', docs_from_dispatcher=True, verify=False)
    73|         0|            0|            0|  0.00%|
    74|         0|            0|            0|  0.00%|
    75|         1|  4.05312e-06|  4.05312e-06|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.empty_like)
    76|         0|            0|            0|  0.00%|def empty_like(prototype, dtype=None, order=None, subok=None, shape=None):
    77|         0|            0|            0|  0.00%|    """
    78|         0|            0|            0|  0.00%|    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)
    79|         0|            0|            0|  0.00%|
    80|         0|            0|            0|  0.00%|    Return a new array with the same shape and type as a given array.
    81|         0|            0|            0|  0.00%|
    82|         0|            0|            0|  0.00%|    Parameters
    83|         0|            0|            0|  0.00%|    ----------
    84|         0|            0|            0|  0.00%|    prototype : array_like
    85|         0|            0|            0|  0.00%|        The shape and data-type of `prototype` define these same attributes
    86|         0|            0|            0|  0.00%|        of the returned array.
    87|         0|            0|            0|  0.00%|    dtype : data-type, optional
    88|         0|            0|            0|  0.00%|        Overrides the data type of the result.
    89|         0|            0|            0|  0.00%|
    90|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    91|         0|            0|            0|  0.00%|    order : {'C', 'F', 'A', or 'K'}, optional
    92|         0|            0|            0|  0.00%|        Overrides the memory layout of the result. 'C' means C-order,
    93|         0|            0|            0|  0.00%|        'F' means F-order, 'A' means 'F' if `prototype` is Fortran
    94|         0|            0|            0|  0.00%|        contiguous, 'C' otherwise. 'K' means match the layout of `prototype`
    95|         0|            0|            0|  0.00%|        as closely as possible.
    96|         0|            0|            0|  0.00%|
    97|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
    98|         0|            0|            0|  0.00%|    subok : bool, optional.
    99|         0|            0|            0|  0.00%|        If True, then the newly created array will use the sub-class
   100|         0|            0|            0|  0.00%|        type of `prototype`, otherwise it will be a base-class array. Defaults
   101|         0|            0|            0|  0.00%|        to True.
   102|         0|            0|            0|  0.00%|    shape : int or sequence of ints, optional.
   103|         0|            0|            0|  0.00%|        Overrides the shape of the result. If order='K' and the number of
   104|         0|            0|            0|  0.00%|        dimensions is unchanged, will try to keep order, otherwise,
   105|         0|            0|            0|  0.00%|        order='C' is implied.
   106|         0|            0|            0|  0.00%|
   107|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
   108|         0|            0|            0|  0.00%|
   109|         0|            0|            0|  0.00%|    Returns
   110|         0|            0|            0|  0.00%|    -------
   111|         0|            0|            0|  0.00%|    out : ndarray
   112|         0|            0|            0|  0.00%|        Array of uninitialized (arbitrary) data with the same
   113|         0|            0|            0|  0.00%|        shape and type as `prototype`.
   114|         0|            0|            0|  0.00%|
   115|         0|            0|            0|  0.00%|    See Also
   116|         0|            0|            0|  0.00%|    --------
   117|         0|            0|            0|  0.00%|    ones_like : Return an array of ones with shape and type of input.
   118|         0|            0|            0|  0.00%|    zeros_like : Return an array of zeros with shape and type of input.
   119|         0|            0|            0|  0.00%|    full_like : Return a new array with shape of input filled with value.
   120|         0|            0|            0|  0.00%|    empty : Return a new uninitialized array.
   121|         0|            0|            0|  0.00%|
   122|         0|            0|            0|  0.00%|    Notes
   123|         0|            0|            0|  0.00%|    -----
   124|         0|            0|            0|  0.00%|    This function does *not* initialize the returned array; to do that use
   125|         0|            0|            0|  0.00%|    `zeros_like` or `ones_like` instead.  It may be marginally faster than
   126|         0|            0|            0|  0.00%|    the functions that do set the array values.
   127|         0|            0|            0|  0.00%|
   128|         0|            0|            0|  0.00%|    Examples
   129|         0|            0|            0|  0.00%|    --------
   130|         0|            0|            0|  0.00%|    >>> a = ([1,2,3], [4,5,6])                         # a is array-like
   131|         0|            0|            0|  0.00%|    >>> np.empty_like(a)
   132|         0|            0|            0|  0.00%|    array([[-1073741821, -1073741821,           3],    # uninitialized
   133|         0|            0|            0|  0.00%|           [          0,           0, -1073741821]])
   134|         0|            0|            0|  0.00%|    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])
   135|         0|            0|            0|  0.00%|    >>> np.empty_like(a)
   136|         0|            0|            0|  0.00%|    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000], # uninitialized
   137|         0|            0|            0|  0.00%|           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])
   138|         0|            0|            0|  0.00%|
   139|         0|            0|            0|  0.00%|    """
   140|         1|  2.14577e-06|  2.14577e-06|  0.00%|    return (prototype,)
   141|         0|            0|            0|  0.00%|
   142|         0|            0|            0|  0.00%|
   143|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.concatenate)
   144|         0|            0|            0|  0.00%|def concatenate(arrays, axis=None, out=None, *, dtype=None, casting=None):
   145|         0|            0|            0|  0.00%|    """
   146|         0|            0|            0|  0.00%|    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting="same_kind")
   147|         0|            0|            0|  0.00%|
   148|         0|            0|            0|  0.00%|    Join a sequence of arrays along an existing axis.
   149|         0|            0|            0|  0.00%|
   150|         0|            0|            0|  0.00%|    Parameters
   151|         0|            0|            0|  0.00%|    ----------
   152|         0|            0|            0|  0.00%|    a1, a2, ... : sequence of array_like
   153|         0|            0|            0|  0.00%|        The arrays must have the same shape, except in the dimension
   154|         0|            0|            0|  0.00%|        corresponding to `axis` (the first, by default).
   155|         0|            0|            0|  0.00%|    axis : int, optional
   156|         0|            0|            0|  0.00%|        The axis along which the arrays will be joined.  If axis is None,
   157|         0|            0|            0|  0.00%|        arrays are flattened before use.  Default is 0.
   158|         0|            0|            0|  0.00%|    out : ndarray, optional
   159|         0|            0|            0|  0.00%|        If provided, the destination to place the result. The shape must be
   160|         0|            0|            0|  0.00%|        correct, matching that of what concatenate would have returned if no
   161|         0|            0|            0|  0.00%|        out argument were specified.
   162|         0|            0|            0|  0.00%|    dtype : str or dtype
   163|         0|            0|            0|  0.00%|        If provided, the destination array will have this dtype. Cannot be
   164|         0|            0|            0|  0.00%|        provided together with `out`.
   165|         0|            0|            0|  0.00%|
   166|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   167|         0|            0|            0|  0.00%|
   168|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
   169|         0|            0|            0|  0.00%|        Controls what kind of data casting may occur. Defaults to 'same_kind'.
   170|         0|            0|            0|  0.00%|
   171|         0|            0|            0|  0.00%|        .. versionadded:: 1.20.0
   172|         0|            0|            0|  0.00%|
   173|         0|            0|            0|  0.00%|    Returns
   174|         0|            0|            0|  0.00%|    -------
   175|         0|            0|            0|  0.00%|    res : ndarray
   176|         0|            0|            0|  0.00%|        The concatenated array.
   177|         0|            0|            0|  0.00%|
   178|         0|            0|            0|  0.00%|    See Also
   179|         0|            0|            0|  0.00%|    --------
   180|         0|            0|            0|  0.00%|    ma.concatenate : Concatenate function that preserves input masks.
   181|         0|            0|            0|  0.00%|    array_split : Split an array into multiple sub-arrays of equal or
   182|         0|            0|            0|  0.00%|                  near-equal size.
   183|         0|            0|            0|  0.00%|    split : Split array into a list of multiple sub-arrays of equal size.
   184|         0|            0|            0|  0.00%|    hsplit : Split array into multiple sub-arrays horizontally (column wise).
   185|         0|            0|            0|  0.00%|    vsplit : Split array into multiple sub-arrays vertically (row wise).
   186|         0|            0|            0|  0.00%|    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).
   187|         0|            0|            0|  0.00%|    stack : Stack a sequence of arrays along a new axis.
   188|         0|            0|            0|  0.00%|    block : Assemble arrays from blocks.
   189|         0|            0|            0|  0.00%|    hstack : Stack arrays in sequence horizontally (column wise).
   190|         0|            0|            0|  0.00%|    vstack : Stack arrays in sequence vertically (row wise).
   191|         0|            0|            0|  0.00%|    dstack : Stack arrays in sequence depth wise (along third dimension).
   192|         0|            0|            0|  0.00%|    column_stack : Stack 1-D arrays as columns into a 2-D array.
   193|         0|            0|            0|  0.00%|
   194|         0|            0|            0|  0.00%|    Notes
   195|         0|            0|            0|  0.00%|    -----
   196|         0|            0|            0|  0.00%|    When one or more of the arrays to be concatenated is a MaskedArray,
   197|         0|            0|            0|  0.00%|    this function will return a MaskedArray object instead of an ndarray,
   198|         0|            0|            0|  0.00%|    but the input masks are *not* preserved. In cases where a MaskedArray
   199|         0|            0|            0|  0.00%|    is expected as input, use the ma.concatenate function from the masked
   200|         0|            0|            0|  0.00%|    array module instead.
   201|         0|            0|            0|  0.00%|
   202|         0|            0|            0|  0.00%|    Examples
   203|         0|            0|            0|  0.00%|    --------
   204|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 2], [3, 4]])
   205|         0|            0|            0|  0.00%|    >>> b = np.array([[5, 6]])
   206|         0|            0|            0|  0.00%|    >>> np.concatenate((a, b), axis=0)
   207|         0|            0|            0|  0.00%|    array([[1, 2],
   208|         0|            0|            0|  0.00%|           [3, 4],
   209|         0|            0|            0|  0.00%|           [5, 6]])
   210|         0|            0|            0|  0.00%|    >>> np.concatenate((a, b.T), axis=1)
   211|         0|            0|            0|  0.00%|    array([[1, 2, 5],
   212|         0|            0|            0|  0.00%|           [3, 4, 6]])
   213|         0|            0|            0|  0.00%|    >>> np.concatenate((a, b), axis=None)
   214|         0|            0|            0|  0.00%|    array([1, 2, 3, 4, 5, 6])
   215|         0|            0|            0|  0.00%|
   216|         0|            0|            0|  0.00%|    This function will not preserve masking of MaskedArray inputs.
   217|         0|            0|            0|  0.00%|
   218|         0|            0|            0|  0.00%|    >>> a = np.ma.arange(3)
   219|         0|            0|            0|  0.00%|    >>> a[1] = np.ma.masked
   220|         0|            0|            0|  0.00%|    >>> b = np.arange(2, 5)
   221|         0|            0|            0|  0.00%|    >>> a
   222|         0|            0|            0|  0.00%|    masked_array(data=[0, --, 2],
   223|         0|            0|            0|  0.00%|                 mask=[False,  True, False],
   224|         0|            0|            0|  0.00%|           fill_value=999999)
   225|         0|            0|            0|  0.00%|    >>> b
   226|         0|            0|            0|  0.00%|    array([2, 3, 4])
   227|         0|            0|            0|  0.00%|    >>> np.concatenate([a, b])
   228|         0|            0|            0|  0.00%|    masked_array(data=[0, 1, 2, 2, 3, 4],
   229|         0|            0|            0|  0.00%|                 mask=False,
   230|         0|            0|            0|  0.00%|           fill_value=999999)
   231|         0|            0|            0|  0.00%|    >>> np.ma.concatenate([a, b])
   232|         0|            0|            0|  0.00%|    masked_array(data=[0, --, 2, 2, 3, 4],
   233|         0|            0|            0|  0.00%|                 mask=[False,  True, False, False, False, False],
   234|         0|            0|            0|  0.00%|           fill_value=999999)
   235|         0|            0|            0|  0.00%|
   236|         0|            0|            0|  0.00%|    """
   237|         0|            0|            0|  0.00%|    if out is not None:
   238|         0|            0|            0|  0.00%|        # optimize for the typical case where only arrays is provided
   239|         0|            0|            0|  0.00%|        arrays = list(arrays)
   240|         0|            0|            0|  0.00%|        arrays.append(out)
   241|         0|            0|            0|  0.00%|    return arrays
   242|         0|            0|            0|  0.00%|
   243|         0|            0|            0|  0.00%|
   244|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.inner)
   245|         0|            0|            0|  0.00%|def inner(a, b):
   246|         0|            0|            0|  0.00%|    """
   247|         0|            0|            0|  0.00%|    inner(a, b)
   248|         0|            0|            0|  0.00%|
   249|         0|            0|            0|  0.00%|    Inner product of two arrays.
   250|         0|            0|            0|  0.00%|
   251|         0|            0|            0|  0.00%|    Ordinary inner product of vectors for 1-D arrays (without complex
   252|         0|            0|            0|  0.00%|    conjugation), in higher dimensions a sum product over the last axes.
   253|         0|            0|            0|  0.00%|
   254|         0|            0|            0|  0.00%|    Parameters
   255|         0|            0|            0|  0.00%|    ----------
   256|         0|            0|            0|  0.00%|    a, b : array_like
   257|         0|            0|            0|  0.00%|        If `a` and `b` are nonscalar, their last dimensions must match.
   258|         0|            0|            0|  0.00%|
   259|         0|            0|            0|  0.00%|    Returns
   260|         0|            0|            0|  0.00%|    -------
   261|         0|            0|            0|  0.00%|    out : ndarray
   262|         0|            0|            0|  0.00%|        `out.shape = a.shape[:-1] + b.shape[:-1]`
   263|         0|            0|            0|  0.00%|
   264|         0|            0|            0|  0.00%|    Raises
   265|         0|            0|            0|  0.00%|    ------
   266|         0|            0|            0|  0.00%|    ValueError
   267|         0|            0|            0|  0.00%|        If the last dimension of `a` and `b` has different size.
   268|         0|            0|            0|  0.00%|
   269|         0|            0|            0|  0.00%|    See Also
   270|         0|            0|            0|  0.00%|    --------
   271|         0|            0|            0|  0.00%|    tensordot : Sum products over arbitrary axes.
   272|         0|            0|            0|  0.00%|    dot : Generalised matrix product, using second last dimension of `b`.
   273|         0|            0|            0|  0.00%|    einsum : Einstein summation convention.
   274|         0|            0|            0|  0.00%|
   275|         0|            0|            0|  0.00%|    Notes
   276|         0|            0|            0|  0.00%|    -----
   277|         0|            0|            0|  0.00%|    For vectors (1-D arrays) it computes the ordinary inner-product::
   278|         0|            0|            0|  0.00%|
   279|         0|            0|            0|  0.00%|        np.inner(a, b) = sum(a[:]*b[:])
   280|         0|            0|            0|  0.00%|
   281|         0|            0|            0|  0.00%|    More generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`::
   282|         0|            0|            0|  0.00%|
   283|         0|            0|            0|  0.00%|        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))
   284|         0|            0|            0|  0.00%|
   285|         0|            0|            0|  0.00%|    or explicitly::
   286|         0|            0|            0|  0.00%|
   287|         0|            0|            0|  0.00%|        np.inner(a, b)[i0,...,ir-1,j0,...,js-1]
   288|         0|            0|            0|  0.00%|             = sum(a[i0,...,ir-1,:]*b[j0,...,js-1,:])
   289|         0|            0|            0|  0.00%|
   290|         0|            0|            0|  0.00%|    In addition `a` or `b` may be scalars, in which case::
   291|         0|            0|            0|  0.00%|
   292|         0|            0|            0|  0.00%|       np.inner(a,b) = a*b
   293|         0|            0|            0|  0.00%|
   294|         0|            0|            0|  0.00%|    Examples
   295|         0|            0|            0|  0.00%|    --------
   296|         0|            0|            0|  0.00%|    Ordinary inner product for vectors:
   297|         0|            0|            0|  0.00%|
   298|         0|            0|            0|  0.00%|    >>> a = np.array([1,2,3])
   299|         0|            0|            0|  0.00%|    >>> b = np.array([0,1,0])
   300|         0|            0|            0|  0.00%|    >>> np.inner(a, b)
   301|         0|            0|            0|  0.00%|    2
   302|         0|            0|            0|  0.00%|
   303|         0|            0|            0|  0.00%|    A multidimensional example:
   304|         0|            0|            0|  0.00%|
   305|         0|            0|            0|  0.00%|    >>> a = np.arange(24).reshape((2,3,4))
   306|         0|            0|            0|  0.00%|    >>> b = np.arange(4)
   307|         0|            0|            0|  0.00%|    >>> np.inner(a, b)
   308|         0|            0|            0|  0.00%|    array([[ 14,  38,  62],
   309|         0|            0|            0|  0.00%|           [ 86, 110, 134]])
   310|         0|            0|            0|  0.00%|
   311|         0|            0|            0|  0.00%|    An example where `b` is a scalar:
   312|         0|            0|            0|  0.00%|
   313|         0|            0|            0|  0.00%|    >>> np.inner(np.eye(2), 7)
   314|         0|            0|            0|  0.00%|    array([[7., 0.],
   315|         0|            0|            0|  0.00%|           [0., 7.]])
   316|         0|            0|            0|  0.00%|
   317|         0|            0|            0|  0.00%|    """
   318|         0|            0|            0|  0.00%|    return (a, b)
   319|         0|            0|            0|  0.00%|
   320|         0|            0|            0|  0.00%|
   321|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.where)
   322|         0|            0|            0|  0.00%|def where(condition, x=None, y=None):
   323|         0|            0|            0|  0.00%|    """
   324|         0|            0|            0|  0.00%|    where(condition, [x, y])
   325|         0|            0|            0|  0.00%|
   326|         0|            0|            0|  0.00%|    Return elements chosen from `x` or `y` depending on `condition`.
   327|         0|            0|            0|  0.00%|
   328|         0|            0|            0|  0.00%|    .. note::
   329|         0|            0|            0|  0.00%|        When only `condition` is provided, this function is a shorthand for
   330|         0|            0|            0|  0.00%|        ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be
   331|         0|            0|            0|  0.00%|        preferred, as it behaves correctly for subclasses. The rest of this
   332|         0|            0|            0|  0.00%|        documentation covers only the case where all three arguments are
   333|         0|            0|            0|  0.00%|        provided.
   334|         0|            0|            0|  0.00%|
   335|         0|            0|            0|  0.00%|    Parameters
   336|         0|            0|            0|  0.00%|    ----------
   337|         0|            0|            0|  0.00%|    condition : array_like, bool
   338|         0|            0|            0|  0.00%|        Where True, yield `x`, otherwise yield `y`.
   339|         0|            0|            0|  0.00%|    x, y : array_like
   340|         0|            0|            0|  0.00%|        Values from which to choose. `x`, `y` and `condition` need to be
   341|         0|            0|            0|  0.00%|        broadcastable to some shape.
   342|         0|            0|            0|  0.00%|
   343|         0|            0|            0|  0.00%|    Returns
   344|         0|            0|            0|  0.00%|    -------
   345|         0|            0|            0|  0.00%|    out : ndarray
   346|         0|            0|            0|  0.00%|        An array with elements from `x` where `condition` is True, and elements
   347|         0|            0|            0|  0.00%|        from `y` elsewhere.
   348|         0|            0|            0|  0.00%|
   349|         0|            0|            0|  0.00%|    See Also
   350|         0|            0|            0|  0.00%|    --------
   351|         0|            0|            0|  0.00%|    choose
   352|         0|            0|            0|  0.00%|    nonzero : The function that is called when x and y are omitted
   353|         0|            0|            0|  0.00%|
   354|         0|            0|            0|  0.00%|    Notes
   355|         0|            0|            0|  0.00%|    -----
   356|         0|            0|            0|  0.00%|    If all the arrays are 1-D, `where` is equivalent to::
   357|         0|            0|            0|  0.00%|
   358|         0|            0|            0|  0.00%|        [xv if c else yv
   359|         0|            0|            0|  0.00%|         for c, xv, yv in zip(condition, x, y)]
   360|         0|            0|            0|  0.00%|
   361|         0|            0|            0|  0.00%|    Examples
   362|         0|            0|            0|  0.00%|    --------
   363|         0|            0|            0|  0.00%|    >>> a = np.arange(10)
   364|         0|            0|            0|  0.00%|    >>> a
   365|         0|            0|            0|  0.00%|    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
   366|         0|            0|            0|  0.00%|    >>> np.where(a < 5, a, 10*a)
   367|         0|            0|            0|  0.00%|    array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])
   368|         0|            0|            0|  0.00%|
   369|         0|            0|            0|  0.00%|    This can be used on multidimensional arrays too:
   370|         0|            0|            0|  0.00%|
   371|         0|            0|            0|  0.00%|    >>> np.where([[True, False], [True, True]],
   372|         0|            0|            0|  0.00%|    ...          [[1, 2], [3, 4]],
   373|         0|            0|            0|  0.00%|    ...          [[9, 8], [7, 6]])
   374|         0|            0|            0|  0.00%|    array([[1, 8],
   375|         0|            0|            0|  0.00%|           [3, 4]])
   376|         0|            0|            0|  0.00%|
   377|         0|            0|            0|  0.00%|    The shapes of x, y, and the condition are broadcast together:
   378|         0|            0|            0|  0.00%|
   379|         0|            0|            0|  0.00%|    >>> x, y = np.ogrid[:3, :4]
   380|         0|            0|            0|  0.00%|    >>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast
   381|         0|            0|            0|  0.00%|    array([[10,  0,  0,  0],
   382|         0|            0|            0|  0.00%|           [10, 11,  1,  1],
   383|         0|            0|            0|  0.00%|           [10, 11, 12,  2]])
   384|         0|            0|            0|  0.00%|
   385|         0|            0|            0|  0.00%|    >>> a = np.array([[0, 1, 2],
   386|         0|            0|            0|  0.00%|    ...               [0, 2, 4],
   387|         0|            0|            0|  0.00%|    ...               [0, 3, 6]])
   388|         0|            0|            0|  0.00%|    >>> np.where(a < 4, a, -1)  # -1 is broadcast
   389|         0|            0|            0|  0.00%|    array([[ 0,  1,  2],
   390|         0|            0|            0|  0.00%|           [ 0,  2, -1],
   391|         0|            0|            0|  0.00%|           [ 0,  3, -1]])
   392|         0|            0|            0|  0.00%|    """
   393|         0|            0|            0|  0.00%|    return (condition, x, y)
   394|         0|            0|            0|  0.00%|
   395|         0|            0|            0|  0.00%|
   396|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.lexsort)
   397|         0|            0|            0|  0.00%|def lexsort(keys, axis=None):
   398|         0|            0|            0|  0.00%|    """
   399|         0|            0|            0|  0.00%|    lexsort(keys, axis=-1)
   400|         0|            0|            0|  0.00%|
   401|         0|            0|            0|  0.00%|    Perform an indirect stable sort using a sequence of keys.
   402|         0|            0|            0|  0.00%|
   403|         0|            0|            0|  0.00%|    Given multiple sorting keys, which can be interpreted as columns in a
   404|         0|            0|            0|  0.00%|    spreadsheet, lexsort returns an array of integer indices that describes
   405|         0|            0|            0|  0.00%|    the sort order by multiple columns. The last key in the sequence is used
   406|         0|            0|            0|  0.00%|    for the primary sort order, the second-to-last key for the secondary sort
   407|         0|            0|            0|  0.00%|    order, and so on. The keys argument must be a sequence of objects that
   408|         0|            0|            0|  0.00%|    can be converted to arrays of the same shape. If a 2D array is provided
   409|         0|            0|            0|  0.00%|    for the keys argument, its rows are interpreted as the sorting keys and
   410|         0|            0|            0|  0.00%|    sorting is according to the last row, second last row etc.
   411|         0|            0|            0|  0.00%|
   412|         0|            0|            0|  0.00%|    Parameters
   413|         0|            0|            0|  0.00%|    ----------
   414|         0|            0|            0|  0.00%|    keys : (k, N) array or tuple containing k (N,)-shaped sequences
   415|         0|            0|            0|  0.00%|        The `k` different "columns" to be sorted.  The last column (or row if
   416|         0|            0|            0|  0.00%|        `keys` is a 2D array) is the primary sort key.
   417|         0|            0|            0|  0.00%|    axis : int, optional
   418|         0|            0|            0|  0.00%|        Axis to be indirectly sorted.  By default, sort over the last axis.
   419|         0|            0|            0|  0.00%|
   420|         0|            0|            0|  0.00%|    Returns
   421|         0|            0|            0|  0.00%|    -------
   422|         0|            0|            0|  0.00%|    indices : (N,) ndarray of ints
   423|         0|            0|            0|  0.00%|        Array of indices that sort the keys along the specified axis.
   424|         0|            0|            0|  0.00%|
   425|         0|            0|            0|  0.00%|    See Also
   426|         0|            0|            0|  0.00%|    --------
   427|         0|            0|            0|  0.00%|    argsort : Indirect sort.
   428|         0|            0|            0|  0.00%|    ndarray.sort : In-place sort.
   429|         0|            0|            0|  0.00%|    sort : Return a sorted copy of an array.
   430|         0|            0|            0|  0.00%|
   431|         0|            0|            0|  0.00%|    Examples
   432|         0|            0|            0|  0.00%|    --------
   433|         0|            0|            0|  0.00%|    Sort names: first by surname, then by name.
   434|         0|            0|            0|  0.00%|
   435|         0|            0|            0|  0.00%|    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')
   436|         0|            0|            0|  0.00%|    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')
   437|         0|            0|            0|  0.00%|    >>> ind = np.lexsort((first_names, surnames))
   438|         0|            0|            0|  0.00%|    >>> ind
   439|         0|            0|            0|  0.00%|    array([1, 2, 0])
   440|         0|            0|            0|  0.00%|
   441|         0|            0|            0|  0.00%|    >>> [surnames[i] + ", " + first_names[i] for i in ind]
   442|         0|            0|            0|  0.00%|    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']
   443|         0|            0|            0|  0.00%|
   444|         0|            0|            0|  0.00%|    Sort two columns of numbers:
   445|         0|            0|            0|  0.00%|
   446|         0|            0|            0|  0.00%|    >>> a = [1,5,1,4,3,4,4] # First column
   447|         0|            0|            0|  0.00%|    >>> b = [9,4,0,4,0,2,1] # Second column
   448|         0|            0|            0|  0.00%|    >>> ind = np.lexsort((b,a)) # Sort by a, then by b
   449|         0|            0|            0|  0.00%|    >>> ind
   450|         0|            0|            0|  0.00%|    array([2, 0, 4, 6, 5, 3, 1])
   451|         0|            0|            0|  0.00%|
   452|         0|            0|            0|  0.00%|    >>> [(a[i],b[i]) for i in ind]
   453|         0|            0|            0|  0.00%|    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]
   454|         0|            0|            0|  0.00%|
   455|         0|            0|            0|  0.00%|    Note that sorting is first according to the elements of ``a``.
   456|         0|            0|            0|  0.00%|    Secondary sorting is according to the elements of ``b``.
   457|         0|            0|            0|  0.00%|
   458|         0|            0|            0|  0.00%|    A normal ``argsort`` would have yielded:
   459|         0|            0|            0|  0.00%|
   460|         0|            0|            0|  0.00%|    >>> [(a[i],b[i]) for i in np.argsort(a)]
   461|         0|            0|            0|  0.00%|    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]
   462|         0|            0|            0|  0.00%|
   463|         0|            0|            0|  0.00%|    Structured arrays are sorted lexically by ``argsort``:
   464|         0|            0|            0|  0.00%|
   465|         0|            0|            0|  0.00%|    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],
   466|         0|            0|            0|  0.00%|    ...              dtype=np.dtype([('x', int), ('y', int)]))
   467|         0|            0|            0|  0.00%|
   468|         0|            0|            0|  0.00%|    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))
   469|         0|            0|            0|  0.00%|    array([2, 0, 4, 6, 5, 3, 1])
   470|         0|            0|            0|  0.00%|
   471|         0|            0|            0|  0.00%|    """
   472|         0|            0|            0|  0.00%|    if isinstance(keys, tuple):
   473|         0|            0|            0|  0.00%|        return keys
   474|         0|            0|            0|  0.00%|    else:
   475|         0|            0|            0|  0.00%|        return (keys,)
   476|         0|            0|            0|  0.00%|
   477|         0|            0|            0|  0.00%|
   478|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.can_cast)
   479|         0|            0|            0|  0.00%|def can_cast(from_, to, casting=None):
   480|         0|            0|            0|  0.00%|    """
   481|         0|            0|            0|  0.00%|    can_cast(from_, to, casting='safe')
   482|         0|            0|            0|  0.00%|
   483|         0|            0|            0|  0.00%|    Returns True if cast between data types can occur according to the
   484|         0|            0|            0|  0.00%|    casting rule.  If from is a scalar or array scalar, also returns
   485|         0|            0|            0|  0.00%|    True if the scalar value can be cast without overflow or truncation
   486|         0|            0|            0|  0.00%|    to an integer.
   487|         0|            0|            0|  0.00%|
   488|         0|            0|            0|  0.00%|    Parameters
   489|         0|            0|            0|  0.00%|    ----------
   490|         0|            0|            0|  0.00%|    from_ : dtype, dtype specifier, scalar, or array
   491|         0|            0|            0|  0.00%|        Data type, scalar, or array to cast from.
   492|         0|            0|            0|  0.00%|    to : dtype or dtype specifier
   493|         0|            0|            0|  0.00%|        Data type to cast to.
   494|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
   495|         0|            0|            0|  0.00%|        Controls what kind of data casting may occur.
   496|         0|            0|            0|  0.00%|
   497|         0|            0|            0|  0.00%|          * 'no' means the data types should not be cast at all.
   498|         0|            0|            0|  0.00%|          * 'equiv' means only byte-order changes are allowed.
   499|         0|            0|            0|  0.00%|          * 'safe' means only casts which can preserve values are allowed.
   500|         0|            0|            0|  0.00%|          * 'same_kind' means only safe casts or casts within a kind,
   501|         0|            0|            0|  0.00%|            like float64 to float32, are allowed.
   502|         0|            0|            0|  0.00%|          * 'unsafe' means any data conversions may be done.
   503|         0|            0|            0|  0.00%|
   504|         0|            0|            0|  0.00%|    Returns
   505|         0|            0|            0|  0.00%|    -------
   506|         0|            0|            0|  0.00%|    out : bool
   507|         0|            0|            0|  0.00%|        True if cast can occur according to the casting rule.
   508|         0|            0|            0|  0.00%|
   509|         0|            0|            0|  0.00%|    Notes
   510|         0|            0|            0|  0.00%|    -----
   511|         0|            0|            0|  0.00%|    .. versionchanged:: 1.17.0
   512|         0|            0|            0|  0.00%|       Casting between a simple data type and a structured one is possible only
   513|         0|            0|            0|  0.00%|       for "unsafe" casting.  Casting to multiple fields is allowed, but
   514|         0|            0|            0|  0.00%|       casting from multiple fields is not.
   515|         0|            0|            0|  0.00%|
   516|         0|            0|            0|  0.00%|    .. versionchanged:: 1.9.0
   517|         0|            0|            0|  0.00%|       Casting from numeric to string types in 'safe' casting mode requires
   518|         0|            0|            0|  0.00%|       that the string dtype length is long enough to store the maximum
   519|         0|            0|            0|  0.00%|       integer/float value converted.
   520|         0|            0|            0|  0.00%|
   521|         0|            0|            0|  0.00%|    See also
   522|         0|            0|            0|  0.00%|    --------
   523|         0|            0|            0|  0.00%|    dtype, result_type
   524|         0|            0|            0|  0.00%|
   525|         0|            0|            0|  0.00%|    Examples
   526|         0|            0|            0|  0.00%|    --------
   527|         0|            0|            0|  0.00%|    Basic examples
   528|         0|            0|            0|  0.00%|
   529|         0|            0|            0|  0.00%|    >>> np.can_cast(np.int32, np.int64)
   530|         0|            0|            0|  0.00%|    True
   531|         0|            0|            0|  0.00%|    >>> np.can_cast(np.float64, complex)
   532|         0|            0|            0|  0.00%|    True
   533|         0|            0|            0|  0.00%|    >>> np.can_cast(complex, float)
   534|         0|            0|            0|  0.00%|    False
   535|         0|            0|            0|  0.00%|
   536|         0|            0|            0|  0.00%|    >>> np.can_cast('i8', 'f8')
   537|         0|            0|            0|  0.00%|    True
   538|         0|            0|            0|  0.00%|    >>> np.can_cast('i8', 'f4')
   539|         0|            0|            0|  0.00%|    False
   540|         0|            0|            0|  0.00%|    >>> np.can_cast('i4', 'S4')
   541|         0|            0|            0|  0.00%|    False
   542|         0|            0|            0|  0.00%|
   543|         0|            0|            0|  0.00%|    Casting scalars
   544|         0|            0|            0|  0.00%|
   545|         0|            0|            0|  0.00%|    >>> np.can_cast(100, 'i1')
   546|         0|            0|            0|  0.00%|    True
   547|         0|            0|            0|  0.00%|    >>> np.can_cast(150, 'i1')
   548|         0|            0|            0|  0.00%|    False
   549|         0|            0|            0|  0.00%|    >>> np.can_cast(150, 'u1')
   550|         0|            0|            0|  0.00%|    True
   551|         0|            0|            0|  0.00%|
   552|         0|            0|            0|  0.00%|    >>> np.can_cast(3.5e100, np.float32)
   553|         0|            0|            0|  0.00%|    False
   554|         0|            0|            0|  0.00%|    >>> np.can_cast(1000.0, np.float32)
   555|         0|            0|            0|  0.00%|    True
   556|         0|            0|            0|  0.00%|
   557|         0|            0|            0|  0.00%|    Array scalar checks the value, array does not
   558|         0|            0|            0|  0.00%|
   559|         0|            0|            0|  0.00%|    >>> np.can_cast(np.array(1000.0), np.float32)
   560|         0|            0|            0|  0.00%|    True
   561|         0|            0|            0|  0.00%|    >>> np.can_cast(np.array([1000.0]), np.float32)
   562|         0|            0|            0|  0.00%|    False
   563|         0|            0|            0|  0.00%|
   564|         0|            0|            0|  0.00%|    Using the casting rules
   565|         0|            0|            0|  0.00%|
   566|         0|            0|            0|  0.00%|    >>> np.can_cast('i8', 'i8', 'no')
   567|         0|            0|            0|  0.00%|    True
   568|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i8', 'no')
   569|         0|            0|            0|  0.00%|    False
   570|         0|            0|            0|  0.00%|
   571|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i8', 'equiv')
   572|         0|            0|            0|  0.00%|    True
   573|         0|            0|            0|  0.00%|    >>> np.can_cast('<i4', '>i8', 'equiv')
   574|         0|            0|            0|  0.00%|    False
   575|         0|            0|            0|  0.00%|
   576|         0|            0|            0|  0.00%|    >>> np.can_cast('<i4', '>i8', 'safe')
   577|         0|            0|            0|  0.00%|    True
   578|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i4', 'safe')
   579|         0|            0|            0|  0.00%|    False
   580|         0|            0|            0|  0.00%|
   581|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>i4', 'same_kind')
   582|         0|            0|            0|  0.00%|    True
   583|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>u4', 'same_kind')
   584|         0|            0|            0|  0.00%|    False
   585|         0|            0|            0|  0.00%|
   586|         0|            0|            0|  0.00%|    >>> np.can_cast('<i8', '>u4', 'unsafe')
   587|         0|            0|            0|  0.00%|    True
   588|         0|            0|            0|  0.00%|
   589|         0|            0|            0|  0.00%|    """
   590|         0|            0|            0|  0.00%|    return (from_,)
   591|         0|            0|            0|  0.00%|
   592|         0|            0|            0|  0.00%|
   593|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.min_scalar_type)
   594|         0|            0|            0|  0.00%|def min_scalar_type(a):
   595|         0|            0|            0|  0.00%|    """
   596|         0|            0|            0|  0.00%|    min_scalar_type(a)
   597|         0|            0|            0|  0.00%|
   598|         0|            0|            0|  0.00%|    For scalar ``a``, returns the data type with the smallest size
   599|         0|            0|            0|  0.00%|    and smallest scalar kind which can hold its value.  For non-scalar
   600|         0|            0|            0|  0.00%|    array ``a``, returns the vector's dtype unmodified.
   601|         0|            0|            0|  0.00%|
   602|         0|            0|            0|  0.00%|    Floating point values are not demoted to integers,
   603|         0|            0|            0|  0.00%|    and complex values are not demoted to floats.
   604|         0|            0|            0|  0.00%|
   605|         0|            0|            0|  0.00%|    Parameters
   606|         0|            0|            0|  0.00%|    ----------
   607|         0|            0|            0|  0.00%|    a : scalar or array_like
   608|         0|            0|            0|  0.00%|        The value whose minimal data type is to be found.
   609|         0|            0|            0|  0.00%|
   610|         0|            0|            0|  0.00%|    Returns
   611|         0|            0|            0|  0.00%|    -------
   612|         0|            0|            0|  0.00%|    out : dtype
   613|         0|            0|            0|  0.00%|        The minimal data type.
   614|         0|            0|            0|  0.00%|
   615|         0|            0|            0|  0.00%|    Notes
   616|         0|            0|            0|  0.00%|    -----
   617|         0|            0|            0|  0.00%|    .. versionadded:: 1.6.0
   618|         0|            0|            0|  0.00%|
   619|         0|            0|            0|  0.00%|    See Also
   620|         0|            0|            0|  0.00%|    --------
   621|         0|            0|            0|  0.00%|    result_type, promote_types, dtype, can_cast
   622|         0|            0|            0|  0.00%|
   623|         0|            0|            0|  0.00%|    Examples
   624|         0|            0|            0|  0.00%|    --------
   625|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(10)
   626|         0|            0|            0|  0.00%|    dtype('uint8')
   627|         0|            0|            0|  0.00%|
   628|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(-260)
   629|         0|            0|            0|  0.00%|    dtype('int16')
   630|         0|            0|            0|  0.00%|
   631|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(3.1)
   632|         0|            0|            0|  0.00%|    dtype('float16')
   633|         0|            0|            0|  0.00%|
   634|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(1e50)
   635|         0|            0|            0|  0.00%|    dtype('float64')
   636|         0|            0|            0|  0.00%|
   637|         0|            0|            0|  0.00%|    >>> np.min_scalar_type(np.arange(4,dtype='f8'))
   638|         0|            0|            0|  0.00%|    dtype('float64')
   639|         0|            0|            0|  0.00%|
   640|         0|            0|            0|  0.00%|    """
   641|         0|            0|            0|  0.00%|    return (a,)
   642|         0|            0|            0|  0.00%|
   643|         0|            0|            0|  0.00%|
   644|         1|  2.86102e-06|  2.86102e-06|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.result_type)
   645|         0|            0|            0|  0.00%|def result_type(*arrays_and_dtypes):
   646|         0|            0|            0|  0.00%|    """
   647|         0|            0|            0|  0.00%|    result_type(*arrays_and_dtypes)
   648|         0|            0|            0|  0.00%|
   649|         0|            0|            0|  0.00%|    Returns the type that results from applying the NumPy
   650|         0|            0|            0|  0.00%|    type promotion rules to the arguments.
   651|         0|            0|            0|  0.00%|
   652|         0|            0|            0|  0.00%|    Type promotion in NumPy works similarly to the rules in languages
   653|         0|            0|            0|  0.00%|    like C++, with some slight differences.  When both scalars and
   654|         0|            0|            0|  0.00%|    arrays are used, the array's type takes precedence and the actual value
   655|         0|            0|            0|  0.00%|    of the scalar is taken into account.
   656|         0|            0|            0|  0.00%|
   657|         0|            0|            0|  0.00%|    For example, calculating 3*a, where a is an array of 32-bit floats,
   658|         0|            0|            0|  0.00%|    intuitively should result in a 32-bit float output.  If the 3 is a
   659|         0|            0|            0|  0.00%|    32-bit integer, the NumPy rules indicate it can't convert losslessly
   660|         0|            0|            0|  0.00%|    into a 32-bit float, so a 64-bit float should be the result type.
   661|         0|            0|            0|  0.00%|    By examining the value of the constant, '3', we see that it fits in
   662|         0|            0|            0|  0.00%|    an 8-bit integer, which can be cast losslessly into the 32-bit float.
   663|         0|            0|            0|  0.00%|
   664|         0|            0|            0|  0.00%|    Parameters
   665|         0|            0|            0|  0.00%|    ----------
   666|         0|            0|            0|  0.00%|    arrays_and_dtypes : list of arrays and dtypes
   667|         0|            0|            0|  0.00%|        The operands of some operation whose result type is needed.
   668|         0|            0|            0|  0.00%|
   669|         0|            0|            0|  0.00%|    Returns
   670|         0|            0|            0|  0.00%|    -------
   671|         0|            0|            0|  0.00%|    out : dtype
   672|         0|            0|            0|  0.00%|        The result type.
   673|         0|            0|            0|  0.00%|
   674|         0|            0|            0|  0.00%|    See also
   675|         0|            0|            0|  0.00%|    --------
   676|         0|            0|            0|  0.00%|    dtype, promote_types, min_scalar_type, can_cast
   677|         0|            0|            0|  0.00%|
   678|         0|            0|            0|  0.00%|    Notes
   679|         0|            0|            0|  0.00%|    -----
   680|         0|            0|            0|  0.00%|    .. versionadded:: 1.6.0
   681|         0|            0|            0|  0.00%|
   682|         0|            0|            0|  0.00%|    The specific algorithm used is as follows.
   683|         0|            0|            0|  0.00%|
   684|         0|            0|            0|  0.00%|    Categories are determined by first checking which of boolean,
   685|         0|            0|            0|  0.00%|    integer (int/uint), or floating point (float/complex) the maximum
   686|         0|            0|            0|  0.00%|    kind of all the arrays and the scalars are.
   687|         0|            0|            0|  0.00%|
   688|         0|            0|            0|  0.00%|    If there are only scalars or the maximum category of the scalars
   689|         0|            0|            0|  0.00%|    is higher than the maximum category of the arrays,
   690|         0|            0|            0|  0.00%|    the data types are combined with :func:`promote_types`
   691|         0|            0|            0|  0.00%|    to produce the return value.
   692|         0|            0|            0|  0.00%|
   693|         0|            0|            0|  0.00%|    Otherwise, `min_scalar_type` is called on each array, and
   694|         0|            0|            0|  0.00%|    the resulting data types are all combined with :func:`promote_types`
   695|         0|            0|            0|  0.00%|    to produce the return value.
   696|         0|            0|            0|  0.00%|
   697|         0|            0|            0|  0.00%|    The set of int values is not a subset of the uint values for types
   698|         0|            0|            0|  0.00%|    with the same number of bits, something not reflected in
   699|         0|            0|            0|  0.00%|    :func:`min_scalar_type`, but handled as a special case in `result_type`.
   700|         0|            0|            0|  0.00%|
   701|         0|            0|            0|  0.00%|    Examples
   702|         0|            0|            0|  0.00%|    --------
   703|         0|            0|            0|  0.00%|    >>> np.result_type(3, np.arange(7, dtype='i1'))
   704|         0|            0|            0|  0.00%|    dtype('int8')
   705|         0|            0|            0|  0.00%|
   706|         0|            0|            0|  0.00%|    >>> np.result_type('i4', 'c8')
   707|         0|            0|            0|  0.00%|    dtype('complex128')
   708|         0|            0|            0|  0.00%|
   709|         0|            0|            0|  0.00%|    >>> np.result_type(3.0, -2)
   710|         0|            0|            0|  0.00%|    dtype('float64')
   711|         0|            0|            0|  0.00%|
   712|         0|            0|            0|  0.00%|    """
   713|         1|  4.05312e-06|  4.05312e-06|  0.00%|    return arrays_and_dtypes
   714|         0|            0|            0|  0.00%|
   715|         0|            0|            0|  0.00%|
   716|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.dot)
   717|         0|            0|            0|  0.00%|def dot(a, b, out=None):
   718|         0|            0|            0|  0.00%|    """
   719|         0|            0|            0|  0.00%|    dot(a, b, out=None)
   720|         0|            0|            0|  0.00%|
   721|         0|            0|            0|  0.00%|    Dot product of two arrays. Specifically,
   722|         0|            0|            0|  0.00%|
   723|         0|            0|            0|  0.00%|    - If both `a` and `b` are 1-D arrays, it is inner product of vectors
   724|         0|            0|            0|  0.00%|      (without complex conjugation).
   725|         0|            0|            0|  0.00%|
   726|         0|            0|            0|  0.00%|    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,
   727|         0|            0|            0|  0.00%|      but using :func:`matmul` or ``a @ b`` is preferred.
   728|         0|            0|            0|  0.00%|
   729|         0|            0|            0|  0.00%|    - If either `a` or `b` is 0-D (scalar), it is equivalent to :func:`multiply`
   730|         0|            0|            0|  0.00%|      and using ``numpy.multiply(a, b)`` or ``a * b`` is preferred.
   731|         0|            0|            0|  0.00%|
   732|         0|            0|            0|  0.00%|    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over
   733|         0|            0|            0|  0.00%|      the last axis of `a` and `b`.
   734|         0|            0|            0|  0.00%|
   735|         0|            0|            0|  0.00%|    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a
   736|         0|            0|            0|  0.00%|      sum product over the last axis of `a` and the second-to-last axis of `b`::
   737|         0|            0|            0|  0.00%|
   738|         0|            0|            0|  0.00%|        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])
   739|         0|            0|            0|  0.00%|
   740|         0|            0|            0|  0.00%|    Parameters
   741|         0|            0|            0|  0.00%|    ----------
   742|         0|            0|            0|  0.00%|    a : array_like
   743|         0|            0|            0|  0.00%|        First argument.
   744|         0|            0|            0|  0.00%|    b : array_like
   745|         0|            0|            0|  0.00%|        Second argument.
   746|         0|            0|            0|  0.00%|    out : ndarray, optional
   747|         0|            0|            0|  0.00%|        Output argument. This must have the exact kind that would be returned
   748|         0|            0|            0|  0.00%|        if it was not used. In particular, it must have the right type, must be
   749|         0|            0|            0|  0.00%|        C-contiguous, and its dtype must be the dtype that would be returned
   750|         0|            0|            0|  0.00%|        for `dot(a,b)`. This is a performance feature. Therefore, if these
   751|         0|            0|            0|  0.00%|        conditions are not met, an exception is raised, instead of attempting
   752|         0|            0|            0|  0.00%|        to be flexible.
   753|         0|            0|            0|  0.00%|
   754|         0|            0|            0|  0.00%|    Returns
   755|         0|            0|            0|  0.00%|    -------
   756|         0|            0|            0|  0.00%|    output : ndarray
   757|         0|            0|            0|  0.00%|        Returns the dot product of `a` and `b`.  If `a` and `b` are both
   758|         0|            0|            0|  0.00%|        scalars or both 1-D arrays then a scalar is returned; otherwise
   759|         0|            0|            0|  0.00%|        an array is returned.
   760|         0|            0|            0|  0.00%|        If `out` is given, then it is returned.
   761|         0|            0|            0|  0.00%|
   762|         0|            0|            0|  0.00%|    Raises
   763|         0|            0|            0|  0.00%|    ------
   764|         0|            0|            0|  0.00%|    ValueError
   765|         0|            0|            0|  0.00%|        If the last dimension of `a` is not the same size as
   766|         0|            0|            0|  0.00%|        the second-to-last dimension of `b`.
   767|         0|            0|            0|  0.00%|
   768|         0|            0|            0|  0.00%|    See Also
   769|         0|            0|            0|  0.00%|    --------
   770|         0|            0|            0|  0.00%|    vdot : Complex-conjugating dot product.
   771|         0|            0|            0|  0.00%|    tensordot : Sum products over arbitrary axes.
   772|         0|            0|            0|  0.00%|    einsum : Einstein summation convention.
   773|         0|            0|            0|  0.00%|    matmul : '@' operator as method with out parameter.
   774|         0|            0|            0|  0.00%|    linalg.multi_dot : Chained dot product.
   775|         0|            0|            0|  0.00%|
   776|         0|            0|            0|  0.00%|    Examples
   777|         0|            0|            0|  0.00%|    --------
   778|         0|            0|            0|  0.00%|    >>> np.dot(3, 4)
   779|         0|            0|            0|  0.00%|    12
   780|         0|            0|            0|  0.00%|
   781|         0|            0|            0|  0.00%|    Neither argument is complex-conjugated:
   782|         0|            0|            0|  0.00%|
   783|         0|            0|            0|  0.00%|    >>> np.dot([2j, 3j], [2j, 3j])
   784|         0|            0|            0|  0.00%|    (-13+0j)
   785|         0|            0|            0|  0.00%|
   786|         0|            0|            0|  0.00%|    For 2-D arrays it is the matrix product:
   787|         0|            0|            0|  0.00%|
   788|         0|            0|            0|  0.00%|    >>> a = [[1, 0], [0, 1]]
   789|         0|            0|            0|  0.00%|    >>> b = [[4, 1], [2, 2]]
   790|         0|            0|            0|  0.00%|    >>> np.dot(a, b)
   791|         0|            0|            0|  0.00%|    array([[4, 1],
   792|         0|            0|            0|  0.00%|           [2, 2]])
   793|         0|            0|            0|  0.00%|
   794|         0|            0|            0|  0.00%|    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))
   795|         0|            0|            0|  0.00%|    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))
   796|         0|            0|            0|  0.00%|    >>> np.dot(a, b)[2,3,2,1,2,2]
   797|         0|            0|            0|  0.00%|    499128
   798|         0|            0|            0|  0.00%|    >>> sum(a[2,3,2,:] * b[1,2,:,2])
   799|         0|            0|            0|  0.00%|    499128
   800|         0|            0|            0|  0.00%|
   801|         0|            0|            0|  0.00%|    """
   802|         0|            0|            0|  0.00%|    return (a, b, out)
   803|         0|            0|            0|  0.00%|
   804|         0|            0|            0|  0.00%|
   805|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.vdot)
   806|         0|            0|            0|  0.00%|def vdot(a, b):
   807|         0|            0|            0|  0.00%|    """
   808|         0|            0|            0|  0.00%|    vdot(a, b)
   809|         0|            0|            0|  0.00%|
   810|         0|            0|            0|  0.00%|    Return the dot product of two vectors.
   811|         0|            0|            0|  0.00%|
   812|         0|            0|            0|  0.00%|    The vdot(`a`, `b`) function handles complex numbers differently than
   813|         0|            0|            0|  0.00%|    dot(`a`, `b`).  If the first argument is complex the complex conjugate
   814|         0|            0|            0|  0.00%|    of the first argument is used for the calculation of the dot product.
   815|         0|            0|            0|  0.00%|
   816|         0|            0|            0|  0.00%|    Note that `vdot` handles multidimensional arrays differently than `dot`:
   817|         0|            0|            0|  0.00%|    it does *not* perform a matrix product, but flattens input arguments
   818|         0|            0|            0|  0.00%|    to 1-D vectors first. Consequently, it should only be used for vectors.
   819|         0|            0|            0|  0.00%|
   820|         0|            0|            0|  0.00%|    Parameters
   821|         0|            0|            0|  0.00%|    ----------
   822|         0|            0|            0|  0.00%|    a : array_like
   823|         0|            0|            0|  0.00%|        If `a` is complex the complex conjugate is taken before calculation
   824|         0|            0|            0|  0.00%|        of the dot product.
   825|         0|            0|            0|  0.00%|    b : array_like
   826|         0|            0|            0|  0.00%|        Second argument to the dot product.
   827|         0|            0|            0|  0.00%|
   828|         0|            0|            0|  0.00%|    Returns
   829|         0|            0|            0|  0.00%|    -------
   830|         0|            0|            0|  0.00%|    output : ndarray
   831|         0|            0|            0|  0.00%|        Dot product of `a` and `b`.  Can be an int, float, or
   832|         0|            0|            0|  0.00%|        complex depending on the types of `a` and `b`.
   833|         0|            0|            0|  0.00%|
   834|         0|            0|            0|  0.00%|    See Also
   835|         0|            0|            0|  0.00%|    --------
   836|         0|            0|            0|  0.00%|    dot : Return the dot product without using the complex conjugate of the
   837|         0|            0|            0|  0.00%|          first argument.
   838|         0|            0|            0|  0.00%|
   839|         0|            0|            0|  0.00%|    Examples
   840|         0|            0|            0|  0.00%|    --------
   841|         0|            0|            0|  0.00%|    >>> a = np.array([1+2j,3+4j])
   842|         0|            0|            0|  0.00%|    >>> b = np.array([5+6j,7+8j])
   843|         0|            0|            0|  0.00%|    >>> np.vdot(a, b)
   844|         0|            0|            0|  0.00%|    (70-8j)
   845|         0|            0|            0|  0.00%|    >>> np.vdot(b, a)
   846|         0|            0|            0|  0.00%|    (70+8j)
   847|         0|            0|            0|  0.00%|
   848|         0|            0|            0|  0.00%|    Note that higher-dimensional arrays are flattened!
   849|         0|            0|            0|  0.00%|
   850|         0|            0|            0|  0.00%|    >>> a = np.array([[1, 4], [5, 6]])
   851|         0|            0|            0|  0.00%|    >>> b = np.array([[4, 1], [2, 2]])
   852|         0|            0|            0|  0.00%|    >>> np.vdot(a, b)
   853|         0|            0|            0|  0.00%|    30
   854|         0|            0|            0|  0.00%|    >>> np.vdot(b, a)
   855|         0|            0|            0|  0.00%|    30
   856|         0|            0|            0|  0.00%|    >>> 1*4 + 4*1 + 5*2 + 6*2
   857|         0|            0|            0|  0.00%|    30
   858|         0|            0|            0|  0.00%|
   859|         0|            0|            0|  0.00%|    """
   860|         0|            0|            0|  0.00%|    return (a, b)
   861|         0|            0|            0|  0.00%|
   862|         0|            0|            0|  0.00%|
   863|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.bincount)
   864|         0|            0|            0|  0.00%|def bincount(x, weights=None, minlength=None):
   865|         0|            0|            0|  0.00%|    """
   866|         0|            0|            0|  0.00%|    bincount(x, weights=None, minlength=0)
   867|         0|            0|            0|  0.00%|
   868|         0|            0|            0|  0.00%|    Count number of occurrences of each value in array of non-negative ints.
   869|         0|            0|            0|  0.00%|
   870|         0|            0|            0|  0.00%|    The number of bins (of size 1) is one larger than the largest value in
   871|         0|            0|            0|  0.00%|    `x`. If `minlength` is specified, there will be at least this number
   872|         0|            0|            0|  0.00%|    of bins in the output array (though it will be longer if necessary,
   873|         0|            0|            0|  0.00%|    depending on the contents of `x`).
   874|         0|            0|            0|  0.00%|    Each bin gives the number of occurrences of its index value in `x`.
   875|         0|            0|            0|  0.00%|    If `weights` is specified the input array is weighted by it, i.e. if a
   876|         0|            0|            0|  0.00%|    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead
   877|         0|            0|            0|  0.00%|    of ``out[n] += 1``.
   878|         0|            0|            0|  0.00%|
   879|         0|            0|            0|  0.00%|    Parameters
   880|         0|            0|            0|  0.00%|    ----------
   881|         0|            0|            0|  0.00%|    x : array_like, 1 dimension, nonnegative ints
   882|         0|            0|            0|  0.00%|        Input array.
   883|         0|            0|            0|  0.00%|    weights : array_like, optional
   884|         0|            0|            0|  0.00%|        Weights, array of the same shape as `x`.
   885|         0|            0|            0|  0.00%|    minlength : int, optional
   886|         0|            0|            0|  0.00%|        A minimum number of bins for the output array.
   887|         0|            0|            0|  0.00%|
   888|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
   889|         0|            0|            0|  0.00%|
   890|         0|            0|            0|  0.00%|    Returns
   891|         0|            0|            0|  0.00%|    -------
   892|         0|            0|            0|  0.00%|    out : ndarray of ints
   893|         0|            0|            0|  0.00%|        The result of binning the input array.
   894|         0|            0|            0|  0.00%|        The length of `out` is equal to ``np.amax(x)+1``.
   895|         0|            0|            0|  0.00%|
   896|         0|            0|            0|  0.00%|    Raises
   897|         0|            0|            0|  0.00%|    ------
   898|         0|            0|            0|  0.00%|    ValueError
   899|         0|            0|            0|  0.00%|        If the input is not 1-dimensional, or contains elements with negative
   900|         0|            0|            0|  0.00%|        values, or if `minlength` is negative.
   901|         0|            0|            0|  0.00%|    TypeError
   902|         0|            0|            0|  0.00%|        If the type of the input is float or complex.
   903|         0|            0|            0|  0.00%|
   904|         0|            0|            0|  0.00%|    See Also
   905|         0|            0|            0|  0.00%|    --------
   906|         0|            0|            0|  0.00%|    histogram, digitize, unique
   907|         0|            0|            0|  0.00%|
   908|         0|            0|            0|  0.00%|    Examples
   909|         0|            0|            0|  0.00%|    --------
   910|         0|            0|            0|  0.00%|    >>> np.bincount(np.arange(5))
   911|         0|            0|            0|  0.00%|    array([1, 1, 1, 1, 1])
   912|         0|            0|            0|  0.00%|    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))
   913|         0|            0|            0|  0.00%|    array([1, 3, 1, 1, 0, 0, 0, 1])
   914|         0|            0|            0|  0.00%|
   915|         0|            0|            0|  0.00%|    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])
   916|         0|            0|            0|  0.00%|    >>> np.bincount(x).size == np.amax(x)+1
   917|         0|            0|            0|  0.00%|    True
   918|         0|            0|            0|  0.00%|
   919|         0|            0|            0|  0.00%|    The input array needs to be of integer dtype, otherwise a
   920|         0|            0|            0|  0.00%|    TypeError is raised:
   921|         0|            0|            0|  0.00%|
   922|         0|            0|            0|  0.00%|    >>> np.bincount(np.arange(5, dtype=float))
   923|         0|            0|            0|  0.00%|    Traceback (most recent call last):
   924|         0|            0|            0|  0.00%|      ...
   925|         0|            0|            0|  0.00%|    TypeError: Cannot cast array data from dtype('float64') to dtype('int64')
   926|         0|            0|            0|  0.00%|    according to the rule 'safe'
   927|         0|            0|            0|  0.00%|
   928|         0|            0|            0|  0.00%|    A possible use of ``bincount`` is to perform sums over
   929|         0|            0|            0|  0.00%|    variable-size chunks of an array, using the ``weights`` keyword.
   930|         0|            0|            0|  0.00%|
   931|         0|            0|            0|  0.00%|    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights
   932|         0|            0|            0|  0.00%|    >>> x = np.array([0, 1, 1, 2, 2, 2])
   933|         0|            0|            0|  0.00%|    >>> np.bincount(x,  weights=w)
   934|         0|            0|            0|  0.00%|    array([ 0.3,  0.7,  1.1])
   935|         0|            0|            0|  0.00%|
   936|         0|            0|            0|  0.00%|    """
   937|         0|            0|            0|  0.00%|    return (x, weights)
   938|         0|            0|            0|  0.00%|
   939|         0|            0|            0|  0.00%|
   940|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.ravel_multi_index)
   941|         0|            0|            0|  0.00%|def ravel_multi_index(multi_index, dims, mode=None, order=None):
   942|         0|            0|            0|  0.00%|    """
   943|         0|            0|            0|  0.00%|    ravel_multi_index(multi_index, dims, mode='raise', order='C')
   944|         0|            0|            0|  0.00%|
   945|         0|            0|            0|  0.00%|    Converts a tuple of index arrays into an array of flat
   946|         0|            0|            0|  0.00%|    indices, applying boundary modes to the multi-index.
   947|         0|            0|            0|  0.00%|
   948|         0|            0|            0|  0.00%|    Parameters
   949|         0|            0|            0|  0.00%|    ----------
   950|         0|            0|            0|  0.00%|    multi_index : tuple of array_like
   951|         0|            0|            0|  0.00%|        A tuple of integer arrays, one array for each dimension.
   952|         0|            0|            0|  0.00%|    dims : tuple of ints
   953|         0|            0|            0|  0.00%|        The shape of array into which the indices from ``multi_index`` apply.
   954|         0|            0|            0|  0.00%|    mode : {'raise', 'wrap', 'clip'}, optional
   955|         0|            0|            0|  0.00%|        Specifies how out-of-bounds indices are handled.  Can specify
   956|         0|            0|            0|  0.00%|        either one mode or a tuple of modes, one mode per index.
   957|         0|            0|            0|  0.00%|
   958|         0|            0|            0|  0.00%|        * 'raise' -- raise an error (default)
   959|         0|            0|            0|  0.00%|        * 'wrap' -- wrap around
   960|         0|            0|            0|  0.00%|        * 'clip' -- clip to the range
   961|         0|            0|            0|  0.00%|
   962|         0|            0|            0|  0.00%|        In 'clip' mode, a negative index which would normally
   963|         0|            0|            0|  0.00%|        wrap will clip to 0 instead.
   964|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional
   965|         0|            0|            0|  0.00%|        Determines whether the multi-index should be viewed as
   966|         0|            0|            0|  0.00%|        indexing in row-major (C-style) or column-major
   967|         0|            0|            0|  0.00%|        (Fortran-style) order.
   968|         0|            0|            0|  0.00%|
   969|         0|            0|            0|  0.00%|    Returns
   970|         0|            0|            0|  0.00%|    -------
   971|         0|            0|            0|  0.00%|    raveled_indices : ndarray
   972|         0|            0|            0|  0.00%|        An array of indices into the flattened version of an array
   973|         0|            0|            0|  0.00%|        of dimensions ``dims``.
   974|         0|            0|            0|  0.00%|
   975|         0|            0|            0|  0.00%|    See Also
   976|         0|            0|            0|  0.00%|    --------
   977|         0|            0|            0|  0.00%|    unravel_index
   978|         0|            0|            0|  0.00%|
   979|         0|            0|            0|  0.00%|    Notes
   980|         0|            0|            0|  0.00%|    -----
   981|         0|            0|            0|  0.00%|    .. versionadded:: 1.6.0
   982|         0|            0|            0|  0.00%|
   983|         0|            0|            0|  0.00%|    Examples
   984|         0|            0|            0|  0.00%|    --------
   985|         0|            0|            0|  0.00%|    >>> arr = np.array([[3,6,6],[4,5,1]])
   986|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (7,6))
   987|         0|            0|            0|  0.00%|    array([22, 41, 37])
   988|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (7,6), order='F')
   989|         0|            0|            0|  0.00%|    array([31, 41, 13])
   990|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (4,6), mode='clip')
   991|         0|            0|            0|  0.00%|    array([22, 23, 19])
   992|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))
   993|         0|            0|            0|  0.00%|    array([12, 13, 13])
   994|         0|            0|            0|  0.00%|
   995|         0|            0|            0|  0.00%|    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))
   996|         0|            0|            0|  0.00%|    1621
   997|         0|            0|            0|  0.00%|    """
   998|         0|            0|            0|  0.00%|    return multi_index
   999|         0|            0|            0|  0.00%|
  1000|         0|            0|            0|  0.00%|
  1001|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.unravel_index)
  1002|         0|            0|            0|  0.00%|def unravel_index(indices, shape=None, order=None, dims=None):
  1003|         0|            0|            0|  0.00%|    """
  1004|         0|            0|            0|  0.00%|    unravel_index(indices, shape, order='C')
  1005|         0|            0|            0|  0.00%|
  1006|         0|            0|            0|  0.00%|    Converts a flat index or array of flat indices into a tuple
  1007|         0|            0|            0|  0.00%|    of coordinate arrays.
  1008|         0|            0|            0|  0.00%|
  1009|         0|            0|            0|  0.00%|    Parameters
  1010|         0|            0|            0|  0.00%|    ----------
  1011|         0|            0|            0|  0.00%|    indices : array_like
  1012|         0|            0|            0|  0.00%|        An integer array whose elements are indices into the flattened
  1013|         0|            0|            0|  0.00%|        version of an array of dimensions ``shape``. Before version 1.6.0,
  1014|         0|            0|            0|  0.00%|        this function accepted just one index value.
  1015|         0|            0|            0|  0.00%|    shape : tuple of ints
  1016|         0|            0|            0|  0.00%|        The shape of the array to use for unraveling ``indices``.
  1017|         0|            0|            0|  0.00%|
  1018|         0|            0|            0|  0.00%|        .. versionchanged:: 1.16.0
  1019|         0|            0|            0|  0.00%|            Renamed from ``dims`` to ``shape``.
  1020|         0|            0|            0|  0.00%|
  1021|         0|            0|            0|  0.00%|    order : {'C', 'F'}, optional
  1022|         0|            0|            0|  0.00%|        Determines whether the indices should be viewed as indexing in
  1023|         0|            0|            0|  0.00%|        row-major (C-style) or column-major (Fortran-style) order.
  1024|         0|            0|            0|  0.00%|
  1025|         0|            0|            0|  0.00%|        .. versionadded:: 1.6.0
  1026|         0|            0|            0|  0.00%|
  1027|         0|            0|            0|  0.00%|    Returns
  1028|         0|            0|            0|  0.00%|    -------
  1029|         0|            0|            0|  0.00%|    unraveled_coords : tuple of ndarray
  1030|         0|            0|            0|  0.00%|        Each array in the tuple has the same shape as the ``indices``
  1031|         0|            0|            0|  0.00%|        array.
  1032|         0|            0|            0|  0.00%|
  1033|         0|            0|            0|  0.00%|    See Also
  1034|         0|            0|            0|  0.00%|    --------
  1035|         0|            0|            0|  0.00%|    ravel_multi_index
  1036|         0|            0|            0|  0.00%|
  1037|         0|            0|            0|  0.00%|    Examples
  1038|         0|            0|            0|  0.00%|    --------
  1039|         0|            0|            0|  0.00%|    >>> np.unravel_index([22, 41, 37], (7,6))
  1040|         0|            0|            0|  0.00%|    (array([3, 6, 6]), array([4, 5, 1]))
  1041|         0|            0|            0|  0.00%|    >>> np.unravel_index([31, 41, 13], (7,6), order='F')
  1042|         0|            0|            0|  0.00%|    (array([3, 6, 6]), array([4, 5, 1]))
  1043|         0|            0|            0|  0.00%|
  1044|         0|            0|            0|  0.00%|    >>> np.unravel_index(1621, (6,7,8,9))
  1045|         0|            0|            0|  0.00%|    (3, 1, 4, 1)
  1046|         0|            0|            0|  0.00%|
  1047|         0|            0|            0|  0.00%|    """
  1048|         0|            0|            0|  0.00%|    if dims is not None:
  1049|         0|            0|            0|  0.00%|        warnings.warn("'shape' argument should be used instead of 'dims'",
  1050|         0|            0|            0|  0.00%|                      DeprecationWarning, stacklevel=3)
  1051|         0|            0|            0|  0.00%|    return (indices,)
  1052|         0|            0|            0|  0.00%|
  1053|         0|            0|            0|  0.00%|
  1054|         2|   3.8147e-06|  1.90735e-06|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.copyto)
  1055|         0|            0|            0|  0.00%|def copyto(dst, src, casting=None, where=None):
  1056|         0|            0|            0|  0.00%|    """
  1057|         0|            0|            0|  0.00%|    copyto(dst, src, casting='same_kind', where=True)
  1058|         0|            0|            0|  0.00%|
  1059|         0|            0|            0|  0.00%|    Copies values from one array to another, broadcasting as necessary.
  1060|         0|            0|            0|  0.00%|
  1061|         0|            0|            0|  0.00%|    Raises a TypeError if the `casting` rule is violated, and if
  1062|         0|            0|            0|  0.00%|    `where` is provided, it selects which elements to copy.
  1063|         0|            0|            0|  0.00%|
  1064|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1065|         0|            0|            0|  0.00%|
  1066|         0|            0|            0|  0.00%|    Parameters
  1067|         0|            0|            0|  0.00%|    ----------
  1068|         0|            0|            0|  0.00%|    dst : ndarray
  1069|         0|            0|            0|  0.00%|        The array into which values are copied.
  1070|         0|            0|            0|  0.00%|    src : array_like
  1071|         0|            0|            0|  0.00%|        The array from which values are copied.
  1072|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional
  1073|         0|            0|            0|  0.00%|        Controls what kind of data casting may occur when copying.
  1074|         0|            0|            0|  0.00%|
  1075|         0|            0|            0|  0.00%|          * 'no' means the data types should not be cast at all.
  1076|         0|            0|            0|  0.00%|          * 'equiv' means only byte-order changes are allowed.
  1077|         0|            0|            0|  0.00%|          * 'safe' means only casts which can preserve values are allowed.
  1078|         0|            0|            0|  0.00%|          * 'same_kind' means only safe casts or casts within a kind,
  1079|         0|            0|            0|  0.00%|            like float64 to float32, are allowed.
  1080|         0|            0|            0|  0.00%|          * 'unsafe' means any data conversions may be done.
  1081|         0|            0|            0|  0.00%|    where : array_like of bool, optional
  1082|         0|            0|            0|  0.00%|        A boolean array which is broadcasted to match the dimensions
  1083|         0|            0|            0|  0.00%|        of `dst`, and selects elements to copy from `src` to `dst`
  1084|         0|            0|            0|  0.00%|        wherever it contains the value True.
  1085|         0|            0|            0|  0.00%|    """
  1086|         2|  4.52995e-06|  2.26498e-06|  0.00%|    return (dst, src, where)
  1087|         0|            0|            0|  0.00%|
  1088|         0|            0|            0|  0.00%|
  1089|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.putmask)
  1090|         0|            0|            0|  0.00%|def putmask(a, mask, values):
  1091|         0|            0|            0|  0.00%|    """
  1092|         0|            0|            0|  0.00%|    putmask(a, mask, values)
  1093|         0|            0|            0|  0.00%|
  1094|         0|            0|            0|  0.00%|    Changes elements of an array based on conditional and input values.
  1095|         0|            0|            0|  0.00%|
  1096|         0|            0|            0|  0.00%|    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.
  1097|         0|            0|            0|  0.00%|
  1098|         0|            0|            0|  0.00%|    If `values` is not the same size as `a` and `mask` then it will repeat.
  1099|         0|            0|            0|  0.00%|    This gives behavior different from ``a[mask] = values``.
  1100|         0|            0|            0|  0.00%|
  1101|         0|            0|            0|  0.00%|    Parameters
  1102|         0|            0|            0|  0.00%|    ----------
  1103|         0|            0|            0|  0.00%|    a : ndarray
  1104|         0|            0|            0|  0.00%|        Target array.
  1105|         0|            0|            0|  0.00%|    mask : array_like
  1106|         0|            0|            0|  0.00%|        Boolean mask array. It has to be the same shape as `a`.
  1107|         0|            0|            0|  0.00%|    values : array_like
  1108|         0|            0|            0|  0.00%|        Values to put into `a` where `mask` is True. If `values` is smaller
  1109|         0|            0|            0|  0.00%|        than `a` it will be repeated.
  1110|         0|            0|            0|  0.00%|
  1111|         0|            0|            0|  0.00%|    See Also
  1112|         0|            0|            0|  0.00%|    --------
  1113|         0|            0|            0|  0.00%|    place, put, take, copyto
  1114|         0|            0|            0|  0.00%|
  1115|         0|            0|            0|  0.00%|    Examples
  1116|         0|            0|            0|  0.00%|    --------
  1117|         0|            0|            0|  0.00%|    >>> x = np.arange(6).reshape(2, 3)
  1118|         0|            0|            0|  0.00%|    >>> np.putmask(x, x>2, x**2)
  1119|         0|            0|            0|  0.00%|    >>> x
  1120|         0|            0|            0|  0.00%|    array([[ 0,  1,  2],
  1121|         0|            0|            0|  0.00%|           [ 9, 16, 25]])
  1122|         0|            0|            0|  0.00%|
  1123|         0|            0|            0|  0.00%|    If `values` is smaller than `a` it is repeated:
  1124|         0|            0|            0|  0.00%|
  1125|         0|            0|            0|  0.00%|    >>> x = np.arange(5)
  1126|         0|            0|            0|  0.00%|    >>> np.putmask(x, x>1, [-33, -44])
  1127|         0|            0|            0|  0.00%|    >>> x
  1128|         0|            0|            0|  0.00%|    array([  0,   1, -33, -44, -33])
  1129|         0|            0|            0|  0.00%|
  1130|         0|            0|            0|  0.00%|    """
  1131|         0|            0|            0|  0.00%|    return (a, mask, values)
  1132|         0|            0|            0|  0.00%|
  1133|         0|            0|            0|  0.00%|
  1134|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.packbits)
  1135|         0|            0|            0|  0.00%|def packbits(a, axis=None, bitorder='big'):
  1136|         0|            0|            0|  0.00%|    """
  1137|         0|            0|            0|  0.00%|    packbits(a, axis=None, bitorder='big')
  1138|         0|            0|            0|  0.00%|
  1139|         0|            0|            0|  0.00%|    Packs the elements of a binary-valued array into bits in a uint8 array.
  1140|         0|            0|            0|  0.00%|
  1141|         0|            0|            0|  0.00%|    The result is padded to full bytes by inserting zero bits at the end.
  1142|         0|            0|            0|  0.00%|
  1143|         0|            0|            0|  0.00%|    Parameters
  1144|         0|            0|            0|  0.00%|    ----------
  1145|         0|            0|            0|  0.00%|    a : array_like
  1146|         0|            0|            0|  0.00%|        An array of integers or booleans whose elements should be packed to
  1147|         0|            0|            0|  0.00%|        bits.
  1148|         0|            0|            0|  0.00%|    axis : int, optional
  1149|         0|            0|            0|  0.00%|        The dimension over which bit-packing is done.
  1150|         0|            0|            0|  0.00%|        ``None`` implies packing the flattened array.
  1151|         0|            0|            0|  0.00%|    bitorder : {'big', 'little'}, optional
  1152|         0|            0|            0|  0.00%|        The order of the input bits. 'big' will mimic bin(val),
  1153|         0|            0|            0|  0.00%|        ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will
  1154|         0|            0|            0|  0.00%|        reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.
  1155|         0|            0|            0|  0.00%|        Defaults to 'big'.
  1156|         0|            0|            0|  0.00%|
  1157|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  1158|         0|            0|            0|  0.00%|
  1159|         0|            0|            0|  0.00%|    Returns
  1160|         0|            0|            0|  0.00%|    -------
  1161|         0|            0|            0|  0.00%|    packed : ndarray
  1162|         0|            0|            0|  0.00%|        Array of type uint8 whose elements represent bits corresponding to the
  1163|         0|            0|            0|  0.00%|        logical (0 or nonzero) value of the input elements. The shape of
  1164|         0|            0|            0|  0.00%|        `packed` has the same number of dimensions as the input (unless `axis`
  1165|         0|            0|            0|  0.00%|        is None, in which case the output is 1-D).
  1166|         0|            0|            0|  0.00%|
  1167|         0|            0|            0|  0.00%|    See Also
  1168|         0|            0|            0|  0.00%|    --------
  1169|         0|            0|            0|  0.00%|    unpackbits: Unpacks elements of a uint8 array into a binary-valued output
  1170|         0|            0|            0|  0.00%|                array.
  1171|         0|            0|            0|  0.00%|
  1172|         0|            0|            0|  0.00%|    Examples
  1173|         0|            0|            0|  0.00%|    --------
  1174|         0|            0|            0|  0.00%|    >>> a = np.array([[[1,0,1],
  1175|         0|            0|            0|  0.00%|    ...                [0,1,0]],
  1176|         0|            0|            0|  0.00%|    ...               [[1,1,0],
  1177|         0|            0|            0|  0.00%|    ...                [0,0,1]]])
  1178|         0|            0|            0|  0.00%|    >>> b = np.packbits(a, axis=-1)
  1179|         0|            0|            0|  0.00%|    >>> b
  1180|         0|            0|            0|  0.00%|    array([[[160],
  1181|         0|            0|            0|  0.00%|            [ 64]],
  1182|         0|            0|            0|  0.00%|           [[192],
  1183|         0|            0|            0|  0.00%|            [ 32]]], dtype=uint8)
  1184|         0|            0|            0|  0.00%|
  1185|         0|            0|            0|  0.00%|    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,
  1186|         0|            0|            0|  0.00%|    and 32 = 0010 0000.
  1187|         0|            0|            0|  0.00%|
  1188|         0|            0|            0|  0.00%|    """
  1189|         0|            0|            0|  0.00%|    return (a,)
  1190|         0|            0|            0|  0.00%|
  1191|         0|            0|            0|  0.00%|
  1192|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.unpackbits)
  1193|         0|            0|            0|  0.00%|def unpackbits(a, axis=None, count=None, bitorder='big'):
  1194|         0|            0|            0|  0.00%|    """
  1195|         0|            0|            0|  0.00%|    unpackbits(a, axis=None, count=None, bitorder='big')
  1196|         0|            0|            0|  0.00%|
  1197|         0|            0|            0|  0.00%|    Unpacks elements of a uint8 array into a binary-valued output array.
  1198|         0|            0|            0|  0.00%|
  1199|         0|            0|            0|  0.00%|    Each element of `a` represents a bit-field that should be unpacked
  1200|         0|            0|            0|  0.00%|    into a binary-valued output array. The shape of the output array is
  1201|         0|            0|            0|  0.00%|    either 1-D (if `axis` is ``None``) or the same shape as the input
  1202|         0|            0|            0|  0.00%|    array with unpacking done along the axis specified.
  1203|         0|            0|            0|  0.00%|
  1204|         0|            0|            0|  0.00%|    Parameters
  1205|         0|            0|            0|  0.00%|    ----------
  1206|         0|            0|            0|  0.00%|    a : ndarray, uint8 type
  1207|         0|            0|            0|  0.00%|       Input array.
  1208|         0|            0|            0|  0.00%|    axis : int, optional
  1209|         0|            0|            0|  0.00%|        The dimension over which bit-unpacking is done.
  1210|         0|            0|            0|  0.00%|        ``None`` implies unpacking the flattened array.
  1211|         0|            0|            0|  0.00%|    count : int or None, optional
  1212|         0|            0|            0|  0.00%|        The number of elements to unpack along `axis`, provided as a way
  1213|         0|            0|            0|  0.00%|        of undoing the effect of packing a size that is not a multiple
  1214|         0|            0|            0|  0.00%|        of eight. A non-negative number means to only unpack `count`
  1215|         0|            0|            0|  0.00%|        bits. A negative number means to trim off that many bits from
  1216|         0|            0|            0|  0.00%|        the end. ``None`` means to unpack the entire array (the
  1217|         0|            0|            0|  0.00%|        default). Counts larger than the available number of bits will
  1218|         0|            0|            0|  0.00%|        add zero padding to the output. Negative counts must not
  1219|         0|            0|            0|  0.00%|        exceed the available number of bits.
  1220|         0|            0|            0|  0.00%|
  1221|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  1222|         0|            0|            0|  0.00%|
  1223|         0|            0|            0|  0.00%|    bitorder : {'big', 'little'}, optional
  1224|         0|            0|            0|  0.00%|        The order of the returned bits. 'big' will mimic bin(val),
  1225|         0|            0|            0|  0.00%|        ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse
  1226|         0|            0|            0|  0.00%|        the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.
  1227|         0|            0|            0|  0.00%|        Defaults to 'big'.
  1228|         0|            0|            0|  0.00%|
  1229|         0|            0|            0|  0.00%|        .. versionadded:: 1.17.0
  1230|         0|            0|            0|  0.00%|
  1231|         0|            0|            0|  0.00%|    Returns
  1232|         0|            0|            0|  0.00%|    -------
  1233|         0|            0|            0|  0.00%|    unpacked : ndarray, uint8 type
  1234|         0|            0|            0|  0.00%|       The elements are binary-valued (0 or 1).
  1235|         0|            0|            0|  0.00%|
  1236|         0|            0|            0|  0.00%|    See Also
  1237|         0|            0|            0|  0.00%|    --------
  1238|         0|            0|            0|  0.00%|    packbits : Packs the elements of a binary-valued array into bits in
  1239|         0|            0|            0|  0.00%|               a uint8 array.
  1240|         0|            0|            0|  0.00%|
  1241|         0|            0|            0|  0.00%|    Examples
  1242|         0|            0|            0|  0.00%|    --------
  1243|         0|            0|            0|  0.00%|    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)
  1244|         0|            0|            0|  0.00%|    >>> a
  1245|         0|            0|            0|  0.00%|    array([[ 2],
  1246|         0|            0|            0|  0.00%|           [ 7],
  1247|         0|            0|            0|  0.00%|           [23]], dtype=uint8)
  1248|         0|            0|            0|  0.00%|    >>> b = np.unpackbits(a, axis=1)
  1249|         0|            0|            0|  0.00%|    >>> b
  1250|         0|            0|            0|  0.00%|    array([[0, 0, 0, 0, 0, 0, 1, 0],
  1251|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 1, 1, 1],
  1252|         0|            0|            0|  0.00%|           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)
  1253|         0|            0|            0|  0.00%|    >>> c = np.unpackbits(a, axis=1, count=-3)
  1254|         0|            0|            0|  0.00%|    >>> c
  1255|         0|            0|            0|  0.00%|    array([[0, 0, 0, 0, 0],
  1256|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0],
  1257|         0|            0|            0|  0.00%|           [0, 0, 0, 1, 0]], dtype=uint8)
  1258|         0|            0|            0|  0.00%|
  1259|         0|            0|            0|  0.00%|    >>> p = np.packbits(b, axis=0)
  1260|         0|            0|            0|  0.00%|    >>> np.unpackbits(p, axis=0)
  1261|         0|            0|            0|  0.00%|    array([[0, 0, 0, 0, 0, 0, 1, 0],
  1262|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 1, 1, 1],
  1263|         0|            0|            0|  0.00%|           [0, 0, 0, 1, 0, 1, 1, 1],
  1264|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1265|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1266|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1267|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0],
  1268|         0|            0|            0|  0.00%|           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)
  1269|         0|            0|            0|  0.00%|    >>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))
  1270|         0|            0|            0|  0.00%|    True
  1271|         0|            0|            0|  0.00%|
  1272|         0|            0|            0|  0.00%|    """
  1273|         0|            0|            0|  0.00%|    return (a,)
  1274|         0|            0|            0|  0.00%|
  1275|         0|            0|            0|  0.00%|
  1276|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.shares_memory)
  1277|         0|            0|            0|  0.00%|def shares_memory(a, b, max_work=None):
  1278|         0|            0|            0|  0.00%|    """
  1279|         0|            0|            0|  0.00%|    shares_memory(a, b, max_work=None)
  1280|         0|            0|            0|  0.00%|
  1281|         0|            0|            0|  0.00%|    Determine if two arrays share memory.
  1282|         0|            0|            0|  0.00%|
  1283|         0|            0|            0|  0.00%|    .. warning::
  1284|         0|            0|            0|  0.00%|
  1285|         0|            0|            0|  0.00%|       This function can be exponentially slow for some inputs, unless
  1286|         0|            0|            0|  0.00%|       `max_work` is set to a finite number or ``MAY_SHARE_BOUNDS``.
  1287|         0|            0|            0|  0.00%|       If in doubt, use `numpy.may_share_memory` instead.
  1288|         0|            0|            0|  0.00%|
  1289|         0|            0|            0|  0.00%|    Parameters
  1290|         0|            0|            0|  0.00%|    ----------
  1291|         0|            0|            0|  0.00%|    a, b : ndarray
  1292|         0|            0|            0|  0.00%|        Input arrays
  1293|         0|            0|            0|  0.00%|    max_work : int, optional
  1294|         0|            0|            0|  0.00%|        Effort to spend on solving the overlap problem (maximum number
  1295|         0|            0|            0|  0.00%|        of candidate solutions to consider). The following special
  1296|         0|            0|            0|  0.00%|        values are recognized:
  1297|         0|            0|            0|  0.00%|
  1298|         0|            0|            0|  0.00%|        max_work=MAY_SHARE_EXACT  (default)
  1299|         0|            0|            0|  0.00%|            The problem is solved exactly. In this case, the function returns
  1300|         0|            0|            0|  0.00%|            True only if there is an element shared between the arrays. Finding
  1301|         0|            0|            0|  0.00%|            the exact solution may take extremely long in some cases.
  1302|         0|            0|            0|  0.00%|        max_work=MAY_SHARE_BOUNDS
  1303|         0|            0|            0|  0.00%|            Only the memory bounds of a and b are checked.
  1304|         0|            0|            0|  0.00%|
  1305|         0|            0|            0|  0.00%|    Raises
  1306|         0|            0|            0|  0.00%|    ------
  1307|         0|            0|            0|  0.00%|    numpy.TooHardError
  1308|         0|            0|            0|  0.00%|        Exceeded max_work.
  1309|         0|            0|            0|  0.00%|
  1310|         0|            0|            0|  0.00%|    Returns
  1311|         0|            0|            0|  0.00%|    -------
  1312|         0|            0|            0|  0.00%|    out : bool
  1313|         0|            0|            0|  0.00%|
  1314|         0|            0|            0|  0.00%|    See Also
  1315|         0|            0|            0|  0.00%|    --------
  1316|         0|            0|            0|  0.00%|    may_share_memory
  1317|         0|            0|            0|  0.00%|
  1318|         0|            0|            0|  0.00%|    Examples
  1319|         0|            0|            0|  0.00%|    --------
  1320|         0|            0|            0|  0.00%|    >>> x = np.array([1, 2, 3, 4])
  1321|         0|            0|            0|  0.00%|    >>> np.shares_memory(x, np.array([5, 6, 7]))
  1322|         0|            0|            0|  0.00%|    False
  1323|         0|            0|            0|  0.00%|    >>> np.shares_memory(x[::2], x)
  1324|         0|            0|            0|  0.00%|    True
  1325|         0|            0|            0|  0.00%|    >>> np.shares_memory(x[::2], x[1::2])
  1326|         0|            0|            0|  0.00%|    False
  1327|         0|            0|            0|  0.00%|
  1328|         0|            0|            0|  0.00%|    Checking whether two arrays share memory is NP-complete, and
  1329|         0|            0|            0|  0.00%|    runtime may increase exponentially in the number of
  1330|         0|            0|            0|  0.00%|    dimensions. Hence, `max_work` should generally be set to a finite
  1331|         0|            0|            0|  0.00%|    number, as it is possible to construct examples that take
  1332|         0|            0|            0|  0.00%|    extremely long to run:
  1333|         0|            0|            0|  0.00%|
  1334|         0|            0|            0|  0.00%|    >>> from numpy.lib.stride_tricks import as_strided
  1335|         0|            0|            0|  0.00%|    >>> x = np.zeros([192163377], dtype=np.int8)
  1336|         0|            0|            0|  0.00%|    >>> x1 = as_strided(x, strides=(36674, 61119, 85569), shape=(1049, 1049, 1049))
  1337|         0|            0|            0|  0.00%|    >>> x2 = as_strided(x[64023025:], strides=(12223, 12224, 1), shape=(1049, 1049, 1))
  1338|         0|            0|            0|  0.00%|    >>> np.shares_memory(x1, x2, max_work=1000)
  1339|         0|            0|            0|  0.00%|    Traceback (most recent call last):
  1340|         0|            0|            0|  0.00%|    ...
  1341|         0|            0|            0|  0.00%|    numpy.TooHardError: Exceeded max_work
  1342|         0|            0|            0|  0.00%|
  1343|         0|            0|            0|  0.00%|    Running ``np.shares_memory(x1, x2)`` without `max_work` set takes
  1344|         0|            0|            0|  0.00%|    around 1 minute for this case. It is possible to find problems
  1345|         0|            0|            0|  0.00%|    that take still significantly longer.
  1346|         0|            0|            0|  0.00%|
  1347|         0|            0|            0|  0.00%|    """
  1348|         0|            0|            0|  0.00%|    return (a, b)
  1349|         0|            0|            0|  0.00%|
  1350|         0|            0|            0|  0.00%|
  1351|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.may_share_memory)
  1352|         0|            0|            0|  0.00%|def may_share_memory(a, b, max_work=None):
  1353|         0|            0|            0|  0.00%|    """
  1354|         0|            0|            0|  0.00%|    may_share_memory(a, b, max_work=None)
  1355|         0|            0|            0|  0.00%|
  1356|         0|            0|            0|  0.00%|    Determine if two arrays might share memory
  1357|         0|            0|            0|  0.00%|
  1358|         0|            0|            0|  0.00%|    A return of True does not necessarily mean that the two arrays
  1359|         0|            0|            0|  0.00%|    share any element.  It just means that they *might*.
  1360|         0|            0|            0|  0.00%|
  1361|         0|            0|            0|  0.00%|    Only the memory bounds of a and b are checked by default.
  1362|         0|            0|            0|  0.00%|
  1363|         0|            0|            0|  0.00%|    Parameters
  1364|         0|            0|            0|  0.00%|    ----------
  1365|         0|            0|            0|  0.00%|    a, b : ndarray
  1366|         0|            0|            0|  0.00%|        Input arrays
  1367|         0|            0|            0|  0.00%|    max_work : int, optional
  1368|         0|            0|            0|  0.00%|        Effort to spend on solving the overlap problem.  See
  1369|         0|            0|            0|  0.00%|        `shares_memory` for details.  Default for ``may_share_memory``
  1370|         0|            0|            0|  0.00%|        is to do a bounds check.
  1371|         0|            0|            0|  0.00%|
  1372|         0|            0|            0|  0.00%|    Returns
  1373|         0|            0|            0|  0.00%|    -------
  1374|         0|            0|            0|  0.00%|    out : bool
  1375|         0|            0|            0|  0.00%|
  1376|         0|            0|            0|  0.00%|    See Also
  1377|         0|            0|            0|  0.00%|    --------
  1378|         0|            0|            0|  0.00%|    shares_memory
  1379|         0|            0|            0|  0.00%|
  1380|         0|            0|            0|  0.00%|    Examples
  1381|         0|            0|            0|  0.00%|    --------
  1382|         0|            0|            0|  0.00%|    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))
  1383|         0|            0|            0|  0.00%|    False
  1384|         0|            0|            0|  0.00%|    >>> x = np.zeros([3, 4])
  1385|         0|            0|            0|  0.00%|    >>> np.may_share_memory(x[:,0], x[:,1])
  1386|         0|            0|            0|  0.00%|    True
  1387|         0|            0|            0|  0.00%|
  1388|         0|            0|            0|  0.00%|    """
  1389|         0|            0|            0|  0.00%|    return (a, b)
  1390|         0|            0|            0|  0.00%|
  1391|         0|            0|            0|  0.00%|
  1392|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.is_busday)
  1393|         0|            0|            0|  0.00%|def is_busday(dates, weekmask=None, holidays=None, busdaycal=None, out=None):
  1394|         0|            0|            0|  0.00%|    """
  1395|         0|            0|            0|  0.00%|    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)
  1396|         0|            0|            0|  0.00%|
  1397|         0|            0|            0|  0.00%|    Calculates which of the given dates are valid days, and which are not.
  1398|         0|            0|            0|  0.00%|
  1399|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1400|         0|            0|            0|  0.00%|
  1401|         0|            0|            0|  0.00%|    Parameters
  1402|         0|            0|            0|  0.00%|    ----------
  1403|         0|            0|            0|  0.00%|    dates : array_like of datetime64[D]
  1404|         0|            0|            0|  0.00%|        The array of dates to process.
  1405|         0|            0|            0|  0.00%|    weekmask : str or array_like of bool, optional
  1406|         0|            0|            0|  0.00%|        A seven-element array indicating which of Monday through Sunday are
  1407|         0|            0|            0|  0.00%|        valid days. May be specified as a length-seven list or array, like
  1408|         0|            0|            0|  0.00%|        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
  1409|         0|            0|            0|  0.00%|        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
  1410|         0|            0|            0|  0.00%|        weekdays, optionally separated by white space. Valid abbreviations
  1411|         0|            0|            0|  0.00%|        are: Mon Tue Wed Thu Fri Sat Sun
  1412|         0|            0|            0|  0.00%|    holidays : array_like of datetime64[D], optional
  1413|         0|            0|            0|  0.00%|        An array of dates to consider as invalid dates.  They may be
  1414|         0|            0|            0|  0.00%|        specified in any order, and NaT (not-a-time) dates are ignored.
  1415|         0|            0|            0|  0.00%|        This list is saved in a normalized form that is suited for
  1416|         0|            0|            0|  0.00%|        fast calculations of valid days.
  1417|         0|            0|            0|  0.00%|    busdaycal : busdaycalendar, optional
  1418|         0|            0|            0|  0.00%|        A `busdaycalendar` object which specifies the valid days. If this
  1419|         0|            0|            0|  0.00%|        parameter is provided, neither weekmask nor holidays may be
  1420|         0|            0|            0|  0.00%|        provided.
  1421|         0|            0|            0|  0.00%|    out : array of bool, optional
  1422|         0|            0|            0|  0.00%|        If provided, this array is filled with the result.
  1423|         0|            0|            0|  0.00%|
  1424|         0|            0|            0|  0.00%|    Returns
  1425|         0|            0|            0|  0.00%|    -------
  1426|         0|            0|            0|  0.00%|    out : array of bool
  1427|         0|            0|            0|  0.00%|        An array with the same shape as ``dates``, containing True for
  1428|         0|            0|            0|  0.00%|        each valid day, and False for each invalid day.
  1429|         0|            0|            0|  0.00%|
  1430|         0|            0|            0|  0.00%|    See Also
  1431|         0|            0|            0|  0.00%|    --------
  1432|         0|            0|            0|  0.00%|    busdaycalendar: An object that specifies a custom set of valid days.
  1433|         0|            0|            0|  0.00%|    busday_offset : Applies an offset counted in valid days.
  1434|         0|            0|            0|  0.00%|    busday_count : Counts how many valid days are in a half-open date range.
  1435|         0|            0|            0|  0.00%|
  1436|         0|            0|            0|  0.00%|    Examples
  1437|         0|            0|            0|  0.00%|    --------
  1438|         0|            0|            0|  0.00%|    >>> # The weekdays are Friday, Saturday, and Monday
  1439|         0|            0|            0|  0.00%|    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],
  1440|         0|            0|            0|  0.00%|    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])
  1441|         0|            0|            0|  0.00%|    array([False, False,  True])
  1442|         0|            0|            0|  0.00%|    """
  1443|         0|            0|            0|  0.00%|    return (dates, weekmask, holidays, out)
  1444|         0|            0|            0|  0.00%|
  1445|         0|            0|            0|  0.00%|
  1446|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.busday_offset)
  1447|         0|            0|            0|  0.00%|def busday_offset(dates, offsets, roll=None, weekmask=None, holidays=None,
  1448|         0|            0|            0|  0.00%|                  busdaycal=None, out=None):
  1449|         0|            0|            0|  0.00%|    """
  1450|         0|            0|            0|  0.00%|    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)
  1451|         0|            0|            0|  0.00%|
  1452|         0|            0|            0|  0.00%|    First adjusts the date to fall on a valid day according to
  1453|         0|            0|            0|  0.00%|    the ``roll`` rule, then applies offsets to the given dates
  1454|         0|            0|            0|  0.00%|    counted in valid days.
  1455|         0|            0|            0|  0.00%|
  1456|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1457|         0|            0|            0|  0.00%|
  1458|         0|            0|            0|  0.00%|    Parameters
  1459|         0|            0|            0|  0.00%|    ----------
  1460|         0|            0|            0|  0.00%|    dates : array_like of datetime64[D]
  1461|         0|            0|            0|  0.00%|        The array of dates to process.
  1462|         0|            0|            0|  0.00%|    offsets : array_like of int
  1463|         0|            0|            0|  0.00%|        The array of offsets, which is broadcast with ``dates``.
  1464|         0|            0|            0|  0.00%|    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional
  1465|         0|            0|            0|  0.00%|        How to treat dates that do not fall on a valid day. The default
  1466|         0|            0|            0|  0.00%|        is 'raise'.
  1467|         0|            0|            0|  0.00%|
  1468|         0|            0|            0|  0.00%|          * 'raise' means to raise an exception for an invalid day.
  1469|         0|            0|            0|  0.00%|          * 'nat' means to return a NaT (not-a-time) for an invalid day.
  1470|         0|            0|            0|  0.00%|          * 'forward' and 'following' mean to take the first valid day
  1471|         0|            0|            0|  0.00%|            later in time.
  1472|         0|            0|            0|  0.00%|          * 'backward' and 'preceding' mean to take the first valid day
  1473|         0|            0|            0|  0.00%|            earlier in time.
  1474|         0|            0|            0|  0.00%|          * 'modifiedfollowing' means to take the first valid day
  1475|         0|            0|            0|  0.00%|            later in time unless it is across a Month boundary, in which
  1476|         0|            0|            0|  0.00%|            case to take the first valid day earlier in time.
  1477|         0|            0|            0|  0.00%|          * 'modifiedpreceding' means to take the first valid day
  1478|         0|            0|            0|  0.00%|            earlier in time unless it is across a Month boundary, in which
  1479|         0|            0|            0|  0.00%|            case to take the first valid day later in time.
  1480|         0|            0|            0|  0.00%|    weekmask : str or array_like of bool, optional
  1481|         0|            0|            0|  0.00%|        A seven-element array indicating which of Monday through Sunday are
  1482|         0|            0|            0|  0.00%|        valid days. May be specified as a length-seven list or array, like
  1483|         0|            0|            0|  0.00%|        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
  1484|         0|            0|            0|  0.00%|        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
  1485|         0|            0|            0|  0.00%|        weekdays, optionally separated by white space. Valid abbreviations
  1486|         0|            0|            0|  0.00%|        are: Mon Tue Wed Thu Fri Sat Sun
  1487|         0|            0|            0|  0.00%|    holidays : array_like of datetime64[D], optional
  1488|         0|            0|            0|  0.00%|        An array of dates to consider as invalid dates.  They may be
  1489|         0|            0|            0|  0.00%|        specified in any order, and NaT (not-a-time) dates are ignored.
  1490|         0|            0|            0|  0.00%|        This list is saved in a normalized form that is suited for
  1491|         0|            0|            0|  0.00%|        fast calculations of valid days.
  1492|         0|            0|            0|  0.00%|    busdaycal : busdaycalendar, optional
  1493|         0|            0|            0|  0.00%|        A `busdaycalendar` object which specifies the valid days. If this
  1494|         0|            0|            0|  0.00%|        parameter is provided, neither weekmask nor holidays may be
  1495|         0|            0|            0|  0.00%|        provided.
  1496|         0|            0|            0|  0.00%|    out : array of datetime64[D], optional
  1497|         0|            0|            0|  0.00%|        If provided, this array is filled with the result.
  1498|         0|            0|            0|  0.00%|
  1499|         0|            0|            0|  0.00%|    Returns
  1500|         0|            0|            0|  0.00%|    -------
  1501|         0|            0|            0|  0.00%|    out : array of datetime64[D]
  1502|         0|            0|            0|  0.00%|        An array with a shape from broadcasting ``dates`` and ``offsets``
  1503|         0|            0|            0|  0.00%|        together, containing the dates with offsets applied.
  1504|         0|            0|            0|  0.00%|
  1505|         0|            0|            0|  0.00%|    See Also
  1506|         0|            0|            0|  0.00%|    --------
  1507|         0|            0|            0|  0.00%|    busdaycalendar: An object that specifies a custom set of valid days.
  1508|         0|            0|            0|  0.00%|    is_busday : Returns a boolean array indicating valid days.
  1509|         0|            0|            0|  0.00%|    busday_count : Counts how many valid days are in a half-open date range.
  1510|         0|            0|            0|  0.00%|
  1511|         0|            0|            0|  0.00%|    Examples
  1512|         0|            0|            0|  0.00%|    --------
  1513|         0|            0|            0|  0.00%|    >>> # First business day in October 2011 (not accounting for holidays)
  1514|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-10', 0, roll='forward')
  1515|         0|            0|            0|  0.00%|    numpy.datetime64('2011-10-03')
  1516|         0|            0|            0|  0.00%|    >>> # Last business day in February 2012 (not accounting for holidays)
  1517|         0|            0|            0|  0.00%|    ... np.busday_offset('2012-03', -1, roll='forward')
  1518|         0|            0|            0|  0.00%|    numpy.datetime64('2012-02-29')
  1519|         0|            0|            0|  0.00%|    >>> # Third Wednesday in January 2011
  1520|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')
  1521|         0|            0|            0|  0.00%|    numpy.datetime64('2011-01-19')
  1522|         0|            0|            0|  0.00%|    >>> # 2012 Mother's Day in Canada and the U.S.
  1523|         0|            0|            0|  0.00%|    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')
  1524|         0|            0|            0|  0.00%|    numpy.datetime64('2012-05-13')
  1525|         0|            0|            0|  0.00%|
  1526|         0|            0|            0|  0.00%|    >>> # First business day on or after a date
  1527|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-03-20', 0, roll='forward')
  1528|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-21')
  1529|         0|            0|            0|  0.00%|    >>> np.busday_offset('2011-03-22', 0, roll='forward')
  1530|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-22')
  1531|         0|            0|            0|  0.00%|    >>> # First business day after a date
  1532|         0|            0|            0|  0.00%|    ... np.busday_offset('2011-03-20', 1, roll='backward')
  1533|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-21')
  1534|         0|            0|            0|  0.00%|    >>> np.busday_offset('2011-03-22', 1, roll='backward')
  1535|         0|            0|            0|  0.00%|    numpy.datetime64('2011-03-23')
  1536|         0|            0|            0|  0.00%|    """
  1537|         0|            0|            0|  0.00%|    return (dates, offsets, weekmask, holidays, out)
  1538|         0|            0|            0|  0.00%|
  1539|         0|            0|            0|  0.00%|
  1540|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(_multiarray_umath.busday_count)
  1541|         0|            0|            0|  0.00%|def busday_count(begindates, enddates, weekmask=None, holidays=None,
  1542|         0|            0|            0|  0.00%|                 busdaycal=None, out=None):
  1543|         0|            0|            0|  0.00%|    """
  1544|         0|            0|            0|  0.00%|    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)
  1545|         0|            0|            0|  0.00%|
  1546|         0|            0|            0|  0.00%|    Counts the number of valid days between `begindates` and
  1547|         0|            0|            0|  0.00%|    `enddates`, not including the day of `enddates`.
  1548|         0|            0|            0|  0.00%|
  1549|         0|            0|            0|  0.00%|    If ``enddates`` specifies a date value that is earlier than the
  1550|         0|            0|            0|  0.00%|    corresponding ``begindates`` date value, the count will be negative.
  1551|         0|            0|            0|  0.00%|
  1552|         0|            0|            0|  0.00%|    .. versionadded:: 1.7.0
  1553|         0|            0|            0|  0.00%|
  1554|         0|            0|            0|  0.00%|    Parameters
  1555|         0|            0|            0|  0.00%|    ----------
  1556|         0|            0|            0|  0.00%|    begindates : array_like of datetime64[D]
  1557|         0|            0|            0|  0.00%|        The array of the first dates for counting.
  1558|         0|            0|            0|  0.00%|    enddates : array_like of datetime64[D]
  1559|         0|            0|            0|  0.00%|        The array of the end dates for counting, which are excluded
  1560|         0|            0|            0|  0.00%|        from the count themselves.
  1561|         0|            0|            0|  0.00%|    weekmask : str or array_like of bool, optional
  1562|         0|            0|            0|  0.00%|        A seven-element array indicating which of Monday through Sunday are
  1563|         0|            0|            0|  0.00%|        valid days. May be specified as a length-seven list or array, like
  1564|         0|            0|            0|  0.00%|        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string
  1565|         0|            0|            0|  0.00%|        like "Mon Tue Wed Thu Fri", made up of 3-character abbreviations for
  1566|         0|            0|            0|  0.00%|        weekdays, optionally separated by white space. Valid abbreviations
  1567|         0|            0|            0|  0.00%|        are: Mon Tue Wed Thu Fri Sat Sun
  1568|         0|            0|            0|  0.00%|    holidays : array_like of datetime64[D], optional
  1569|         0|            0|            0|  0.00%|        An array of dates to consider as invalid dates.  They may be
  1570|         0|            0|            0|  0.00%|        specified in any order, and NaT (not-a-time) dates are ignored.
  1571|         0|            0|            0|  0.00%|        This list is saved in a normalized form that is suited for
  1572|         0|            0|            0|  0.00%|        fast calculations of valid days.
  1573|         0|            0|            0|  0.00%|    busdaycal : busdaycalendar, optional
  1574|         0|            0|            0|  0.00%|        A `busdaycalendar` object which specifies the valid days. If this
  1575|         0|            0|            0|  0.00%|        parameter is provided, neither weekmask nor holidays may be
  1576|         0|            0|            0|  0.00%|        provided.
  1577|         0|            0|            0|  0.00%|    out : array of int, optional
  1578|         0|            0|            0|  0.00%|        If provided, this array is filled with the result.
  1579|         0|            0|            0|  0.00%|
  1580|         0|            0|            0|  0.00%|    Returns
  1581|         0|            0|            0|  0.00%|    -------
  1582|         0|            0|            0|  0.00%|    out : array of int
  1583|         0|            0|            0|  0.00%|        An array with a shape from broadcasting ``begindates`` and ``enddates``
  1584|         0|            0|            0|  0.00%|        together, containing the number of valid days between
  1585|         0|            0|            0|  0.00%|        the begin and end dates.
  1586|         0|            0|            0|  0.00%|
  1587|         0|            0|            0|  0.00%|    See Also
  1588|         0|            0|            0|  0.00%|    --------
  1589|         0|            0|            0|  0.00%|    busdaycalendar: An object that specifies a custom set of valid days.
  1590|         0|            0|            0|  0.00%|    is_busday : Returns a boolean array indicating valid days.
  1591|         0|            0|            0|  0.00%|    busday_offset : Applies an offset counted in valid days.
  1592|         0|            0|            0|  0.00%|
  1593|         0|            0|            0|  0.00%|    Examples
  1594|         0|            0|            0|  0.00%|    --------
  1595|         0|            0|            0|  0.00%|    >>> # Number of weekdays in January 2011
  1596|         0|            0|            0|  0.00%|    ... np.busday_count('2011-01', '2011-02')
  1597|         0|            0|            0|  0.00%|    21
  1598|         0|            0|            0|  0.00%|    >>> # Number of weekdays in 2011
  1599|         0|            0|            0|  0.00%|    >>> np.busday_count('2011', '2012')
  1600|         0|            0|            0|  0.00%|    260
  1601|         0|            0|            0|  0.00%|    >>> # Number of Saturdays in 2011
  1602|         0|            0|            0|  0.00%|    ... np.busday_count('2011', '2012', weekmask='Sat')
  1603|         0|            0|            0|  0.00%|    53
  1604|         0|            0|            0|  0.00%|    """
  1605|         0|            0|            0|  0.00%|    return (begindates, enddates, weekmask, holidays, out)
  1606|         0|            0|            0|  0.00%|
  1607|         0|            0|            0|  0.00%|
  1608|         0|            0|            0|  0.00%|@array_function_from_c_func_and_dispatcher(
  1609|         0|            0|            0|  0.00%|    _multiarray_umath.datetime_as_string)
  1610|         0|            0|            0|  0.00%|def datetime_as_string(arr, unit=None, timezone=None, casting=None):
  1611|         0|            0|            0|  0.00%|    """
  1612|         0|            0|            0|  0.00%|    datetime_as_string(arr, unit=None, timezone='naive', casting='same_kind')
  1613|         0|            0|            0|  0.00%|
  1614|         0|            0|            0|  0.00%|    Convert an array of datetimes into an array of strings.
  1615|         0|            0|            0|  0.00%|
  1616|         0|            0|            0|  0.00%|    Parameters
  1617|         0|            0|            0|  0.00%|    ----------
  1618|         0|            0|            0|  0.00%|    arr : array_like of datetime64
  1619|         0|            0|            0|  0.00%|        The array of UTC timestamps to format.
  1620|         0|            0|            0|  0.00%|    unit : str
  1621|         0|            0|            0|  0.00%|        One of None, 'auto', or a :ref:`datetime unit <arrays.dtypes.dateunits>`.
  1622|         0|            0|            0|  0.00%|    timezone : {'naive', 'UTC', 'local'} or tzinfo
  1623|         0|            0|            0|  0.00%|        Timezone information to use when displaying the datetime. If 'UTC', end
  1624|         0|            0|            0|  0.00%|        with a Z to indicate UTC time. If 'local', convert to the local timezone
  1625|         0|            0|            0|  0.00%|        first, and suffix with a +-#### timezone offset. If a tzinfo object,
  1626|         0|            0|            0|  0.00%|        then do as with 'local', but use the specified timezone.
  1627|         0|            0|            0|  0.00%|    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}
  1628|         0|            0|            0|  0.00%|        Casting to allow when changing between datetime units.
  1629|         0|            0|            0|  0.00%|
  1630|         0|            0|            0|  0.00%|    Returns
  1631|         0|            0|            0|  0.00%|    -------
  1632|         0|            0|            0|  0.00%|    str_arr : ndarray
  1633|         0|            0|            0|  0.00%|        An array of strings the same shape as `arr`.
  1634|         0|            0|            0|  0.00%|
  1635|         0|            0|            0|  0.00%|    Examples
  1636|         0|            0|            0|  0.00%|    --------
  1637|         0|            0|            0|  0.00%|    >>> import pytz
  1638|         0|            0|            0|  0.00%|    >>> d = np.arange('2002-10-27T04:30', 4*60, 60, dtype='M8[m]')
  1639|         0|            0|            0|  0.00%|    >>> d
  1640|         0|            0|            0|  0.00%|    array(['2002-10-27T04:30', '2002-10-27T05:30', '2002-10-27T06:30',
  1641|         0|            0|            0|  0.00%|           '2002-10-27T07:30'], dtype='datetime64[m]')
  1642|         0|            0|            0|  0.00%|
  1643|         0|            0|            0|  0.00%|    Setting the timezone to UTC shows the same information, but with a Z suffix
  1644|         0|            0|            0|  0.00%|
  1645|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, timezone='UTC')
  1646|         0|            0|            0|  0.00%|    array(['2002-10-27T04:30Z', '2002-10-27T05:30Z', '2002-10-27T06:30Z',
  1647|         0|            0|            0|  0.00%|           '2002-10-27T07:30Z'], dtype='<U35')
  1648|         0|            0|            0|  0.00%|
  1649|         0|            0|            0|  0.00%|    Note that we picked datetimes that cross a DST boundary. Passing in a
  1650|         0|            0|            0|  0.00%|    ``pytz`` timezone object will print the appropriate offset
  1651|         0|            0|            0|  0.00%|
  1652|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, timezone=pytz.timezone('US/Eastern'))
  1653|         0|            0|            0|  0.00%|    array(['2002-10-27T00:30-0400', '2002-10-27T01:30-0400',
  1654|         0|            0|            0|  0.00%|           '2002-10-27T01:30-0500', '2002-10-27T02:30-0500'], dtype='<U39')
  1655|         0|            0|            0|  0.00%|
  1656|         0|            0|            0|  0.00%|    Passing in a unit will change the precision
  1657|         0|            0|            0|  0.00%|
  1658|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, unit='h')
  1659|         0|            0|            0|  0.00%|    array(['2002-10-27T04', '2002-10-27T05', '2002-10-27T06', '2002-10-27T07'],
  1660|         0|            0|            0|  0.00%|          dtype='<U32')
  1661|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, unit='s')
  1662|         0|            0|            0|  0.00%|    array(['2002-10-27T04:30:00', '2002-10-27T05:30:00', '2002-10-27T06:30:00',
  1663|         0|            0|            0|  0.00%|           '2002-10-27T07:30:00'], dtype='<U38')
  1664|         0|            0|            0|  0.00%|
  1665|         0|            0|            0|  0.00%|    'casting' can be used to specify whether precision can be changed
  1666|         0|            0|            0|  0.00%|
  1667|         0|            0|            0|  0.00%|    >>> np.datetime_as_string(d, unit='h', casting='safe')
  1668|         0|            0|            0|  0.00%|    Traceback (most recent call last):
  1669|         0|            0|            0|  0.00%|        ...
  1670|         0|            0|            0|  0.00%|    TypeError: Cannot create a datetime string as units 'h' from a NumPy
  1671|         0|            0|            0|  0.00%|    datetime with units 'm' according to the rule 'safe'
  1672|         0|            0|            0|  0.00%|    """
  1673|         0|            0|            0|  0.00%|    return (arr,)
File: <__array_function__ internals>_9
File duration: 2.14577e-05s (0.00%)
Line #|      Hits|         Time| Time per hit|      %|Source code
------+----------+-------------+-------------+-------+-----------
     1|         0|            0|            0|  0.00%|
     2|         1|  2.14577e-06|  2.14577e-06|  0.00%|
     3|         0|            0|            0|  0.00%|
     4|         1|  9.29832e-06|  9.29832e-06|  0.00%|
(call)|         1|  6.19888e-06|  6.19888e-06|  0.00%|# /home/robert/anaconda3/envs/alibi/lib/python3.8/site-packages/numpy/core/multiarray.py:75 empty_like
     5|         2|  8.34465e-06|  4.17233e-06|  0.00%|
     6|         1|  1.66893e-06|  1.66893e-06|  0.00%|
