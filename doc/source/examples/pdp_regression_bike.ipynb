{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5005fb3c",
   "metadata": {},
   "source": [
    "# Partial Dependence and Individual Conditional Expectation for predicting bike renting\n",
    "\n",
    "<a id='source_1'></a>\n",
    "<a id='source_2'></a>\n",
    "\n",
    "\n",
    "In this example we will explain the behavior of a regression model on the [Bike rentals](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)[[1]](#References) dataset. We will show how to calculate the partial dependence (`PD`) and the individual conditional expectation (`ICE`) to determine the feature effects on the model.\n",
    "\n",
    "We will follow the example from the [PDP](https://christophm.github.io/interpretable-ml-book/pdp.html) chapter of the [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)[[2]](#References) book and use the cleaned version of the dataset from the [github repository](https://github.com/christophM/interpretable-ml-book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6071199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from alibi.explainers import PartialDependence, plot_pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bb79a",
   "metadata": {},
   "source": [
    "### Read and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dea500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>days_since_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WINTER</td>\n",
       "      <td>2011</td>\n",
       "      <td>JAN</td>\n",
       "      <td>NO HOLIDAY</td>\n",
       "      <td>SAT</td>\n",
       "      <td>NO WORKING DAY</td>\n",
       "      <td>MISTY</td>\n",
       "      <td>8.175849</td>\n",
       "      <td>80.5833</td>\n",
       "      <td>10.749882</td>\n",
       "      <td>985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WINTER</td>\n",
       "      <td>2011</td>\n",
       "      <td>JAN</td>\n",
       "      <td>NO HOLIDAY</td>\n",
       "      <td>SUN</td>\n",
       "      <td>NO WORKING DAY</td>\n",
       "      <td>MISTY</td>\n",
       "      <td>9.083466</td>\n",
       "      <td>69.6087</td>\n",
       "      <td>16.652113</td>\n",
       "      <td>801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WINTER</td>\n",
       "      <td>2011</td>\n",
       "      <td>JAN</td>\n",
       "      <td>NO HOLIDAY</td>\n",
       "      <td>MON</td>\n",
       "      <td>WORKING DAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>1.229108</td>\n",
       "      <td>43.7273</td>\n",
       "      <td>16.636703</td>\n",
       "      <td>1349</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WINTER</td>\n",
       "      <td>2011</td>\n",
       "      <td>JAN</td>\n",
       "      <td>NO HOLIDAY</td>\n",
       "      <td>TUE</td>\n",
       "      <td>WORKING DAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>59.0435</td>\n",
       "      <td>10.739832</td>\n",
       "      <td>1562</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WINTER</td>\n",
       "      <td>2011</td>\n",
       "      <td>JAN</td>\n",
       "      <td>NO HOLIDAY</td>\n",
       "      <td>WED</td>\n",
       "      <td>WORKING DAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>2.666979</td>\n",
       "      <td>43.6957</td>\n",
       "      <td>12.522300</td>\n",
       "      <td>1600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season    yr mnth     holiday weekday      workingday weathersit      temp  \\\n",
       "0  WINTER  2011  JAN  NO HOLIDAY     SAT  NO WORKING DAY      MISTY  8.175849   \n",
       "1  WINTER  2011  JAN  NO HOLIDAY     SUN  NO WORKING DAY      MISTY  9.083466   \n",
       "2  WINTER  2011  JAN  NO HOLIDAY     MON     WORKING DAY       GOOD  1.229108   \n",
       "3  WINTER  2011  JAN  NO HOLIDAY     TUE     WORKING DAY       GOOD  1.400000   \n",
       "4  WINTER  2011  JAN  NO HOLIDAY     WED     WORKING DAY       GOOD  2.666979   \n",
       "\n",
       "       hum  windspeed   cnt  days_since_2011  \n",
       "0  80.5833  10.749882   985                0  \n",
       "1  69.6087  16.652113   801                1  \n",
       "2  43.7273  16.636703  1349                2  \n",
       "3  59.0435  10.739832  1562                3  \n",
       "4  43.6957  12.522300  1600                4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/christophM/interpretable-ml-book/master/data/bike.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d9a02",
   "metadata": {},
   "source": [
    "We will be using the `cnt` column as the target in the regression task. The `cnt` stands for the `Count of bicycles` which includes the casual and the registered users. We invite the reader to follow [this](https://christophm.github.io/interpretable-ml-book/bike-data.html) link for more details on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68732b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature names\n",
    "feature_names = df.columns.tolist()\n",
    "feature_names.remove('cnt')\n",
    "\n",
    "# define target names\n",
    "target_names = ['Number of bikes']\n",
    "\n",
    "# define categorical columns\n",
    "categorical_columns_names = ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "# define categorical and numerical indices for later preprocessing\n",
    "categorical_columns_indices = [feature_names.index(cn) for cn in categorical_columns_names] \n",
    "numerical_columns_indices = [feature_names.index(fn) for fn in feature_names if fn not in categorical_columns_names]\n",
    "\n",
    "# extract data\n",
    "X = df[feature_names]\n",
    "y = df['cnt']\n",
    "\n",
    "# split data in train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4c00e",
   "metadata": {},
   "source": [
    "To preprocess the dataset in a format expected by the `alibi` explainers, we ordinally encode the categorical columns (i.e. string to integer) and we construct the `categorical_names` necessary to specify to the explainer which are the categorical features of the datasets. The `categorical_names` is a dictionary having as key the indices of the categorical columns and as values the corresponding feature values. For more details, see the [method description page](../methods/PartialDependence.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31bedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit the oridnal encoder\n",
    "oe = OrdinalEncoder().fit(X_train[categorical_columns_names])\n",
    "\n",
    "# transform the categorical columns to ordinal encoding\n",
    "X_train.loc[:, categorical_columns_names] = oe.transform(X_train[categorical_columns_names])\n",
    "X_test.loc[:, categorical_columns_names] = oe.transform(X_test[categorical_columns_names])\n",
    "\n",
    "# convert data to numpy\n",
    "X_train, y_train = X_train.to_numpy(), y_train.to_numpy()\n",
    "X_test, y_test = X_test.to_numpy(), y_test.to_numpy()\n",
    "\n",
    "# define categorical mappings\n",
    "categorical_names = {i: list(v) for (i, v) in zip(categorical_columns_indices, oe.categories_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de7cf0",
   "metadata": {},
   "source": [
    "We apply standard preprocessing steps to the dataset: standardization for the numerical features and one-hot encoding for the categorical ones. Note that the one-hot encoding is the representation to be used by the classifier. We require the previous label encoding step to transform the data into the standard format used by the `alibi` explainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74069911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numerical standard sclaer\n",
    "num_transf = StandardScaler()\n",
    "\n",
    "# define categorical one-hot encoder\n",
    "cat_transf = OneHotEncoder(\n",
    "    categories=[range(len(x)) for x in categorical_names.values()],\n",
    "    drop='first'\n",
    ")\n",
    "\n",
    "# define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transf, categorical_columns_indices),\n",
    "        ('num', num_transf, numerical_columns_indices),\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d466bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit preprocessor\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# preprocess train and test datasets\n",
    "X_train_ohe = preprocessor.transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4caf402",
   "metadata": {},
   "source": [
    "### Train regressor\n",
    "\n",
    "Now that we have the dataset in a good format, we are ready to train the model. For this example, we use a `RandomForestRegressor` from `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1d69c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.96\n",
      "Test score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# define and fit regressor - feel free to play with the hyperparameters \n",
    "predictor = RandomForestRegressor(max_depth=8, min_samples_split=5, n_estimators=100, random_state=13)\n",
    "predictor.fit(X_train_ohe, y_train)\n",
    "\n",
    "# compute scores\n",
    "print('Train score: %.2f' % (predictor.score(X_train_ohe, y_train)))\n",
    "print('Test score: %.2f' % (predictor.score(X_test_ohe, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4f6a6",
   "metadata": {},
   "source": [
    "### Partial dependence \n",
    "\n",
    "Before proceeding with the explanation, there is one additional step we need to perform. The `PartialDependece` explainer expects the categorical features to be ordinal encoding and does not have explicit support for one-hot encoding yet (to be addressed in future releases).\n",
    "\n",
    "To address this limitation we can simply provide the explainer with the raw dataset and define a pipline in which we include the preprocessing step. This can be achieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae873512",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_predictor = Pipeline(steps=[('preprocessor', preprocessor), ('predictor', predictor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ca2d2",
   "metadata": {},
   "source": [
    "Now that we defined the prediction pipeline, we are ready to initialize the explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a59e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define explainer\n",
    "explainer = PartialDependence(predictor=pipe_predictor,\n",
    "                              feature_names=feature_names,\n",
    "                              target_names=target_names,\n",
    "                              categorical_names=categorical_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2dc9c",
   "metadata": {},
   "source": [
    "Select a few features of interest, such as *temperature*, *humidity*, *wind speed*, and *season*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f231af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select temperature, humidity, wind speed, and season\n",
    "features = [feature_names.index('temp'), \n",
    "            feature_names.index('hum'), \n",
    "            feature_names.index('windspeed'),\n",
    "            feature_names.index('season')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5a847",
   "metadata": {},
   "source": [
    "To compute the `PD` for the features listed we call the `explain` method. The parameter `kind='average'` specifies to return of the `PD` values and the `method='brute'` specified the method of computation. For tree-based models, the method can be set to `method='recursive'` for which the computation is faster. Note that the two methods do not agree in general on the values they return. This is because the marginal effect is computed with respect to different probability distributions. For more details on the computation method, check the `sklearn` [documentation page](https://scikit-learn.org/stable/modules/partial_dependence.html#computation-methods).\n",
    "\n",
    "Following the `PD` computation, we can simply display the `PD` curves by calling the `plot_pd` method. The method allows the user to customize the plots as desired. For more details, see the [method description page](../methods/PartialDependence.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f34ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-883011abaa8d>\", line 2, in <cell line: 2>\n",
      "    exp = explainer.explain(X=X_train,\n",
      "  File \"/home/robert/Desktop/alibi/alibi/explainers/partial_dependence.py\", line 230, in explain\n",
      "    self._partial_dependence(\n",
      "  File \"/home/robert/Desktop/alibi/alibi/explainers/partial_dependence.py\", line 490, in _partial_dependence\n",
      "    averaged_predictions, predictions = self._pd_brute(grid=grid,\n",
      "  File \"/home/robert/Desktop/alibi/alibi/explainers/partial_dependence.py\", line 637, in _pd_brute\n",
      "    pred = prediction_method(X_eval)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/pipeline.py\", line 458, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 1004, in predict\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 664, in _accumulate_prediction\n",
      "    prediction = predict(X, check_input=False)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 506, in predict\n",
      "    proba = self.tree_.predict(X)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/robert/miniconda3/envs/alibi/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-883011abaa8d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute explanations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m exp = explainer.explain(X=X_train,\n\u001b[0m\u001b[1;32m      3\u001b[0m                         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/alibi/alibi/explainers/partial_dependence.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, X, features, response_method, method, kind, percentiles, grid_resolution, grid_points)\u001b[0m\n\u001b[1;32m    229\u001b[0m             pds.append(\n\u001b[0;32m--> 230\u001b[0;31m                 self._partial_dependence(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/alibi/alibi/explainers/partial_dependence.py\u001b[0m in \u001b[0;36m_partial_dependence\u001b[0;34m(self, X, features, response_method, method, kind, percentiles, grid_resolution, grid_points)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"brute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             averaged_predictions, predictions = self._pd_brute(grid=grid,\n\u001b[0m\u001b[1;32m    491\u001b[0m                                                                \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/alibi/alibi/explainers/partial_dependence.py\u001b[0m in \u001b[0;36m_pd_brute\u001b[0;34m(self, grid, features, X, response_method)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;31m# (n_points, n_classes) for multiclass classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n\u001b[0m\u001b[1;32m   1005\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \"\"\"\n\u001b[0;32m--> 664\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# compute explanations\n",
    "exp = explainer.explain(X=X_train,\n",
    "                        features=features,\n",
    "                        kind='average',\n",
    "                        method='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022203a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot partial dependece curves\n",
    "plot_pd(exp=exp,\n",
    "        n_cols=3,\n",
    "        sharey='row',\n",
    "        fig_kw={'figheight': 10, 'figwidth': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575a98b",
   "metadata": {},
   "source": [
    "We can observe that the average model prediction increases with the temperature till it reaches approximately $17^\\circ C$. Then it flattens at a high number until the weather becomes too hot (i.e. approx. $27^\\circ C$), after which it starts dropping again. \n",
    "\n",
    "The humidity larger than $60\\%$ seems to be a factor that inhibits the number of rentals since we can observe a downward trend from that point onward.\n",
    "\n",
    "A similar analysis can be conducted for the wind speed. As the wind speed increases, fewer and fewer people are riding the bike. Interestingly, as also mentioned in [here](https://christophm.github.io/interpretable-ml-book/pdp.html), the number of bike rentals flattens between $25$ and $35 \\text{km/h}$. By looking at the decile ticks, we can observe that there is not much data in that intervals. The model might not have learned to extrapolate correctly in that region, thus the predictions might not be meaningful.\n",
    "\n",
    "Lastly, looking at the average prediction for each season, we can observe that all seasons show a similar effect on the model predictions, with a slight decrease for the winter season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeaca8b",
   "metadata": {},
   "source": [
    "###  Individual conditional expectation\n",
    "\n",
    "Although the `PD` plots can give us some insight concerning the average model response, they can also hide some heterogeneous effects. This is because the `PD` plots show the average marginal effects. To visualize the response of each data point and uncover heterogeneous effects we can use the `ICE` plots.\n",
    "\n",
    "To compute both the `PD` and the `ICE`, we simply set the parameter `kind='both'`. In this setting, the method parameter must be set to `method='brute'`, since the `ICE` cannot be computed for the `method='recursive'`. The rest of the calls remain the same.\n",
    "\n",
    "Because the `PD` is the average of the `ICE`, the `ICE` plots can be heavily dispersed around the `PD` which can hide away the evolution of a data point as we change the feature value. Thus, it is recommended to center the plots at 0 by subtracting the value corresponding to the initial feature value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute explanations\n",
    "exp = explainer.explain(X=X_train,\n",
    "                        features=features,\n",
    "                        kind='both',\n",
    "                        method='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the pd and ice\n",
    "plot_pd(exp=exp,\n",
    "        n_cols=3,\n",
    "        n_ice=25,   # number of ICE curves to be displayed. Can be set to 'all' or provided a list of indices\n",
    "        sharey='row',\n",
    "        center=True,  # center the plots for better visualization\n",
    "        fig_kw={'figheight': 10, 'figwidth': 15});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b8cb0",
   "metadata": {},
   "source": [
    "For example, we can observe that there exist some particular scenarios in which the bike rental increases significantly and stays constant as the wind speed increases between $5$ and $22 \\text{km/h}$. Similarly, in some scenarios, the bike rental may stay the almost the same for winter relative to the other seasons. Such effects were hidden from us in the `PD` plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2c3d1",
   "metadata": {},
   "source": [
    "### Partial dependence for two features\n",
    "\n",
    "We will continue to provide some examples and a brief analysis of two feature `PD` plots, including a combination of two numerical features, two categorical features, and one numerical & one categorical. As we will see, 2-way `PD` plots helps us understand and visualize feature intereactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (feature_names.index('temp'), feature_names.index('windspeed')),\n",
    "    (feature_names.index('mnth'), feature_names.index('weathersit')),\n",
    "    (feature_names.index('season'), feature_names.index('temp'))    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute explanations\n",
    "exp = explainer.explain(X=X_train,\n",
    "                        features=features,\n",
    "                        kind='both',\n",
    "                        method='brute',\n",
    "                        grid_resolution=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot partial dependece curves\n",
    "plot_pd(exp=exp,\n",
    "        n_cols=2,\n",
    "        fig_kw={'figheight': 10, 'figwidth': 10});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99bd66",
   "metadata": {},
   "source": [
    "From the interaction plot between the temperature and wind speed, we can observe that between $-5$ and about $12^\\circ C$, the wind speed does not influence the average prediction that much. This can be deduced from the vertical strips of similar values restricted to the feature values domain of the reference dataset. The global trend is such that no matter the wind speed, the number of rented bikes increases with the temperature. As the temperature increases over $12^\\circ C$ and stays below $30^\\circ C$, we can observe that the wind speed starts to become more relevant for the model's prediction. We note that the number of rented bikes stays high until the wind speed surpasses the value of approximately $23 \\text{km/h}$, after which it starts dropping. This suggests that for relatively warm weather, the number of rentals increases as long as the wind is not too rough. Finally, we can observe that for extremely hot weather, the number of rentals drops again with the temperature.\n",
    "\n",
    "By inspecting the weather situation against the month, interestingly, we can observe the rental prediction is influenced by the weather situation and not by the calendar month. As the weather deteriorates, the rentals drop, independent of the calendar month.\n",
    "\n",
    "A similar situation can be observed in the plot of temperature against the season. Something that we've seen before is that the number of predicted rentals seems to be independent of the season and only depends on the temperature outside. As we have mentioned before, as the temperature increases, the number of rentals seems to increase till it reaches $17^\\circ C$. Then it flattens at a high number until the weather becomes too hot (i.e. approx. $27^\\circ C$), after which it starts dropping again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b04d2",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id='References'></a>\n",
    "\n",
    "[[1]](#source_2) Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg.\n",
    "\n",
    "[[2]](#source_1) Molnar, Christoph. Interpretable machine learning. Lulu. com, 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibi",
   "language": "python",
   "name": "alibi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
