{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc83782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from alibi.explainers import PartialDependence, plot_pd\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905d615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression one output\n",
    "X_train = np.random.randn(15, 10)\n",
    "y_train = np.random.randint(0, 2, 15)\n",
    "\n",
    "rf = GradientBoostingClassifier()\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f0e3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = rf\n",
    "features=[0]\n",
    "response_method='auto'\n",
    "percentiles=(0, 1)\n",
    "grid_resolution=10\n",
    "method='brute'\n",
    "kind='both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "857ee395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "import numbers\n",
    "\n",
    "# compute pd with alibi\n",
    "features=[(0, 1)]\n",
    "explainer = PartialDependence(predictor=rf)\n",
    "exp_alibi = explainer.explain(X=X_train, \n",
    "                              features=features,\n",
    "                              response_method=response_method,\n",
    "                              percentiles=percentiles,\n",
    "                              grid_resolution=grid_resolution,\n",
    "                              method=method,\n",
    "                              kind=kind)\n",
    "\n",
    "\n",
    "\n",
    "# compute pd with sklearn\n",
    "exp_sklearn = partial_dependence(X=X_train, \n",
    "                                 estimator=rf, \n",
    "                                 features=features, \n",
    "                                 response_method=response_method,\n",
    "                                 percentiles=percentiles,\n",
    "                                 grid_resolution=grid_resolution,\n",
    "                                 method=method,\n",
    "                                 kind=kind)\n",
    "\n",
    "# assert np.allclose(exp_alibi.pd_values[0], exp_sklearn['average'])\n",
    "# if isinstance(features[0], numbers.Integral):\n",
    "#     assert np.allclose(exp_alibi.feature_values[0], exp_sklearn['values'][0])\n",
    "# else:\n",
    "#     for i in range(len(exp_sklearn['values'])):\n",
    "#         assert np.allclose(exp_alibi.feature_values[0][i], exp_sklearn['values'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4ac3eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 10, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_alibi.data['ice_values'][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f27203d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 10, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_sklearn['individual'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882a577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(5)\n",
    "np.atleast_2d(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea28f6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-646e1ed5e054>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcartesian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartesian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.extmath import cartesian\n",
    "y = cartesian(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import is_classifier, is_regressor\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils import check_matplotlib_support  # noqa\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn.utils import _determine_key_type\n",
    "from sklearn.utils import _get_column_indices\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.ensemble._gb import BaseGradientBoosting\n",
    "from sklearn.ensemble._hist_gradient_boosting.gradient_boosting import (\n",
    "    BaseHistGradientBoosting,\n",
    ")\n",
    "from sklearn.inspection._partial_dependence import _partial_dependence_recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03220139",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _partial_dependence_brute(est, grid, features, X, response_method):\n",
    "\n",
    "#     predictions = []\n",
    "#     averaged_predictions = []\n",
    "\n",
    "#     # define the prediction_method (predict, predict_proba, decision_function).\n",
    "#     if is_regressor(est):\n",
    "#         prediction_method = est.predict\n",
    "#     else:\n",
    "#         predict_proba = getattr(est, \"predict_proba\", None)\n",
    "#         decision_function = getattr(est, \"decision_function\", None)\n",
    "#         if response_method == \"auto\":\n",
    "#             # try predict_proba, then decision_function if it doesn't exist\n",
    "#             prediction_method = predict_proba or decision_function\n",
    "#         else:\n",
    "#             prediction_method = (\n",
    "#                 predict_proba\n",
    "#                 if response_method == \"predict_proba\"\n",
    "#                 else decision_function\n",
    "#             )\n",
    "#         if prediction_method is None:\n",
    "#             if response_method == \"auto\":\n",
    "#                 raise ValueError(\n",
    "#                     \"The estimator has no predict_proba and no \"\n",
    "#                     \"decision_function method.\"\n",
    "#                 )\n",
    "#             elif response_method == \"predict_proba\":\n",
    "#                 raise ValueError(\"The estimator has no predict_proba method.\")\n",
    "#             else:\n",
    "#                 raise ValueError(\"The estimator has no decision_function method.\")\n",
    "\n",
    "#     print(grid[:4])\n",
    "#     print(features)\n",
    "                \n",
    "#     X_eval = X.copy()\n",
    "#     for new_values in grid:\n",
    "#         for i, variable in enumerate(features):\n",
    "#             if hasattr(X_eval, \"iloc\"):\n",
    "#                 X_eval.iloc[:, variable] = new_values[i]\n",
    "#             else:\n",
    "#                 X_eval[:, variable] = new_values[i]\n",
    "                \n",
    "#         try:\n",
    "#             # Note: predictions is of shape\n",
    "#             # (n_points,) for non-multioutput regressors\n",
    "#             # (n_points, n_tasks) for multioutput regressors\n",
    "#             # (n_points, 1) for the regressors in cross_decomposition (I think)\n",
    "#             # (n_points, 2) for binary classification\n",
    "#             # (n_points, n_classes) for multiclass classification\n",
    "#             pred = prediction_method(X_eval)\n",
    "\n",
    "#             predictions.append(pred)\n",
    "#             # average over samples\n",
    "#             averaged_predictions.append(np.mean(pred, axis=0))\n",
    "#         except NotFittedError as e:\n",
    "#             raise ValueError(\"'estimator' parameter must be a fitted estimator\") from e\n",
    "\n",
    "#     n_samples = X.shape[0]\n",
    "\n",
    "#     # reshape to (n_targets, n_instances, n_points) where n_targets is:\n",
    "#     # - 1 for non-multioutput regression and binary classification (shape is\n",
    "#     #   already correct in those cases)\n",
    "#     # - n_tasks for multi-output regression\n",
    "#     # - n_classes for multiclass classification.\n",
    "#     predictions = np.array(predictions).T\n",
    "#     if is_regressor(est) and predictions.ndim == 2:\n",
    "#         # non-multioutput regression, shape is (n_instances, n_points,)\n",
    "#         predictions = predictions.reshape(n_samples, -1)\n",
    "#     elif is_classifier(est) and predictions.shape[0] == 2:\n",
    "#         # Binary classification, shape is (2, n_instances, n_points).\n",
    "#         # we output the effect of **positive** class\n",
    "#         predictions = predictions[1]\n",
    "#         predictions = predictions.reshape(n_samples, -1)\n",
    "\n",
    "#     # reshape averaged_predictions to (n_targets, n_points) where n_targets is:\n",
    "#     # - 1 for non-multioutput regression and binary classification (shape is\n",
    "#     #   already correct in those cases)\n",
    "#     # - n_tasks for multi-output regression\n",
    "#     # - n_classes for multiclass classification.\n",
    "#     averaged_predictions = np.array(averaged_predictions).T\n",
    "#     if is_regressor(est) and averaged_predictions.ndim == 1:\n",
    "#         # non-multioutput regression, shape is (n_points,)\n",
    "#         averaged_predictions = averaged_predictions.reshape(1, -1)\n",
    "#     elif is_classifier(est) and averaged_predictions.shape[0] == 2:\n",
    "#         # Binary classification, shape is (2, n_points).\n",
    "#         # we output the effect of **positive** class\n",
    "#         averaged_predictions = averaged_predictions[1]\n",
    "#         averaged_predictions = averaged_predictions.reshape(1, -1)\n",
    "\n",
    "#     return averaged_predictions, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92442ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_is_fitted(estimator)\n",
    "\n",
    "# if not (is_classifier(estimator) or is_regressor(estimator)):\n",
    "#     raise ValueError(\"'estimator' must be a fitted regressor or classifier.\")\n",
    "\n",
    "# if is_classifier(estimator) and isinstance(estimator.classes_[0], np.ndarray):\n",
    "#     raise ValueError(\"Multiclass-multioutput estimators are not supported\")\n",
    "\n",
    "# # Use check_array only on lists and other non-array-likes / sparse. Do not\n",
    "# # convert DataFrame into a NumPy array.\n",
    "# if not (hasattr(X, \"__array__\") or sparse.issparse(X)):\n",
    "#     X = check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n",
    "\n",
    "# accepted_responses = (\"auto\", \"predict_proba\", \"decision_function\")\n",
    "# if response_method not in accepted_responses:\n",
    "#     raise ValueError(\n",
    "#         \"response_method {} is invalid. Accepted response_method names \"\n",
    "#         \"are {}.\".format(response_method, \", \".join(accepted_responses))\n",
    "#     )\n",
    "\n",
    "# if is_regressor(estimator) and response_method != \"auto\":\n",
    "#     raise ValueError(\n",
    "#         \"The response_method parameter is ignored for regressors and \"\n",
    "#         \"must be 'auto'.\"\n",
    "#     )\n",
    "\n",
    "# accepted_methods = (\"brute\", \"recursion\", \"auto\")\n",
    "# if method not in accepted_methods:\n",
    "#     raise ValueError(\n",
    "#         \"method {} is invalid. Accepted method names are {}.\".format(\n",
    "#             method, \", \".join(accepted_methods)\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# if kind != \"average\":\n",
    "#     if method == \"recursion\":\n",
    "#         raise ValueError(\n",
    "#             \"The 'recursion' method only applies when 'kind' is set to 'average'\"\n",
    "#         )\n",
    "#     method = \"brute\"\n",
    "\n",
    "# if method == \"auto\":\n",
    "#     if isinstance(estimator, BaseGradientBoosting) and estimator.init is None:\n",
    "#         method = \"recursion\"\n",
    "#     elif isinstance(\n",
    "#         estimator,\n",
    "#         (BaseHistGradientBoosting, DecisionTreeRegressor, RandomForestRegressor),\n",
    "#     ):\n",
    "#         method = \"recursion\"\n",
    "#     else:\n",
    "#         method = \"brute\"\n",
    "\n",
    "# if method == \"recursion\":\n",
    "#     if not isinstance(\n",
    "#         estimator,\n",
    "#         (\n",
    "#             BaseGradientBoosting,\n",
    "#             BaseHistGradientBoosting,\n",
    "#             DecisionTreeRegressor,\n",
    "#             RandomForestRegressor,\n",
    "#         ),\n",
    "#     ):\n",
    "#         supported_classes_recursion = (\n",
    "#             \"GradientBoostingClassifier\",\n",
    "#             \"GradientBoostingRegressor\",\n",
    "#             \"HistGradientBoostingClassifier\",\n",
    "#             \"HistGradientBoostingRegressor\",\n",
    "#             \"HistGradientBoostingRegressor\",\n",
    "#             \"DecisionTreeRegressor\",\n",
    "#             \"RandomForestRegressor\",\n",
    "#         )\n",
    "#         raise ValueError(\n",
    "#             \"Only the following estimators support the 'recursion' \"\n",
    "#             \"method: {}. Try using method='brute'.\".format(\n",
    "#                 \", \".join(supported_classes_recursion)\n",
    "#             )\n",
    "#         )\n",
    "#     if response_method == \"auto\":\n",
    "#         response_method = \"decision_function\"\n",
    "\n",
    "#     if response_method != \"decision_function\":\n",
    "#         raise ValueError(\n",
    "#             \"With the 'recursion' method, the response_method must be \"\n",
    "#             \"'decision_function'. Got {}.\".format(response_method)\n",
    "#         )\n",
    "\n",
    "# if _determine_key_type(features, accept_slice=False) == \"int\":\n",
    "#     # _get_column_indices() supports negative indexing. Here, we limit\n",
    "#     # the indexing to be positive. The upper bound will be checked\n",
    "#     # by _get_column_indices()\n",
    "#     if np.any(np.less(features, 0)):\n",
    "#         raise ValueError(\"all features must be in [0, {}]\".format(X.shape[1] - 1))\n",
    "\n",
    "# features_indices = np.asarray(\n",
    "#     _get_column_indices(X, features), dtype=np.int32, order=\"C\"\n",
    "# ).ravel()\n",
    "\n",
    "# grid, values = _grid_from_X(\n",
    "#     _safe_indexing(X, features_indices, axis=1), percentiles, grid_resolution\n",
    "# )\n",
    "\n",
    "# if method == \"brute\":\n",
    "#     averaged_predictions, predictions = _partial_dependence_brute(\n",
    "#         estimator, grid, features_indices, X, response_method\n",
    "#     )\n",
    "\n",
    "#     # reshape predictions to\n",
    "#     # (n_outputs, n_instances, n_values_feature_0, n_values_feature_1, ...)\n",
    "#     predictions = predictions.reshape(\n",
    "#         -1, X.shape[0], *[val.shape[0] for val in values]\n",
    "#     )\n",
    "    \n",
    "# # reshape averaged_predictions to\n",
    "# # (n_outputs, n_values_feature_0, n_values_feature_1, ...)\n",
    "# averaged_predictions = averaged_predictions.reshape(\n",
    "#     -1, *[val.shape[0] for val in values]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d18231",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sklearn.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05177b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibi",
   "language": "python",
   "name": "alibi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
