{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "85f47029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from alibi.explainers import PartialDependence, plot_pd\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b05e6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression one output\n",
    "X_train = np.random.randn(15, 10)\n",
    "y_train = np.random.randn(15)\n",
    "\n",
    "rf = GradientBoostingRegressor()\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "39338a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = rf\n",
    "features=[0, 1]\n",
    "response_method='auto'\n",
    "percentiles=(0, 1)\n",
    "grid_resolution=10\n",
    "method='brute'\n",
    "kind='average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e8250b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "import numbers\n",
    "\n",
    "# compute pd with alibi\n",
    "features=[(0, 1)]\n",
    "explainer = PartialDependence(predictor=rf)\n",
    "exp_alibi = explainer.explain(X=X_train, \n",
    "                              features=features,\n",
    "                              response_method=response_method,\n",
    "                              percentiles=percentiles,\n",
    "                              grid_resolution=grid_resolution,\n",
    "                              method=method,\n",
    "                              kind=kind)\n",
    "\n",
    "\n",
    "\n",
    "# compute pd with sklearn\n",
    "exp_sklearn = partial_dependence(X=X_train, \n",
    "                                 estimator=rf, \n",
    "                                 features=features, \n",
    "                                 response_method=response_method,\n",
    "                                 percentiles=percentiles,\n",
    "                                 grid_resolution=grid_resolution,\n",
    "                                 method=method,\n",
    "                                 kind=kind)\n",
    "\n",
    "# assert np.allclose(exp_alibi.pd_values[0], exp_sklearn['average'])\n",
    "# if isinstance(features[0], numbers.Integral):\n",
    "#     assert np.allclose(exp_alibi.feature_values[0], exp_sklearn['values'][0])\n",
    "# else:\n",
    "#     for i in range(len(exp_sklearn['values'])):\n",
    "#         assert np.allclose(exp_alibi.feature_values[0][i], exp_sklearn['values'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d3e1fd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.13194945, -0.13194945, -0.13194945, -0.13177829,\n",
       "          -0.13177829, -0.1317881 , -0.14809519, -0.14909082,\n",
       "          -0.14671739,  0.00760363],\n",
       "         [-0.13996984, -0.13996984, -0.13996984, -0.13979869,\n",
       "          -0.13979869, -0.1398085 , -0.15611558, -0.15711121,\n",
       "          -0.15473779, -0.00041677],\n",
       "         [-0.13996984, -0.13996984, -0.13996984, -0.13979869,\n",
       "          -0.13979869, -0.1398085 , -0.15611558, -0.15711121,\n",
       "          -0.15473779, -0.00041677],\n",
       "         [-0.13992446, -0.13992446, -0.13992446, -0.13975331,\n",
       "          -0.13975331, -0.13976312, -0.15607021, -0.15706584,\n",
       "          -0.15469241, -0.00037139],\n",
       "         [-0.151012  , -0.151012  , -0.151012  , -0.15084085,\n",
       "          -0.15084085, -0.15085066, -0.16063385, -0.16162948,\n",
       "          -0.15925605, -0.00254013],\n",
       "         [-0.17386315, -0.17386315, -0.17386315, -0.173692  ,\n",
       "          -0.173692  , -0.1737018 , -0.183485  , -0.18448063,\n",
       "          -0.1821072 , -0.02539128],\n",
       "         [-0.17386315, -0.17386315, -0.17386315, -0.173692  ,\n",
       "          -0.173692  , -0.1737018 , -0.17927724, -0.18027287,\n",
       "          -0.17789944, -0.02539128],\n",
       "         [-0.09826744, -0.09826744, -0.09826744, -0.09809629,\n",
       "          -0.09809629, -0.0981061 , -0.10368153, -0.10467716,\n",
       "          -0.10230374,  0.01905065],\n",
       "         [-0.07060415, -0.07060415, -0.07060415, -0.070433  ,\n",
       "          -0.070433  , -0.07044281, -0.07601824, -0.07701387,\n",
       "          -0.07464044,  0.03861465],\n",
       "         [-0.07060415, -0.07060415, -0.07060415, -0.070433  ,\n",
       "          -0.070433  , -0.07044281, -0.07601824, -0.07701387,\n",
       "          -0.07464044,  0.03861465]]])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_alibi.data['pd_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9ccef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6466cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import is_classifier, is_regressor\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils import check_matplotlib_support  # noqa\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn.utils import _determine_key_type\n",
    "from sklearn.utils import _get_column_indices\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.ensemble._gb import BaseGradientBoosting\n",
    "from sklearn.ensemble._hist_gradient_boosting.gradient_boosting import (\n",
    "    BaseHistGradientBoosting,\n",
    ")\n",
    "from sklearn.inspection._partial_dependence import _partial_dependence_recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ca120415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "623c0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _partial_dependence_brute(est, grid, features, X, response_method):\n",
    "\n",
    "    predictions = []\n",
    "    averaged_predictions = []\n",
    "\n",
    "    # define the prediction_method (predict, predict_proba, decision_function).\n",
    "    if is_regressor(est):\n",
    "        prediction_method = est.predict\n",
    "    else:\n",
    "        predict_proba = getattr(est, \"predict_proba\", None)\n",
    "        decision_function = getattr(est, \"decision_function\", None)\n",
    "        if response_method == \"auto\":\n",
    "            # try predict_proba, then decision_function if it doesn't exist\n",
    "            prediction_method = predict_proba or decision_function\n",
    "        else:\n",
    "            prediction_method = (\n",
    "                predict_proba\n",
    "                if response_method == \"predict_proba\"\n",
    "                else decision_function\n",
    "            )\n",
    "        if prediction_method is None:\n",
    "            if response_method == \"auto\":\n",
    "                raise ValueError(\n",
    "                    \"The estimator has no predict_proba and no \"\n",
    "                    \"decision_function method.\"\n",
    "                )\n",
    "            elif response_method == \"predict_proba\":\n",
    "                raise ValueError(\"The estimator has no predict_proba method.\")\n",
    "            else:\n",
    "                raise ValueError(\"The estimator has no decision_function method.\")\n",
    "\n",
    "    print(grid[:4])\n",
    "    print(features)\n",
    "                \n",
    "    X_eval = X.copy()\n",
    "    for new_values in grid:\n",
    "        for i, variable in enumerate(features):\n",
    "            if hasattr(X_eval, \"iloc\"):\n",
    "                X_eval.iloc[:, variable] = new_values[i]\n",
    "            else:\n",
    "                X_eval[:, variable] = new_values[i]\n",
    "                \n",
    "        try:\n",
    "            # Note: predictions is of shape\n",
    "            # (n_points,) for non-multioutput regressors\n",
    "            # (n_points, n_tasks) for multioutput regressors\n",
    "            # (n_points, 1) for the regressors in cross_decomposition (I think)\n",
    "            # (n_points, 2) for binary classification\n",
    "            # (n_points, n_classes) for multiclass classification\n",
    "            pred = prediction_method(X_eval)\n",
    "\n",
    "            predictions.append(pred)\n",
    "            # average over samples\n",
    "            averaged_predictions.append(np.mean(pred, axis=0))\n",
    "        except NotFittedError as e:\n",
    "            raise ValueError(\"'estimator' parameter must be a fitted estimator\") from e\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # reshape to (n_targets, n_instances, n_points) where n_targets is:\n",
    "    # - 1 for non-multioutput regression and binary classification (shape is\n",
    "    #   already correct in those cases)\n",
    "    # - n_tasks for multi-output regression\n",
    "    # - n_classes for multiclass classification.\n",
    "    predictions = np.array(predictions).T\n",
    "    if is_regressor(est) and predictions.ndim == 2:\n",
    "        # non-multioutput regression, shape is (n_instances, n_points,)\n",
    "        predictions = predictions.reshape(n_samples, -1)\n",
    "    elif is_classifier(est) and predictions.shape[0] == 2:\n",
    "        # Binary classification, shape is (2, n_instances, n_points).\n",
    "        # we output the effect of **positive** class\n",
    "        predictions = predictions[1]\n",
    "        predictions = predictions.reshape(n_samples, -1)\n",
    "\n",
    "    # reshape averaged_predictions to (n_targets, n_points) where n_targets is:\n",
    "    # - 1 for non-multioutput regression and binary classification (shape is\n",
    "    #   already correct in those cases)\n",
    "    # - n_tasks for multi-output regression\n",
    "    # - n_classes for multiclass classification.\n",
    "    averaged_predictions = np.array(averaged_predictions).T\n",
    "    if is_regressor(est) and averaged_predictions.ndim == 1:\n",
    "        # non-multioutput regression, shape is (n_points,)\n",
    "        averaged_predictions = averaged_predictions.reshape(1, -1)\n",
    "    elif is_classifier(est) and averaged_predictions.shape[0] == 2:\n",
    "        # Binary classification, shape is (2, n_points).\n",
    "        # we output the effect of **positive** class\n",
    "        averaged_predictions = averaged_predictions[1]\n",
    "        averaged_predictions = averaged_predictions.reshape(1, -1)\n",
    "\n",
    "    return averaged_predictions, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "00c912ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.73229473 -2.24234335]\n",
      " [-0.73229473 -1.89252712]\n",
      " [-0.73229473 -1.54271089]\n",
      " [-0.73229473 -1.19289467]]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "check_is_fitted(estimator)\n",
    "\n",
    "if not (is_classifier(estimator) or is_regressor(estimator)):\n",
    "    raise ValueError(\"'estimator' must be a fitted regressor or classifier.\")\n",
    "\n",
    "if is_classifier(estimator) and isinstance(estimator.classes_[0], np.ndarray):\n",
    "    raise ValueError(\"Multiclass-multioutput estimators are not supported\")\n",
    "\n",
    "# Use check_array only on lists and other non-array-likes / sparse. Do not\n",
    "# convert DataFrame into a NumPy array.\n",
    "if not (hasattr(X, \"__array__\") or sparse.issparse(X)):\n",
    "    X = check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n",
    "\n",
    "accepted_responses = (\"auto\", \"predict_proba\", \"decision_function\")\n",
    "if response_method not in accepted_responses:\n",
    "    raise ValueError(\n",
    "        \"response_method {} is invalid. Accepted response_method names \"\n",
    "        \"are {}.\".format(response_method, \", \".join(accepted_responses))\n",
    "    )\n",
    "\n",
    "if is_regressor(estimator) and response_method != \"auto\":\n",
    "    raise ValueError(\n",
    "        \"The response_method parameter is ignored for regressors and \"\n",
    "        \"must be 'auto'.\"\n",
    "    )\n",
    "\n",
    "accepted_methods = (\"brute\", \"recursion\", \"auto\")\n",
    "if method not in accepted_methods:\n",
    "    raise ValueError(\n",
    "        \"method {} is invalid. Accepted method names are {}.\".format(\n",
    "            method, \", \".join(accepted_methods)\n",
    "        )\n",
    "    )\n",
    "\n",
    "if kind != \"average\":\n",
    "    if method == \"recursion\":\n",
    "        raise ValueError(\n",
    "            \"The 'recursion' method only applies when 'kind' is set to 'average'\"\n",
    "        )\n",
    "    method = \"brute\"\n",
    "\n",
    "if method == \"auto\":\n",
    "    if isinstance(estimator, BaseGradientBoosting) and estimator.init is None:\n",
    "        method = \"recursion\"\n",
    "    elif isinstance(\n",
    "        estimator,\n",
    "        (BaseHistGradientBoosting, DecisionTreeRegressor, RandomForestRegressor),\n",
    "    ):\n",
    "        method = \"recursion\"\n",
    "    else:\n",
    "        method = \"brute\"\n",
    "\n",
    "if method == \"recursion\":\n",
    "    if not isinstance(\n",
    "        estimator,\n",
    "        (\n",
    "            BaseGradientBoosting,\n",
    "            BaseHistGradientBoosting,\n",
    "            DecisionTreeRegressor,\n",
    "            RandomForestRegressor,\n",
    "        ),\n",
    "    ):\n",
    "        supported_classes_recursion = (\n",
    "            \"GradientBoostingClassifier\",\n",
    "            \"GradientBoostingRegressor\",\n",
    "            \"HistGradientBoostingClassifier\",\n",
    "            \"HistGradientBoostingRegressor\",\n",
    "            \"HistGradientBoostingRegressor\",\n",
    "            \"DecisionTreeRegressor\",\n",
    "            \"RandomForestRegressor\",\n",
    "        )\n",
    "        raise ValueError(\n",
    "            \"Only the following estimators support the 'recursion' \"\n",
    "            \"method: {}. Try using method='brute'.\".format(\n",
    "                \", \".join(supported_classes_recursion)\n",
    "            )\n",
    "        )\n",
    "    if response_method == \"auto\":\n",
    "        response_method = \"decision_function\"\n",
    "\n",
    "    if response_method != \"decision_function\":\n",
    "        raise ValueError(\n",
    "            \"With the 'recursion' method, the response_method must be \"\n",
    "            \"'decision_function'. Got {}.\".format(response_method)\n",
    "        )\n",
    "\n",
    "if _determine_key_type(features, accept_slice=False) == \"int\":\n",
    "    # _get_column_indices() supports negative indexing. Here, we limit\n",
    "    # the indexing to be positive. The upper bound will be checked\n",
    "    # by _get_column_indices()\n",
    "    if np.any(np.less(features, 0)):\n",
    "        raise ValueError(\"all features must be in [0, {}]\".format(X.shape[1] - 1))\n",
    "\n",
    "features_indices = np.asarray(\n",
    "    _get_column_indices(X, features), dtype=np.int32, order=\"C\"\n",
    ").ravel()\n",
    "\n",
    "grid, values = _grid_from_X(\n",
    "    _safe_indexing(X, features_indices, axis=1), percentiles, grid_resolution\n",
    ")\n",
    "\n",
    "if method == \"brute\":\n",
    "    averaged_predictions, predictions = _partial_dependence_brute(\n",
    "        estimator, grid, features_indices, X, response_method\n",
    "    )\n",
    "\n",
    "    # reshape predictions to\n",
    "    # (n_outputs, n_instances, n_values_feature_0, n_values_feature_1, ...)\n",
    "    predictions = predictions.reshape(\n",
    "        -1, X.shape[0], *[val.shape[0] for val in values]\n",
    "    )\n",
    "    \n",
    "# reshape averaged_predictions to\n",
    "# (n_outputs, n_values_feature_0, n_values_feature_1, ...)\n",
    "averaged_predictions = averaged_predictions.reshape(\n",
    "    -1, *[val.shape[0] for val in values]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9f0d185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.13194945, -0.13194945, -0.13194945, -0.13177829,\n",
       "         -0.13177829, -0.1317881 , -0.14809519, -0.14909082,\n",
       "         -0.14671739,  0.00760363],\n",
       "        [-0.13996984, -0.13996984, -0.13996984, -0.13979869,\n",
       "         -0.13979869, -0.1398085 , -0.15611558, -0.15711121,\n",
       "         -0.15473779, -0.00041677],\n",
       "        [-0.13996984, -0.13996984, -0.13996984, -0.13979869,\n",
       "         -0.13979869, -0.1398085 , -0.15611558, -0.15711121,\n",
       "         -0.15473779, -0.00041677],\n",
       "        [-0.13992446, -0.13992446, -0.13992446, -0.13975331,\n",
       "         -0.13975331, -0.13976312, -0.15607021, -0.15706584,\n",
       "         -0.15469241, -0.00037139],\n",
       "        [-0.151012  , -0.151012  , -0.151012  , -0.15084085,\n",
       "         -0.15084085, -0.15085066, -0.16063385, -0.16162948,\n",
       "         -0.15925605, -0.00254013],\n",
       "        [-0.17386315, -0.17386315, -0.17386315, -0.173692  ,\n",
       "         -0.173692  , -0.1737018 , -0.183485  , -0.18448063,\n",
       "         -0.1821072 , -0.02539128],\n",
       "        [-0.17386315, -0.17386315, -0.17386315, -0.173692  ,\n",
       "         -0.173692  , -0.1737018 , -0.17927724, -0.18027287,\n",
       "         -0.17789944, -0.02539128],\n",
       "        [-0.09826744, -0.09826744, -0.09826744, -0.09809629,\n",
       "         -0.09809629, -0.0981061 , -0.10368153, -0.10467716,\n",
       "         -0.10230374,  0.01905065],\n",
       "        [-0.07060415, -0.07060415, -0.07060415, -0.070433  ,\n",
       "         -0.070433  , -0.07044281, -0.07601824, -0.07701387,\n",
       "         -0.07464044,  0.03861465],\n",
       "        [-0.07060415, -0.07060415, -0.07060415, -0.070433  ,\n",
       "         -0.070433  , -0.07044281, -0.07601824, -0.07701387,\n",
       "         -0.07464044,  0.03861465]]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "16573194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.13194945, -0.13194945, -0.13194945, -0.13177829,\n",
       "         -0.13177829, -0.1317881 , -0.14809519, -0.14909082,\n",
       "         -0.14671739,  0.00760363],\n",
       "        [-0.13996984, -0.13996984, -0.13996984, -0.13979869,\n",
       "         -0.13979869, -0.1398085 , -0.15611558, -0.15711121,\n",
       "         -0.15473779, -0.00041677],\n",
       "        [-0.13996984, -0.13996984, -0.13996984, -0.13979869,\n",
       "         -0.13979869, -0.1398085 , -0.15611558, -0.15711121,\n",
       "         -0.15473779, -0.00041677],\n",
       "        [-0.13992446, -0.13992446, -0.13992446, -0.13975331,\n",
       "         -0.13975331, -0.13976312, -0.15607021, -0.15706584,\n",
       "         -0.15469241, -0.00037139],\n",
       "        [-0.151012  , -0.151012  , -0.151012  , -0.15084085,\n",
       "         -0.15084085, -0.15085066, -0.16063385, -0.16162948,\n",
       "         -0.15925605, -0.00254013],\n",
       "        [-0.17386315, -0.17386315, -0.17386315, -0.173692  ,\n",
       "         -0.173692  , -0.1737018 , -0.183485  , -0.18448063,\n",
       "         -0.1821072 , -0.02539128],\n",
       "        [-0.17386315, -0.17386315, -0.17386315, -0.173692  ,\n",
       "         -0.173692  , -0.1737018 , -0.17927724, -0.18027287,\n",
       "         -0.17789944, -0.02539128],\n",
       "        [-0.09826744, -0.09826744, -0.09826744, -0.09809629,\n",
       "         -0.09809629, -0.0981061 , -0.10368153, -0.10467716,\n",
       "         -0.10230374,  0.01905065],\n",
       "        [-0.07060415, -0.07060415, -0.07060415, -0.070433  ,\n",
       "         -0.070433  , -0.07044281, -0.07601824, -0.07701387,\n",
       "         -0.07464044,  0.03861465],\n",
       "        [-0.07060415, -0.07060415, -0.07060415, -0.070433  ,\n",
       "         -0.070433  , -0.07044281, -0.07601824, -0.07701387,\n",
       "         -0.07464044,  0.03861465]]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_sklearn.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4b035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibi",
   "language": "python",
   "name": "alibi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
