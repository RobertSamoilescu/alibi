{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual with Reinforcement Learning (CFRL) on Adult Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is described in [Model-agnostic and Scalable Counterfactual Explanations via Reinforcement Learning](https://arxiv.org/abs/2106.02597) and can generate counterfactual instances for any black-box model. The usual optimization procedure is transformed into a learnable process allowing to generate batches of counterfactual instances in a single forward pass even for high dimensional data. The training pipeline is model-agnostic and relies only on prediction feedback by querying the black-box model. Furthermore, the method allows target and feature conditioning. \n",
    "\n",
    "**We exemplify the use case for the TensorFlow backend. This means that all models: the autoencoder, the actor, the critic, and possibly the black-box classifier are TensorFlow models. Our implementation supports PyTorch backend as well.**\n",
    "\n",
    "CfRL uses [Deep Deterministic Policy Gradient (DDPG)](https://arxiv.org/abs/1509.02971) by interleaving a state-action function approximator called critic, with a learning an approximator called actor to predict the optimal action. The method assumes that the critic is differentiable with respect to the action argument, thus allowing to optimize the actor's parameters efficiently through gradient-based methods.\n",
    "\n",
    "The DDPG algorithm requires two separate networks, an actor $\\mu$ and a critic $Q$. Given the encoded representation of the input instance $z = enc(x)$, the model prediction $y_M$, the target prediction\n",
    "$y_T$ and the conditioning vector $c$, the actor outputs the counterfactual’s latent representation $z_{CF} = \\mu(z, y_M, y_T, c)$. The decoder then projects the embedding $z_{CF}$ back to the original input space,\n",
    "followed by optional post-processing.\n",
    "\n",
    "The training step consists of simultaneously optimizing the actor and critic networks. The critic regresses on the reward $R$ determined by the model prediction, while the actor maximizes the critic’s output for the given instance through $L_{max}$. The actor also minimizes two objectives to encourage the generation of sparse, in-distribution counterfactuals. The sparsity loss $L_{sparsity}$ operates on the decoded counterfactual $x_{CF}$ and combines the $L_1$ loss over the standardized numerical features and the $L_0$ loss over the categorical ones. The consistency loss $L_{consist}$ aims to encode the counterfactual $x_{CF}$ back to the same latent representation where it was decoded from and helps to produce in-distribution counterfactual instances. Formally, the actor's loss can be written as:\n",
    "$L_{actor} = L_{max} + \\lambda_{1}L_{sparsity} + \\lambda_{2}L_{consistency}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/dl/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from alibi.explainers import CounterfactualRLTabular, CounterfactualRLBase\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.models.tensorflow.autoencoder import HeAE\n",
    "from alibi.models.tensorflow.actor_critic import Actor, Critic\n",
    "from alibi.models.tensorflow.cfrl_models import ADULTEncoder, ADULTDecoder\n",
    "from alibi.explainers.cfrl_base import Callback\n",
    "from alibi.explainers.backends.cfrl_tabular import get_he_preprocessor, get_statistics, \\\n",
    "    get_conditional_vector, apply_category_mapping\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Adult Census Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch adult dataset\n",
    "adult = fetch_adult()\n",
    "\n",
    "# Separate columns in numerical and categorical.\n",
    "categorical_names = [adult.feature_names[i] for i in adult.category_map.keys()]\n",
    "categorical_ids = list(adult.category_map.keys())\n",
    "\n",
    "numerical_names = [name for i, name in enumerate(adult.feature_names) if i not in adult.category_map.keys()]\n",
    "numerical_ids = [i for i in range(len(adult.feature_names)) if i not in adult.category_map.keys()]\n",
    "\n",
    "# split data into train and test\n",
    "X, Y = adult.data, adult.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train black-box classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical standard scaler.\n",
    "num_transf = StandardScaler()\n",
    "\n",
    "# Define categorical one-hot encoder.\n",
    "cat_transf = OneHotEncoder(\n",
    "    categories=[range(len(x)) for x in adult.category_map.values()],\n",
    "    handle_unknown=\"ignore\"\n",
    ")\n",
    "\n",
    "# Define column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transf, numerical_ids),\n",
    "        (\"cat\", cat_transf, categorical_ids),\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit preprocessor.\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Preprocess train and test dataset.\n",
    "X_train_ohe = preprocessor.transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=50,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit black-box classifier.\n",
    "clf = RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=50, random_state=0)\n",
    "clf.fit(X_train_ohe, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the predictor (black-box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the classifier, we can define the black-box model. Note that the output of the black-box is a distribution which can be either a soft-label distribution (probabilities/logits for each class) or a hard-label distribution (one-hot encoding). Internally, CfRL takes the `argmax`. Moreover the output **DOES NOT HAVE TO BE DIFFERENTIABLE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction function.\n",
    "predictor = lambda x: clf.predict_proba(preprocessor.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy.\n",
    "acc = accuracy_score(y_true=Y_test, y_pred=predictor(X_test).argmax(axis=1))\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly modelling the perturbation vector in the potentially high-dimensional input space, we first train an autoencoder. The weights of the encoder are frozen and the actor applies the\n",
    "counterfactual perturbations in the latent space of the encoder. The pre-trained decoder maps the counterfactual embedding back to the input feature space. \n",
    "\n",
    "The autoencoder follows a standard design. The model is composed from two submodules, the encoder and the decoder. The forward pass consists of passing the input to the encoder, obtain the input embedding and pass the embedding through the decoder.\n",
    "\n",
    "```python\n",
    "class HeAE(keras.Model):\n",
    "    def __init__(self, encoder: keras.Model, decoder: keras.Model, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x: tf.Tensor, **kwargs):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "```\n",
    "\n",
    "The heterogeneous variant used in this example uses an additional type checking to ensure that the output of the decoder is a list of tensors.\n",
    "\n",
    "Heterogeneous dataset require special treatment. In this work we modeled the numerical features by normal distributions with constant standard deviation and categorical features by categorical distributions. Due to the choice of feature modeling, some numerical features can end up having different types than the original numerical features. For example, a feature like `Age` having the type of `int` can become a `float` due to the autoencoder reconstruction (e.g., `Age=26 -> Age=26.3`). This behavior can be undesirable. Thus we performed casting when process the output of the autoencoder (decoder component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attribute types, required for datatype conversion.\n",
    "feature_types = {\"Age\": int, \"Capital Gain\": int, \"Capital Loss\": int, \"Hours per week\": int}\n",
    "\n",
    "# Define data preprocessor and inverse preprocessor. The invers preprocessor include datatype conversions.\n",
    "heae_preprocessor, heae_inv_preprocessor = get_he_preprocessor(X=X_train,\n",
    "                                                               feature_names=adult.feature_names,\n",
    "                                                               category_map=adult.category_map,\n",
    "                                                               feature_types=feature_types)\n",
    "\n",
    "# Define trainset\n",
    "trainset_input = heae_preprocessor(X_train).astype(np.float32)\n",
    "trainset_outputs = {\n",
    "    \"output_1\": X_train_ohe[:, :len(numerical_ids)]\n",
    "}\n",
    "\n",
    "for i, cat_id in enumerate(categorical_ids):\n",
    "    trainset_outputs.update({\n",
    "        f\"output_{i+2}\": X_train[:, cat_id]\n",
    "    })\n",
    "    \n",
    "trainset = tf.data.Dataset.from_tensor_slices((trainset_input, trainset_outputs))\n",
    "trainset = trainset.shuffle(1024).batch(128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 3s 5ms/step - loss: 1.6459 - output_1_loss: 0.4931 - output_2_loss: 1.4061 - output_3_loss: 1.3984 - output_4_loss: 0.9151 - output_5_loss: 1.8602 - output_6_loss: 1.2932 - output_7_loss: 0.7774 - output_8_loss: 0.4853 - output_9_loss: 1.0864 - output_2_sparse_categorical_accuracy: 0.5974 - output_3_sparse_categorical_accuracy: 0.5599 - output_4_sparse_categorical_accuracy: 0.6121 - output_5_sparse_categorical_accuracy: 0.3074 - output_6_sparse_categorical_accuracy: 0.5352 - output_7_sparse_categorical_accuracy: 0.8543 - output_8_sparse_categorical_accuracy: 0.7623 - output_9_sparse_categorical_accuracy: 0.7659\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4783 - output_1_loss: 0.0477 - output_2_loss: 0.6650 - output_3_loss: 0.6055 - output_4_loss: 0.2367 - output_5_loss: 0.7959 - output_6_loss: 0.3428 - output_7_loss: 0.3250 - output_8_loss: 0.1010 - output_9_loss: 0.3726 - output_2_sparse_categorical_accuracy: 0.7844 - output_3_sparse_categorical_accuracy: 0.7952 - output_4_sparse_categorical_accuracy: 0.9297 - output_5_sparse_categorical_accuracy: 0.7812 - output_6_sparse_categorical_accuracy: 0.9090 - output_7_sparse_categorical_accuracy: 0.8891 - output_8_sparse_categorical_accuracy: 0.9784 - output_9_sparse_categorical_accuracy: 0.9014\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2544 - output_1_loss: 0.0323 - output_2_loss: 0.2949 - output_3_loss: 0.2962 - output_4_loss: 0.1436 - output_5_loss: 0.2977 - output_6_loss: 0.2028 - output_7_loss: 0.2070 - output_8_loss: 0.0523 - output_9_loss: 0.2818 - output_2_sparse_categorical_accuracy: 0.9167 - output_3_sparse_categorical_accuracy: 0.9193 - output_4_sparse_categorical_accuracy: 0.9594 - output_5_sparse_categorical_accuracy: 0.9341 - output_6_sparse_categorical_accuracy: 0.9469 - output_7_sparse_categorical_accuracy: 0.9417 - output_8_sparse_categorical_accuracy: 0.9898 - output_9_sparse_categorical_accuracy: 0.9154\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1713 - output_1_loss: 0.0242 - output_2_loss: 0.1810 - output_3_loss: 0.1843 - output_4_loss: 0.0890 - output_5_loss: 0.2004 - output_6_loss: 0.1332 - output_7_loss: 0.1389 - output_8_loss: 0.0370 - output_9_loss: 0.2130 - output_2_sparse_categorical_accuracy: 0.9502 - output_3_sparse_categorical_accuracy: 0.9530 - output_4_sparse_categorical_accuracy: 0.9772 - output_5_sparse_categorical_accuracy: 0.9516 - output_6_sparse_categorical_accuracy: 0.9679 - output_7_sparse_categorical_accuracy: 0.9625 - output_8_sparse_categorical_accuracy: 0.9914 - output_9_sparse_categorical_accuracy: 0.9336\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1311 - output_1_loss: 0.0193 - output_2_loss: 0.1291 - output_3_loss: 0.1325 - output_4_loss: 0.0666 - output_5_loss: 0.1503 - output_6_loss: 0.1048 - output_7_loss: 0.1056 - output_8_loss: 0.0289 - output_9_loss: 0.1768 - output_2_sparse_categorical_accuracy: 0.9686 - output_3_sparse_categorical_accuracy: 0.9687 - output_4_sparse_categorical_accuracy: 0.9835 - output_5_sparse_categorical_accuracy: 0.9619 - output_6_sparse_categorical_accuracy: 0.9726 - output_7_sparse_categorical_accuracy: 0.9701 - output_8_sparse_categorical_accuracy: 0.9933 - output_9_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1074 - output_1_loss: 0.0161 - output_2_loss: 0.1022 - output_3_loss: 0.1050 - output_4_loss: 0.0547 - output_5_loss: 0.1202 - output_6_loss: 0.0869 - output_7_loss: 0.0848 - output_8_loss: 0.0226 - output_9_loss: 0.1536 - output_2_sparse_categorical_accuracy: 0.9747 - output_3_sparse_categorical_accuracy: 0.9753 - output_4_sparse_categorical_accuracy: 0.9859 - output_5_sparse_categorical_accuracy: 0.9685 - output_6_sparse_categorical_accuracy: 0.9762 - output_7_sparse_categorical_accuracy: 0.9760 - output_8_sparse_categorical_accuracy: 0.9947 - output_9_sparse_categorical_accuracy: 0.9507\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.0906 - output_1_loss: 0.0137 - output_2_loss: 0.0833 - output_3_loss: 0.0895 - output_4_loss: 0.0474 - output_5_loss: 0.0992 - output_6_loss: 0.0736 - output_7_loss: 0.0696 - output_8_loss: 0.0193 - output_9_loss: 0.1336 - output_2_sparse_categorical_accuracy: 0.9787 - output_3_sparse_categorical_accuracy: 0.9782 - output_4_sparse_categorical_accuracy: 0.9877 - output_5_sparse_categorical_accuracy: 0.9733 - output_6_sparse_categorical_accuracy: 0.9800 - output_7_sparse_categorical_accuracy: 0.9791 - output_8_sparse_categorical_accuracy: 0.9959 - output_9_sparse_categorical_accuracy: 0.9577\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0788 - output_1_loss: 0.0123 - output_2_loss: 0.0708 - output_3_loss: 0.0759 - output_4_loss: 0.0425 - output_5_loss: 0.0840 - output_6_loss: 0.0634 - output_7_loss: 0.0601 - output_8_loss: 0.0153 - output_9_loss: 0.1199 - output_2_sparse_categorical_accuracy: 0.9815 - output_3_sparse_categorical_accuracy: 0.9809 - output_4_sparse_categorical_accuracy: 0.9885 - output_5_sparse_categorical_accuracy: 0.9778 - output_6_sparse_categorical_accuracy: 0.9823 - output_7_sparse_categorical_accuracy: 0.9828 - output_8_sparse_categorical_accuracy: 0.9962 - output_9_sparse_categorical_accuracy: 0.9618\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 0.0700 - output_1_loss: 0.0111 - output_2_loss: 0.0585 - output_3_loss: 0.0686 - output_4_loss: 0.0380 - output_5_loss: 0.0729 - output_6_loss: 0.0568 - output_7_loss: 0.0540 - output_8_loss: 0.0142 - output_9_loss: 0.1083 - output_2_sparse_categorical_accuracy: 0.9850 - output_3_sparse_categorical_accuracy: 0.9821 - output_4_sparse_categorical_accuracy: 0.9904 - output_5_sparse_categorical_accuracy: 0.9818 - output_6_sparse_categorical_accuracy: 0.9842 - output_7_sparse_categorical_accuracy: 0.9842 - output_8_sparse_categorical_accuracy: 0.9964 - output_9_sparse_categorical_accuracy: 0.9664\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.0618 - output_1_loss: 0.0100 - output_2_loss: 0.0501 - output_3_loss: 0.0597 - output_4_loss: 0.0346 - output_5_loss: 0.0623 - output_6_loss: 0.0498 - output_7_loss: 0.0474 - output_8_loss: 0.0125 - output_9_loss: 0.0988 - output_2_sparse_categorical_accuracy: 0.9877 - output_3_sparse_categorical_accuracy: 0.9843 - output_4_sparse_categorical_accuracy: 0.9911 - output_5_sparse_categorical_accuracy: 0.9850 - output_6_sparse_categorical_accuracy: 0.9874 - output_7_sparse_categorical_accuracy: 0.9861 - output_8_sparse_categorical_accuracy: 0.9965 - output_9_sparse_categorical_accuracy: 0.9702\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0551 - output_1_loss: 0.0092 - output_2_loss: 0.0437 - output_3_loss: 0.0524 - output_4_loss: 0.0312 - output_5_loss: 0.0542 - output_6_loss: 0.0432 - output_7_loss: 0.0417 - output_8_loss: 0.0109 - output_9_loss: 0.0897 - output_2_sparse_categorical_accuracy: 0.9899 - output_3_sparse_categorical_accuracy: 0.9863 - output_4_sparse_categorical_accuracy: 0.9924 - output_5_sparse_categorical_accuracy: 0.9880 - output_6_sparse_categorical_accuracy: 0.9894 - output_7_sparse_categorical_accuracy: 0.9880 - output_8_sparse_categorical_accuracy: 0.9973 - output_9_sparse_categorical_accuracy: 0.9741\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0500 - output_1_loss: 0.0084 - output_2_loss: 0.0386 - output_3_loss: 0.0471 - output_4_loss: 0.0277 - output_5_loss: 0.0490 - output_6_loss: 0.0403 - output_7_loss: 0.0385 - output_8_loss: 0.0093 - output_9_loss: 0.0822 - output_2_sparse_categorical_accuracy: 0.9909 - output_3_sparse_categorical_accuracy: 0.9879 - output_4_sparse_categorical_accuracy: 0.9926 - output_5_sparse_categorical_accuracy: 0.9883 - output_6_sparse_categorical_accuracy: 0.9898 - output_7_sparse_categorical_accuracy: 0.9891 - output_8_sparse_categorical_accuracy: 0.9976 - output_9_sparse_categorical_accuracy: 0.9751\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0456 - output_1_loss: 0.0081 - output_2_loss: 0.0341 - output_3_loss: 0.0412 - output_4_loss: 0.0261 - output_5_loss: 0.0434 - output_6_loss: 0.0370 - output_7_loss: 0.0344 - output_8_loss: 0.0086 - output_9_loss: 0.0756 - output_2_sparse_categorical_accuracy: 0.9922 - output_3_sparse_categorical_accuracy: 0.9903 - output_4_sparse_categorical_accuracy: 0.9931 - output_5_sparse_categorical_accuracy: 0.9901 - output_6_sparse_categorical_accuracy: 0.9901 - output_7_sparse_categorical_accuracy: 0.9908 - output_8_sparse_categorical_accuracy: 0.9978 - output_9_sparse_categorical_accuracy: 0.9776\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0418 - output_1_loss: 0.0073 - output_2_loss: 0.0310 - output_3_loss: 0.0379 - output_4_loss: 0.0240 - output_5_loss: 0.0393 - output_6_loss: 0.0341 - output_7_loss: 0.0316 - output_8_loss: 0.0082 - output_9_loss: 0.0699 - output_2_sparse_categorical_accuracy: 0.9931 - output_3_sparse_categorical_accuracy: 0.9912 - output_4_sparse_categorical_accuracy: 0.9944 - output_5_sparse_categorical_accuracy: 0.9907 - output_6_sparse_categorical_accuracy: 0.9915 - output_7_sparse_categorical_accuracy: 0.9920 - output_8_sparse_categorical_accuracy: 0.9979 - output_9_sparse_categorical_accuracy: 0.9798\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0386 - output_1_loss: 0.0070 - output_2_loss: 0.0285 - output_3_loss: 0.0337 - output_4_loss: 0.0219 - output_5_loss: 0.0362 - output_6_loss: 0.0311 - output_7_loss: 0.0291 - output_8_loss: 0.0076 - output_9_loss: 0.0646 - output_2_sparse_categorical_accuracy: 0.9937 - output_3_sparse_categorical_accuracy: 0.9926 - output_4_sparse_categorical_accuracy: 0.9949 - output_5_sparse_categorical_accuracy: 0.9911 - output_6_sparse_categorical_accuracy: 0.9921 - output_7_sparse_categorical_accuracy: 0.9928 - output_8_sparse_categorical_accuracy: 0.9981 - output_9_sparse_categorical_accuracy: 0.9814\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0356 - output_1_loss: 0.0064 - output_2_loss: 0.0258 - output_3_loss: 0.0320 - output_4_loss: 0.0205 - output_5_loss: 0.0324 - output_6_loss: 0.0293 - output_7_loss: 0.0275 - output_8_loss: 0.0069 - output_9_loss: 0.0593 - output_2_sparse_categorical_accuracy: 0.9942 - output_3_sparse_categorical_accuracy: 0.9932 - output_4_sparse_categorical_accuracy: 0.9951 - output_5_sparse_categorical_accuracy: 0.9927 - output_6_sparse_categorical_accuracy: 0.9928 - output_7_sparse_categorical_accuracy: 0.9926 - output_8_sparse_categorical_accuracy: 0.9981 - output_9_sparse_categorical_accuracy: 0.9830\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0335 - output_1_loss: 0.0063 - output_2_loss: 0.0238 - output_3_loss: 0.0299 - output_4_loss: 0.0194 - output_5_loss: 0.0300 - output_6_loss: 0.0271 - output_7_loss: 0.0261 - output_8_loss: 0.0069 - output_9_loss: 0.0544 - output_2_sparse_categorical_accuracy: 0.9944 - output_3_sparse_categorical_accuracy: 0.9935 - output_4_sparse_categorical_accuracy: 0.9955 - output_5_sparse_categorical_accuracy: 0.9930 - output_6_sparse_categorical_accuracy: 0.9932 - output_7_sparse_categorical_accuracy: 0.9935 - output_8_sparse_categorical_accuracy: 0.9980 - output_9_sparse_categorical_accuracy: 0.9840\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0308 - output_1_loss: 0.0058 - output_2_loss: 0.0216 - output_3_loss: 0.0276 - output_4_loss: 0.0176 - output_5_loss: 0.0277 - output_6_loss: 0.0245 - output_7_loss: 0.0236 - output_8_loss: 0.0060 - output_9_loss: 0.0509 - output_2_sparse_categorical_accuracy: 0.9948 - output_3_sparse_categorical_accuracy: 0.9941 - output_4_sparse_categorical_accuracy: 0.9964 - output_5_sparse_categorical_accuracy: 0.9937 - output_6_sparse_categorical_accuracy: 0.9940 - output_7_sparse_categorical_accuracy: 0.9938 - output_8_sparse_categorical_accuracy: 0.9985 - output_9_sparse_categorical_accuracy: 0.9853\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0291 - output_1_loss: 0.0058 - output_2_loss: 0.0201 - output_3_loss: 0.0257 - output_4_loss: 0.0169 - output_5_loss: 0.0255 - output_6_loss: 0.0225 - output_7_loss: 0.0222 - output_8_loss: 0.0059 - output_9_loss: 0.0474 - output_2_sparse_categorical_accuracy: 0.9953 - output_3_sparse_categorical_accuracy: 0.9944 - output_4_sparse_categorical_accuracy: 0.9967 - output_5_sparse_categorical_accuracy: 0.9939 - output_6_sparse_categorical_accuracy: 0.9944 - output_7_sparse_categorical_accuracy: 0.9942 - output_8_sparse_categorical_accuracy: 0.9985 - output_9_sparse_categorical_accuracy: 0.9859\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0269 - output_1_loss: 0.0054 - output_2_loss: 0.0186 - output_3_loss: 0.0232 - output_4_loss: 0.0157 - output_5_loss: 0.0232 - output_6_loss: 0.0214 - output_7_loss: 0.0209 - output_8_loss: 0.0058 - output_9_loss: 0.0432 - output_2_sparse_categorical_accuracy: 0.9959 - output_3_sparse_categorical_accuracy: 0.9951 - output_4_sparse_categorical_accuracy: 0.9968 - output_5_sparse_categorical_accuracy: 0.9950 - output_6_sparse_categorical_accuracy: 0.9949 - output_7_sparse_categorical_accuracy: 0.9944 - output_8_sparse_categorical_accuracy: 0.9985 - output_9_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0252 - output_1_loss: 0.0052 - output_2_loss: 0.0170 - output_3_loss: 0.0218 - output_4_loss: 0.0158 - output_5_loss: 0.0213 - output_6_loss: 0.0196 - output_7_loss: 0.0199 - output_8_loss: 0.0050 - output_9_loss: 0.0395 - output_2_sparse_categorical_accuracy: 0.9964 - output_3_sparse_categorical_accuracy: 0.9950 - output_4_sparse_categorical_accuracy: 0.9967 - output_5_sparse_categorical_accuracy: 0.9958 - output_6_sparse_categorical_accuracy: 0.9953 - output_7_sparse_categorical_accuracy: 0.9947 - output_8_sparse_categorical_accuracy: 0.9988 - output_9_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0237 - output_1_loss: 0.0050 - output_2_loss: 0.0159 - output_3_loss: 0.0201 - output_4_loss: 0.0141 - output_5_loss: 0.0203 - output_6_loss: 0.0185 - output_7_loss: 0.0187 - output_8_loss: 0.0044 - output_9_loss: 0.0379 - output_2_sparse_categorical_accuracy: 0.9963 - output_3_sparse_categorical_accuracy: 0.9957 - output_4_sparse_categorical_accuracy: 0.9972 - output_5_sparse_categorical_accuracy: 0.9955 - output_6_sparse_categorical_accuracy: 0.9956 - output_7_sparse_categorical_accuracy: 0.9949 - output_8_sparse_categorical_accuracy: 0.9990 - output_9_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0221 - output_1_loss: 0.0049 - output_2_loss: 0.0147 - output_3_loss: 0.0180 - output_4_loss: 0.0131 - output_5_loss: 0.0186 - output_6_loss: 0.0170 - output_7_loss: 0.0171 - output_8_loss: 0.0044 - output_9_loss: 0.0350 - output_2_sparse_categorical_accuracy: 0.9965 - output_3_sparse_categorical_accuracy: 0.9957 - output_4_sparse_categorical_accuracy: 0.9972 - output_5_sparse_categorical_accuracy: 0.9963 - output_6_sparse_categorical_accuracy: 0.9968 - output_7_sparse_categorical_accuracy: 0.9955 - output_8_sparse_categorical_accuracy: 0.9986 - output_9_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0206 - output_1_loss: 0.0047 - output_2_loss: 0.0135 - output_3_loss: 0.0168 - output_4_loss: 0.0126 - output_5_loss: 0.0172 - output_6_loss: 0.0157 - output_7_loss: 0.0161 - output_8_loss: 0.0042 - output_9_loss: 0.0317 - output_2_sparse_categorical_accuracy: 0.9973 - output_3_sparse_categorical_accuracy: 0.9964 - output_4_sparse_categorical_accuracy: 0.9977 - output_5_sparse_categorical_accuracy: 0.9963 - output_6_sparse_categorical_accuracy: 0.9968 - output_7_sparse_categorical_accuracy: 0.9954 - output_8_sparse_categorical_accuracy: 0.9985 - output_9_sparse_categorical_accuracy: 0.9911\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0194 - output_1_loss: 0.0043 - output_2_loss: 0.0125 - output_3_loss: 0.0163 - output_4_loss: 0.0120 - output_5_loss: 0.0158 - output_6_loss: 0.0147 - output_7_loss: 0.0158 - output_8_loss: 0.0041 - output_9_loss: 0.0297 - output_2_sparse_categorical_accuracy: 0.9970 - output_3_sparse_categorical_accuracy: 0.9964 - output_4_sparse_categorical_accuracy: 0.9980 - output_5_sparse_categorical_accuracy: 0.9968 - output_6_sparse_categorical_accuracy: 0.9971 - output_7_sparse_categorical_accuracy: 0.9953 - output_8_sparse_categorical_accuracy: 0.9987 - output_9_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0184 - output_1_loss: 0.0043 - output_2_loss: 0.0116 - output_3_loss: 0.0147 - output_4_loss: 0.0115 - output_5_loss: 0.0153 - output_6_loss: 0.0137 - output_7_loss: 0.0141 - output_8_loss: 0.0039 - output_9_loss: 0.0277 - output_2_sparse_categorical_accuracy: 0.9976 - output_3_sparse_categorical_accuracy: 0.9963 - output_4_sparse_categorical_accuracy: 0.9977 - output_5_sparse_categorical_accuracy: 0.9968 - output_6_sparse_categorical_accuracy: 0.9975 - output_7_sparse_categorical_accuracy: 0.9962 - output_8_sparse_categorical_accuracy: 0.9990 - output_9_sparse_categorical_accuracy: 0.9927\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0175 - output_1_loss: 0.0042 - output_2_loss: 0.0110 - output_3_loss: 0.0138 - output_4_loss: 0.0114 - output_5_loss: 0.0140 - output_6_loss: 0.0128 - output_7_loss: 0.0138 - output_8_loss: 0.0035 - output_9_loss: 0.0262 - output_2_sparse_categorical_accuracy: 0.9979 - output_3_sparse_categorical_accuracy: 0.9969 - output_4_sparse_categorical_accuracy: 0.9979 - output_5_sparse_categorical_accuracy: 0.9971 - output_6_sparse_categorical_accuracy: 0.9976 - output_7_sparse_categorical_accuracy: 0.9967 - output_8_sparse_categorical_accuracy: 0.9991 - output_9_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0167 - output_1_loss: 0.0042 - output_2_loss: 0.0102 - output_3_loss: 0.0132 - output_4_loss: 0.0107 - output_5_loss: 0.0131 - output_6_loss: 0.0121 - output_7_loss: 0.0126 - output_8_loss: 0.0035 - output_9_loss: 0.0249 - output_2_sparse_categorical_accuracy: 0.9981 - output_3_sparse_categorical_accuracy: 0.9973 - output_4_sparse_categorical_accuracy: 0.9979 - output_5_sparse_categorical_accuracy: 0.9978 - output_6_sparse_categorical_accuracy: 0.9976 - output_7_sparse_categorical_accuracy: 0.9968 - output_8_sparse_categorical_accuracy: 0.9993 - output_9_sparse_categorical_accuracy: 0.9936\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0158 - output_1_loss: 0.0039 - output_2_loss: 0.0098 - output_3_loss: 0.0122 - output_4_loss: 0.0102 - output_5_loss: 0.0127 - output_6_loss: 0.0115 - output_7_loss: 0.0121 - output_8_loss: 0.0030 - output_9_loss: 0.0235 - output_2_sparse_categorical_accuracy: 0.9980 - output_3_sparse_categorical_accuracy: 0.9974 - output_4_sparse_categorical_accuracy: 0.9983 - output_5_sparse_categorical_accuracy: 0.9977 - output_6_sparse_categorical_accuracy: 0.9976 - output_7_sparse_categorical_accuracy: 0.9974 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9944\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0149 - output_1_loss: 0.0037 - output_2_loss: 0.0089 - output_3_loss: 0.0120 - output_4_loss: 0.0094 - output_5_loss: 0.0115 - output_6_loss: 0.0111 - output_7_loss: 0.0119 - output_8_loss: 0.0026 - output_9_loss: 0.0223 - output_2_sparse_categorical_accuracy: 0.9984 - output_3_sparse_categorical_accuracy: 0.9975 - output_4_sparse_categorical_accuracy: 0.9986 - output_5_sparse_categorical_accuracy: 0.9974 - output_6_sparse_categorical_accuracy: 0.9978 - output_7_sparse_categorical_accuracy: 0.9972 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9945\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0147 - output_1_loss: 0.0041 - output_2_loss: 0.0086 - output_3_loss: 0.0111 - output_4_loss: 0.0089 - output_5_loss: 0.0114 - output_6_loss: 0.0105 - output_7_loss: 0.0109 - output_8_loss: 0.0026 - output_9_loss: 0.0206 - output_2_sparse_categorical_accuracy: 0.9985 - output_3_sparse_categorical_accuracy: 0.9977 - output_4_sparse_categorical_accuracy: 0.9985 - output_5_sparse_categorical_accuracy: 0.9978 - output_6_sparse_categorical_accuracy: 0.9978 - output_7_sparse_categorical_accuracy: 0.9978 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9953\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0134 - output_1_loss: 0.0035 - output_2_loss: 0.0079 - output_3_loss: 0.0104 - output_4_loss: 0.0082 - output_5_loss: 0.0110 - output_6_loss: 0.0094 - output_7_loss: 0.0106 - output_8_loss: 0.0028 - output_9_loss: 0.0196 - output_2_sparse_categorical_accuracy: 0.9983 - output_3_sparse_categorical_accuracy: 0.9979 - output_4_sparse_categorical_accuracy: 0.9987 - output_5_sparse_categorical_accuracy: 0.9979 - output_6_sparse_categorical_accuracy: 0.9985 - output_7_sparse_categorical_accuracy: 0.9975 - output_8_sparse_categorical_accuracy: 0.9992 - output_9_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 33/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0132 - output_1_loss: 0.0035 - output_2_loss: 0.0077 - output_3_loss: 0.0105 - output_4_loss: 0.0077 - output_5_loss: 0.0105 - output_6_loss: 0.0093 - output_7_loss: 0.0093 - output_8_loss: 0.0030 - output_9_loss: 0.0189 - output_2_sparse_categorical_accuracy: 0.9987 - output_3_sparse_categorical_accuracy: 0.9978 - output_4_sparse_categorical_accuracy: 0.9989 - output_5_sparse_categorical_accuracy: 0.9978 - output_6_sparse_categorical_accuracy: 0.9982 - output_7_sparse_categorical_accuracy: 0.9983 - output_8_sparse_categorical_accuracy: 0.9992 - output_9_sparse_categorical_accuracy: 0.9954\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0125 - output_1_loss: 0.0034 - output_2_loss: 0.0073 - output_3_loss: 0.0097 - output_4_loss: 0.0080 - output_5_loss: 0.0102 - output_6_loss: 0.0088 - output_7_loss: 0.0093 - output_8_loss: 0.0026 - output_9_loss: 0.0174 - output_2_sparse_categorical_accuracy: 0.9989 - output_3_sparse_categorical_accuracy: 0.9982 - output_4_sparse_categorical_accuracy: 0.9986 - output_5_sparse_categorical_accuracy: 0.9979 - output_6_sparse_categorical_accuracy: 0.9987 - output_7_sparse_categorical_accuracy: 0.9980 - output_8_sparse_categorical_accuracy: 0.9993 - output_9_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0119 - output_1_loss: 0.0032 - output_2_loss: 0.0068 - output_3_loss: 0.0092 - output_4_loss: 0.0070 - output_5_loss: 0.0091 - output_6_loss: 0.0084 - output_7_loss: 0.0089 - output_8_loss: 0.0028 - output_9_loss: 0.0168 - output_2_sparse_categorical_accuracy: 0.9989 - output_3_sparse_categorical_accuracy: 0.9983 - output_4_sparse_categorical_accuracy: 0.9990 - output_5_sparse_categorical_accuracy: 0.9980 - output_6_sparse_categorical_accuracy: 0.9987 - output_7_sparse_categorical_accuracy: 0.9981 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0114 - output_1_loss: 0.0032 - output_2_loss: 0.0068 - output_3_loss: 0.0087 - output_4_loss: 0.0068 - output_5_loss: 0.0089 - output_6_loss: 0.0078 - output_7_loss: 0.0086 - output_8_loss: 0.0022 - output_9_loss: 0.0160 - output_2_sparse_categorical_accuracy: 0.9989 - output_3_sparse_categorical_accuracy: 0.9984 - output_4_sparse_categorical_accuracy: 0.9986 - output_5_sparse_categorical_accuracy: 0.9982 - output_6_sparse_categorical_accuracy: 0.9986 - output_7_sparse_categorical_accuracy: 0.9982 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0108 - output_1_loss: 0.0029 - output_2_loss: 0.0060 - output_3_loss: 0.0080 - output_4_loss: 0.0064 - output_5_loss: 0.0089 - output_6_loss: 0.0078 - output_7_loss: 0.0082 - output_8_loss: 0.0021 - output_9_loss: 0.0153 - output_2_sparse_categorical_accuracy: 0.9992 - output_3_sparse_categorical_accuracy: 0.9986 - output_4_sparse_categorical_accuracy: 0.9990 - output_5_sparse_categorical_accuracy: 0.9979 - output_6_sparse_categorical_accuracy: 0.9987 - output_7_sparse_categorical_accuracy: 0.9983 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0106 - output_1_loss: 0.0031 - output_2_loss: 0.0060 - output_3_loss: 0.0079 - output_4_loss: 0.0063 - output_5_loss: 0.0084 - output_6_loss: 0.0070 - output_7_loss: 0.0079 - output_8_loss: 0.0018 - output_9_loss: 0.0146 - output_2_sparse_categorical_accuracy: 0.9989 - output_3_sparse_categorical_accuracy: 0.9987 - output_4_sparse_categorical_accuracy: 0.9990 - output_5_sparse_categorical_accuracy: 0.9981 - output_6_sparse_categorical_accuracy: 0.9990 - output_7_sparse_categorical_accuracy: 0.9983 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0099 - output_1_loss: 0.0029 - output_2_loss: 0.0056 - output_3_loss: 0.0074 - output_4_loss: 0.0058 - output_5_loss: 0.0078 - output_6_loss: 0.0070 - output_7_loss: 0.0073 - output_8_loss: 0.0019 - output_9_loss: 0.0136 - output_2_sparse_categorical_accuracy: 0.9990 - output_3_sparse_categorical_accuracy: 0.9988 - output_4_sparse_categorical_accuracy: 0.9992 - output_5_sparse_categorical_accuracy: 0.9983 - output_6_sparse_categorical_accuracy: 0.9987 - output_7_sparse_categorical_accuracy: 0.9985 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0095 - output_1_loss: 0.0028 - output_2_loss: 0.0053 - output_3_loss: 0.0069 - output_4_loss: 0.0055 - output_5_loss: 0.0073 - output_6_loss: 0.0065 - output_7_loss: 0.0075 - output_8_loss: 0.0017 - output_9_loss: 0.0130 - output_2_sparse_categorical_accuracy: 0.9992 - output_3_sparse_categorical_accuracy: 0.9986 - output_4_sparse_categorical_accuracy: 0.9992 - output_5_sparse_categorical_accuracy: 0.9988 - output_6_sparse_categorical_accuracy: 0.9990 - output_7_sparse_categorical_accuracy: 0.9985 - output_8_sparse_categorical_accuracy: 0.9999 - output_9_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0093 - output_1_loss: 0.0028 - output_2_loss: 0.0055 - output_3_loss: 0.0067 - output_4_loss: 0.0054 - output_5_loss: 0.0071 - output_6_loss: 0.0062 - output_7_loss: 0.0067 - output_8_loss: 0.0018 - output_9_loss: 0.0124 - output_2_sparse_categorical_accuracy: 0.9993 - output_3_sparse_categorical_accuracy: 0.9988 - output_4_sparse_categorical_accuracy: 0.9994 - output_5_sparse_categorical_accuracy: 0.9989 - output_6_sparse_categorical_accuracy: 0.9991 - output_7_sparse_categorical_accuracy: 0.9988 - output_8_sparse_categorical_accuracy: 0.9997 - output_9_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0092 - output_1_loss: 0.0029 - output_2_loss: 0.0052 - output_3_loss: 0.0066 - output_4_loss: 0.0052 - output_5_loss: 0.0068 - output_6_loss: 0.0057 - output_7_loss: 0.0069 - output_8_loss: 0.0019 - output_9_loss: 0.0121 - output_2_sparse_categorical_accuracy: 0.9992 - output_3_sparse_categorical_accuracy: 0.9987 - output_4_sparse_categorical_accuracy: 0.9993 - output_5_sparse_categorical_accuracy: 0.9990 - output_6_sparse_categorical_accuracy: 0.9995 - output_7_sparse_categorical_accuracy: 0.9986 - output_8_sparse_categorical_accuracy: 0.9997 - output_9_sparse_categorical_accuracy: 0.9975\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0085 - output_1_loss: 0.0026 - output_2_loss: 0.0047 - output_3_loss: 0.0062 - output_4_loss: 0.0049 - output_5_loss: 0.0062 - output_6_loss: 0.0056 - output_7_loss: 0.0062 - output_8_loss: 0.0016 - output_9_loss: 0.0117 - output_2_sparse_categorical_accuracy: 0.9993 - output_3_sparse_categorical_accuracy: 0.9987 - output_4_sparse_categorical_accuracy: 0.9991 - output_5_sparse_categorical_accuracy: 0.9991 - output_6_sparse_categorical_accuracy: 0.9993 - output_7_sparse_categorical_accuracy: 0.9990 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0086 - output_1_loss: 0.0027 - output_2_loss: 0.0049 - output_3_loss: 0.0061 - output_4_loss: 0.0048 - output_5_loss: 0.0068 - output_6_loss: 0.0052 - output_7_loss: 0.0064 - output_8_loss: 0.0015 - output_9_loss: 0.0115 - output_2_sparse_categorical_accuracy: 0.9994 - output_3_sparse_categorical_accuracy: 0.9991 - output_4_sparse_categorical_accuracy: 0.9992 - output_5_sparse_categorical_accuracy: 0.9988 - output_6_sparse_categorical_accuracy: 0.9994 - output_7_sparse_categorical_accuracy: 0.9989 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0082 - output_1_loss: 0.0027 - output_2_loss: 0.0046 - output_3_loss: 0.0058 - output_4_loss: 0.0046 - output_5_loss: 0.0059 - output_6_loss: 0.0054 - output_7_loss: 0.0057 - output_8_loss: 0.0014 - output_9_loss: 0.0108 - output_2_sparse_categorical_accuracy: 0.9993 - output_3_sparse_categorical_accuracy: 0.9989 - output_4_sparse_categorical_accuracy: 0.9995 - output_5_sparse_categorical_accuracy: 0.9992 - output_6_sparse_categorical_accuracy: 0.9989 - output_7_sparse_categorical_accuracy: 0.9989 - output_8_sparse_categorical_accuracy: 1.0000 - output_9_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0080 - output_1_loss: 0.0025 - output_2_loss: 0.0047 - output_3_loss: 0.0057 - output_4_loss: 0.0047 - output_5_loss: 0.0058 - output_6_loss: 0.0052 - output_7_loss: 0.0058 - output_8_loss: 0.0018 - output_9_loss: 0.0103 - output_2_sparse_categorical_accuracy: 0.9991 - output_3_sparse_categorical_accuracy: 0.9988 - output_4_sparse_categorical_accuracy: 0.9991 - output_5_sparse_categorical_accuracy: 0.9991 - output_6_sparse_categorical_accuracy: 0.9991 - output_7_sparse_categorical_accuracy: 0.9992 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0078 - output_1_loss: 0.0026 - output_2_loss: 0.0045 - output_3_loss: 0.0055 - output_4_loss: 0.0045 - output_5_loss: 0.0055 - output_6_loss: 0.0050 - output_7_loss: 0.0056 - output_8_loss: 0.0017 - output_9_loss: 0.0098 - output_2_sparse_categorical_accuracy: 0.9993 - output_3_sparse_categorical_accuracy: 0.9990 - output_4_sparse_categorical_accuracy: 0.9993 - output_5_sparse_categorical_accuracy: 0.9988 - output_6_sparse_categorical_accuracy: 0.9991 - output_7_sparse_categorical_accuracy: 0.9988 - output_8_sparse_categorical_accuracy: 0.9993 - output_9_sparse_categorical_accuracy: 0.9982\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0074 - output_1_loss: 0.0025 - output_2_loss: 0.0041 - output_3_loss: 0.0051 - output_4_loss: 0.0039 - output_5_loss: 0.0056 - output_6_loss: 0.0043 - output_7_loss: 0.0055 - output_8_loss: 0.0017 - output_9_loss: 0.0096 - output_2_sparse_categorical_accuracy: 0.9993 - output_3_sparse_categorical_accuracy: 0.9991 - output_4_sparse_categorical_accuracy: 0.9995 - output_5_sparse_categorical_accuracy: 0.9992 - output_6_sparse_categorical_accuracy: 0.9996 - output_7_sparse_categorical_accuracy: 0.9991 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0069 - output_1_loss: 0.0023 - output_2_loss: 0.0039 - output_3_loss: 0.0050 - output_4_loss: 0.0040 - output_5_loss: 0.0048 - output_6_loss: 0.0041 - output_7_loss: 0.0049 - output_8_loss: 0.0014 - output_9_loss: 0.0087 - output_2_sparse_categorical_accuracy: 0.9996 - output_3_sparse_categorical_accuracy: 0.9993 - output_4_sparse_categorical_accuracy: 0.9993 - output_5_sparse_categorical_accuracy: 0.9993 - output_6_sparse_categorical_accuracy: 0.9996 - output_7_sparse_categorical_accuracy: 0.9993 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0070 - output_1_loss: 0.0024 - output_2_loss: 0.0046 - output_3_loss: 0.0047 - output_4_loss: 0.0042 - output_5_loss: 0.0049 - output_6_loss: 0.0038 - output_7_loss: 0.0049 - output_8_loss: 0.0014 - output_9_loss: 0.0082 - output_2_sparse_categorical_accuracy: 0.9992 - output_3_sparse_categorical_accuracy: 0.9990 - output_4_sparse_categorical_accuracy: 0.9993 - output_5_sparse_categorical_accuracy: 0.9993 - output_6_sparse_categorical_accuracy: 0.9997 - output_7_sparse_categorical_accuracy: 0.9990 - output_8_sparse_categorical_accuracy: 0.9997 - output_9_sparse_categorical_accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: tensorflow/ADULT_autoencoder/assets\n"
     ]
    }
   ],
   "source": [
    "# Define autoencoder path and create dir if it doesn't exist.\n",
    "heae_path = os.path.join(\"tensorflow\", \"ADULT_autoencoder\")\n",
    "if not os.path.exists(heae_path):\n",
    "    os.makedirs(heae_path)\n",
    "\n",
    "# Define constants.\n",
    "EPOCHS = 50             # epochs to train the autoencoder\n",
    "HIDDEN_DIM = 128         # hidden dimension of the autoencoder\n",
    "LATENT_DIM = 15          # define latent dimension\n",
    "\n",
    "# Define output dimensions.\n",
    "OUTPUT_DIMS = [len(numerical_ids)]\n",
    "OUTPUT_DIMS += [len(adult.category_map[cat_id]) for cat_id in categorical_ids]\n",
    "\n",
    "# Define the heterogeneous auto-encoder.\n",
    "heae = HeAE(encoder=ADULTEncoder(hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM),\n",
    "            decoder=ADULTDecoder(hidden_dim=HIDDEN_DIM, output_dims=OUTPUT_DIMS))\n",
    "\n",
    "# Define loss functions.\n",
    "he_loss = [keras.losses.MeanSquaredError()]\n",
    "he_loss_weights = [1.]\n",
    "\n",
    "# Add categorical losses.\n",
    "for i in range(len(categorical_names)):\n",
    "    he_loss.append(keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "    he_loss_weights.append(1./len(categorical_names))\n",
    "\n",
    "# Define metrics.\n",
    "metrics = {}\n",
    "for i, cat_name in enumerate(categorical_names):\n",
    "    metrics.update({f\"output_{i+2}\": keras.metrics.SparseCategoricalAccuracy()})\n",
    "    \n",
    "# Compile model.\n",
    "heae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "             loss=he_loss,\n",
    "             loss_weights=he_loss_weights,\n",
    "             metrics=metrics)\n",
    "\n",
    "if len(os.listdir(heae_path)) == 0:\n",
    "    # Fit and save autoencoder.\n",
    "    heae.fit(trainset, epochs=EPOCHS)\n",
    "    heae.save(heae_path, save_format=\"tf\")\n",
    "else:\n",
    "    # Load the model.\n",
    "    heae = keras.models.load_model(heae_path, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual with Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "COEFF_SPARSITY = 0.5               # sparisty coefficient\n",
    "COEFF_CONSISTENCY = 0.5            # consisteny coefficient -> No consistency.\n",
    "TRAIN_STEPS = 1000                 # number of training steps -> increase this to 150.000 or even further\n",
    "BATCH_SIZE = 100                   # batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset specific attributes and constraints\n",
    "\n",
    "A desirable property of a method for generating counterfactuals is to allow feature conditioning. Real-world datasets usually include immutable features such as *gender* or *race*, which should remain unchanged throughout the counterfactual search procedure. Similarly, a numerical feature such as `Age` should only increase for a counterfactual to be actionable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define immutable features.\n",
    "immutable_features = ['Marital Status', 'Relationship', 'Race', 'Sex']\n",
    "\n",
    "# Define ranges. This means that the `Age` feature can not decrease.\n",
    "ranges = {'Age': [0.0, 1.0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and fit the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CounterfactualRLTabular(predictor=predictor,\n",
    "                                    encoder=heae.encoder,\n",
    "                                    decoder=heae.decoder,\n",
    "                                    latent_dim=LATENT_DIM,\n",
    "                                    encoder_preprocessor=heae_preprocessor,\n",
    "                                    decoder_inv_preprocessor=heae_inv_preprocessor,\n",
    "                                    coeff_sparsity=COEFF_SPARSITY,\n",
    "                                    coeff_consistency=COEFF_CONSISTENCY,\n",
    "                                    category_map=adult.category_map,\n",
    "                                    feature_names=adult.feature_names,\n",
    "                                    ranges=ranges,\n",
    "                                    immutable_features=immutable_features,\n",
    "                                    train_steps=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    backend=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit the explainer.\n",
    "explainer = explainer.fit(X=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some positive examples.\n",
    "X_positive = X_test[np.argmax(predictor(X_test), axis=1) == 1]\n",
    "\n",
    "X = X_positive[:100]\n",
    "Y_t = np.array([0])\n",
    "C = [{\"Age\": [0, 20], \"Workclass\": [\"State-gov\", \"?\", \"Local-gov\"]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactual instances.\n",
    "explanation = explainer.explain(X, Y_t, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat labels to the original instances.\n",
    "orig = np.concatenate(\n",
    "    [explanation.data['orig']['X'], explanation.data['orig']['class']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Concat labels to the counterfactual instances.\n",
    "cf = np.concatenate(\n",
    "    [explanation.data['cf']['X'], explanation.data['cf']['class']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Define new feature names and category map by including the label.\n",
    "feature_names = adult.feature_names + [\"Label\"]\n",
    "category_map = deepcopy(adult.category_map)\n",
    "category_map.update({feature_names.index(\"Label\"): adult.target_names})\n",
    "\n",
    "# Replace label encodings with strings.\n",
    "orig_pd = pd.DataFrame(\n",
    "    apply_category_mapping(orig, category_map),\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "cf_pd = pd.DataFrame(\n",
    "    apply_category_mapping(cf, category_map),\n",
    "    columns=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>7298</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Separated</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>13550</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age     Workclass         Education Marital Status    Occupation  \\\n",
       "0  60       Private  High School grad        Married   Blue-Collar   \n",
       "1  35       Private  High School grad        Married  White-Collar   \n",
       "2  39     State-gov           Masters        Married  Professional   \n",
       "3  44  Self-emp-inc  High School grad        Married         Sales   \n",
       "4  39       Private         Bachelors      Separated  White-Collar   \n",
       "\n",
       "    Relationship   Race     Sex Capital Gain Capital Loss Hours per week  \\\n",
       "0        Husband  White    Male         7298            0             40   \n",
       "1        Husband  White    Male         7688            0             50   \n",
       "2           Wife  White  Female         5178            0             38   \n",
       "3        Husband  White    Male            0            0             50   \n",
       "4  Not-in-family  White  Female        13550            0             50   \n",
       "\n",
       "         Country Label  \n",
       "0  United-States  >50K  \n",
       "1  United-States  >50K  \n",
       "2  United-States  >50K  \n",
       "3  United-States  >50K  \n",
       "4  United-States  >50K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>59516</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>56465</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>?</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>49166</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>54059</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>56217</td>\n",
       "      <td>229</td>\n",
       "      <td>60</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age     Workclass  Education Marital Status Occupation   Relationship  \\\n",
       "0  60       Private  Bachelors        Married      Sales        Husband   \n",
       "1  35       Private  Bachelors        Married      Sales        Husband   \n",
       "2  39             ?  Bachelors        Married      Sales           Wife   \n",
       "3  44  Self-emp-inc  Bachelors        Married      Sales        Husband   \n",
       "4  39       Private  Bachelors      Separated      Sales  Not-in-family   \n",
       "\n",
       "    Race     Sex Capital Gain Capital Loss Hours per week        Country Label  \n",
       "0  White    Male        59516            0             50  Latin-America  >50K  \n",
       "1  White    Male        56465            0             48  Latin-America  >50K  \n",
       "2  White  Female        49166            0             51  Latin-America  >50K  \n",
       "3  White    Male        54059           11             60  Latin-America  >50K  \n",
       "4  White  Female        56217          229             60  Latin-America  >50K  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactual instances.\n",
    "X = X_positive[2].reshape(1, -1)\n",
    "explanation = explainer.explain(X=X, Y_t=Y_t, C=[], diversity=True, num_samples=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat label column.\n",
    "orig = np.concatenate(\n",
    "    [explanation.data['orig']['X'], explanation.data['orig']['class']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "cf = np.concatenate(\n",
    "    [explanation.data['cf']['X'], explanation.data['cf']['class']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Transfrom label encodings to string.\n",
    "orig_pd = pd.DataFrame(\n",
    "    apply_category_mapping(orig, category_map),\n",
    "    columns=feature_names,\n",
    ")\n",
    "\n",
    "cf_pd = pd.DataFrame(\n",
    "    apply_category_mapping(cf, category_map),\n",
    "    columns=feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age  Workclass Education Marital Status    Occupation Relationship   Race  \\\n",
       "0  39  State-gov   Masters        Married  Professional         Wife  White   \n",
       "\n",
       "      Sex Capital Gain Capital Loss Hours per week        Country Label  \n",
       "0  Female         5178            0             38  United-States  >50K  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>?</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>6912</td>\n",
       "      <td>136</td>\n",
       "      <td>33</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>?</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>5382</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>?</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Married</td>\n",
       "      <td>Other</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>6874</td>\n",
       "      <td>613</td>\n",
       "      <td>43</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>6741</td>\n",
       "      <td>362</td>\n",
       "      <td>45</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>6761</td>\n",
       "      <td>510</td>\n",
       "      <td>42</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age    Workclass  Education Marital Status   Occupation Relationship   Race  \\\n",
       "0  17            ?  Bachelors        Married      Service         Wife  White   \n",
       "1  17            ?    Dropout        Married  Blue-Collar         Wife  White   \n",
       "2  17            ?    Dropout        Married        Other         Wife  White   \n",
       "3  17  Federal-gov    Dropout        Married  Blue-Collar         Wife  White   \n",
       "4  17    Local-gov  Bachelors        Married      Service         Wife  White   \n",
       "\n",
       "      Sex Capital Gain Capital Loss Hours per week        Country  Label  \n",
       "0  Female         6912          136             33  Latin-America  <=50K  \n",
       "1  Female         5382           47             31  Latin-America  <=50K  \n",
       "2  Female         6874          613             43  Latin-America  <=50K  \n",
       "3  Female         6741          362             45  Latin-America  <=50K  \n",
       "4  Female         6761          510             42  Latin-America  <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging is clearly important when dealing with deep learning models. Thus, we provide an interface to write custom callbacks for logging purposes after each training step:\n",
    "\n",
    "```python\n",
    "class Callback:\n",
    "    def __call__(self,\n",
    "                 step: int,\n",
    "                 update: int,\n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]) -> None:\n",
    "        \"\"\"\n",
    "        Training call-back applied after every training step.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        step\n",
    "            Current experience step.\n",
    "        update\n",
    "            Current update. The ration between the number experience steps and the number of training \n",
    "            updates is bound to 1.\n",
    "        model\n",
    "            CounterfactualRLBase explainer.\n",
    "        sample\n",
    "            Dictionary of samples used for an update. This is sampled from the replay buffer.\n",
    "        losses\n",
    "            Dictionary of losses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "In the following cells we provide some example to log in **Weights and Biases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging reward callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardCallback(Callback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        \n",
    "        if (step + update) % 100 != 0:\n",
    "            return\n",
    "        \n",
    "        # get the counterfactual and target\n",
    "        Y_t = sample[\"Y_t\"]\n",
    "        X_cf = model.params[\"decoder_inv_preprocessor\"](sample[\"X_cf\"])\n",
    "        \n",
    "        # get prediction label\n",
    "        Y_m_cf = predictor(X_cf)\n",
    "        \n",
    "        # compute reward\n",
    "        reward = np.mean(model.params[\"reward_func\"](Y_m_cf, Y_t))\n",
    "        wandb.log({\"reward\": reward})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging losses callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCallback(Callback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        # Log training losses.\n",
    "        if (step + update) % 100 == 0:\n",
    "            wandb.log(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging tables callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TablesCallback(Callback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        # Log every 1000 steps\n",
    "        if step % 1000 != 0:\n",
    "            return\n",
    "        \n",
    "        # Define number of samples to be displayed.\n",
    "        NUM_SAMPLES = 5\n",
    "        \n",
    "        X = heae_inv_preprocessor(sample[\"X\"][:NUM_SAMPLES])        # input instance\n",
    "        X_cf = heae_inv_preprocessor(sample[\"X_cf\"][:NUM_SAMPLES])  # counterfactual\n",
    "        \n",
    "        Y_m = np.argmax(sample[\"Y_m\"][:NUM_SAMPLES], axis=1).astype(int).reshape(-1, 1) # input labels\n",
    "        Y_t = np.argmax(sample[\"Y_t\"][:NUM_SAMPLES], axis=1).astype(int).reshape(-1, 1) # target labels\n",
    "        Y_m_cf = np.argmax(predictor(X_cf), axis=1).astype(int).reshape(-1, 1)          # counterfactual labels\n",
    "        \n",
    "        # Define feature names and category map for input.\n",
    "        feature_names = adult.feature_names + [\"Label\"]\n",
    "        category_map = deepcopy(adult.category_map)\n",
    "        category_map.update({feature_names.index(\"Label\"): adult.target_names})\n",
    "        \n",
    "        # Construct input array.\n",
    "        input = np.concatenate([X, Y_m], axis=1)\n",
    "        input = pd.DataFrame(apply_category_mapping(input, category_map),\n",
    "                             columns=feature_names)\n",
    "        \n",
    "        # Define feature names and category map for counterfactual output.\n",
    "        feature_names += [\"Target\"]\n",
    "        category_map.update({feature_names.index(\"Target\"): adult.target_names})\n",
    "        \n",
    "        # Construct output array.\n",
    "        output = np.concatenate([X, Y_m_cf, Y_t], axis=1)\n",
    "        output = pd.DataFrame(apply_category_mapping(output, category_map),\n",
    "                              columns=feature_names)\n",
    "        \n",
    "        # Log table. For some reason, this is very slow ...\n",
    "        wandb.log({\n",
    "            \"Input\": wandb.Table(dataframe=input),\n",
    "            \"Output\": wandb.Table(dataframe=output)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the callbacks, we can define a new explainer that will include logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CounterfactualRLTabular(predictor=predictor,\n",
    "                                    encoder=heae.encoder,\n",
    "                                    decoder=heae.decoder,\n",
    "                                    latent_dim=LATENT_DIM,\n",
    "                                    encoder_preprocessor=heae_preprocessor,\n",
    "                                    decoder_inv_preprocessor=heae_inv_preprocessor,\n",
    "                                    coeff_sparsity=COEFF_SPARSITY,\n",
    "                                    coeff_consistency=COEFF_CONSISTENCY,\n",
    "                                    category_map=adult.category_map,\n",
    "                                    feature_names=adult.feature_names,\n",
    "                                    ranges=ranges,\n",
    "                                    immutable_features=immutable_features,\n",
    "                                    train_steps=TRAIN_STEPS,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    callbacks=[LossCallback(), RewardCallback()],  # <--- here \n",
    "                                    backend=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrfs\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">copper-star-268</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rfs/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning\" target=\"_blank\">https://wandb.ai/rfs/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/rfs/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/369ek6nx\" target=\"_blank\">https://wandb.ai/rfs/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/369ek6nx</a><br/>\n",
       "                Run data is saved locally in <code>/home/robert/Desktop/seldon/alibi/examples/wandb/run-20210809_213420-369ek6nx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:37<00:00, 26.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17445<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/robert/Desktop/seldon/alibi/examples/wandb/run-20210809_213420-369ek6nx/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/robert/Desktop/seldon/alibi/examples/wandb/run-20210809_213420-369ek6nx/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss_critic</td><td>0.0572</td></tr><tr><td>loss_actor</td><td>-0.88425</td></tr><tr><td>sparsity_num_loss</td><td>0.2943</td></tr><tr><td>sparsity_cat_loss</td><td>0.3825</td></tr><tr><td>consistency_loss</td><td>0.10981</td></tr><tr><td>_runtime</td><td>38</td></tr><tr><td>_timestamp</td><td>1628534098</td></tr><tr><td>_step</td><td>17</td></tr><tr><td>reward</td><td>0.96</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss_critic</td><td>█▄▃▃▂▂▁▂▁</td></tr><tr><td>loss_actor</td><td>▅█▅▂▁▂▁▃▃</td></tr><tr><td>sparsity_num_loss</td><td>▄▃▁█▇▄▄▁▃</td></tr><tr><td>sparsity_cat_loss</td><td>█▇▁▂▃▁▃▁▁</td></tr><tr><td>consistency_loss</td><td>█▃▂▂▂▂▂▁▁</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>reward</td><td>▂▁▂▇████▇</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">copper-star-268</strong>: <a href=\"https://wandb.ai/rfs/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/369ek6nx\" target=\"_blank\">https://wandb.ai/rfs/Adult%20Census%20Counterfactual%20with%20Reinforcement%20Learning/runs/369ek6nx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb.\n",
    "wandb_project = \"Adult Census Counterfactual with Reinforcement Learning\"\n",
    "wandb.init(project=wandb_project)\n",
    "\n",
    "# Fit the explainers.\n",
    "explainer = explainer.fit(X=X_train)\n",
    "\n",
    "# Close wandb.\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
