{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual with Reinforcement Learning (CFRL) on Adult Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is described in [Model-agnostic and Scalable Counterfactual Explanations via Reinforcement Learning](https://arxiv.org/abs/2106.02597) and can generate counterfactual instances for any black-box model. The usual optimization procedure is transformed into a learnable process allowing to generate batches of counterfactual instances in a single forward pass even for high dimensional data. The training pipeline is model-agnostic and relies only on prediction feedback by querying the black-box model. Furthermore, the method allows target and feature conditioning. \n",
    "\n",
    "**We exemplify the use case for the TensorFlow backend. This means that all models: the autoencoder, the actor, the critic, and possibly the black-box classifier are TensorFlow models. Our implementation supports PyTorch backend as well.**\n",
    "\n",
    "CfRL uses [Deep Deterministic Policy Gradient (DDPG)](https://arxiv.org/abs/1509.02971) by interleaving a state-action function approximator called critic, with a learning an approximator called actor to predict the optimal action. The method assumes that the critic is differentiable with respect to the action argument, thus allowing to optimize the actor's parameters efficiently through gradient-based methods.\n",
    "\n",
    "The DDPG algorithm requires two separate networks, an actor $\\mu$ and a critic $Q$. Given the encoded representation of the input instance $z = enc(x)$, the model prediction $y_M$, the target prediction\n",
    "$y_T$ and the conditioning vector $c$, the actor outputs the counterfactual’s latent representation $z_{CF} = \\mu(z, y_M, y_T, c)$. The decoder then projects the embedding $z_{CF}$ back to the original input space,\n",
    "followed by optional post-processing.\n",
    "\n",
    "The training step consists of simultaneously optimizing the actor and critic networks. The critic regresses on the reward $R$ determined by the model prediction, while the actor maximizes the critic’s output for the given instance through $L_{max}$. The actor also minimizes two objectives to encourage the generation of sparse, in-distribution counterfactuals. The sparsity loss $L_{sparsity}$ operates on the decoded counterfactual $x_{CF}$ and combines the $L_1$ loss over the standardized numerical features and the $L_0$ loss over the categorical ones. The consistency loss $L_{consist}$ aims to encode the counterfactual $x_{CF}$ back to the same latent representation where it was decoded from and helps to produce in-distribution counterfactual instances. Formally, the actor's loss can be written as:\n",
    "$L_{actor} = L_{max} + \\lambda_{1}L_{sparsity} + \\lambda_{2}L_{consistency}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/dl/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from alibi.explainers import CounterfactualRLTabular, CounterfactualRLBase\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.models.tensorflow.autoencoder import HeAE\n",
    "from alibi.models.tensorflow.actor_critic import Actor, Critic\n",
    "from alibi.models.tensorflow.cfrl_models import ADULTEncoder, ADULTDecoder\n",
    "from alibi.explainers.cfrl_base import ExperienceCallback, TrainingCallback\n",
    "from alibi.explainers.backends.cfrl_tabular import get_he_preprocessor, get_statistics, \\\n",
    "    get_conditional_vector, apply_category_mapping\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Adult Census Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch adult dataset\n",
    "adult = fetch_adult()\n",
    "\n",
    "# Separate columns in numerical and categorical.\n",
    "categorical_names = [adult.feature_names[i] for i in adult.category_map.keys()]\n",
    "categorical_ids = list(adult.category_map.keys())\n",
    "\n",
    "numerical_names = [name for i, name in enumerate(adult.feature_names) if i not in adult.category_map.keys()]\n",
    "numerical_ids = [i for i in range(len(adult.feature_names)) if i not in adult.category_map.keys()]\n",
    "\n",
    "# split data into train and test\n",
    "X, Y = adult.data, adult.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train black-box classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical standard scaler.\n",
    "num_transf = StandardScaler()\n",
    "\n",
    "# Define categorical one-hot encoder.\n",
    "cat_transf = OneHotEncoder(\n",
    "    categories=[range(len(x)) for x in adult.category_map.values()],\n",
    "    handle_unknown=\"ignore\"\n",
    ")\n",
    "\n",
    "# Define column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transf, numerical_ids),\n",
    "        (\"cat\", cat_transf, categorical_ids),\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit preprocessor.\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Preprocess train and test dataset.\n",
    "X_train_ohe = preprocessor.transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=50,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit black-box classifier.\n",
    "clf = RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=50, random_state=0)\n",
    "clf.fit(X_train_ohe, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the predictor (black-box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the classifier, we can define the black-box model. Note that the output of the black-box is a distribution which can be either a soft-label distribution (probabilities/logits for each class) or a hard-label distribution (one-hot encoding). Internally, CfRL takes the `argmax`. Moreover the output **DOES NOT HAVE TO BE DIFFERENTIABLE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction function.\n",
    "predictor = lambda x: clf.predict_proba(preprocessor.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy.\n",
    "acc = accuracy_score(y_true=Y_test, y_pred=predictor(X_test).argmax(axis=1))\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly modelling the perturbation vector in the potentially high-dimensional input space, we first train an autoencoder. The weights of the encoder are frozen and the actor applies the\n",
    "counterfactual perturbations in the latent space of the encoder. The pre-trained decoder maps the counterfactual embedding back to the input feature space. \n",
    "\n",
    "The autoencoder follows a standard design. The model is composed from two submodules, the encoder and the decoder. The forward pass consists of passing the input to the encoder, obtain the input embedding and pass the embedding through the decoder.\n",
    "\n",
    "```python\n",
    "class HeAE(keras.Model):\n",
    "    def __init__(self, encoder: keras.Model, decoder: keras.Model, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x: tf.Tensor, **kwargs):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "```\n",
    "\n",
    "The heterogeneous variant used in this example uses an additional type checking to ensure that the output of the decoder is a list of tensors.\n",
    "\n",
    "Heterogeneous dataset require special treatment. In this work we modeled the numerical features by normal distributions with constant standard deviation and categorical features by categorical distributions. Due to the choice of feature modeling, some numerical features can end up having different types than the original numerical features. For example, a feature like `Age` having the type of `int` can become a `float` due to the autoencoder reconstruction (e.g., `Age=26 -> Age=26.3`). This behavior can be undesirable. Thus we performed casting when process the output of the autoencoder (decoder component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attribute types, required for datatype conversion.\n",
    "feature_types = {\"Age\": int, \"Capital Gain\": int, \"Capital Loss\": int, \"Hours per week\": int}\n",
    "\n",
    "# Define data preprocessor and inverse preprocessor. The invers preprocessor include datatype conversions.\n",
    "heae_preprocessor, heae_inv_preprocessor = get_he_preprocessor(X=X_train,\n",
    "                                                               feature_names=adult.feature_names,\n",
    "                                                               category_map=adult.category_map,\n",
    "                                                               feature_types=feature_types)\n",
    "\n",
    "# Define trainset\n",
    "trainset_input = heae_preprocessor(X_train).astype(np.float32)\n",
    "trainset_outputs = {\n",
    "    \"output_1\": X_train_ohe[:, :len(numerical_ids)]\n",
    "}\n",
    "\n",
    "for i, cat_id in enumerate(categorical_ids):\n",
    "    trainset_outputs.update({\n",
    "        f\"output_{i+2}\": X_train[:, cat_id]\n",
    "    })\n",
    "    \n",
    "trainset = tf.data.Dataset.from_tensor_slices((trainset_input, trainset_outputs))\n",
    "trainset = trainset.shuffle(1024).batch(128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 2s 5ms/step - loss: 1.6970 - output_1_loss: 0.4910 - output_2_loss: 1.4696 - output_3_loss: 1.4395 - output_4_loss: 0.9966 - output_5_loss: 1.8818 - output_6_loss: 1.3113 - output_7_loss: 0.8857 - output_8_loss: 0.4694 - output_9_loss: 1.1939 - output_2_sparse_categorical_accuracy: 0.5852 - output_3_sparse_categorical_accuracy: 0.5196 - output_4_sparse_categorical_accuracy: 0.5738 - output_5_sparse_categorical_accuracy: 0.3448 - output_6_sparse_categorical_accuracy: 0.5961 - output_7_sparse_categorical_accuracy: 0.7805 - output_8_sparse_categorical_accuracy: 0.7765 - output_9_sparse_categorical_accuracy: 0.7331\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4608 - output_1_loss: 0.0458 - output_2_loss: 0.5467 - output_3_loss: 0.5175 - output_4_loss: 0.2355 - output_5_loss: 0.8700 - output_6_loss: 0.3807 - output_7_loss: 0.3162 - output_8_loss: 0.1108 - output_9_loss: 0.3426 - output_2_sparse_categorical_accuracy: 0.8218 - output_3_sparse_categorical_accuracy: 0.8460 - output_4_sparse_categorical_accuracy: 0.9325 - output_5_sparse_categorical_accuracy: 0.7166 - output_6_sparse_categorical_accuracy: 0.8960 - output_7_sparse_categorical_accuracy: 0.8767 - output_8_sparse_categorical_accuracy: 0.9710 - output_9_sparse_categorical_accuracy: 0.9090\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2504 - output_1_loss: 0.0327 - output_2_loss: 0.2901 - output_3_loss: 0.2529 - output_4_loss: 0.1401 - output_5_loss: 0.3476 - output_6_loss: 0.2167 - output_7_loss: 0.1778 - output_8_loss: 0.0548 - output_9_loss: 0.2614 - output_2_sparse_categorical_accuracy: 0.9172 - output_3_sparse_categorical_accuracy: 0.9306 - output_4_sparse_categorical_accuracy: 0.9588 - output_5_sparse_categorical_accuracy: 0.9172 - output_6_sparse_categorical_accuracy: 0.9428 - output_7_sparse_categorical_accuracy: 0.9530 - output_8_sparse_categorical_accuracy: 0.9868 - output_9_sparse_categorical_accuracy: 0.9219\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1656 - output_1_loss: 0.0237 - output_2_loss: 0.1914 - output_3_loss: 0.1661 - output_4_loss: 0.0920 - output_5_loss: 0.1957 - output_6_loss: 0.1414 - output_7_loss: 0.1117 - output_8_loss: 0.0323 - output_9_loss: 0.2050 - output_2_sparse_categorical_accuracy: 0.9494 - output_3_sparse_categorical_accuracy: 0.9598 - output_4_sparse_categorical_accuracy: 0.9774 - output_5_sparse_categorical_accuracy: 0.9569 - output_6_sparse_categorical_accuracy: 0.9644 - output_7_sparse_categorical_accuracy: 0.9701 - output_8_sparse_categorical_accuracy: 0.9928 - output_9_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1255 - output_1_loss: 0.0190 - output_2_loss: 0.1382 - output_3_loss: 0.1212 - output_4_loss: 0.0695 - output_5_loss: 0.1424 - output_6_loss: 0.0979 - output_7_loss: 0.0880 - output_8_loss: 0.0227 - output_9_loss: 0.1721 - output_2_sparse_categorical_accuracy: 0.9647 - output_3_sparse_categorical_accuracy: 0.9712 - output_4_sparse_categorical_accuracy: 0.9828 - output_5_sparse_categorical_accuracy: 0.9682 - output_6_sparse_categorical_accuracy: 0.9769 - output_7_sparse_categorical_accuracy: 0.9759 - output_8_sparse_categorical_accuracy: 0.9957 - output_9_sparse_categorical_accuracy: 0.9466\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1001 - output_1_loss: 0.0158 - output_2_loss: 0.1053 - output_3_loss: 0.0929 - output_4_loss: 0.0552 - output_5_loss: 0.1109 - output_6_loss: 0.0746 - output_7_loss: 0.0726 - output_8_loss: 0.0173 - output_9_loss: 0.1461 - output_2_sparse_categorical_accuracy: 0.9734 - output_3_sparse_categorical_accuracy: 0.9778 - output_4_sparse_categorical_accuracy: 0.9861 - output_5_sparse_categorical_accuracy: 0.9762 - output_6_sparse_categorical_accuracy: 0.9840 - output_7_sparse_categorical_accuracy: 0.9790 - output_8_sparse_categorical_accuracy: 0.9970 - output_9_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0844 - output_1_loss: 0.0137 - output_2_loss: 0.0854 - output_3_loss: 0.0763 - output_4_loss: 0.0481 - output_5_loss: 0.0899 - output_6_loss: 0.0614 - output_7_loss: 0.0623 - output_8_loss: 0.0141 - output_9_loss: 0.1275 - output_2_sparse_categorical_accuracy: 0.9792 - output_3_sparse_categorical_accuracy: 0.9818 - output_4_sparse_categorical_accuracy: 0.9881 - output_5_sparse_categorical_accuracy: 0.9825 - output_6_sparse_categorical_accuracy: 0.9872 - output_7_sparse_categorical_accuracy: 0.9814 - output_8_sparse_categorical_accuracy: 0.9974 - output_9_sparse_categorical_accuracy: 0.9610\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0725 - output_1_loss: 0.0121 - output_2_loss: 0.0721 - output_3_loss: 0.0642 - output_4_loss: 0.0422 - output_5_loss: 0.0739 - output_6_loss: 0.0516 - output_7_loss: 0.0541 - output_8_loss: 0.0119 - output_9_loss: 0.1135 - output_2_sparse_categorical_accuracy: 0.9834 - output_3_sparse_categorical_accuracy: 0.9841 - output_4_sparse_categorical_accuracy: 0.9901 - output_5_sparse_categorical_accuracy: 0.9854 - output_6_sparse_categorical_accuracy: 0.9891 - output_7_sparse_categorical_accuracy: 0.9838 - output_8_sparse_categorical_accuracy: 0.9976 - output_9_sparse_categorical_accuracy: 0.9653\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0638 - output_1_loss: 0.0108 - output_2_loss: 0.0621 - output_3_loss: 0.0564 - output_4_loss: 0.0367 - output_5_loss: 0.0616 - output_6_loss: 0.0456 - output_7_loss: 0.0485 - output_8_loss: 0.0104 - output_9_loss: 0.1033 - output_2_sparse_categorical_accuracy: 0.9852 - output_3_sparse_categorical_accuracy: 0.9865 - output_4_sparse_categorical_accuracy: 0.9908 - output_5_sparse_categorical_accuracy: 0.9873 - output_6_sparse_categorical_accuracy: 0.9907 - output_7_sparse_categorical_accuracy: 0.9858 - output_8_sparse_categorical_accuracy: 0.9979 - output_9_sparse_categorical_accuracy: 0.9678\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0569 - output_1_loss: 0.0100 - output_2_loss: 0.0553 - output_3_loss: 0.0506 - output_4_loss: 0.0327 - output_5_loss: 0.0523 - output_6_loss: 0.0401 - output_7_loss: 0.0419 - output_8_loss: 0.0094 - output_9_loss: 0.0928 - output_2_sparse_categorical_accuracy: 0.9870 - output_3_sparse_categorical_accuracy: 0.9870 - output_4_sparse_categorical_accuracy: 0.9924 - output_5_sparse_categorical_accuracy: 0.9899 - output_6_sparse_categorical_accuracy: 0.9919 - output_7_sparse_categorical_accuracy: 0.9880 - output_8_sparse_categorical_accuracy: 0.9979 - output_9_sparse_categorical_accuracy: 0.9723\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0512 - output_1_loss: 0.0091 - output_2_loss: 0.0488 - output_3_loss: 0.0447 - output_4_loss: 0.0293 - output_5_loss: 0.0465 - output_6_loss: 0.0359 - output_7_loss: 0.0387 - output_8_loss: 0.0083 - output_9_loss: 0.0845 - output_2_sparse_categorical_accuracy: 0.9882 - output_3_sparse_categorical_accuracy: 0.9884 - output_4_sparse_categorical_accuracy: 0.9934 - output_5_sparse_categorical_accuracy: 0.9909 - output_6_sparse_categorical_accuracy: 0.9915 - output_7_sparse_categorical_accuracy: 0.9891 - output_8_sparse_categorical_accuracy: 0.9982 - output_9_sparse_categorical_accuracy: 0.9746\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0469 - output_1_loss: 0.0086 - output_2_loss: 0.0449 - output_3_loss: 0.0416 - output_4_loss: 0.0265 - output_5_loss: 0.0425 - output_6_loss: 0.0318 - output_7_loss: 0.0350 - output_8_loss: 0.0072 - output_9_loss: 0.0771 - output_2_sparse_categorical_accuracy: 0.9891 - output_3_sparse_categorical_accuracy: 0.9888 - output_4_sparse_categorical_accuracy: 0.9943 - output_5_sparse_categorical_accuracy: 0.9916 - output_6_sparse_categorical_accuracy: 0.9928 - output_7_sparse_categorical_accuracy: 0.9904 - output_8_sparse_categorical_accuracy: 0.9987 - output_9_sparse_categorical_accuracy: 0.9763\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0435 - output_1_loss: 0.0082 - output_2_loss: 0.0413 - output_3_loss: 0.0373 - output_4_loss: 0.0244 - output_5_loss: 0.0392 - output_6_loss: 0.0298 - output_7_loss: 0.0325 - output_8_loss: 0.0068 - output_9_loss: 0.0715 - output_2_sparse_categorical_accuracy: 0.9898 - output_3_sparse_categorical_accuracy: 0.9899 - output_4_sparse_categorical_accuracy: 0.9944 - output_5_sparse_categorical_accuracy: 0.9916 - output_6_sparse_categorical_accuracy: 0.9928 - output_7_sparse_categorical_accuracy: 0.9910 - output_8_sparse_categorical_accuracy: 0.9985 - output_9_sparse_categorical_accuracy: 0.9782\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0400 - output_1_loss: 0.0076 - output_2_loss: 0.0383 - output_3_loss: 0.0349 - output_4_loss: 0.0223 - output_5_loss: 0.0357 - output_6_loss: 0.0270 - output_7_loss: 0.0295 - output_8_loss: 0.0059 - output_9_loss: 0.0660 - output_2_sparse_categorical_accuracy: 0.9902 - output_3_sparse_categorical_accuracy: 0.9905 - output_4_sparse_categorical_accuracy: 0.9952 - output_5_sparse_categorical_accuracy: 0.9923 - output_6_sparse_categorical_accuracy: 0.9943 - output_7_sparse_categorical_accuracy: 0.9923 - output_8_sparse_categorical_accuracy: 0.9987 - output_9_sparse_categorical_accuracy: 0.9811\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0374 - output_1_loss: 0.0073 - output_2_loss: 0.0360 - output_3_loss: 0.0317 - output_4_loss: 0.0212 - output_5_loss: 0.0331 - output_6_loss: 0.0251 - output_7_loss: 0.0277 - output_8_loss: 0.0057 - output_9_loss: 0.0608 - output_2_sparse_categorical_accuracy: 0.9907 - output_3_sparse_categorical_accuracy: 0.9913 - output_4_sparse_categorical_accuracy: 0.9952 - output_5_sparse_categorical_accuracy: 0.9928 - output_6_sparse_categorical_accuracy: 0.9944 - output_7_sparse_categorical_accuracy: 0.9929 - output_8_sparse_categorical_accuracy: 0.9991 - output_9_sparse_categorical_accuracy: 0.9819\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0347 - output_1_loss: 0.0069 - output_2_loss: 0.0331 - output_3_loss: 0.0292 - output_4_loss: 0.0194 - output_5_loss: 0.0304 - output_6_loss: 0.0228 - output_7_loss: 0.0256 - output_8_loss: 0.0054 - output_9_loss: 0.0560 - output_2_sparse_categorical_accuracy: 0.9920 - output_3_sparse_categorical_accuracy: 0.9920 - output_4_sparse_categorical_accuracy: 0.9959 - output_5_sparse_categorical_accuracy: 0.9935 - output_6_sparse_categorical_accuracy: 0.9951 - output_7_sparse_categorical_accuracy: 0.9931 - output_8_sparse_categorical_accuracy: 0.9990 - output_9_sparse_categorical_accuracy: 0.9845\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0322 - output_1_loss: 0.0065 - output_2_loss: 0.0302 - output_3_loss: 0.0269 - output_4_loss: 0.0177 - output_5_loss: 0.0283 - output_6_loss: 0.0220 - output_7_loss: 0.0239 - output_8_loss: 0.0049 - output_9_loss: 0.0512 - output_2_sparse_categorical_accuracy: 0.9924 - output_3_sparse_categorical_accuracy: 0.9934 - output_4_sparse_categorical_accuracy: 0.9968 - output_5_sparse_categorical_accuracy: 0.9940 - output_6_sparse_categorical_accuracy: 0.9951 - output_7_sparse_categorical_accuracy: 0.9938 - output_8_sparse_categorical_accuracy: 0.9992 - output_9_sparse_categorical_accuracy: 0.9853\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0304 - output_1_loss: 0.0062 - output_2_loss: 0.0287 - output_3_loss: 0.0249 - output_4_loss: 0.0168 - output_5_loss: 0.0267 - output_6_loss: 0.0204 - output_7_loss: 0.0231 - output_8_loss: 0.0047 - output_9_loss: 0.0476 - output_2_sparse_categorical_accuracy: 0.9924 - output_3_sparse_categorical_accuracy: 0.9937 - output_4_sparse_categorical_accuracy: 0.9962 - output_5_sparse_categorical_accuracy: 0.9942 - output_6_sparse_categorical_accuracy: 0.9958 - output_7_sparse_categorical_accuracy: 0.9938 - output_8_sparse_categorical_accuracy: 0.9991 - output_9_sparse_categorical_accuracy: 0.9869\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0285 - output_1_loss: 0.0060 - output_2_loss: 0.0271 - output_3_loss: 0.0236 - output_4_loss: 0.0158 - output_5_loss: 0.0251 - output_6_loss: 0.0191 - output_7_loss: 0.0214 - output_8_loss: 0.0042 - output_9_loss: 0.0438 - output_2_sparse_categorical_accuracy: 0.9933 - output_3_sparse_categorical_accuracy: 0.9947 - output_4_sparse_categorical_accuracy: 0.9969 - output_5_sparse_categorical_accuracy: 0.9942 - output_6_sparse_categorical_accuracy: 0.9960 - output_7_sparse_categorical_accuracy: 0.9946 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9883\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0268 - output_1_loss: 0.0058 - output_2_loss: 0.0250 - output_3_loss: 0.0211 - output_4_loss: 0.0154 - output_5_loss: 0.0237 - output_6_loss: 0.0179 - output_7_loss: 0.0207 - output_8_loss: 0.0041 - output_9_loss: 0.0407 - output_2_sparse_categorical_accuracy: 0.9936 - output_3_sparse_categorical_accuracy: 0.9954 - output_4_sparse_categorical_accuracy: 0.9970 - output_5_sparse_categorical_accuracy: 0.9944 - output_6_sparse_categorical_accuracy: 0.9961 - output_7_sparse_categorical_accuracy: 0.9948 - output_8_sparse_categorical_accuracy: 0.9992 - output_9_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0254 - output_1_loss: 0.0056 - output_2_loss: 0.0241 - output_3_loss: 0.0198 - output_4_loss: 0.0144 - output_5_loss: 0.0226 - output_6_loss: 0.0168 - output_7_loss: 0.0186 - output_8_loss: 0.0040 - output_9_loss: 0.0379 - output_2_sparse_categorical_accuracy: 0.9937 - output_3_sparse_categorical_accuracy: 0.9957 - output_4_sparse_categorical_accuracy: 0.9972 - output_5_sparse_categorical_accuracy: 0.9955 - output_6_sparse_categorical_accuracy: 0.9968 - output_7_sparse_categorical_accuracy: 0.9954 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0238 - output_1_loss: 0.0053 - output_2_loss: 0.0229 - output_3_loss: 0.0184 - output_4_loss: 0.0133 - output_5_loss: 0.0213 - output_6_loss: 0.0158 - output_7_loss: 0.0182 - output_8_loss: 0.0035 - output_9_loss: 0.0346 - output_2_sparse_categorical_accuracy: 0.9946 - output_3_sparse_categorical_accuracy: 0.9962 - output_4_sparse_categorical_accuracy: 0.9977 - output_5_sparse_categorical_accuracy: 0.9955 - output_6_sparse_categorical_accuracy: 0.9965 - output_7_sparse_categorical_accuracy: 0.9952 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9911\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0228 - output_1_loss: 0.0053 - output_2_loss: 0.0204 - output_3_loss: 0.0178 - output_4_loss: 0.0129 - output_5_loss: 0.0201 - output_6_loss: 0.0157 - output_7_loss: 0.0168 - output_8_loss: 0.0034 - output_9_loss: 0.0330 - output_2_sparse_categorical_accuracy: 0.9939 - output_3_sparse_categorical_accuracy: 0.9961 - output_4_sparse_categorical_accuracy: 0.9974 - output_5_sparse_categorical_accuracy: 0.9955 - output_6_sparse_categorical_accuracy: 0.9968 - output_7_sparse_categorical_accuracy: 0.9959 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9916\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0217 - output_1_loss: 0.0051 - output_2_loss: 0.0201 - output_3_loss: 0.0165 - output_4_loss: 0.0123 - output_5_loss: 0.0186 - output_6_loss: 0.0148 - output_7_loss: 0.0161 - output_8_loss: 0.0033 - output_9_loss: 0.0312 - output_2_sparse_categorical_accuracy: 0.9945 - output_3_sparse_categorical_accuracy: 0.9967 - output_4_sparse_categorical_accuracy: 0.9976 - output_5_sparse_categorical_accuracy: 0.9960 - output_6_sparse_categorical_accuracy: 0.9965 - output_7_sparse_categorical_accuracy: 0.9964 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9921\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0208 - output_1_loss: 0.0050 - output_2_loss: 0.0201 - output_3_loss: 0.0156 - output_4_loss: 0.0114 - output_5_loss: 0.0182 - output_6_loss: 0.0137 - output_7_loss: 0.0151 - output_8_loss: 0.0032 - output_9_loss: 0.0292 - output_2_sparse_categorical_accuracy: 0.9941 - output_3_sparse_categorical_accuracy: 0.9967 - output_4_sparse_categorical_accuracy: 0.9980 - output_5_sparse_categorical_accuracy: 0.9957 - output_6_sparse_categorical_accuracy: 0.9966 - output_7_sparse_categorical_accuracy: 0.9963 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0196 - output_1_loss: 0.0048 - output_2_loss: 0.0178 - output_3_loss: 0.0144 - output_4_loss: 0.0114 - output_5_loss: 0.0170 - output_6_loss: 0.0128 - output_7_loss: 0.0144 - output_8_loss: 0.0031 - output_9_loss: 0.0276 - output_2_sparse_categorical_accuracy: 0.9954 - output_3_sparse_categorical_accuracy: 0.9969 - output_4_sparse_categorical_accuracy: 0.9979 - output_5_sparse_categorical_accuracy: 0.9965 - output_6_sparse_categorical_accuracy: 0.9968 - output_7_sparse_categorical_accuracy: 0.9962 - output_8_sparse_categorical_accuracy: 0.9991 - output_9_sparse_categorical_accuracy: 0.9936\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0186 - output_1_loss: 0.0045 - output_2_loss: 0.0168 - output_3_loss: 0.0140 - output_4_loss: 0.0107 - output_5_loss: 0.0169 - output_6_loss: 0.0125 - output_7_loss: 0.0133 - output_8_loss: 0.0028 - output_9_loss: 0.0258 - output_2_sparse_categorical_accuracy: 0.9957 - output_3_sparse_categorical_accuracy: 0.9971 - output_4_sparse_categorical_accuracy: 0.9981 - output_5_sparse_categorical_accuracy: 0.9964 - output_6_sparse_categorical_accuracy: 0.9972 - output_7_sparse_categorical_accuracy: 0.9965 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9938\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0179 - output_1_loss: 0.0044 - output_2_loss: 0.0165 - output_3_loss: 0.0133 - output_4_loss: 0.0105 - output_5_loss: 0.0162 - output_6_loss: 0.0115 - output_7_loss: 0.0125 - output_8_loss: 0.0029 - output_9_loss: 0.0243 - output_2_sparse_categorical_accuracy: 0.9955 - output_3_sparse_categorical_accuracy: 0.9977 - output_4_sparse_categorical_accuracy: 0.9983 - output_5_sparse_categorical_accuracy: 0.9960 - output_6_sparse_categorical_accuracy: 0.9973 - output_7_sparse_categorical_accuracy: 0.9973 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9943\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0171 - output_1_loss: 0.0042 - output_2_loss: 0.0149 - output_3_loss: 0.0125 - output_4_loss: 0.0103 - output_5_loss: 0.0151 - output_6_loss: 0.0117 - output_7_loss: 0.0127 - output_8_loss: 0.0028 - output_9_loss: 0.0230 - output_2_sparse_categorical_accuracy: 0.9964 - output_3_sparse_categorical_accuracy: 0.9976 - output_4_sparse_categorical_accuracy: 0.9982 - output_5_sparse_categorical_accuracy: 0.9967 - output_6_sparse_categorical_accuracy: 0.9972 - output_7_sparse_categorical_accuracy: 0.9972 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9944\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0164 - output_1_loss: 0.0042 - output_2_loss: 0.0144 - output_3_loss: 0.0118 - output_4_loss: 0.0098 - output_5_loss: 0.0145 - output_6_loss: 0.0107 - output_7_loss: 0.0118 - output_8_loss: 0.0027 - output_9_loss: 0.0216 - output_2_sparse_categorical_accuracy: 0.9961 - output_3_sparse_categorical_accuracy: 0.9977 - output_4_sparse_categorical_accuracy: 0.9985 - output_5_sparse_categorical_accuracy: 0.9971 - output_6_sparse_categorical_accuracy: 0.9977 - output_7_sparse_categorical_accuracy: 0.9971 - output_8_sparse_categorical_accuracy: 0.9992 - output_9_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0161 - output_1_loss: 0.0043 - output_2_loss: 0.0139 - output_3_loss: 0.0116 - output_4_loss: 0.0095 - output_5_loss: 0.0141 - output_6_loss: 0.0107 - output_7_loss: 0.0106 - output_8_loss: 0.0027 - output_9_loss: 0.0205 - output_2_sparse_categorical_accuracy: 0.9962 - output_3_sparse_categorical_accuracy: 0.9979 - output_4_sparse_categorical_accuracy: 0.9983 - output_5_sparse_categorical_accuracy: 0.9967 - output_6_sparse_categorical_accuracy: 0.9976 - output_7_sparse_categorical_accuracy: 0.9979 - output_8_sparse_categorical_accuracy: 0.9994 - output_9_sparse_categorical_accuracy: 0.9953\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0148 - output_1_loss: 0.0038 - output_2_loss: 0.0133 - output_3_loss: 0.0108 - output_4_loss: 0.0090 - output_5_loss: 0.0127 - output_6_loss: 0.0096 - output_7_loss: 0.0100 - output_8_loss: 0.0024 - output_9_loss: 0.0197 - output_2_sparse_categorical_accuracy: 0.9967 - output_3_sparse_categorical_accuracy: 0.9980 - output_4_sparse_categorical_accuracy: 0.9984 - output_5_sparse_categorical_accuracy: 0.9972 - output_6_sparse_categorical_accuracy: 0.9982 - output_7_sparse_categorical_accuracy: 0.9982 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9957\n",
      "Epoch 33/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0146 - output_1_loss: 0.0042 - output_2_loss: 0.0128 - output_3_loss: 0.0097 - output_4_loss: 0.0086 - output_5_loss: 0.0127 - output_6_loss: 0.0095 - output_7_loss: 0.0096 - output_8_loss: 0.0023 - output_9_loss: 0.0180 - output_2_sparse_categorical_accuracy: 0.9968 - output_3_sparse_categorical_accuracy: 0.9985 - output_4_sparse_categorical_accuracy: 0.9982 - output_5_sparse_categorical_accuracy: 0.9972 - output_6_sparse_categorical_accuracy: 0.9979 - output_7_sparse_categorical_accuracy: 0.9979 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9956\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.0140 - output_1_loss: 0.0039 - output_2_loss: 0.0125 - output_3_loss: 0.0094 - output_4_loss: 0.0084 - output_5_loss: 0.0121 - output_6_loss: 0.0093 - output_7_loss: 0.0091 - output_8_loss: 0.0023 - output_9_loss: 0.0175 - output_2_sparse_categorical_accuracy: 0.9969 - output_3_sparse_categorical_accuracy: 0.9981 - output_4_sparse_categorical_accuracy: 0.9984 - output_5_sparse_categorical_accuracy: 0.9976 - output_6_sparse_categorical_accuracy: 0.9977 - output_7_sparse_categorical_accuracy: 0.9980 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9961\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0133 - output_1_loss: 0.0037 - output_2_loss: 0.0114 - output_3_loss: 0.0089 - output_4_loss: 0.0083 - output_5_loss: 0.0113 - output_6_loss: 0.0088 - output_7_loss: 0.0083 - output_8_loss: 0.0024 - output_9_loss: 0.0173 - output_2_sparse_categorical_accuracy: 0.9971 - output_3_sparse_categorical_accuracy: 0.9985 - output_4_sparse_categorical_accuracy: 0.9982 - output_5_sparse_categorical_accuracy: 0.9977 - output_6_sparse_categorical_accuracy: 0.9977 - output_7_sparse_categorical_accuracy: 0.9983 - output_8_sparse_categorical_accuracy: 0.9993 - output_9_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0129 - output_1_loss: 0.0038 - output_2_loss: 0.0110 - output_3_loss: 0.0085 - output_4_loss: 0.0078 - output_5_loss: 0.0111 - output_6_loss: 0.0081 - output_7_loss: 0.0082 - output_8_loss: 0.0020 - output_9_loss: 0.0158 - output_2_sparse_categorical_accuracy: 0.9974 - output_3_sparse_categorical_accuracy: 0.9987 - output_4_sparse_categorical_accuracy: 0.9987 - output_5_sparse_categorical_accuracy: 0.9979 - output_6_sparse_categorical_accuracy: 0.9983 - output_7_sparse_categorical_accuracy: 0.9981 - output_8_sparse_categorical_accuracy: 0.9997 - output_9_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0123 - output_1_loss: 0.0035 - output_2_loss: 0.0110 - output_3_loss: 0.0081 - output_4_loss: 0.0075 - output_5_loss: 0.0104 - output_6_loss: 0.0079 - output_7_loss: 0.0078 - output_8_loss: 0.0021 - output_9_loss: 0.0152 - output_2_sparse_categorical_accuracy: 0.9976 - output_3_sparse_categorical_accuracy: 0.9985 - output_4_sparse_categorical_accuracy: 0.9985 - output_5_sparse_categorical_accuracy: 0.9979 - output_6_sparse_categorical_accuracy: 0.9984 - output_7_sparse_categorical_accuracy: 0.9982 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0122 - output_1_loss: 0.0037 - output_2_loss: 0.0105 - output_3_loss: 0.0081 - output_4_loss: 0.0070 - output_5_loss: 0.0102 - output_6_loss: 0.0077 - output_7_loss: 0.0074 - output_8_loss: 0.0021 - output_9_loss: 0.0145 - output_2_sparse_categorical_accuracy: 0.9979 - output_3_sparse_categorical_accuracy: 0.9985 - output_4_sparse_categorical_accuracy: 0.9988 - output_5_sparse_categorical_accuracy: 0.9981 - output_6_sparse_categorical_accuracy: 0.9981 - output_7_sparse_categorical_accuracy: 0.9988 - output_8_sparse_categorical_accuracy: 0.9997 - output_9_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0117 - output_1_loss: 0.0036 - output_2_loss: 0.0100 - output_3_loss: 0.0078 - output_4_loss: 0.0069 - output_5_loss: 0.0097 - output_6_loss: 0.0076 - output_7_loss: 0.0070 - output_8_loss: 0.0018 - output_9_loss: 0.0139 - output_2_sparse_categorical_accuracy: 0.9977 - output_3_sparse_categorical_accuracy: 0.9985 - output_4_sparse_categorical_accuracy: 0.9987 - output_5_sparse_categorical_accuracy: 0.9984 - output_6_sparse_categorical_accuracy: 0.9984 - output_7_sparse_categorical_accuracy: 0.9985 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9970\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.0112 - output_1_loss: 0.0035 - output_2_loss: 0.0098 - output_3_loss: 0.0069 - output_4_loss: 0.0066 - output_5_loss: 0.0098 - output_6_loss: 0.0071 - output_7_loss: 0.0067 - output_8_loss: 0.0019 - output_9_loss: 0.0133 - output_2_sparse_categorical_accuracy: 0.9978 - output_3_sparse_categorical_accuracy: 0.9989 - output_4_sparse_categorical_accuracy: 0.9988 - output_5_sparse_categorical_accuracy: 0.9982 - output_6_sparse_categorical_accuracy: 0.9984 - output_7_sparse_categorical_accuracy: 0.9986 - output_8_sparse_categorical_accuracy: 0.9995 - output_9_sparse_categorical_accuracy: 0.9967\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0108 - output_1_loss: 0.0033 - output_2_loss: 0.0091 - output_3_loss: 0.0068 - output_4_loss: 0.0059 - output_5_loss: 0.0090 - output_6_loss: 0.0070 - output_7_loss: 0.0068 - output_8_loss: 0.0018 - output_9_loss: 0.0133 - output_2_sparse_categorical_accuracy: 0.9980 - output_3_sparse_categorical_accuracy: 0.9991 - output_4_sparse_categorical_accuracy: 0.9989 - output_5_sparse_categorical_accuracy: 0.9983 - output_6_sparse_categorical_accuracy: 0.9986 - output_7_sparse_categorical_accuracy: 0.9988 - output_8_sparse_categorical_accuracy: 0.9996 - output_9_sparse_categorical_accuracy: 0.9971\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0107 - output_1_loss: 0.0034 - output_2_loss: 0.0088 - output_3_loss: 0.0066 - output_4_loss: 0.0060 - output_5_loss: 0.0087 - output_6_loss: 0.0065 - output_7_loss: 0.0069 - output_8_loss: 0.0018 - output_9_loss: 0.0128 - output_2_sparse_categorical_accuracy: 0.9982 - output_3_sparse_categorical_accuracy: 0.9991 - output_4_sparse_categorical_accuracy: 0.9989 - output_5_sparse_categorical_accuracy: 0.9982 - output_6_sparse_categorical_accuracy: 0.9987 - output_7_sparse_categorical_accuracy: 0.9985 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9969\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0096 - output_1_loss: 0.0029 - output_2_loss: 0.0080 - output_3_loss: 0.0062 - output_4_loss: 0.0055 - output_5_loss: 0.0082 - output_6_loss: 0.0061 - output_7_loss: 0.0060 - output_8_loss: 0.0017 - output_9_loss: 0.0118 - output_2_sparse_categorical_accuracy: 0.9983 - output_3_sparse_categorical_accuracy: 0.9990 - output_4_sparse_categorical_accuracy: 0.9990 - output_5_sparse_categorical_accuracy: 0.9986 - output_6_sparse_categorical_accuracy: 0.9992 - output_7_sparse_categorical_accuracy: 0.9988 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0095 - output_1_loss: 0.0030 - output_2_loss: 0.0080 - output_3_loss: 0.0058 - output_4_loss: 0.0051 - output_5_loss: 0.0080 - output_6_loss: 0.0060 - output_7_loss: 0.0060 - output_8_loss: 0.0016 - output_9_loss: 0.0111 - output_2_sparse_categorical_accuracy: 0.9982 - output_3_sparse_categorical_accuracy: 0.9993 - output_4_sparse_categorical_accuracy: 0.9992 - output_5_sparse_categorical_accuracy: 0.9988 - output_6_sparse_categorical_accuracy: 0.9991 - output_7_sparse_categorical_accuracy: 0.9988 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9974\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0090 - output_1_loss: 0.0029 - output_2_loss: 0.0073 - output_3_loss: 0.0055 - output_4_loss: 0.0051 - output_5_loss: 0.0073 - output_6_loss: 0.0056 - output_7_loss: 0.0057 - output_8_loss: 0.0015 - output_9_loss: 0.0106 - output_2_sparse_categorical_accuracy: 0.9985 - output_3_sparse_categorical_accuracy: 0.9993 - output_4_sparse_categorical_accuracy: 0.9991 - output_5_sparse_categorical_accuracy: 0.9989 - output_6_sparse_categorical_accuracy: 0.9993 - output_7_sparse_categorical_accuracy: 0.9986 - output_8_sparse_categorical_accuracy: 0.9999 - output_9_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0096 - output_1_loss: 0.0034 - output_2_loss: 0.0076 - output_3_loss: 0.0054 - output_4_loss: 0.0054 - output_5_loss: 0.0078 - output_6_loss: 0.0059 - output_7_loss: 0.0053 - output_8_loss: 0.0014 - output_9_loss: 0.0104 - output_2_sparse_categorical_accuracy: 0.9982 - output_3_sparse_categorical_accuracy: 0.9992 - output_4_sparse_categorical_accuracy: 0.9989 - output_5_sparse_categorical_accuracy: 0.9981 - output_6_sparse_categorical_accuracy: 0.9989 - output_7_sparse_categorical_accuracy: 0.9990 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0087 - output_1_loss: 0.0029 - output_2_loss: 0.0070 - output_3_loss: 0.0054 - output_4_loss: 0.0050 - output_5_loss: 0.0069 - output_6_loss: 0.0053 - output_7_loss: 0.0053 - output_8_loss: 0.0014 - output_9_loss: 0.0099 - output_2_sparse_categorical_accuracy: 0.9983 - output_3_sparse_categorical_accuracy: 0.9989 - output_4_sparse_categorical_accuracy: 0.9993 - output_5_sparse_categorical_accuracy: 0.9989 - output_6_sparse_categorical_accuracy: 0.9989 - output_7_sparse_categorical_accuracy: 0.9989 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0084 - output_1_loss: 0.0028 - output_2_loss: 0.0070 - output_3_loss: 0.0051 - output_4_loss: 0.0047 - output_5_loss: 0.0071 - output_6_loss: 0.0048 - output_7_loss: 0.0048 - output_8_loss: 0.0014 - output_9_loss: 0.0097 - output_2_sparse_categorical_accuracy: 0.9984 - output_3_sparse_categorical_accuracy: 0.9992 - output_4_sparse_categorical_accuracy: 0.9989 - output_5_sparse_categorical_accuracy: 0.9990 - output_6_sparse_categorical_accuracy: 0.9990 - output_7_sparse_categorical_accuracy: 0.9992 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0086 - output_1_loss: 0.0030 - output_2_loss: 0.0069 - output_3_loss: 0.0049 - output_4_loss: 0.0050 - output_5_loss: 0.0062 - output_6_loss: 0.0055 - output_7_loss: 0.0049 - output_8_loss: 0.0015 - output_9_loss: 0.0096 - output_2_sparse_categorical_accuracy: 0.9986 - output_3_sparse_categorical_accuracy: 0.9992 - output_4_sparse_categorical_accuracy: 0.9991 - output_5_sparse_categorical_accuracy: 0.9990 - output_6_sparse_categorical_accuracy: 0.9990 - output_7_sparse_categorical_accuracy: 0.9992 - output_8_sparse_categorical_accuracy: 0.9997 - output_9_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.0083 - output_1_loss: 0.0029 - output_2_loss: 0.0068 - output_3_loss: 0.0048 - output_4_loss: 0.0044 - output_5_loss: 0.0068 - output_6_loss: 0.0050 - output_7_loss: 0.0044 - output_8_loss: 0.0015 - output_9_loss: 0.0095 - output_2_sparse_categorical_accuracy: 0.9986 - output_3_sparse_categorical_accuracy: 0.9993 - output_4_sparse_categorical_accuracy: 0.9994 - output_5_sparse_categorical_accuracy: 0.9989 - output_6_sparse_categorical_accuracy: 0.9989 - output_7_sparse_categorical_accuracy: 0.9993 - output_8_sparse_categorical_accuracy: 0.9998 - output_9_sparse_categorical_accuracy: 0.9979\n",
      "INFO:tensorflow:Assets written to: tensorflow/ADULT_autoencoder/assets\n"
     ]
    }
   ],
   "source": [
    "# Define autoencoder path and create dir if it doesn't exist.\n",
    "heae_path = os.path.join(\"tensorflow\", \"ADULT_autoencoder\")\n",
    "if not os.path.exists(heae_path):\n",
    "    os.makedirs(heae_path)\n",
    "\n",
    "# Define constants.\n",
    "EPOCHS = 50             # epochs to train the autoencoder\n",
    "HIDDEN_DIM = 128         # hidden dimension of the autoencoder\n",
    "LATENT_DIM = 15          # define latent dimension\n",
    "\n",
    "# Define output dimensions.\n",
    "OUTPUT_DIMS = [len(numerical_ids)]\n",
    "OUTPUT_DIMS += [len(adult.category_map[cat_id]) for cat_id in categorical_ids]\n",
    "\n",
    "# Define the heterogeneous auto-encoder.\n",
    "heae = HeAE(encoder=ADULTEncoder(hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM),\n",
    "            decoder=ADULTDecoder(hidden_dim=HIDDEN_DIM, output_dims=OUTPUT_DIMS))\n",
    "\n",
    "# Define loss functions.\n",
    "he_loss = [keras.losses.MeanSquaredError()]\n",
    "he_loss_weights = [1.]\n",
    "\n",
    "# Add categorical losses.\n",
    "for i in range(len(categorical_names)):\n",
    "    he_loss.append(keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "    he_loss_weights.append(1./len(categorical_names))\n",
    "\n",
    "# Define metrics.\n",
    "metrics = {}\n",
    "for i, cat_name in enumerate(categorical_names):\n",
    "    metrics.update({f\"output_{i+2}\": keras.metrics.SparseCategoricalAccuracy()})\n",
    "    \n",
    "# Compile model.\n",
    "heae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "             loss=he_loss,\n",
    "             loss_weights=he_loss_weights,\n",
    "             metrics=metrics)\n",
    "\n",
    "if len(os.listdir(heae_path)) == 0:\n",
    "    # Fit and save autoencoder.\n",
    "    heae.fit(trainset, epochs=EPOCHS)\n",
    "    heae.save(heae_path, save_format=\"tf\")\n",
    "else:\n",
    "    # Load the model.\n",
    "    heae = keras.models.load_model(heae_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers.backends.tensorflow.cfrl_base import to_numpy\n",
    "X_train_hat_ohe = np.concatenate(to_numpy(heae(X_train_ohe)), axis=1)\n",
    "X_train_hat = heae_inv_preprocessor(X_train_hat_ohe)\n",
    "X_train_hat[0].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028751813109047656"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((X_train_ohe[:, :4] - X_train_hat_ohe[:, :4])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual with Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "COEFF_SPARSITY = 0.5               # sparisty coefficient\n",
    "COEFF_CONSISTENCY = 0.5            # consisteny coefficient -> No consistency.\n",
    "TRAIN_STEPS = 100000               # number of training steps -> increase this to 150.000 or even further\n",
    "BATCH_SIZE = 128                   # batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset specific attributes and constraints\n",
    "\n",
    "A desirable property of a method for generating counterfactuals is to allow feature conditioning. Real-world datasets usually include immutable features such as *gender* or *race*, which should remain unchanged throughout the counterfactual search procedure. Similarly, a numerical feature such as `Age` should only increase for a counterfactual to be actionable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define immutable features.\n",
    "immutable_features = ['Marital Status', 'Relationship', 'Race', 'Sex']\n",
    "\n",
    "# Define ranges. This means that the `Age` feature can not decrease.\n",
    "ranges = {'Age': [0.0, 1.0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and fit the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = CounterfactualRLTabular(predictor=predictor,\n",
    "#                                     encoder=heae.encoder,\n",
    "#                                     decoder=heae.decoder,\n",
    "#                                     latent_dim=LATENT_DIM,\n",
    "#                                     encoder_preprocessor=heae_preprocessor,\n",
    "#                                     decoder_inv_preprocessor=heae_inv_preprocessor,\n",
    "#                                     coeff_sparsity=COEFF_SPARSITY,\n",
    "#                                     coeff_consistency=COEFF_CONSISTENCY,\n",
    "#                                     category_map=adult.category_map,\n",
    "#                                     feature_names=adult.feature_names,\n",
    "#                                     ranges=ranges,\n",
    "#                                     immutable_features=immutable_features,\n",
    "#                                     train_steps=10,\n",
    "#                                     batch_size=BATCH_SIZE,\n",
    "#                                     backend=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the explainer.\n",
    "# explainer = explainer.fit(X=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select some positive examples.\n",
    "# X_positive = X_test[np.argmax(predictor(X_test), axis=1) == 1]\n",
    "\n",
    "# X = X_positive[:100]\n",
    "# Y_t = np.array([0])\n",
    "# C = [{\"Age\": [0, 20], \"Workclass\": [\"State-gov\", \"?\", \"Local-gov\"]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate counterfactual instances.\n",
    "# explanation = explainer.explain(X, Y_t, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concat labels to the original instances.\n",
    "# orig = np.concatenate(\n",
    "#     [explanation.data['orig']['X'], explanation.data['orig']['class']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Concat labels to the counterfactual instances.\n",
    "# cf = np.concatenate(\n",
    "#     [explanation.data['cf']['X'], explanation.data['cf']['class']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Define new feature names and category map by including the label.\n",
    "# feature_names = adult.feature_names + [\"Label\"]\n",
    "# category_map = deepcopy(adult.category_map)\n",
    "# category_map.update({feature_names.index(\"Label\"): adult.target_names})\n",
    "\n",
    "# # Replace label encodings with strings.\n",
    "# orig_pd = pd.DataFrame(\n",
    "#     apply_category_mapping(orig, category_map),\n",
    "#     columns=feature_names\n",
    "# )\n",
    "\n",
    "# cf_pd = pd.DataFrame(\n",
    "#     apply_category_mapping(cf, category_map),\n",
    "#     columns=feature_names\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate counterfactual instances.\n",
    "# X = X_positive[2].reshape(1, -1)\n",
    "# explanation = explainer.explain(X=X, Y_t=Y_t, C=[], diversity=True, num_samples=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concat label column.\n",
    "# orig = np.concatenate(\n",
    "#     [explanation.data['orig']['X'], explanation.data['orig']['class']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# cf = np.concatenate(\n",
    "#     [explanation.data['cf']['X'], explanation.data['cf']['class']],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # Transfrom label encodings to string.\n",
    "# orig_pd = pd.DataFrame(\n",
    "#     apply_category_mapping(orig, category_map),\n",
    "#     columns=feature_names,\n",
    "# )\n",
    "\n",
    "# cf_pd = pd.DataFrame(\n",
    "#     apply_category_mapping(cf, category_map),\n",
    "#     columns=feature_names,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging is clearly important when dealing with deep learning models. Thus, we provide two interfaces to write custom callbacks for logging purposes:\n",
    "\n",
    "* an `ExperienceCallback`, called after each collected experience step;\n",
    "\n",
    "```python\n",
    "class ExperienceCallback:\n",
    "    def __call__(self,\n",
    "                 step: int,\n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray]) -> None:\n",
    "        \"\"\"\n",
    "        Experience call-back applied after gather an experience.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        step\n",
    "            Current experience step.\n",
    "        model\n",
    "            CounterfactualRLBase explainer.\n",
    "        sample\n",
    "            Dictionary of sample gathered in an experience. This includes dataset inputs and intermediate\n",
    "            results obtained during an experience.\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "* a `TrainingCallback`, called after each training step;\n",
    "\n",
    "```python\n",
    "class TrainingCallback:\n",
    "    def __call__(self,\n",
    "                 step: int,\n",
    "                 update: int,\n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]) -> None:\n",
    "        \"\"\"\n",
    "        Training call-back applied after every training step.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        step\n",
    "            Current experience step.\n",
    "        update\n",
    "            Current update. The ration between the number experience steps and the number of training \n",
    "            updates is bound to 1.\n",
    "        model\n",
    "            CounterfactualRLBase explainer.\n",
    "        sample\n",
    "            Dictionary of samples used for an update. This is sampled from the replay buffer.\n",
    "        losses\n",
    "            Dictionary of losses.\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "In the following cells we provide some example to log in **Weights and Biases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging tables callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TablesCallback(ExperienceCallback):\n",
    "    def __call__(self,\n",
    "                 step:int,\n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray]):\n",
    "        # Log every 1000 steps\n",
    "        if step % 1000 != 0:\n",
    "            return\n",
    "        \n",
    "        # Define number of samples to be displayed.\n",
    "        NUM_SAMPLES = 5\n",
    "        \n",
    "        X = heae_inv_preprocessor(sample[\"X\"][:NUM_SAMPLES])        # input instance\n",
    "        X_cf = heae_inv_preprocessor(sample[\"X_cf\"][:NUM_SAMPLES])  # counterfactual\n",
    "        \n",
    "        Y_m = np.argmax(sample[\"Y_m\"][:NUM_SAMPLES], axis=1).astype(int).reshape(-1, 1) # input labels\n",
    "        Y_t = np.argmax(sample[\"Y_t\"][:NUM_SAMPLES], axis=1).astype(int).reshape(-1, 1) # target labels\n",
    "        Y_m_cf = np.argmax(predictor(X_cf), axis=1).astype(int).reshape(-1, 1)          # counterfactual labels\n",
    "        \n",
    "        # Define feature names and category map for input.\n",
    "        feature_names = adult.feature_names + [\"Label\"]\n",
    "        category_map = deepcopy(adult.category_map)\n",
    "        category_map.update({feature_names.index(\"Label\"): adult.target_names})\n",
    "        \n",
    "        # Construct input array.\n",
    "        input = np.concatenate([X, Y_m], axis=1)\n",
    "        input = pd.DataFrame(apply_category_mapping(input, category_map),\n",
    "                             columns=feature_names)\n",
    "        \n",
    "        # Define feature names and category map for counterfactual output.\n",
    "        feature_names += [\"Target\"]\n",
    "        category_map.update({feature_names.index(\"Target\"): adult.target_names})\n",
    "        \n",
    "        # Construct output array.\n",
    "        output = np.concatenate([X, Y_m_cf, Y_t], axis=1)\n",
    "        output = pd.DataFrame(apply_category_mapping(output, category_map),\n",
    "                              columns=feature_names)\n",
    "        \n",
    "        # Log table. For some reason, this is very slow ...\n",
    "        wandb.log({\n",
    "            \"Input\": wandb.Table(dataframe=input),\n",
    "            \"Output\": wandb.Table(dataframe=output)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging reward callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardCallback(TrainingCallback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        \n",
    "        if (step + update) % 100 != 0:\n",
    "            return\n",
    "        \n",
    "        # get the counterfactual and target\n",
    "        Y_t = sample[\"Y_t\"]\n",
    "        X_cf = model.params[\"decoder_inv_preprocessor\"](sample[\"X_cf\"])\n",
    "        \n",
    "        # get prediction label\n",
    "        Y_m_cf = predictor(X_cf)\n",
    "        \n",
    "        # compute reward\n",
    "        reward = np.mean(model.params[\"reward_func\"](Y_m_cf, Y_t))\n",
    "        wandb.log({\"reward\": reward})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging losses callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCallback(TrainingCallback):\n",
    "    def __call__(self,\n",
    "                 step: int, \n",
    "                 update: int, \n",
    "                 model: CounterfactualRLBase,\n",
    "                 sample: Dict[str, np.ndarray],\n",
    "                 losses: Dict[str, float]):\n",
    "        # Log training losses.\n",
    "        if (step + update) % 100 == 0:\n",
    "            wandb.log(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the callbacks, we can define a new explainer that will include logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CounterfactualRLTabular(predictor=predictor,\n",
    "                                    encoder=heae.encoder,\n",
    "                                    decoder=heae.decoder,\n",
    "                                    latent_dim=LATENT_DIM,\n",
    "                                    encoder_preprocessor=heae_preprocessor,\n",
    "                                    decoder_inv_preprocessor=heae_inv_preprocessor,\n",
    "                                    coeff_sparsity=COEFF_SPARSITY,\n",
    "                                    coeff_consistency=COEFF_CONSISTENCY,\n",
    "                                    category_map=adult.category_map,\n",
    "                                    feature_names=adult.feature_names,\n",
    "                                    ranges=ranges,\n",
    "                                    immutable_features=immutable_features,\n",
    "                                    train_steps=100000,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    train_callbacks=[LossCallback(), RewardCallback()],        # <--- here \n",
    "                                    backend=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb.\n",
    "wandb_project = \"Adult Census Counterfactual with Reinforcement Learning\"\n",
    "wandb.init(project=wandb_project)\n",
    "\n",
    "# Fit the explainers.\n",
    "explainer = explainer.fit(X=X_train)\n",
    "\n",
    "# Close wandb.\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
