{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e78b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from alibi.datasets import fetch_adult\n",
    "from alibi.explainers.backends.cfrl_tabular import apply_category_mapping\n",
    "\n",
    "from alibi.prototypes import ProtoSelect\n",
    "from alibi.prototypes.protoselect import cv_protoselect_euclidean\n",
    "from alibi.utils.kernel import EuclideanDistance\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058a53c",
   "metadata": {},
   "source": [
    "# Tabular dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9704e1",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c209123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(X: np.ndarray, \n",
    "                  Y: np.ndarray, \n",
    "                  feature_names: List[str],\n",
    "                  category_map: Dict[int, List[str]],\n",
    "                  target_names: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Displays the table in a human readable format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Array of data instances to be displayed.\n",
    "    Y\n",
    "        Array of data labels.\n",
    "    feature_names\n",
    "        List of feature names.\n",
    "    category_map\n",
    "        Category mapping dictionary having as keys the categorical index and as values the categorical values#\n",
    "        each feature takes.\n",
    "    target_names\n",
    "        List of label names.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    DataFrame containing the concatenation of X and Y in a human readable format.\n",
    "    \"\"\"\n",
    "    # Concat labels to the original instances.\n",
    "    orig = np.concatenate([X, Y.reshape(-1, 1)], axis=1)\n",
    "\n",
    "    # Define new feature names and category map by including the label.\n",
    "    feature_names = feature_names + [\"Label\"]\n",
    "    category_map.update({feature_names.index(\"Label\"): [target_names[i] for i in np.unique(Y)]})\n",
    "\n",
    "    # Replace label encodings with strings.\n",
    "    df = pd.DataFrame(\n",
    "        apply_category_mapping(orig, category_map),\n",
    "        columns=feature_names\n",
    "    )\n",
    "    \n",
    "    dfs = []\n",
    "    for l in np.unique(Y):\n",
    "        dfs.append(df[df['Label'] == target_names[l]])\n",
    "        \n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18039f2a",
   "metadata": {},
   "source": [
    "### Load Adult Census dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca98d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch adult datasets\n",
    "adult = fetch_adult()\n",
    "\n",
    "# split dataset into train-test-validation\n",
    "X, Y = adult.data, adult.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=1000, test_size=2000, random_state=13)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, random_state=13)\n",
    "\n",
    "# identify numerical and categorical columns\n",
    "categorical_ids = list(adult.category_map.keys())\n",
    "numerical_ids = [i for i in range(len(adult.feature_names)) if i not in adult.category_map]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c838ea3",
   "metadata": {},
   "source": [
    "### Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebbfbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preprocessor\n",
    "num_transf = StandardScaler()\n",
    "cat_transf = OneHotEncoder(\n",
    "    categories=[range(len(x)) for x in adult.category_map.values()],\n",
    "    handle_unknown='ignore'\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transf, categorical_ids),\n",
    "        ('num', num_transf, numerical_ids)\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")\n",
    "\n",
    "# fit data perprocessor\n",
    "preprocessor = preprocessor.fit(adult.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c025f",
   "metadata": {},
   "source": [
    "### Prototypes selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "061d5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prototypes = 20\n",
    "grid_size = 25\n",
    "quantiles = (0., .4)\n",
    "\n",
    "# search for the best epslion-radius value\n",
    "eps = cv_protoselect_euclidean(refset=(X_train, Y_train),\n",
    "                               protoset=(X_train,),\n",
    "                               valset=(X_val, Y_val),\n",
    "                               num_prototypes=num_prototypes,\n",
    "                               quantiles=quantiles,\n",
    "                               grid_size=grid_size,\n",
    "                               preprocess_fn=preprocessor.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbd86380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prototypes\n",
    "explainer = ProtoSelect(kernel_distance=EuclideanDistance(), eps=eps, preprocess_fn=preprocessor.transform)\n",
    "explainer = explainer.fit(X=X_train, X_labels=Y_train, Y=X_train)\n",
    "explanation = explainer.explain(num_prototypes=num_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c93978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>Private</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1055</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>?</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63</td>\n",
       "      <td>Private</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>16</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Never-Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Latin-America</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>High School grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age         Workclass         Education Marital Status    Occupation  \\\n",
       "0   30           Private  High School grad  Never-Married   Blue-Collar   \n",
       "1   31           Private  High School grad  Never-Married       Service   \n",
       "2   44           Private  High School grad      Separated         Admin   \n",
       "3   56           Private           Dropout      Separated   Blue-Collar   \n",
       "4   23           Private  High School grad  Never-Married         Admin   \n",
       "5   63  Self-emp-not-inc           Dropout        Married  White-Collar   \n",
       "6   35           Private           Dropout  Never-Married       Service   \n",
       "7   28       Federal-gov         Bachelors  Never-Married  Professional   \n",
       "8   40         State-gov           Dropout      Separated   Blue-Collar   \n",
       "9   21                 ?  High School grad  Never-Married             ?   \n",
       "10  40         Local-gov  High School grad        Married       Service   \n",
       "11  63           Private           Dropout        Widowed       Service   \n",
       "12  31           Private  High School grad  Never-Married       Service   \n",
       "13  39           Private           Dropout  Never-Married       Service   \n",
       "14  28         State-gov         Bachelors        Married  Professional   \n",
       "15  42         Local-gov  High School grad      Separated   Blue-Collar   \n",
       "16  28           Private           Dropout      Separated       Service   \n",
       "17  45         Local-gov           Masters        Married  White-Collar   \n",
       "18  53           Private  High School grad        Married  White-Collar   \n",
       "19  45  Self-emp-not-inc         Doctorate        Married  Professional   \n",
       "\n",
       "     Relationship   Race     Sex Capital Gain Capital Loss Hours per week  \\\n",
       "0   Not-in-family  White    Male            0            0             40   \n",
       "1       Own-child  White  Female            0            0             30   \n",
       "2       Unmarried  White  Female            0            0             40   \n",
       "3   Not-in-family  White  Female            0            0             40   \n",
       "4       Own-child  White    Male         1055            0             20   \n",
       "5         Husband  White    Male            0            0             15   \n",
       "6       Unmarried  Black  Female            0            0             38   \n",
       "7   Not-in-family  White  Female            0            0             40   \n",
       "8   Not-in-family  Black    Male            0            0             40   \n",
       "9       Own-child  White  Female            0            0             35   \n",
       "10        Husband  Other    Male            0            0             40   \n",
       "11  Not-in-family  White  Female            0            0             31   \n",
       "12      Own-child  White    Male            0         1721             16   \n",
       "13      Own-child  White    Male            0            0             40   \n",
       "14        Husband  White    Male            0            0             20   \n",
       "15  Not-in-family  White    Male            0            0             65   \n",
       "16      Unmarried  White  Female            0            0             50   \n",
       "17        Husband  White    Male         7688            0             50   \n",
       "18        Husband  White    Male            0         1977             40   \n",
       "19        Husband  White    Male        15024            0             40   \n",
       "\n",
       "          Country  Label  \n",
       "0   United-States  <=50K  \n",
       "1   United-States  <=50K  \n",
       "2   United-States  <=50K  \n",
       "3   United-States  <=50K  \n",
       "4   United-States  <=50K  \n",
       "5   United-States  <=50K  \n",
       "6   United-States  <=50K  \n",
       "7   United-States  <=50K  \n",
       "8   United-States  <=50K  \n",
       "9   United-States  <=50K  \n",
       "10              ?  <=50K  \n",
       "11  United-States  <=50K  \n",
       "12  United-States  <=50K  \n",
       "13  Latin-America  <=50K  \n",
       "14  United-States  <=50K  \n",
       "15  United-States  <=50K  \n",
       "16  United-States  <=50K  \n",
       "17  United-States   >50K  \n",
       "18  United-States   >50K  \n",
       "19  United-States   >50K  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protos = explanation.data['prototypes']\n",
    "protos_labels = explanation.data['prototypes_labels']\n",
    "\n",
    "# display the prototypes in a human readable format\n",
    "display_table(X=protos, Y=protos_labels, feature_names=adult.feature_names, category_map=adult.category_map, target_names=adult.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb38b1f",
   "metadata": {},
   "source": [
    "By inspecting the prototypes, we can observe that features like `Education` and `Marital Status` can reveal some patterns. People with lower education level (e.g., `High School grad`, `Dropout` etc.) and who don’t have a partner (e.g., `Never-Married`, `Separated`, `Widowed` etc.) tend to be classified as $\\leq 50K$. On the other hand, we have people that have a higher education level (e.g., `Bachelors`, `Masters`, `Doctorate`)  and whom have a partner (e.g., `Married`) that are classified as $>50K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372e545",
   "metadata": {},
   "source": [
    "### Train 1-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad18e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 1-knn classifier using the selected prototypes\n",
    "knn_proto = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_proto = knn_proto.fit(X=preprocessor.transform(protos), y=protos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02dadc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    rand_idx = np.random.choice(len(X_train), size=num_prototypes, replace=False)\n",
    "    rands, rands_labels = X_train[rand_idx], Y_train[rand_idx]\n",
    "    \n",
    "    knn_rand = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_rand = knn_rand.fit(X=preprocessor.transform(rands), y=rands_labels)\n",
    "    scores.append(knn_rand.score(preprocessor.transform(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f550bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtoSelect 1-KNN accuracy: 0.816\n",
      "Random 1-KNN mean accuracy: 0.723\n"
     ]
    }
   ],
   "source": [
    "# compare the scores obtained by ProtoSelect vs random choice\n",
    "print('ProtoSelect 1-KNN accuracy: %.3f' % (knn_proto.score(preprocessor.transform(X_test), Y_test)))\n",
    "print('Random 1-KNN mean accuracy: %.3f' % (np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20783993",
   "metadata": {},
   "source": [
    "We can observe that `ProtoSelect` chooses more representative instances than a naive random selection. The gap between the two should narrow as more prototypes are requested but that can complicate the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80a2e0",
   "metadata": {},
   "source": [
    "## Image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe16d50",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dfc7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = X_train.astype(np.float32) / 255.\n",
    "X_test = X_test.astype(np.float32) / 255.\n",
    "\n",
    "# split the test into test-validation\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, train_size=1000, test_size=1000, random_state=13)\n",
    "\n",
    "# subsample the datasets\n",
    "np.random.seed(13)\n",
    "train_idx = np.random.choice(len(X_train), size=1000, replace=False)\n",
    "X_train, Y_train = X_train[train_idx], Y_train[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103d75b",
   "metadata": {},
   "source": [
    "### Preprocessing function\n",
    "\n",
    "For CIFAR10 we will use a hidden layer output from a pretrained network as our feature representation of the input images. The network was traiend on the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3437ae4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-05 13:54:52--  https://storage.googleapis.com/seldon-models/alibi/model_cifar10/checkpoint\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.169.16, 142.250.178.16, 216.58.212.208, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.169.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81 [application/octet-stream]\n",
      "Saving to: ‘model_cifar10/checkpoint’\n",
      "\n",
      "checkpoint          100%[===================>]      81  --.-KB/s    in 0s      \n",
      "\n",
      "2022-04-05 13:54:52 (10.1 MB/s) - ‘model_cifar10/checkpoint’ saved [81/81]\n",
      "\n",
      "--2022-04-05 13:54:53--  https://storage.googleapis.com/seldon-models/alibi/model_cifar10/cifar10.ckpt.data-00000-of-00001\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.213.16, 172.217.169.80, 172.217.169.48, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.213.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2218891 (2.1M) [application/octet-stream]\n",
      "Saving to: ‘model_cifar10/cifar10.ckpt.data-00000-of-00001’\n",
      "\n",
      "cifar10.ckpt.data-0 100%[===================>]   2.12M  6.01MB/s    in 0.4s    \n",
      "\n",
      "2022-04-05 13:54:53 (6.01 MB/s) - ‘model_cifar10/cifar10.ckpt.data-00000-of-00001’ saved [2218891/2218891]\n",
      "\n",
      "--2022-04-05 13:54:53--  https://storage.googleapis.com/seldon-models/alibi/model_cifar10/cifar10.ckpt.index\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.213.16, 172.217.169.80, 172.217.169.48, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.213.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2828 (2.8K) [application/octet-stream]\n",
      "Saving to: ‘model_cifar10/cifar10.ckpt.index’\n",
      "\n",
      "cifar10.ckpt.index  100%[===================>]   2.76K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-04-05 13:54:54 (30.5 MB/s) - ‘model_cifar10/cifar10.ckpt.index’ saved [2828/2828]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download weights\n",
    "!wget https://storage.googleapis.com/seldon-models/alibi/model_cifar10/checkpoint -P model_cifar10\n",
    "!wget https://storage.googleapis.com/seldon-models/alibi/model_cifar10/cifar10.ckpt.data-00000-of-00001 -P model_cifar10\n",
    "!wget https://storage.googleapis.com/seldon-models/alibi/model_cifar10/cifar10.ckpt.index -P model_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95dc0b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8cb3fce130>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the network to be used.\n",
    "model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(32, 32, 3)),\n",
    "        layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, kernel_initializer='he_uniform', name='feature_layer'),\n",
    "        layers.ReLU(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10)\n",
    "])\n",
    "\n",
    "# load the weights\n",
    "model.load_weights('model_cifar10/cifar10.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7a658f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "No algorithm worked! [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5cb0d70b744b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[0;32m--> 420\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     name=None):\n\u001b[0;32m-> 1012\u001b[0;31m   return convolution_internal(\n\u001b[0m\u001b[1;32m   1013\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m       return op(\n\u001b[0m\u001b[1;32m   1143\u001b[0m           \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2594\u001b[0m     \u001b[0;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m     \u001b[0;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2596\u001b[0;31m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[1;32m   2597\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    930\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alibi/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: No algorithm worked! [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "np.mean(np.argmax(model(X_test), axis=-1) == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405da080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibi",
   "language": "python",
   "name": "alibi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
